
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="transformers_docs">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/transformers_docs/1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/">
      
      
        <link rel="prev" href="../installation/">
      
      
        <link rel="next" href="../../2-%E6%95%99%E7%A8%8B/accelerate/">
      
      
      <link rel="icon" href="../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>Quicktour - Transformers 文档</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="Transformers 文档" class="md-header__button md-logo" aria-label="Transformers 文档" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Transformers 文档
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Quicktour
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/transformers_docs" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Transformers 文档" class="md-nav__button md-logo" aria-label="Transformers 文档" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    Transformers 文档
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/transformers_docs" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../autoclass_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autoclass tutorial
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../awesome-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Awesome projects built with Transformers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../big_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Big models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../debugging/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Debugging
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../hpo_train/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hpo train
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../llm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llm tutorial
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../model_sharing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model sharing
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Peft
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../perf_hardware/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Perf hardware
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../perf_torch_compile/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Perf torch compile
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../performance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Performance
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../run_scripts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Run scripts
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../tf_xla/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tf xla
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer_summary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tokenizer summary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_16" checked>
        
          
          <label class="md-nav__link" for="__nav_16" id="__nav_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    1 开始使用
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_16_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_16">
            <span class="md-nav__icon md-icon"></span>
            1 开始使用
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Index
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Quicktour
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Quicktour
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Pipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pipeline_1" class="md-nav__link">
    <span class="md-ellipsis">
      在 pipeline 中使用另一个模型和分词器
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autoclass" class="md-nav__link">
    <span class="md-ellipsis">
      AutoClass
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AutoClass">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autotokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      AutoTokenizer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#automodel" class="md-nav__link">
    <span class="md-ellipsis">
      AutoModel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      保存模型
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      自定义模型构建
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer-pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer - PyTorch 优化训练循环
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow" class="md-nav__link">
    <span class="md-ellipsis">
      使用 Tensorflow 训练
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      接下来做什么?
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../2-%E6%95%99%E7%A8%8B/accelerate/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    2 教程
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    3 开发者指南
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    4 概念指南
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../main_classes/deepspeed/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Main classes
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pipeline" class="md-nav__link">
    <span class="md-ellipsis">
      Pipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pipeline_1" class="md-nav__link">
    <span class="md-ellipsis">
      在 pipeline 中使用另一个模型和分词器
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#autoclass" class="md-nav__link">
    <span class="md-ellipsis">
      AutoClass
    </span>
  </a>
  
    <nav class="md-nav" aria-label="AutoClass">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autotokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      AutoTokenizer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#automodel" class="md-nav__link">
    <span class="md-ellipsis">
      AutoModel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      保存模型
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      自定义模型构建
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer-pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer - PyTorch 优化训练循环
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflow" class="md-nav__link">
    <span class="md-ellipsis">
      使用 Tensorflow 训练
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      接下来做什么?
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/transformers_docs/tree/main/docs/1-开始使用/quicktour.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/transformers_docs/tree/main/docs/1-开始使用/quicktour.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

⚠️ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

<h1 id="_1">快速上手<a class="headerlink" href="#_1" title="Permanent link">⚓︎</a></h1>
<p>[[open-in-colab]]</p>
<p>快来使用 🤗 Transformers 吧！无论你是开发人员还是日常用户，这篇快速上手教程都将帮助你入门并且向你展示如何使用 [<code>pipeline</code>] 进行推理，使用 <a href="./model_doc/auto">AutoClass</a> 加载一个预训练模型和预处理器，以及使用 PyTorch 或 TensorFlow 快速训练一个模型。如果你是一个初学者，我们建议你接下来查看我们的教程或者<a href="https://huggingface.co/course/chapter1/1">课程</a>，来更深入地了解在这里介绍到的概念。</p>
<p>在开始之前，确保你已经安装了所有必要的库：</p>
<div class="highlight"><pre><span></span><code>!pip<span class="w"> </span>install<span class="w"> </span>transformers<span class="w"> </span>datasets
</code></pre></div>
<p>你还需要安装喜欢的机器学习框架：</p>
<p><frameworkcontent>
<pt></p>
<p><div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>torch
</code></pre></div>
</pt>
<tf></p>
<p><div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>tensorflow
</code></pre></div>
</tf>
</frameworkcontent></p>
<h2 id="pipeline">Pipeline<a class="headerlink" href="#pipeline" title="Permanent link">⚓︎</a></h2>
<p><Youtube id="tiZFewofSLM"/></p>
<p>使用 [<code>pipeline</code>] 是利用预训练模型进行推理的最简单的方式。你能够将 [<code>pipeline</code>] 开箱即用地用于跨不同模态的多种任务。来看看它支持的任务列表：</p>
<table>
<thead>
<tr>
<th><strong>任务</strong></th>
<th><strong>描述</strong></th>
<th><strong>模态</strong></th>
<th><strong>Pipeline</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>文本分类</td>
<td>为给定的文本序列分配一个标签</td>
<td>NLP</td>
<td>pipeline(task="sentiment-analysis")</td>
</tr>
<tr>
<td>文本生成</td>
<td>根据给定的提示生成文本</td>
<td>NLP</td>
<td>pipeline(task="text-generation")</td>
</tr>
<tr>
<td>命名实体识别</td>
<td>为序列里的每个 token 分配一个标签（人, 组织, 地址等等）</td>
<td>NLP</td>
<td>pipeline(task="ner")</td>
</tr>
<tr>
<td>问答系统</td>
<td>通过给定的上下文和问题, 在文本中提取答案</td>
<td>NLP</td>
<td>pipeline(task="question-answering")</td>
</tr>
<tr>
<td>掩盖填充</td>
<td>预测出正确的在序列中被掩盖的token</td>
<td>NLP</td>
<td>pipeline(task="fill-mask")</td>
</tr>
<tr>
<td>文本摘要</td>
<td>为文本序列或文档生成总结</td>
<td>NLP</td>
<td>pipeline(task="summarization")</td>
</tr>
<tr>
<td>文本翻译</td>
<td>将文本从一种语言翻译为另一种语言</td>
<td>NLP</td>
<td>pipeline(task="translation")</td>
</tr>
<tr>
<td>图像分类</td>
<td>为图像分配一个标签</td>
<td>Computer vision</td>
<td>pipeline(task="image-classification")</td>
</tr>
<tr>
<td>图像分割</td>
<td>为图像中每个独立的像素分配标签（支持语义、全景和实例分割）</td>
<td>Computer vision</td>
<td>pipeline(task="image-segmentation")</td>
</tr>
<tr>
<td>目标检测</td>
<td>预测图像中目标对象的边界框和类别</td>
<td>Computer vision</td>
<td>pipeline(task="object-detection")</td>
</tr>
<tr>
<td>音频分类</td>
<td>给音频文件分配一个标签</td>
<td>Audio</td>
<td>pipeline(task="audio-classification")</td>
</tr>
<tr>
<td>自动语音识别</td>
<td>将音频文件中的语音提取为文本</td>
<td>Audio</td>
<td>pipeline(task="automatic-speech-recognition")</td>
</tr>
<tr>
<td>视觉问答</td>
<td>给定一个图像和一个问题，正确地回答有关图像的问题</td>
<td>Multimodal</td>
<td>pipeline(task="vqa")</td>
</tr>
</tbody>
</table>
<p>创建一个 [<code>pipeline</code>] 实例并且指定你想要将它用于的任务，就可以开始了。你可以将 [<code>pipeline</code>] 用于任何一个上面提到的任务，如果想知道支持的任务的完整列表，可以查阅 <a href="./main_classes/pipelines">pipeline API 参考</a>。不过, 在这篇教程中，你将把 [<code>pipeline</code>] 用在一个情感分析示例上：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;sentiment-analysis&quot;</span><span class="p">)</span>
</code></pre></div>
<p>[<code>pipeline</code>] 会下载并缓存一个用于情感分析的默认的<a href="https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english">预训练模型</a>和分词器。现在你可以在目标文本上使用 <code>classifier</code> 了：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span><span class="p">)</span>
<span class="p">[{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;POSITIVE&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9998</span><span class="p">}]</span>
</code></pre></div>
<p>如果你有不止一个输入，可以把所有输入放入一个列表然后传给[<code>pipeline</code>]，它将会返回一个字典列表：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">results</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">([</span><span class="s2">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span><span class="p">,</span> <span class="s2">&quot;We hope you don&#39;t hate it.&quot;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
<span class="o">...</span>     <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;label: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, with score: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s1">&#39;score&#39;</span><span class="p">],</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">label</span><span class="p">:</span> <span class="n">POSITIVE</span><span class="p">,</span> <span class="k">with</span> <span class="n">score</span><span class="p">:</span> <span class="mf">0.9998</span>
<span class="n">label</span><span class="p">:</span> <span class="n">NEGATIVE</span><span class="p">,</span> <span class="k">with</span> <span class="n">score</span><span class="p">:</span> <span class="mf">0.5309</span>
</code></pre></div>
<p>[<code>pipeline</code>] 也可以为任何你喜欢的任务遍历整个数据集。在下面这个示例中，让我们选择自动语音识别作为我们的任务：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">speech_recognizer</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;automatic-speech-recognition&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;facebook/wav2vec2-base-960h&quot;</span><span class="p">)</span>
</code></pre></div>
<p>加载一个你想遍历的音频数据集（查阅 🤗 Datasets <a href="https://huggingface.co/docs/datasets/quickstart#audio">快速开始</a> 获得更多信息）。比如，加载 <a href="https://huggingface.co/datasets/PolyAI/minds14">MInDS-14</a> 数据集：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">Audio</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;PolyAI/minds14&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;en-US&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>  <span class="c1"># doctest: +IGNORE_RESULT</span>
</code></pre></div>
<p>你需要确保数据集中的音频的采样率与 <a href="https://huggingface.co/facebook/wav2vec2-base-960h"><code>facebook/wav2vec2-base-960h</code></a> 训练用到的音频的采样率一致：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="n">Audio</span><span class="p">(</span><span class="n">sampling_rate</span><span class="o">=</span><span class="n">speech_recognizer</span><span class="o">.</span><span class="n">feature_extractor</span><span class="o">.</span><span class="n">sampling_rate</span><span class="p">))</span>
</code></pre></div>
<p>当调用 <code>"audio"</code> 列时, 音频文件将会自动加载并重采样。
从前四个样本中提取原始波形数组，将它作为列表传给 pipeline：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">speech_recognizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[:</span><span class="mi">4</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">([</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">result</span><span class="p">])</span>
<span class="p">[</span><span class="s1">&#39;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#39;</span><span class="p">,</span> <span class="s2">&quot;FODING HOW I&#39;D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span><span class="p">,</span> <span class="s2">&quot;I I&#39;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#39;M NOT SEEING THE OPTION TO DO IT ON THE AP SO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I&#39;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span><span class="p">,</span> <span class="s1">&#39;HOW DO I THURN A JOIN A COUNT&#39;</span><span class="p">]</span>
</code></pre></div>
<p>对于输入非常庞大的大型数据集（比如语音或视觉），你会想到使用一个生成器，而不是一个将所有输入都加载进内存的列表。查阅 <a href="./main_classes/pipelines">pipeline API 参考</a> 来获取更多信息。</p>
<h3 id="pipeline_1">在 pipeline 中使用另一个模型和分词器<a class="headerlink" href="#pipeline_1" title="Permanent link">⚓︎</a></h3>
<p>[<code>pipeline</code>] 可以容纳 <a href="https://huggingface.co/models">Hub</a> 中的任何模型，这让 [<code>pipeline</code>] 更容易适用于其他用例。比如，你想要一个能够处理法语文本的模型，就可以使用 Hub 上的标记来筛选出合适的模型。靠前的筛选结果会返回一个为情感分析微调的多语言的 <a href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment">BERT 模型</a>，你可以将它用于法语文本：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
</code></pre></div>
<p><frameworkcontent>
<pt>
使用 [<code>AutoModelForSequenceClassification</code>] 和 [<code>AutoTokenizer</code>] 来加载预训练模型和它关联的分词器（更多信息可以参考下一节的 <code>AutoClass</code>）：</p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</code></pre></div>
</pt>
<tf>
使用 [<code>TFAutoModelForSequenceClassification</code>] 和 [<code>AutoTokenizer</code>] 来加载预训练模型和它关联的分词器（更多信息可以参考下一节的 <code>TFAutoClass</code>）：</p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TFAutoModelForSequenceClassification</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">TFAutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</code></pre></div>
</tf>
</frameworkcontent></p>
<p>在 [<code>pipeline</code>] 中指定模型和分词器，现在你就可以在法语文本上使用 <code>classifier</code> 了：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;sentiment-analysis&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">classifier</span><span class="p">(</span><span class="s2">&quot;Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.&quot;</span><span class="p">)</span>
<span class="p">[{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;5 stars&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.7273</span><span class="p">}]</span>
</code></pre></div>
<p>如果你没有找到适合你的模型，就需要在你的数据上微调一个预训练模型了。查看 <a href="./training">微调教程</a> 来学习怎样进行微调。最后，微调完模型后，考虑一下在 Hub 上与社区 <a href="./model_sharing">分享</a> 这个模型，把机器学习普及到每一个人! 🤗</p>
<h2 id="autoclass">AutoClass<a class="headerlink" href="#autoclass" title="Permanent link">⚓︎</a></h2>
<p><Youtube id="AhChOFRegn4"/></p>
<p>在幕后，是由 [<code>AutoModelForSequenceClassification</code>] 和 [<code>AutoTokenizer</code>] 一起支持你在上面用到的 [<code>pipeline</code>]。<a href="./model_doc/auto">AutoClass</a> 是一个能够通过预训练模型的名称或路径自动查找其架构的快捷方式。你只需要为你的任务选择合适的 <code>AutoClass</code> 和它关联的预处理类。</p>
<p>让我们回过头来看上一节的示例，看看怎样使用 <code>AutoClass</code> 来重现使用 [<code>pipeline</code>] 的结果。</p>
<h3 id="autotokenizer">AutoTokenizer<a class="headerlink" href="#autotokenizer" title="Permanent link">⚓︎</a></h3>
<p>分词器负责预处理文本，将文本转换为用于输入模型的数字数组。有多个用来管理分词过程的规则，包括如何拆分单词和在什么样的级别上拆分单词（在 <a href="./tokenizer_summary">分词器总结</a> 学习更多关于分词的信息）。要记住最重要的是你需要实例化的分词器要与模型的名称相同, 来确保和模型训练时使用相同的分词规则。</p>
<p>使用 [<code>AutoTokenizer</code>] 加载一个分词器:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</code></pre></div>
<p>将文本传入分词器：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span>
<span class="p">{</span><span class="s1">&#39;input_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">101</span><span class="p">,</span> <span class="mi">11312</span><span class="p">,</span> <span class="mi">10320</span><span class="p">,</span> <span class="mi">12495</span><span class="p">,</span> <span class="mi">19308</span><span class="p">,</span> <span class="mi">10114</span><span class="p">,</span> <span class="mi">11391</span><span class="p">,</span> <span class="mi">10855</span><span class="p">,</span> <span class="mi">10103</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">58263</span><span class="p">,</span> <span class="mi">13299</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="mi">102</span><span class="p">],</span>
 <span class="s1">&#39;token_type_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
 <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]}</span>
</code></pre></div>
<p>分词器返回了含有如下内容的字典:</p>
<ul>
<li><a href="./glossary#input-ids">input_ids</a>：用数字表示的 token。</li>
<li><a href=".glossary#attention-mask">attention_mask</a>：应该关注哪些 token 的指示。</li>
</ul>
<p>分词器也可以接受列表作为输入，并填充和截断文本，返回具有统一长度的批次：</p>
<p><frameworkcontent>
<pt></p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_batch</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
<span class="o">...</span>     <span class="p">[</span><span class="s2">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span><span class="p">,</span> <span class="s2">&quot;We hope you don&#39;t hate it.&quot;</span><span class="p">],</span>
<span class="o">...</span>     <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
<span class="o">...</span> <span class="p">)</span>
</code></pre></div>
</pt>
<tf></p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">tf_batch</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
<span class="o">...</span>     <span class="p">[</span><span class="s2">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span><span class="p">,</span> <span class="s2">&quot;We hope you don&#39;t hate it.&quot;</span><span class="p">],</span>
<span class="o">...</span>     <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;tf&quot;</span><span class="p">,</span>
<span class="o">...</span> <span class="p">)</span>
</code></pre></div>
</tf>
</frameworkcontent></p>
<p><Tip></p>
<p>查阅<a href="./preprocessing">预处理</a>教程来获得有关分词的更详细的信息，以及如何使用 [<code>AutoFeatureExtractor</code>] 和 [<code>AutoProcessor</code>] 来处理图像，音频，还有多模式输入。</p>
<p></Tip></p>
<h3 id="automodel">AutoModel<a class="headerlink" href="#automodel" title="Permanent link">⚓︎</a></h3>
<p><frameworkcontent>
<pt>
🤗 Transformers 提供了一种简单统一的方式来加载预训练的实例. 这表示你可以像加载 [<code>AutoTokenizer</code>] 一样加载 [<code>AutoModel</code>]。唯一不同的地方是为你的任务选择正确的[<code>AutoModel</code>]。对于文本（或序列）分类，你应该加载[<code>AutoModelForSequenceClassification</code>]：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pt_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</code></pre></div>
<p><Tip></p>
<p>通过 <a href="./task_summary">任务摘要</a> 查找 [<code>AutoModel</code>] 支持的任务.</p>
<p></Tip></p>
<p>现在可以把预处理好的输入批次直接送进模型。你只需要通过 <code>**</code> 来解包字典:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_outputs</span> <span class="o">=</span> <span class="n">pt_model</span><span class="p">(</span><span class="o">**</span><span class="n">pt_batch</span><span class="p">)</span>
</code></pre></div>
<p>模型在 <code>logits</code> 属性输出最终的激活结果. 在 <code>logits</code> 上应用 softmax 函数来查询概率:</p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">pt_predictions</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pt_outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">pt_predictions</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mf">0.0021</span><span class="p">,</span> <span class="mf">0.0018</span><span class="p">,</span> <span class="mf">0.0115</span><span class="p">,</span> <span class="mf">0.2121</span><span class="p">,</span> <span class="mf">0.7725</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.2084</span><span class="p">,</span> <span class="mf">0.1826</span><span class="p">,</span> <span class="mf">0.1969</span><span class="p">,</span> <span class="mf">0.1755</span><span class="p">,</span> <span class="mf">0.2365</span><span class="p">]],</span> <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">SoftmaxBackward0</span><span class="o">&gt;</span><span class="p">)</span>
</code></pre></div>
</pt>
<tf>
🤗 Transformers 提供了一种简单统一的方式来加载预训练的实例。这表示你可以像加载 [<code>AutoTokenizer</code>] 一样加载 [<code>TFAutoModel</code>]。唯一不同的地方是为你的任务选择正确的 [<code>TFAutoModel</code>]，对于文本（或序列）分类，你应该加载 [<code>TFAutoModelForSequenceClassification</code>]：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TFAutoModelForSequenceClassification</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tf_model</span> <span class="o">=</span> <span class="n">TFAutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
</code></pre></div>
<p><Tip></p>
<p>通过 <a href="./task_summary">任务摘要</a> 查找 [<code>AutoModel</code>] 支持的任务.</p>
<p></Tip></p>
<p>现在通过直接将字典的键传给张量，将预处理的输入批次传给模型。</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">tf_outputs</span> <span class="o">=</span> <span class="n">tf_model</span><span class="p">(</span><span class="n">tf_batch</span><span class="p">)</span>
</code></pre></div>
<p>模型在 <code>logits</code> 属性输出最终的激活结果。在 <code>logits</code> 上应用softmax函数来查询概率：</p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">tf_predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf_outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tf_predictions</span>  <span class="c1"># doctest: +IGNORE_RESULT</span>
</code></pre></div>
</tf>
</frameworkcontent></p>
<p><Tip></p>
<p>所有 🤗 Transformers 模型（PyTorch 或 TensorFlow）在最终的激活函数（比如 softmax）<em>之前</em> 输出张量，
因为最终的激活函数常常与 loss 融合。模型的输出是特殊的数据类，所以它们的属性可以在 IDE 中被自动补全。模型的输出就像一个元组或字典（你可以通过整数、切片或字符串来索引它），在这种情况下，为 None 的属性会被忽略。</p>
<p></Tip></p>
<h3 id="_2">保存模型<a class="headerlink" href="#_2" title="Permanent link">⚓︎</a></h3>
<p><frameworkcontent>
<pt>
当你的模型微调完成，你就可以使用 [<code>PreTrainedModel.save_pretrained</code>] 把它和它的分词器保存下来：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_save_directory</span> <span class="o">=</span> <span class="s2">&quot;./pt_save_pretrained&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">pt_save_directory</span><span class="p">)</span>  <span class="c1"># doctest: +IGNORE_RESULT</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pt_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">pt_save_directory</span><span class="p">)</span>
</code></pre></div>
<p>当你准备再次使用这个模型时，就可以使用 [<code>PreTrainedModel.from_pretrained</code>] 加载它了：</p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">pt_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./pt_save_pretrained&quot;</span><span class="p">)</span>
</code></pre></div>
</pt>
<tf>
当你的模型微调完成，你就可以使用 [<code>TFPreTrainedModel.save_pretrained</code>] 把它和它的分词器保存下来：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">tf_save_directory</span> <span class="o">=</span> <span class="s2">&quot;./tf_save_pretrained&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">tf_save_directory</span><span class="p">)</span>  <span class="c1"># doctest: +IGNORE_RESULT</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tf_model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">tf_save_directory</span><span class="p">)</span>
</code></pre></div>
<p>当你准备再次使用这个模型时，就可以使用 [<code>TFPreTrainedModel.from_pretrained</code>] 加载它了：</p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">tf_model</span> <span class="o">=</span> <span class="n">TFAutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./tf_save_pretrained&quot;</span><span class="p">)</span>
</code></pre></div>
</tf>
</frameworkcontent></p>
<p>🤗 Transformers 有一个特别酷的功能，它能够保存一个模型，并且将它加载为 PyTorch 或 TensorFlow 模型。<code>from_pt</code> 或 <code>from_tf</code> 参数可以将模型从一个框架转换为另一个框架：</p>
<p><frameworkcontent>
<pt></p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">tf_save_directory</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pt_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">tf_save_directory</span><span class="p">,</span> <span class="n">from_tf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
</pt>
<tf></p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TFAutoModel</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pt_save_directory</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tf_model</span> <span class="o">=</span> <span class="n">TFAutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pt_save_directory</span><span class="p">,</span> <span class="n">from_pt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
</tf>
</frameworkcontent></p>
<h2 id="_3">自定义模型构建<a class="headerlink" href="#_3" title="Permanent link">⚓︎</a></h2>
<p>你可以修改模型的配置类来改变模型的构建方式。配置指明了模型的属性，比如隐藏层或者注意力头的数量。当你从自定义的配置类初始化模型时，你就开始自定义模型构建了。模型属性是随机初始化的，你需要先训练模型，然后才能得到有意义的结果。</p>
<p>通过导入 [<code>AutoConfig</code>] 来开始，之后加载你想修改的预训练模型。在 [<code>AutoConfig.from_pretrained</code>] 中，你能够指定想要修改的属性，比如注意力头的数量：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoConfig</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">my_config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</code></pre></div>
<p><frameworkcontent>
<pt>
使用 [<code>AutoModel.from_config</code>] 根据你的自定义配置创建一个模型：</p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">my_model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">my_config</span><span class="p">)</span>
</code></pre></div>
</pt>
<tf>
使用 [<code>TFAutoModel.from_config</code>] 根据你的自定义配置创建一个模型：</p>
<p><div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TFAutoModel</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">my_model</span> <span class="o">=</span> <span class="n">TFAutoModel</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">my_config</span><span class="p">)</span>
</code></pre></div>
</tf>
</frameworkcontent></p>
<p>查阅 <a href="./create_a_model">创建一个自定义结构</a> 指南获取更多关于构建自定义配置的信息。</p>
<h2 id="trainer-pytorch">Trainer - PyTorch 优化训练循环<a class="headerlink" href="#trainer-pytorch" title="Permanent link">⚓︎</a></h2>
<p>所有的模型都是标准的 <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module"><code>torch.nn.Module</code></a>，所以你可以在任何典型的训练模型中使用它们。当你编写自己的训练循环时，🤗 Transformers 为 PyTorch 提供了一个 [<code>Trainer</code>] 类，它包含了基础的训练循环并且为诸如分布式训练，混合精度等特性增加了额外的功能。</p>
<p>取决于你的任务, 你通常可以传递以下的参数给 [<code>Trainer</code>]：</p>
<ol>
<li>[<code>PreTrainedModel</code>] 或者 <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module"><code>torch.nn.Module</code></a>：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">)</span>
</code></pre></div>
<ol>
<li>[<code>TrainingArguments</code>] 含有你可以修改的模型超参数，比如学习率，批次大小和训练时的迭代次数。如果你没有指定训练参数，那么它会使用默认值：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;path/to/save/folder/&quot;</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="o">...</span> <span class="p">)</span>
</code></pre></div>
<ol>
<li>一个预处理类，比如分词器，特征提取器或者处理器：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">)</span>
</code></pre></div>
<ol>
<li>加载一个数据集：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;rotten_tomatoes&quot;</span><span class="p">)</span>  <span class="c1"># doctest: +IGNORE_RESULT</span>
</code></pre></div>
<ol>
<li>创建一个给数据集分词的函数，并且使用 [<code>~datasets.Dataset.map</code>] 应用到整个数据集：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">tokenize_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="o">...</span>     <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_dataset</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<ol>
<li>用来从数据集中创建批次的 [<code>DataCollatorWithPadding</code>]：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorWithPadding</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorWithPadding</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
</code></pre></div>
<p>现在把所有的类传给 [<code>Trainer</code>]：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
<span class="o">...</span>     <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span>
<span class="o">...</span>     <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<span class="o">...</span>     <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
<span class="o">...</span> <span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
</code></pre></div>
<p>一切准备就绪后，调用 [<code>~Trainer.train</code>] 进行训练：</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># doctest: +SKIP</span>
</code></pre></div>
<p><Tip></p>
<p>对于像翻译或摘要这些使用序列到序列模型的任务，用 [<code>Seq2SeqTrainer</code>] 和 [<code>Seq2SeqTrainingArguments</code>] 来替代。</p>
<p></Tip></p>
<p>你可以通过子类化 [<code>Trainer</code>] 中的方法来自定义训练循环。这样你就可以自定义像损失函数，优化器和调度器这样的特性。查阅 [<code>Trainer</code>] 参考手册了解哪些方法能够被子类化。</p>
<p>另一个自定义训练循环的方式是通过<a href="./main_classes/callbacks">回调</a>。你可以使用回调来与其他库集成，查看训练循环来报告进度或提前结束训练。回调不会修改训练循环。如果想自定义损失函数等，就需要子类化 [<code>Trainer</code>] 了。</p>
<h2 id="tensorflow">使用 Tensorflow 训练<a class="headerlink" href="#tensorflow" title="Permanent link">⚓︎</a></h2>
<p>所有模型都是标准的 <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code>tf.keras.Model</code></a>，所以你可以通过 <a href="https://keras.io/">Keras</a> API 实现在 Tensorflow 中训练。🤗 Transformers 提供了 [<code>~TFPreTrainedModel.prepare_tf_dataset</code>] 方法来轻松地将数据集加载为 <code>tf.data.Dataset</code>，这样你就可以使用 Keras 的 <a href="https://keras.io/api/models/model_training_apis/#compile-method"><code>compile</code></a> 和 <a href="https://keras.io/api/models/model_training_apis/#fit-method"><code>fit</code></a> 方法马上开始训练。</p>
<ol>
<li>使用 [<code>TFPreTrainedModel</code>] 或者 <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model"><code>tf.keras.Model</code></a> 来开始：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TFAutoModelForSequenceClassification</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">TFAutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">)</span>
</code></pre></div>
<ol>
<li>一个预处理类，比如分词器，特征提取器或者处理器：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilbert-base-uncased&quot;</span><span class="p">)</span>
</code></pre></div>
<ol>
<li>创建一个给数据集分词的函数</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="k">def</span> <span class="nf">tokenize_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
<span class="o">...</span>     <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>  <span class="c1"># doctest: +SKIP</span>
</code></pre></div>
<ol>
<li>使用 [<code>~datasets.Dataset.map</code>] 将分词器应用到整个数据集，之后将数据集和分词器传给 [<code>~TFPreTrainedModel.prepare_tf_dataset</code>]。如果你需要的话，也可以在这里改变批次大小和是否打乱数据集：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_dataset</span><span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tf_dataset</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">prepare_tf_dataset</span><span class="p">(</span>
<span class="o">...</span>     <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span>
<span class="o">...</span> <span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
</code></pre></div>
<ol>
<li>一切准备就绪后，调用 <code>compile</code> 和 <code>fit</code> 开始训练：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="mf">3e-5</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>  <span class="c1"># doctest: +SKIP</span>
</code></pre></div>
<h2 id="_4">接下来做什么?<a class="headerlink" href="#_4" title="Permanent link">⚓︎</a></h2>
<p>现在你已经完成了 🤗 Transformers 的快速上手教程，来看看我们的指南并且学习如何做一些更具体的事情，比如写一个自定义模型，为某个任务微调一个模型以及如何使用脚本来训练模型。如果你有兴趣了解更多 🤗 Transformers 的核心章节，那就喝杯咖啡然后来看看我们的概念指南吧！</p>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../installation/" class="md-footer__link md-footer__link--prev" aria-label="上一页: Installation">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                Installation
              </div>
            </div>
          </a>
        
        
          
          <a href="../../2-%E6%95%99%E7%A8%8B/accelerate/" class="md-footer__link md-footer__link--next" aria-label="下一页: Accelerate">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                Accelerate
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="b站主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="个人主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>