{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-]","pipeline":["stemmer"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#generating-the-documentation","title":"Generating the documentation","text":"<p>To generate the documentation, you first have to build it. Several packages are necessary to build the doc,  you can install them with the following command, at the root of the code repository:</p> <pre><code>pip install -e \".[docs]\"\n</code></pre> <p>Then you need to install our special tool that builds the documentation:</p> <pre><code>pip install git+https://github.com/huggingface/doc-builder\n</code></pre> <p>NOTE</p> <p>You only need to generate the documentation to inspect it locally (if you're planning changes and want to check how they look before committing for instance). You don't have to commit the built documentation.</p>"},{"location":"#building-the-documentation","title":"Building the documentation","text":"<p>Once you have setup the <code>doc-builder</code> and additional packages, you can generate the documentation by  typing the following command:</p> <pre><code>doc-builder build transformers docs/source/en/ --build_dir ~/tmp/test-build\n</code></pre> <p>You can adapt the <code>--build_dir</code> to set any temporary folder that you prefer. This command will create it and generate the MDX files that will be rendered as the documentation on the main website. You can inspect them in your favorite Markdown editor.</p>"},{"location":"#previewing-the-documentation","title":"Previewing the documentation","text":"<p>To preview the docs, first install the <code>watchdog</code> module with:</p> <pre><code>pip install watchdog\n</code></pre> <p>Then run the following command:</p> <pre><code>doc-builder preview {package_name} {path_to_docs}\n</code></pre> <p>For example:</p> <pre><code>doc-builder preview transformers docs/source/en/\n</code></pre> <p>The docs will be viewable at http://localhost:3000. You can also preview the docs once you have opened a PR. You will see a bot add a comment to a link where the documentation with your changes lives.</p> <p>NOTE</p> <p>The <code>preview</code> command only works with existing doc files. When you add a completely new file, you need to update <code>_toctree.yml</code> &amp; restart <code>preview</code> command (<code>ctrl-c</code> to stop it &amp; call <code>doc-builder preview ...</code> again).</p>"},{"location":"#adding-a-new-element-to-the-navigation-bar","title":"Adding a new element to the navigation bar","text":"<p>Accepted files are Markdown (.md).</p> <p>Create a file with its extension and put it in the source directory. You can then link it to the toc-tree by putting the filename without the extension in the <code>_toctree.yml</code> file.</p>"},{"location":"#renaming-section-headers-and-moving-sections","title":"Renaming section headers and moving sections","text":"<p>It helps to keep the old links working when renaming the section header and/or moving sections from one document to another. This is because the old links are likely to be used in Issues, Forums, and Social media and it'd make for a much more superior user experience if users reading those months later could still easily navigate to the originally intended information.</p> <p>Therefore, we simply keep a little map of moved sections at the end of the document where the original section was. The key is to preserve the original anchor.</p> <p>So if you renamed a section from: \"Section A\" to \"Section B\", then you can add at the end of the file:</p> <p><pre><code>Sections that were moved:\n\n[ &lt;a href=\"#section-b\"&gt;Section A&lt;/a&gt;&lt;a id=\"section-a\"&gt;&lt;/a&gt; ]\n</code></pre> and of course, if you moved it to another file, then:</p> <pre><code>Sections that were moved:\n\n[ &lt;a href=\"../new-file#section-b\"&gt;Section A&lt;/a&gt;&lt;a id=\"section-a\"&gt;&lt;/a&gt; ]\n</code></pre> <p>Use the relative style to link to the new file so that the versioned docs continue to work.</p> <p>For an example of a rich moved section set please see the very end of the Trainer doc.</p>"},{"location":"#writing-documentation-specification","title":"Writing Documentation - Specification","text":"<p>The <code>huggingface/transformers</code> documentation follows the Google documentation style for docstrings, although we can write them directly in Markdown.</p>"},{"location":"#adding-a-new-tutorial","title":"Adding a new tutorial","text":"<p>Adding a new tutorial or section is done in two steps:</p> <ul> <li>Add a new file under <code>./source</code>. This file can either be ReStructuredText (.rst) or Markdown (.md).</li> <li>Link that file in <code>./source/_toctree.yml</code> on the correct toc-tree.</li> </ul> <p>Make sure to put your new file under the proper section. It's unlikely to go in the first section (Get Started), so depending on the intended targets (beginners, more advanced users, or researchers) it should go in sections two, three, or four.</p>"},{"location":"#translating","title":"Translating","text":"<p>When translating, refer to the guide at ./TRANSLATING.md.</p>"},{"location":"#adding-a-new-model","title":"Adding a new model","text":"<p>When adding a new model:</p> <ul> <li>Create a file <code>xxx.md</code> or under <code>./source/model_doc</code> (don't hesitate to copy an existing file as template).</li> <li>Link that file in <code>./source/_toctree.yml</code>.</li> <li>Write a short overview of the model:<ul> <li>Overview with paper &amp; authors</li> <li>Paper abstract</li> <li>Tips and tricks and how to use it best</li> </ul> </li> <li>Add the classes that should be linked in the model. This generally includes the configuration, the tokenizer, and   every model of that class (the base model, alongside models with additional heads), both in PyTorch and TensorFlow.   The order is generally:<ul> <li>Configuration</li> <li>Tokenizer</li> <li>PyTorch base model</li> <li>PyTorch head models</li> <li>TensorFlow base model</li> <li>TensorFlow head models</li> <li>Flax base model</li> <li>Flax head models</li> </ul> </li> </ul> <p>These classes should be added using our Markdown syntax. Usually as follows:</p> <pre><code>## XXXConfig\n\n[[autodoc]] XXXConfig\n</code></pre> <p>This will include every public method of the configuration that is documented. If for some reason you wish for a method not to be displayed in the documentation, you can do so by specifying which methods should be in the docs:</p> <pre><code>## XXXTokenizer\n\n[[autodoc]] XXXTokenizer\n    - build_inputs_with_special_tokens\n    - get_special_tokens_mask\n    - create_token_type_ids_from_sequences\n    - save_vocabulary\n</code></pre> <p>If you just want to add a method that is not documented (for instance magic methods like <code>__call__</code> are not documented by default) you can put the list of methods to add in a list that contains <code>all</code>:</p> <pre><code>## XXXTokenizer\n\n[[autodoc]] XXXTokenizer\n    - all\n    - __call__\n</code></pre>"},{"location":"#writing-source-documentation","title":"Writing source documentation","text":"<p>Values that should be put in <code>code</code> should either be surrounded by backticks: `like so`. Note that argument names and objects like True, None, or any strings should usually be put in <code>code</code>.</p> <p>When mentioning a class, function, or method, it is recommended to use our syntax for internal links so that our tool adds a link to its documentation with this syntax: [`XXXClass`] or [`function`]. This requires the class or  function to be in the main package.</p> <p>If you want to create a link to some internal class or function, you need to provide its path. For instance: [`utils.ModelOutput`]. This will be converted into a link with <code>utils.ModelOutput</code> in the description. To get rid of the path and only keep the name of the object you are linking to in the description, add a ~: [`~utils.ModelOutput`] will generate a link with <code>ModelOutput</code> in the description.</p> <p>The same works for methods so you can either use [`XXXClass.method`] or [~`XXXClass.method`].</p>"},{"location":"#defining-arguments-in-a-method","title":"Defining arguments in a method","text":"<p>Arguments should be defined with the <code>Args:</code> (or <code>Arguments:</code> or <code>Parameters:</code>) prefix, followed by a line return and an indentation. The argument should be followed by its type, with its shape if it is a tensor, a colon, and its description:</p> <pre><code>    Args:\n        n_layers (`int`): The number of layers of the model.\n</code></pre> <p>If the description is too long to fit in one line, another indentation is necessary before writing the description after the argument.</p> <p>Here's an example showcasing everything so far:</p> <pre><code>    Args:\n        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n            Indices of input sequence tokens in the vocabulary.\n\n            Indices can be obtained using [`AlbertTokenizer`]. See [`~PreTrainedTokenizer.encode`] and\n            [`~PreTrainedTokenizer.__call__`] for details.\n\n            [What are input IDs?](../glossary#input-ids)\n</code></pre> <p>For optional arguments or arguments with defaults we follow the following syntax: imagine we have a function with the following signature:</p> <pre><code>def my_function(x: str = None, a: float = 1):\n</code></pre> <p>then its documentation should look like this:</p> <pre><code>    Args:\n        x (`str`, *optional*):\n            This argument controls ...\n        a (`float`, *optional*, defaults to 1):\n            This argument is used to ...\n</code></pre> <p>Note that we always omit the \"defaults to `None`\" when None is the default for any argument. Also note that even if the first line describing your argument type and its default gets long, you can't break it on several lines. You can however write as many lines as you want in the indented description (see the example above with <code>input_ids</code>).</p>"},{"location":"#writing-a-multi-line-code-block","title":"Writing a multi-line code block","text":"<p>Multi-line code blocks can be useful for displaying examples. They are done between two lines of three backticks as usual in Markdown:</p> <pre><code>```\n# first line of code\n# second line\n# etc\n```\n</code></pre> <p>We follow the doctest syntax for the examples to automatically test the results to stay consistent with the library.</p>"},{"location":"#writing-a-return-block","title":"Writing a return block","text":"<p>The return block should be introduced with the <code>Returns:</code> prefix, followed by a line return and an indentation. The first line should be the type of the return, followed by a line return. No need to indent further for the elements building the return.</p> <p>Here's an example of a single value return:</p> <pre><code>    Returns:\n        `List[int]`: A list of integers in the range [0, 1] --- 1 for a special token, 0 for a sequence token.\n</code></pre> <p>Here's an example of a tuple return, comprising several objects:</p> <pre><code>    Returns:\n        `tuple(torch.FloatTensor)` comprising various elements depending on the configuration ([`BertConfig`]) and inputs:\n        - ** loss** (*optional*, returned when `masked_lm_labels` is provided) `torch.FloatTensor` of shape `(1,)` --\n          Total loss is the sum of the masked language modeling loss and the next sequence prediction (classification) loss.\n        - **prediction_scores** (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`) --\n          Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n</code></pre>"},{"location":"#adding-an-image","title":"Adding an image","text":"<p>Due to the rapidly growing repository, it is important to make sure that no files that would significantly weigh down the repository are added. This includes images, videos, and other non-text files. We prefer to leverage a hf.co hosted <code>dataset</code> like the ones hosted on <code>hf-internal-testing</code> in which to place these files and reference them by URL. We recommend putting them in the following dataset: huggingface/documentation-images. If an external contribution, feel free to add the images to your PR and ask a Hugging Face member to migrate your images to this dataset.</p>"},{"location":"#styling-the-docstring","title":"Styling the docstring","text":"<p>We have an automatic script running with the <code>make style</code> comment that will make sure that: - the docstrings fully take advantage of the line width - all code examples are formatted using black, like the code of the Transformers library</p> <p>This script may have some weird failures if you made a syntax mistake or if you uncover a bug. Therefore, it's recommended to commit your changes before running <code>make style</code>, so you can revert the changes done by that script easily.</p>"},{"location":"#testing-documentation-examples","title":"Testing documentation examples","text":"<p>Good documentation often comes with an example of how a specific function or class should be used.  Each model class should contain at least one example showcasing how to use this model class in inference. E.g. the class Wav2Vec2ForCTC  includes an example of how to transcribe speech to text in the  docstring of its forward function.</p>"},{"location":"#writing-documentation-examples","title":"Writing documentation examples","text":"<p>The syntax for Example docstrings can look as follows:</p> <pre><code>    Example:\n\n    ```python\n    &gt;&gt;&gt; from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n    &gt;&gt;&gt; from datasets import load_dataset\n    &gt;&gt;&gt; import torch\n\n    &gt;&gt;&gt; dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n    &gt;&gt;&gt; dataset = dataset.sort(\"id\")\n    &gt;&gt;&gt; sampling_rate = dataset.features[\"audio\"].sampling_rate\n\n    &gt;&gt;&gt; processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n    &gt;&gt;&gt; model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n\n    &gt;&gt;&gt; # audio file is decoded on the fly\n    &gt;&gt;&gt; inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n    &gt;&gt;&gt; with torch.no_grad():\n    ...     logits = model(**inputs).logits\n    &gt;&gt;&gt; predicted_ids = torch.argmax(logits, dim=-1)\n\n    &gt;&gt;&gt; # transcribe speech\n    &gt;&gt;&gt; transcription = processor.batch_decode(predicted_ids)\n    &gt;&gt;&gt; transcription[0]\n    'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'\n    ```\n</code></pre> <p>The docstring should give a minimal, clear example of how the respective model  is to be used in inference and also include the expected (ideally sensible) output. Often, readers will try out the example before even going through the function  or class definitions. Therefore, it is of utmost importance that the example  works as expected.</p>"},{"location":"#docstring-testing","title":"Docstring testing","text":"<p>To do so each example should be included in the doctests.  We use pytests' doctest integration to verify that all of our examples run correctly.  For Transformers, the doctests are run on a daily basis via GitHub Actions as can be  seen here.</p>"},{"location":"#for-python-files","title":"For Python files","text":"<p>Run all the tests in the docstrings of a given file with the following command, here is how we test the modeling file of Wav2Vec2 for instance:</p> <pre><code>pytest --doctest-modules src/transformers/models/wav2vec2/modeling_wav2vec2.py -sv --doctest-continue-on-failure\n</code></pre> <p>If you want to isolate a specific docstring, just add <code>::</code> after the file name then type the whole path of the function/class/method whose docstring you want to test. For instance, here is how to just test the forward method of <code>Wav2Vec2ForCTC</code>:</p> <pre><code>pytest --doctest-modules src/transformers/models/wav2vec2/modeling_wav2vec2.py::transformers.models.wav2vec2.modeling_wav2vec2.Wav2Vec2ForCTC.forward -sv --doctest-continue-on-failure\n</code></pre>"},{"location":"#for-markdown-files","title":"For Markdown files","text":"<p>You can test locally a given file with this command (here testing the quicktour):</p> <pre><code>pytest --doctest-modules docs/source/quicktour.md -sv --doctest-continue-on-failure --doctest-glob=\"*.md\"\n</code></pre>"},{"location":"#writing-doctests","title":"Writing doctests","text":"<p>Here are a few tips to help you debug the doctests and make them pass:</p> <ul> <li>The outputs of the code need to match the expected output exactly, so make sure you have the same outputs. In particular doctest will see a difference between single quotes and double quotes, or a missing parenthesis. The only exceptions to that rule are:</li> <li>whitespace: one give whitespace (space, tabulation, new line) is equivalent to any number of whitespace, so you can add new lines where there are spaces to make your output more readable.</li> <li>numerical values: you should never put more than 4 or 5 digits to expected results as different setups or library versions might get you slightly different results. <code>doctest</code> is configured to ignore any difference lower than the precision to which you wrote (so 1e-4 if you write 4 digits).</li> <li>Don't leave a block of code that is very long to execute. If you can't make it fast, you can either not use the doctest syntax on it (so that it's ignored), or if you want to use the doctest syntax to show the results, you can add a comment <code># doctest: +SKIP</code> at the end of the lines of code too long to execute</li> <li>Each line of code that produces a result needs to have that result written below. You can ignore an output if you don't want to show it in your code example by adding a comment <code># doctest: +IGNORE_RESULT</code> at the end of the line of code producing it.</li> </ul>"},{"location":"autoclass_tutorial/","title":"Autoclass tutorial","text":""},{"location":"autoclass_tutorial/#autoclass","title":"\u4f7f\u7528\u200bAutoClass\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u5b9e\u4f8b","text":"<p>\u200b\u7531\u4e8e\u200b\u5b58\u5728\u200b\u8bb8\u591a\u200b\u4e0d\u540c\u200b\u7684\u200bTransformer\u200b\u67b6\u6784\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4e3a\u200b\u60a8\u200b\u7684\u200bcheckpoint\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u53ef\u7528\u200b\u67b6\u6784\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5177\u6709\u200b\u6311\u6218\u6027\u200b\u3002\u200b\u901a\u8fc7\u200b<code>AutoClass</code>\u200b\u53ef\u4ee5\u200b\u81ea\u52a8\u200b\u63a8\u65ad\u200b\u5e76\u200b\u4ece\u200b\u7ed9\u5b9a\u200b\u7684\u200bcheckpoint\u200b\u52a0\u8f7d\u200b\u6b63\u786e\u200b\u7684\u200b\u67b6\u6784\u200b, \u200b\u8fd9\u200b\u4e5f\u200b\u662f\u200b\ud83e\udd17 Transformers\u200b\u6613\u4e8e\u200b\u4f7f\u7528\u200b\u3001\u200b\u7b80\u5355\u200b\u4e14\u200b\u7075\u6d3b\u200b\u6838\u5fc3\u200b\u89c4\u5219\u200b\u7684\u200b\u91cd\u8981\u200b\u4e00\u90e8\u5206\u200b\u3002<code>from_pretrained()</code>\u200b\u65b9\u6cd5\u200b\u5141\u8bb8\u200b\u60a8\u200b\u5feb\u901f\u200b\u52a0\u8f7d\u200b\u4efb\u4f55\u200b\u67b6\u6784\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff0c\u200b\u56e0\u6b64\u200b\u60a8\u200b\u4e0d\u5fc5\u200b\u82b1\u8d39\u200b\u65f6\u95f4\u200b\u548c\u200b\u7cbe\u529b\u200b\u4ece\u5934\u5f00\u59cb\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002\u200b\u751f\u6210\u200b\u8fd9\u79cd\u200b\u4e0e\u200bcheckpoint\u200b\u65e0\u5173\u200b\u7684\u200b\u4ee3\u7801\u200b\u610f\u5473\u7740\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u4ee3\u7801\u200b\u9002\u7528\u200b\u4e8e\u200b\u4e00\u4e2a\u200bcheckpoint\uff0c\u200b\u5b83\u200b\u5c06\u200b\u9002\u7528\u200b\u4e8e\u200b\u53e6\u200b\u4e00\u4e2a\u200bcheckpoint - \u200b\u53ea\u8981\u200b\u5b83\u4eec\u200b\u662f\u200b\u4e3a\u4e86\u200b\u7c7b\u4f3c\u200b\u7684\u200b\u4efb\u52a1\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u7684\u200b - \u200b\u5373\u4f7f\u200b\u67b6\u6784\u200b\u4e0d\u540c\u200b\u3002</p> <p> <p>\u200b\u8bf7\u200b\u8bb0\u4f4f\u200b\uff0c\u200b\u67b6\u6784\u200b\u6307\u200b\u7684\u200b\u662f\u200b\u6a21\u578b\u200b\u7684\u200b\u7ed3\u6784\u200b\uff0c\u200b\u800c\u200bcheckpoints\u200b\u662f\u200b\u7ed9\u5b9a\u200b\u67b6\u6784\u200b\u7684\u200b\u6743\u91cd\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0cBERT\u200b\u662f\u200b\u4e00\u79cd\u200b\u67b6\u6784\u200b\uff0c\u200b\u800c\u200b<code>bert-base-uncased</code>\u200b\u662f\u200b\u4e00\u4e2a\u200bcheckpoint\u3002\u200b\u6a21\u578b\u200b\u662f\u200b\u4e00\u4e2a\u200b\u901a\u7528\u200b\u672f\u8bed\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u6307\u4ee3\u200b\u67b6\u6784\u200b\u6216\u200bcheckpoint\u3002</p> <p></p> <p>\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u5b66\u4e60\u200b\u5982\u4f55\u200b\uff1a</p> <ul> <li>\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\uff08<code>tokenizer</code>\uff09</li> <li>\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u56fe\u50cf\u200b\u5904\u7406\u5668\u200b(<code>image processor</code>)</li> <li>\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b(<code>feature extractor</code>)</li> <li>\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u5904\u7406\u5668\u200b(<code>processor</code>)</li> <li>\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u3002</li> </ul>"},{"location":"autoclass_tutorial/#autotokenizer","title":"AutoTokenizer","text":"<p>\u200b\u51e0\u4e4e\u200b\u6240\u6709\u200b\u7684\u200bNLP\u200b\u4efb\u52a1\u200b\u90fd\u200b\u4ee5\u200b<code>tokenizer</code>\u200b\u5f00\u59cb\u200b\u3002<code>tokenizer</code>\u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u8f93\u5165\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6a21\u578b\u200b\u53ef\u4ee5\u200b\u5904\u7406\u200b\u7684\u200b\u683c\u5f0f\u200b\u3002</p> <p>\u200b\u4f7f\u7528\u200b[<code>AutoTokenizer.from_pretrained</code>]\u200b\u52a0\u8f7d\u200b<code>tokenizer</code>\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n</code></pre> <p>\u200b\u7136\u540e\u200b\u6309\u7167\u200b\u5982\u4e0b\u200b\u65b9\u5f0f\u200b\u5bf9\u200b\u8f93\u5165\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; sequence = \"In a hole in the ground there lived a hobbit.\"\n&gt;&gt;&gt; print(tokenizer(sequence))\n{'input_ids': [101, 1999, 1037, 4920, 1999, 1996, 2598, 2045, 2973, 1037, 7570, 10322, 4183, 1012, 102], \n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n</code></pre>"},{"location":"autoclass_tutorial/#autoimageprocessor","title":"AutoImageProcessor","text":"<p>\u200b\u5bf9\u4e8e\u200b\u89c6\u89c9\u200b\u4efb\u52a1\u200b\uff0c<code>image processor</code>\u200b\u5c06\u200b\u56fe\u50cf\u5904\u7406\u200b\u6210\u200b\u6b63\u786e\u200b\u7684\u200b\u8f93\u5165\u200b\u683c\u5f0f\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from transformers import AutoImageProcessor\n\n&gt;&gt;&gt; image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n</code></pre>"},{"location":"autoclass_tutorial/#autofeatureextractor","title":"AutoFeatureExtractor","text":"<p>\u200b\u5bf9\u4e8e\u200b\u97f3\u9891\u200b\u4efb\u52a1\u200b,<code>feature extractor</code>\u200b\u5c06\u200b\u97f3\u9891\u200b\u4fe1\u53f7\u5904\u7406\u200b\u6210\u200b\u6b63\u786e\u200b\u7684\u200b\u8f93\u5165\u200b\u683c\u5f0f\u200b\u3002</p> <p>\u200b\u4f7f\u7528\u200b[<code>AutoFeatureExtractor.from_pretrained</code>]\u200b\u52a0\u8f7d\u200b<code>feature extractor</code>\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoFeatureExtractor\n\n&gt;&gt;&gt; feature_extractor = AutoFeatureExtractor.from_pretrained(\n...     \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n... )\n</code></pre>"},{"location":"autoclass_tutorial/#autoprocessor","title":"AutoProcessor","text":"<p>\u200b\u591a\u200b\u6a21\u6001\u200b\u4efb\u52a1\u200b\u9700\u8981\u200b\u4e00\u79cd\u200b<code>processor</code>\uff0c\u200b\u5c06\u200b\u4e24\u79cd\u200b\u7c7b\u578b\u200b\u7684\u200b\u9884\u5904\u7406\u200b\u5de5\u5177\u200b\u7ed3\u5408\u200b\u8d77\u6765\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0cLayoutLMV2\u200b\u6a21\u578b\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b<code>image processo</code>\u200b\u6765\u200b\u5904\u7406\u200b\u56fe\u50cf\u200b\u548c\u200b\u4e00\u4e2a\u200b<code>tokenizer</code>\u200b\u6765\u200b\u5904\u7406\u200b\u6587\u672c\u200b\uff1b<code>processor</code>\u200b\u5c06\u200b\u4e24\u8005\u200b\u7ed3\u5408\u200b\u8d77\u6765\u200b\u3002</p> <p>\u200b\u4f7f\u7528\u200b[<code>AutoProcessor.from_pretrained</code>]\u200b\u52a0\u8f7d\u200b<code>processor</code>\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoProcessor\n\n&gt;&gt;&gt; processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\")\n</code></pre>"},{"location":"autoclass_tutorial/#automodel","title":"AutoModel","text":"<p> <p>\u200b\u6700\u540e\u200b\uff0c<code>AutoModelFor</code>\u200b\u7c7b\u200b\u8ba9\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u52a0\u8f7d\u200b\u7ed9\u5b9a\u200b\u4efb\u52a1\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff08\u200b\u53c2\u89c1\u200b\u8fd9\u91cc\u200b\u83b7\u53d6\u200b\u53ef\u7528\u200b\u4efb\u52a1\u200b\u7684\u200b\u5b8c\u6574\u200b\u5217\u8868\u200b\uff09\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4f7f\u7528\u200b[<code>AutoModelForSequenceClassification.from_pretrained</code>]\u200b\u52a0\u8f7d\u200b\u7528\u4e8e\u200b\u5e8f\u5217\u200b\u5206\u7c7b\u200b\u7684\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoModelForSequenceClassification\n\n&gt;&gt;&gt; model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <p>\u200b\u8f7b\u677e\u200b\u5730\u200b\u91cd\u590d\u4f7f\u7528\u200b\u76f8\u540c\u200b\u7684\u200bcheckpoint\u200b\u6765\u200b\u4e3a\u200b\u4e0d\u540c\u200b\u4efb\u52a1\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoModelForTokenClassification\n\n&gt;&gt;&gt; model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <p> <p>\u200b\u5bf9\u4e8e\u200bPyTorch\u200b\u6a21\u578b\u200b\uff0c<code>from_pretrained()</code>\u200b\u65b9\u6cd5\u200b\u4f7f\u7528\u200b<code>torch.load()</code>\uff0c\u200b\u5b83\u200b\u5185\u90e8\u200b\u4f7f\u7528\u200b\u5df2\u77e5\u200b\u662f\u200b\u4e0d\u200b\u5b89\u5168\u200b\u7684\u200b<code>pickle</code>\u3002\u200b\u4e00\u822c\u6765\u8bf4\u200b\uff0c\u200b\u6c38\u8fdc\u200b\u4e0d\u8981\u200b\u52a0\u8f7d\u200b\u6765\u81ea\u200b\u4e0d\u53ef\u200b\u4fe1\u200b\u6765\u6e90\u200b\u6216\u200b\u53ef\u80fd\u200b\u88ab\u200b\u7be1\u6539\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u6258\u7ba1\u200b\u5728\u200bHugging Face Hub\u200b\u4e0a\u200b\u7684\u200b\u516c\u5171\u200b\u6a21\u578b\u200b\uff0c\u200b\u8fd9\u79cd\u200b\u5b89\u5168\u200b\u98ce\u9669\u200b\u5728\u200b\u4e00\u5b9a\u200b\u7a0b\u5ea6\u200b\u4e0a\u200b\u5f97\u5230\u200b\u4e86\u200b\u7f13\u89e3\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6bcf\u6b21\u200b\u63d0\u4ea4\u200b\u90fd\u200b\u4f1a\u200b\u8fdb\u884c\u200b\u6076\u610f\u8f6f\u4ef6\u200b\u626b\u63cf\u200b\u3002\u200b\u8bf7\u53c2\u9605\u200bHub\u200b\u6587\u6863\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u6700\u4f73\u200b\u5b9e\u8df5\u200b\uff0c\u200b\u4f8b\u5982\u200b\u4f7f\u7528\u200bGPG\u200b\u8fdb\u884c\u200b\u7b7e\u540d\u200b\u63d0\u4ea4\u200b\u9a8c\u8bc1\u200b\u3002</p> <p>TensorFlow\u200b\u548c\u200bFlax\u200b\u7684\u200bcheckpoints\u200b\u4e0d\u200b\u53d7\u200b\u5f71\u54cd\u200b\uff0c\u200b\u5e76\u4e14\u200b\u53ef\u4ee5\u200b\u5728\u200bPyTorch\u200b\u67b6\u6784\u200b\u4e2d\u200b\u4f7f\u7528\u200b<code>from_tf</code>\u200b\u548c\u200b<code>from_flax</code>\u200b\u5173\u952e\u5b57\u200b\u53c2\u6570\u200b,\u200b\u901a\u8fc7\u200b<code>from_pretrained</code>\u200b\u65b9\u6cd5\u200b\u8fdb\u884c\u200b\u52a0\u8f7d\u200b,\u200b\u6765\u200b\u7ed5\u8fc7\u200b\u6b64\u200b\u95ee\u9898\u200b\u3002</p> <p></p> <p>\u200b\u4e00\u822c\u6765\u8bf4\u200b\uff0c\u200b\u6211\u4eec\u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200b<code>AutoTokenizer</code>\u200b\u7c7b\u200b\u548c\u200b<code>AutoModelFor</code>\u200b\u7c7b\u6765\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u5b9e\u4f8b\u200b\u3002\u200b\u8fd9\u6837\u200b\u53ef\u4ee5\u200b\u786e\u4fdd\u200b\u6bcf\u6b21\u200b\u52a0\u8f7d\u200b\u6b63\u786e\u200b\u7684\u200b\u67b6\u6784\u200b\u3002\u200b\u5728\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u5b66\u4e60\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u65b0\u200b\u52a0\u8f7d\u200b\u7684\u200b<code>tokenizer</code>, <code>image processor</code>, <code>feature extractor</code>\u200b\u548c\u200b<code>processor</code>\u200b\u5bf9\u200b\u6570\u636e\u200b\u96c6\u200b\u8fdb\u884c\u200b\u9884\u5904\u7406\u200b\u4ee5\u200b\u8fdb\u884c\u200b\u5fae\u8c03\u200b\u3002</p> <p>  \u200b\u6700\u540e\u200b\uff0c<code>TFAutoModelFor</code>\u200b\u7c7b\u200b\u5141\u8bb8\u200b\u60a8\u200b\u52a0\u8f7d\u200b\u7ed9\u5b9a\u200b\u4efb\u52a1\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff08\u200b\u8bf7\u53c2\u9605\u200b\u8fd9\u91cc\u200b\u83b7\u53d6\u200b\u53ef\u7528\u200b\u4efb\u52a1\u200b\u7684\u200b\u5b8c\u6574\u200b\u5217\u8868\u200b\uff09\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4f7f\u7528\u200b[<code>TFAutoModelForSequenceClassification.from_pretrained</code>]\u200b\u52a0\u8f7d\u200b\u7528\u4e8e\u200b\u5e8f\u5217\u200b\u5206\u7c7b\u200b\u7684\u200b\u6a21\u578b\u200b\uff1a <pre><code>&gt;&gt;&gt; from transformers import TFAutoModelForSequenceClassification\n\n&gt;&gt;&gt; model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <p>\u200b\u8f7b\u677e\u200b\u5730\u200b\u91cd\u590d\u4f7f\u7528\u200b\u76f8\u540c\u200b\u7684\u200bcheckpoint\u200b\u6765\u200b\u4e3a\u200b\u4e0d\u540c\u200b\u4efb\u52a1\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; from transformers import TFAutoModelForTokenClassification\n\n&gt;&gt;&gt; model = TFAutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> \u200b\u4e00\u822c\u6765\u8bf4\u200b\uff0c\u200b\u6211\u4eec\u200b\u63a8\u8350\u200b\u4f7f\u7528\u200b<code>AutoTokenizer</code>\u200b\u7c7b\u200b\u548c\u200b<code>TFAutoModelFor</code>\u200b\u7c7b\u6765\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u5b9e\u4f8b\u200b\u3002\u200b\u8fd9\u6837\u200b\u53ef\u4ee5\u200b\u786e\u4fdd\u200b\u6bcf\u6b21\u200b\u52a0\u8f7d\u200b\u6b63\u786e\u200b\u7684\u200b\u67b6\u6784\u200b\u3002\u200b\u5728\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u5b66\u4e60\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u65b0\u200b\u52a0\u8f7d\u200b\u7684\u200b<code>tokenizer</code>, <code>image processor</code>, <code>feature extractor</code>\u200b\u548c\u200b<code>processor</code>\u200b\u5bf9\u200b\u6570\u636e\u200b\u96c6\u200b\u8fdb\u884c\u200b\u9884\u5904\u7406\u200b\u4ee5\u200b\u8fdb\u884c\u200b\u5fae\u8c03\u200b\u3002</p> <p> </p>"},{"location":"awesome-transformers/","title":"Awesome projects built with Transformers","text":"<p>This page lists awesome projects built on top of Transformers. Transformers is more than a toolkit to use pretrained models: it's a community of projects built around it and the Hugging Face Hub. We want Transformers to enable developers, researchers, students, professors, engineers, and anyone else to build their dream projects.</p> <p>In this list, we showcase incredibly impactful and novel projects that have pushed the field forward. We celebrate 100 of these projects as we reach the milestone of 100k stars as a community; but we're very open to pull requests adding other projects to the list. If you believe a project should be here and it's not, then please, open a PR  to add it.</p>"},{"location":"awesome-transformers/#gpt4all","title":"gpt4all","text":"<p>gpt4all is an ecosystem of open-source chatbots trained on massive collections of clean assistant data including code, stories and dialogue. It offers open-source, large language models such as LLaMA and GPT-J trained in an assistant-style.</p> <p>Keywords: Open-source, LLaMa, GPT-J, instruction, assistant</p>"},{"location":"awesome-transformers/#recommenders","title":"recommenders","text":"<p>This repository contains examples and best practices for building recommendation systems, provided as Jupyter notebooks. It goes over several aspects required to build efficient recommendation systems: data preparation, modeling, evaluation, model selection &amp; optimization, as well as operationalization</p> <p>Keywords: Recommender systems, AzureML</p>"},{"location":"awesome-transformers/#lama-cleaner","title":"lama-cleaner","text":"<p>Image inpainting tool powered by Stable Diffusion. Remove any unwanted object, defect, people from your pictures or erase and replace anything on your pictures.</p> <p>Keywords: inpainting, SD, Stable Diffusion</p>"},{"location":"awesome-transformers/#flair","title":"flair","text":"<p>FLAIR is a powerful PyTorch NLP framework, convering several important tasks: NER, sentiment-analysis, part-of-speech tagging, text and document embeddings, among other things.</p> <p>Keywords: NLP, text embedding, document embedding, biomedical, NER, PoS, sentiment-analysis</p>"},{"location":"awesome-transformers/#mindsdb","title":"mindsdb","text":"<p>MindsDB is a low-code ML platform, which automates and integrates several ML frameworks into the data stack as \"AI Tables\" to streamline the integration of AI into applications, making it accessible to developers of all skill levels.</p> <p>Keywords: Database, low-code, AI table</p>"},{"location":"awesome-transformers/#langchain","title":"langchain","text":"<p>langchain is aimed at assisting in the development of apps merging both LLMs and other sources of knowledge. The library allows chaining calls to applications, creating a sequence across many tools.</p> <p>Keywords: LLMs, Large Language Models, Agents, Chains</p>"},{"location":"awesome-transformers/#llamaindex","title":"LlamaIndex","text":"<p>LlamaIndex is a project that provides a central interface to connect your LLM's with external data. It provides various kinds of indices and retreival mechanisms to perform different LLM tasks and obtain knowledge-augmented results.</p> <p>Keywords: LLMs, Large Language Models, Data Retrieval, Indices, Knowledge Augmentation </p>"},{"location":"awesome-transformers/#parlai","title":"ParlAI","text":"<p>ParlAI is a python framework for sharing, training and testing dialogue models, from open-domain chitchat, to task-oriented dialogue, to visual question answering. It provides more than 100 datasets under the same API, a large zoo of pretrained models, a set of agents, and has several integrations.</p> <p>Keywords: Dialogue, Chatbots, VQA, Datasets, Agents</p>"},{"location":"awesome-transformers/#sentence-transformers","title":"sentence-transformers","text":"<p>This framework provides an easy method to compute dense vector representations for sentences, paragraphs, and images. The models are based on transformer networks like BERT / RoBERTa / XLM-RoBERTa etc. and achieve state-of-the-art performance in various task. Text is embedding in vector space such that similar text is close and can efficiently be found using cosine similarity.</p> <p>Keywords: Dense vector representations, Text embeddings, Sentence embeddings</p>"},{"location":"awesome-transformers/#ludwig","title":"ludwig","text":"<p>Ludwig is a declarative machine learning framework that makes it easy to define machine learning pipelines using a simple and flexible data-driven configuration system. Ludwig is targeted at a wide variety of AI tasks. It provides a data-driven configuration system, training, prediction, and evaluation scripts, as well as a programmatic API.</p> <p>Keywords: Declarative, Data-driven, ML Framework</p>"},{"location":"awesome-transformers/#invokeai","title":"InvokeAI","text":"<p>InvokeAI is an engine for Stable Diffusion models, aimed at professionals, artists, and enthusiasts. It leverages the latest AI-driven technologies through CLI as well as a WebUI.</p> <p>Keywords: Stable-Diffusion, WebUI, CLI</p>"},{"location":"awesome-transformers/#paddlenlp","title":"PaddleNLP","text":"<p>PaddleNLP is an easy-to-use and powerful NLP library particularly targeted at the Chinese languages. It has support for multiple pre-trained model zoos, and supports a wide-range of NLP tasks from research to industrial applications.</p> <p>Keywords: NLP, Chinese, Research, Industry</p>"},{"location":"awesome-transformers/#stanza","title":"stanza","text":"<p>The Stanford NLP Group's official Python NLP library. It contains support for running various accurate natural language processing tools on 60+ languages and for accessing the Java Stanford CoreNLP software from Python.</p> <p>Keywords: NLP, Multilingual, CoreNLP</p>"},{"location":"awesome-transformers/#deeppavlov","title":"DeepPavlov","text":"<p>DeepPavlov is an open-source conversational AI library. It is designed for the development of production ready chat-bots and complex conversational systems, as well as research in the area of NLP and, particularly, of dialog systems.</p> <p>Keywords: Conversational, Chatbot, Dialog</p>"},{"location":"awesome-transformers/#alpaca-lora","title":"alpaca-lora","text":"<p>Alpaca-lora contains code for reproducing the Stanford Alpaca results using low-rank adaptation (LoRA). The repository provides training (fine-tuning) as well as generation scripts.</p> <p>Keywords: LoRA, Parameter-efficient fine-tuning</p>"},{"location":"awesome-transformers/#imagen-pytorch","title":"imagen-pytorch","text":"<p>An open-source Implementation of Imagen, Google's closed-source Text-to-Image Neural Network that beats DALL-E2. As of release, it is the new SOTA for text-to-image synthesis.</p> <p>Keywords: Imagen, Text-to-image</p>"},{"location":"awesome-transformers/#adapter-transformers","title":"adapter-transformers","text":"<p>adapter-transformers is an extension of HuggingFace's Transformers library, integrating adapters into state-of-the-art language models by incorporating AdapterHub, a central repository for pre-trained adapter modules. It is a drop-in replacement for transformers, which is regularly updated to stay up-to-date with the developments of transformers.</p> <p>Keywords: Adapters, LoRA, Parameter-efficient fine-tuning, Hub</p>"},{"location":"awesome-transformers/#nemo","title":"NeMo","text":"<p>NVIDIA NeMo is a conversational AI toolkit built for researchers working on automatic speech recognition (ASR), text-to-speech synthesis (TTS), large language models (LLMs), and natural language processing (NLP). The primary objective of NeMo is to help researchers from industry and academia to reuse prior work (code and pretrained models) and make it easier to create new https://developer.nvidia.com/conversational-ai#started.</p> <p>Keywords: Conversational, ASR, TTS, LLMs, NLP</p>"},{"location":"awesome-transformers/#runhouse","title":"Runhouse","text":"<p>Runhouse allows to send code and data to any of your compute or data infra, all in Python, and continue to interact with them normally from your existing code and environment. Runhouse developers mention:</p> <p>Think of it as an expansion pack to your Python interpreter that lets it take detours to remote machines or manipulate remote data.</p> <p>Keywords: MLOps, Infrastructure, Data storage, Modeling</p>"},{"location":"awesome-transformers/#monai","title":"MONAI","text":"<p>MONAI is a PyTorch-based, open-source framework for deep learning in healthcare imaging, part of PyTorch Ecosystem. Its ambitions are: - developing a community of academic, industrial and clinical researchers collaborating on a common foundation; - creating state-of-the-art, end-to-end training workflows for healthcare imaging; - providing researchers with the optimized and standardized way to create and evaluate deep learning models.</p> <p>Keywords: Healthcare imaging, Training, Evaluation</p>"},{"location":"awesome-transformers/#simpletransformers","title":"simpletransformers","text":"<p>Simple Transformers lets you quickly train and evaluate Transformer models. Only 3 lines of code are needed to initialize, train, and evaluate a model. It supports a wide variety of NLP tasks.</p> <p>Keywords: Framework, simplicity, NLP</p>"},{"location":"awesome-transformers/#jarvis","title":"JARVIS","text":"<p>JARVIS is a system attempting to merge LLMs such as GPT-4 with the rest of the open-source ML community: leveraging up to 60 downstream models in order to perform tasks identified by the LLM.</p> <p>Keywords: LLM, Agents, HF Hub</p>"},{"location":"awesome-transformers/#transformersjs","title":"transformers.js","text":"<p>transformers.js is a JavaScript library targeted at running models from transformers directly within the browser.</p> <p>Keywords: Transformers, JavaScript, browser</p>"},{"location":"awesome-transformers/#bumblebee","title":"bumblebee","text":"<p>Bumblebee provides pre-trained Neural Network models on top of Axon, a neural networks library for the Elixir language. It includes integration with \ud83e\udd17 Models, allowing anyone to download and perform Machine Learning tasks with few lines of code.</p> <p>Keywords: Elixir, Axon</p>"},{"location":"awesome-transformers/#argilla","title":"argilla","text":"<p>Argilla is an open-source platform providing advanced NLP labeling, monitoring, and workspaces. It is compatible with many open source ecosystems such as Hugging Face, Stanza, FLAIR, and others.</p> <p>Keywords: NLP, Labeling, Monitoring, Workspaces</p>"},{"location":"awesome-transformers/#haystack","title":"haystack","text":"<p>Haystack is an open source NLP framework to interact with your data using Transformer models and LLMs. It offers production-ready tools to quickly build complex decision making, question answering, semantic search, text generation applications, and more.</p> <p>Keywords: NLP, Framework, LLM</p>"},{"location":"awesome-transformers/#spacy","title":"spaCy","text":"<p>spaCy is a library for advanced Natural Language Processing in Python and Cython. It's built on the very latest research, and was designed from day one to be used in real products. It offers support for transformers models through its third party package, spacy-transformers.</p> <p>Keywords: NLP, Framework</p>"},{"location":"awesome-transformers/#speechbrain","title":"speechbrain","text":"<p>SpeechBrain is an open-source and all-in-one conversational AI toolkit based on PyTorch. The goal is to create a single, flexible, and user-friendly toolkit that can be used to easily develop state-of-the-art speech technologies, including systems for speech recognition, speaker recognition, speech enhancement, speech separation, language identification, multi-microphone signal processing, and many others.</p> <p>Keywords: Conversational, Speech</p>"},{"location":"awesome-transformers/#skorch","title":"skorch","text":"<p>Skorch is a scikit-learn compatible neural network library that wraps PyTorch. It has support for models within transformers, and tokenizers from tokenizers.</p> <p>Keywords: Scikit-Learn, PyTorch</p>"},{"location":"awesome-transformers/#bertviz","title":"bertviz","text":"<p>BertViz is an interactive tool for visualizing attention in Transformer language models such as BERT, GPT2, or T5. It can be run inside a Jupyter or Colab notebook through a simple Python API that supports most Huggingface models.</p> <p>Keywords: Visualization, Transformers</p>"},{"location":"awesome-transformers/#mesh-transformer-jax","title":"mesh-transformer-jax","text":"<p>mesh-transformer-jax is a haiku library using the xmap/pjit operators in JAX for model parallelism of transformers. This library is designed for scalability up to approximately 40B parameters on TPUv3s. It was the library used to train the GPT-J model.</p> <p>Keywords: Haiku, Model parallelism, LLM, TPU</p>"},{"location":"awesome-transformers/#deepchem","title":"deepchem","text":"<p>DeepChem aims to provide a high quality open-source toolchain that democratizes the use of deep-learning in drug discovery, materials science, quantum chemistry, and biology.</p> <p>Keywords: Drug discovery, Materials Science, Quantum Chemistry, Biology</p>"},{"location":"awesome-transformers/#opennre","title":"OpenNRE","text":"<p>An Open-Source Package for Neural Relation Extraction (NRE). It is targeted at a wide range of users, from newcomers to relation extraction, to developers, researchers, or students.</p> <p>Keywords: Neural Relation Extraction, Framework</p>"},{"location":"awesome-transformers/#pycorrector","title":"pycorrector","text":"<p>PyCorrector is a Chinese Text Error Correction Tool. It uses a language model to detect errors, pinyin feature and shape feature to correct Chinese text errors. it can be used for Chinese Pinyin and stroke input method.</p> <p>Keywords: Chinese, Error correction tool, Language model, Pinyin</p>"},{"location":"awesome-transformers/#nlpaug","title":"nlpaug","text":"<p>This python library helps you with augmenting nlp for machine learning projects. It is a lightweight library featuring synthetic data generation for improving model performance, support for audio and text, and compatibility with several ecosystems (scikit-learn, pytorch, tensorflow).</p> <p>Keywords: Data augmentation, Synthetic data generation, Audio, NLP</p>"},{"location":"awesome-transformers/#dream-textures","title":"dream-textures","text":"<p>dream-textures is a library targeted at bringing stable-diffusion support within Blender. It supports several use-cases, such as image generation, texture projection, inpainting/outpainting, ControlNet, and upscaling.</p> <p>Keywords: Stable-Diffusion, Blender</p>"},{"location":"awesome-transformers/#seldon-core","title":"seldon-core","text":"<p>Seldon core converts your ML models (Tensorflow, Pytorch, H2o, etc.) or language wrappers (Python, Java, etc.) into production REST/GRPC microservices. Seldon handles scaling to thousands of production machine learning models and provides advanced machine learning capabilities out of the box including Advanced Metrics, Request Logging, Explainers, Outlier Detectors, A/B Tests, Canaries and more.</p> <p>Keywords: Microservices, Modeling, Language wrappers</p>"},{"location":"awesome-transformers/#open_model_zoo","title":"open_model_zoo","text":"<p>This repository includes optimized deep learning models and a set of demos to expedite development of high-performance deep learning inference applications. Use these free pre-trained models instead of training your own models to speed-up the development and production deployment process.</p> <p>Keywords: Optimized models, Demos</p>"},{"location":"awesome-transformers/#ml-stable-diffusion","title":"ml-stable-diffusion","text":"<p>ML-Stable-Diffusion is a repository by Apple bringing Stable Diffusion support to Core ML, on Apple Silicon devices. It supports stable diffusion checkpoints hosted on the Hugging Face Hub.</p> <p>Keywords: Stable Diffusion, Apple Silicon, Core ML</p>"},{"location":"awesome-transformers/#stable-dreamfusion","title":"stable-dreamfusion","text":"<p>Stable-Dreamfusion is a pytorch implementation of the text-to-3D model Dreamfusion, powered by the Stable Diffusion text-to-2D model.</p> <p>Keywords: Text-to-3D, Stable Diffusion</p>"},{"location":"awesome-transformers/#txtai","title":"txtai","text":"<p>txtai is an open-source platform for semantic search and workflows powered by language models. txtai builds embeddings databases, which are a union of vector indexes and relational databases enabling similarity search with SQL. Semantic workflows connect language models together into unified applications.</p> <p>Keywords: Semantic search, LLM</p>"},{"location":"awesome-transformers/#djl","title":"djl","text":"<p>Deep Java Library (DJL) is an open-source, high-level, engine-agnostic Java framework for deep learning. DJL is designed to be easy to get started with and simple to use for developers. DJL provides a native Java development experience and functions like any other regular Java library. DJL offers a Java binding for HuggingFace Tokenizers and easy conversion toolkit for HuggingFace model to deploy in Java.</p> <p>Keywords: Java, Framework</p>"},{"location":"awesome-transformers/#lm-evaluation-harness","title":"lm-evaluation-harness","text":"<p>This project provides a unified framework to test generative language models on a large number of different evaluation tasks. It has support for more than 200 tasks, and supports different ecosystems: HF Transformers, GPT-NeoX, DeepSpeed, as well as the OpenAI API.</p> <p>Keywords: LLM, Evaluation, Few-shot</p>"},{"location":"awesome-transformers/#gpt-neox","title":"gpt-neox","text":"<p>This repository records EleutherAI's library for training large-scale language models on GPUs. The framework is based on NVIDIA's Megatron Language Model and has been augmented with techniques from DeepSpeed as well as some novel optimizations. It is focused on training multi-billion-parameter models.</p> <p>Keywords: Training, LLM, Megatron, DeepSpeed</p>"},{"location":"awesome-transformers/#muzic","title":"muzic","text":"<p>Muzic is a research project on AI music that empowers music understanding and generation with deep learning and artificial intelligence. Muzic was created by researchers from Microsoft Research Asia.</p> <p>Keywords: Music understanding, Music generation</p>"},{"location":"awesome-transformers/#dalle-flow","title":"dalle-flow","text":"<p>DALL\u00b7E Flow is an interactive workflow for generating high-definition images from a text prompt. Itt leverages DALL\u00b7E-Mega, GLID-3 XL, and Stable Diffusion to generate image candidates, and then calls CLIP-as-service to rank the candidates w.r.t. the prompt. The preferred candidate is fed to GLID-3 XL for diffusion, which often enriches the texture and background. Finally, the candidate is upscaled to 1024x1024 via SwinIR.</p> <p>Keywords: High-definition image generation, Stable Diffusion, DALL-E Mega, GLID-3 XL, CLIP, SwinIR</p>"},{"location":"awesome-transformers/#lightseq","title":"lightseq","text":"<p>LightSeq is a high performance training and inference library for sequence processing and generation implemented in CUDA. It enables highly efficient computation of modern NLP and CV models such as BERT, GPT, Transformer, etc. It is therefore best useful for machine translation, text generation, image classification, and other sequence related tasks.</p> <p>Keywords: Training, Inference, Sequence Processing, Sequence Generation</p>"},{"location":"awesome-transformers/#latex-ocr","title":"LaTeX-OCR","text":"<p>The goal of this project is to create a learning based system that takes an image of a math formula and returns corresponding LaTeX code.</p> <p>Keywords: OCR, LaTeX, Math formula</p>"},{"location":"awesome-transformers/#open_clip","title":"open_clip","text":"<p>OpenCLIP is an open source implementation of OpenAI's CLIP.</p> <p>The goal of this repository is to enable training models with contrastive image-text supervision, and to investigate their properties such as robustness to distribution shift.  The starting point is an implementation of CLIP that matches the accuracy of the original CLIP models when trained on the same dataset. </p> <p>Specifically, a ResNet-50 model trained with this codebase on OpenAI's 15 million image subset of YFCC achieves 32.7% top-1 accuracy on ImageNet.</p> <p>Keywords: CLIP, Open-source, Contrastive, Image-text</p>"},{"location":"awesome-transformers/#dalle-playground","title":"dalle-playground","text":"<p>A playground to generate images from any text prompt using Stable Diffusion and Dall-E mini.</p> <p>Keywords: WebUI, Stable Diffusion, Dall-E mini</p>"},{"location":"awesome-transformers/#fedml","title":"FedML","text":"<p>FedML is a federated learning and analytics library enabling secure and collaborative machine learning on decentralized data anywhere at any scale.</p> <p>It supports large-scale cross-silo federated learning, and cross-device federated learning on smartphones/IoTs, and research simulation.</p> <p>Keywords: Federated Learning, Analytics, Collaborative ML, Decentralized</p>"},{"location":"awesome-transformers/#gpt-code-clippy","title":"gpt-code-clippy","text":"<p>GPT-Code-Clippy (GPT-CC) is an open source version of GitHub Copilot, a language model -- based on GPT-3, called GPT-Codex -- that is fine-tuned on publicly available code from GitHub.</p> <p>Keywords: LLM, Code</p>"},{"location":"awesome-transformers/#textattack","title":"TextAttack","text":"<p>TextAttack \ud83d\udc19 is a Python framework for adversarial attacks, data augmentation, and model training in NLP.</p> <p>Keywords: Adversarial attacks, Data augmentation, NLP</p>"},{"location":"awesome-transformers/#openprompt","title":"OpenPrompt","text":"<p>Prompt-learning is a paradigm to adapt pre-trained language models (PLMs) to downstream NLP tasks, which modify the input text with a textual template and directly uses PLMs to conduct pre-trained tasks. This library provides a standard, flexible and extensible framework to deploy the prompt-learning pipeline. OpenPrompt supports loading PLMs directly from https://github.com/huggingface/transformers.</p>"},{"location":"awesome-transformers/#text-generation-webui","title":"text-generation-webui","text":"<p>text-generation-webui is a Gradio Web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.</p> <p>Keywords: LLM, WebUI</p>"},{"location":"awesome-transformers/#libra","title":"libra","text":"<p>An ergonomic machine learning library for non-technical users. It focuses on ergonomics and on ensuring that training a model is as simple as it can be.</p> <p>Keywords: Ergonomic, Non-technical</p>"},{"location":"awesome-transformers/#alibi","title":"alibi","text":"<p>Alibi is an open source Python library aimed at machine learning model inspection and interpretation. The focus of the library is to provide high-quality implementations of black-box, white-box, local and global explanation methods for classification and regression models.</p> <p>Keywords: Model inspection, Model interpretation, Black-box, White-box</p>"},{"location":"awesome-transformers/#tortoise-tts","title":"tortoise-tts","text":"<p>Tortoise is a text-to-speech program built with the following priorities: strong multi-voice capabilities, and highly realistic prosody and intonation.</p> <p>Keywords: Text-to-speech</p>"},{"location":"awesome-transformers/#flower","title":"flower","text":"<p>Flower (flwr) is a framework for building federated learning systems. The design of Flower is based on a few guiding principles: customizability, extendability, framework agnosticity, and ease-of-use.</p> <p>Keywords: Federated learning systems, Customizable, Extendable, Framework-agnostic, Simplicity</p>"},{"location":"awesome-transformers/#fast-bert","title":"fast-bert","text":"<p>Fast-Bert is a deep learning library that allows developers and data scientists to train and deploy BERT and XLNet based models for natural language processing tasks beginning with Text Classification. It is aimed at simplicity.</p> <p>Keywords: Deployment, BERT, XLNet</p>"},{"location":"awesome-transformers/#towhee","title":"towhee","text":"<p>Towhee makes it easy to build neural data processing pipelines for AI applications. We provide hundreds of models, algorithms, and transformations that can be used as standard pipeline building blocks. Users can use Towhee's Pythonic API to build a prototype of their pipeline and automatically optimize it for production-ready environments.</p> <p>Keywords: Data processing pipeline, Optimization</p>"},{"location":"awesome-transformers/#alibi-detect","title":"alibi-detect","text":"<p>Alibi Detect is an open source Python library focused on outlier, adversarial and drift detection. The package aims to cover both online and offline detectors for tabular data, text, images and time series. Both TensorFlow and PyTorch backends are supported for drift detection.</p> <p>Keywords: Adversarial, Outlier, Drift detection</p>"},{"location":"awesome-transformers/#farm","title":"FARM","text":"<p>FARM makes Transfer Learning with BERT &amp; Co simple, fast and enterprise-ready. It's built upon transformers and provides additional features to simplify the life of developers: Parallelized preprocessing, highly modular design, multi-task learning, experiment tracking, easy debugging and close integration with AWS SageMaker.</p> <p>Keywords: Transfer Learning, Modular design, Multi-task learning, Experiment tracking</p>"},{"location":"awesome-transformers/#aitextgen","title":"aitextgen","text":"<p>A robust Python tool for text-based AI training and generation using OpenAI's GPT-2 and EleutherAI's GPT Neo/GPT-3 architecture. aitextgen is a Python package that leverages PyTorch, Hugging Face Transformers and pytorch-lightning with specific optimizations for text generation using GPT-2, plus many added features.</p> <p>Keywords: Training, Generation</p>"},{"location":"awesome-transformers/#diffgram","title":"diffgram","text":"<p>Diffgram aims to integrate human supervision into platforms. We support your team programmatically changing the UI (Schema, layout, etc.) like in Streamlit. This means that you can collect and annotate timely data from users. In other words, we are the platform behind your platform, an integrated part of your application, to ship new &amp; better AI products faster.</p> <p>Keywords: Human supervision, Platform</p>"},{"location":"awesome-transformers/#ecco","title":"ecco","text":"<p>Explain, analyze, and visualize NLP language models. Ecco creates interactive visualizations directly in Jupyter notebooks explaining the behavior of Transformer-based language models (like GPT2, BERT, RoBERTA, T5, and T0).</p> <p>Keywords: Model explainability</p>"},{"location":"awesome-transformers/#s3prl","title":"s3prl","text":"<p>s3prl stands for Self-Supervised Speech Pre-training and Representation Learning. Self-supervised speech pre-trained models are called upstream in this toolkit, and are utilized in various downstream tasks.</p> <p>Keywords: Speech, Training</p>"},{"location":"awesome-transformers/#ru-dalle","title":"ru-dalle","text":"<p>RuDALL-E aims to be similar to DALL-E, targeted to Russian.</p> <p>Keywords: DALL-E, Russian</p>"},{"location":"awesome-transformers/#deepke","title":"DeepKE","text":"<p>DeepKE is a knowledge extraction toolkit for knowledge graph construction supporting cnSchema\uff0clow-resource, document-level and multimodal scenarios for entity, relation and attribute extraction.</p> <p>Keywords: Knowledge Extraction, Knowledge Graphs</p>"},{"location":"awesome-transformers/#nebuly","title":"Nebuly","text":"<p>Nebuly is the next-generation platform to monitor and optimize your AI costs in one place. The platform connects to all your AI cost sources (compute, API providers, AI software licenses, etc) and centralizes them in one place to give you full visibility on a model basis. The platform also provides optimization recommendations and a co-pilot model that can guide during the optimization process. The platform builds on top of the open-source tools allowing you to optimize the different steps of your AI stack to squeeze out the best possible cost performances.</p> <p>Keywords: Optimization, Performance, Monitoring</p>"},{"location":"awesome-transformers/#imaginairy","title":"imaginAIry","text":"<p>Offers a CLI and a Python API to generate images with Stable Diffusion. It has support for many tools, like image structure control (controlnet), instruction-based image edits (InstructPix2Pix), prompt-based masking (clipseg), among others.</p> <p>Keywords: Stable Diffusion, CLI, Python API</p>"},{"location":"awesome-transformers/#sparseml","title":"sparseml","text":"<p>SparseML is an open-source model optimization toolkit that enables you to create inference-optimized sparse models using pruning, quantization, and distillation algorithms. Models optimized with SparseML can then be exported to the ONNX and deployed with DeepSparse for GPU-class performance on CPU hardware.</p> <p>Keywords: Model optimization, Pruning, Quantization, Distillation</p>"},{"location":"awesome-transformers/#opacus","title":"opacus","text":"<p>Opacus is a library that enables training PyTorch models with differential privacy. It supports training with minimal code changes required on the client, has little impact on training performance, and allows the client to online track the privacy budget expended at any given moment.</p> <p>Keywords: Differential privacy</p>"},{"location":"awesome-transformers/#lavis","title":"LAVIS","text":"<p>LAVIS is a Python deep learning library for LAnguage-and-VISion intelligence research and applications. This library aims to provide engineers and researchers with a one-stop solution to rapidly develop models for their specific multimodal scenarios, and benchmark them across standard and customized datasets. It features a unified interface design to access</p> <p>Keywords: Multimodal, NLP, Vision</p>"},{"location":"awesome-transformers/#buzz","title":"buzz","text":"<p>Buzz transcribes and translates audio offline on your personal computer. Powered by OpenAI's Whisper.</p> <p>Keywords: Audio transcription, Translation</p>"},{"location":"awesome-transformers/#rust-bert","title":"rust-bert","text":"<p>Rust-native state-of-the-art Natural Language Processing models and pipelines. Port of Hugging Face's Transformers library, using the tch-rs crate and pre-processing from rust-tokenizers. Supports multi-threaded tokenization and GPU inference. This repository exposes the model base architecture, task-specific heads and ready-to-use pipelines.</p> <p>Keywords: Rust, BERT, Inference</p>"},{"location":"awesome-transformers/#easynlp","title":"EasyNLP","text":"<p>EasyNLP is an easy-to-use NLP development and application toolkit in PyTorch, first released inside Alibaba in 2021. It is built with scalable distributed training strategies and supports a comprehensive suite of NLP algorithms for various NLP applications. EasyNLP integrates knowledge distillation and few-shot learning for landing large pre-trained models, together with various popular multi-modality pre-trained models. It provides a unified framework of model training, inference, and deployment for real-world applications.</p> <p>Keywords: NLP, Knowledge distillation, Few-shot learning, Multi-modality, Training, Inference, Deployment</p>"},{"location":"awesome-transformers/#turbotransformers","title":"TurboTransformers","text":"<p>A fast and user-friendly runtime for transformer inference (Bert, Albert, GPT2, Decoders, etc) on CPU and GPU.</p> <p>Keywords: Optimization, Performance</p>"},{"location":"awesome-transformers/#hivemind","title":"hivemind","text":"<p>Hivemind is a PyTorch library for decentralized deep learning across the Internet. Its intended usage is training one large model on hundreds of computers from different universities, companies, and volunteers.</p> <p>Keywords: Decentralized training</p>"},{"location":"awesome-transformers/#docquery","title":"docquery","text":"<p>DocQuery is a library and command-line tool that makes it easy to analyze semi-structured and unstructured documents (PDFs, scanned images, etc.) using large language models (LLMs). You simply point DocQuery at one or more documents and specify a question you want to ask. DocQuery is created by the team at Impira.</p> <p>Keywords: Semi-structured documents, Unstructured documents, LLM, Document Question Answering</p>"},{"location":"awesome-transformers/#codegeex","title":"CodeGeeX","text":"<p>CodeGeeX is a large-scale multilingual code generation model with 13 billion parameters, pre-trained on a large code corpus of more than 20 programming languages. It has several unique features: - Multilingual code generation - Crosslingual code translation - Is a customizable programming assistant</p> <p>Keywords: Code Generation Model</p>"},{"location":"awesome-transformers/#ktrain","title":"ktrain","text":"<p>ktrain is a lightweight wrapper for the deep learning library TensorFlow Keras (and other libraries) to help build, train, and deploy neural networks and other machine learning models. Inspired by ML framework extensions like fastai and ludwig, ktrain is designed to make deep learning and AI more accessible and easier to apply for both newcomers and experienced practitioners.</p> <p>Keywords: Keras wrapper, Model building, Training, Deployment</p>"},{"location":"awesome-transformers/#fastdeploy","title":"FastDeploy","text":"<p>FastDeploy is an Easy-to-use and High Performance AI model deployment toolkit for Cloud, Mobile and Edge with packageout-of-the-box and unified experience, endend-to-end optimization for over fire160+ Text, Vision, Speech and Cross-modal AI models. Including image classification, object detection, OCR, face detection, matting, pp-tracking, NLP, stable diffusion, TTS and other tasks to meet developers' industrial deployment needs for multi-scenario, multi-hardware and multi-platform.</p> <p>Keywords: Model deployment, CLoud, Mobile, Edge</p>"},{"location":"awesome-transformers/#underthesea","title":"underthesea","text":"<p>underthesea is a Vietnamese NLP toolkit. Underthesea is a suite of open source Python modules data sets and tutorials supporting research and development in Vietnamese Natural Language Processing. We provides extremely easy API to quickly apply pretrained NLP models to your Vietnamese text, such as word segmentation, part-of-speech tagging (PoS), named entity recognition (NER), text classification and dependency parsing.</p> <p>Keywords: Vietnamese, NLP</p>"},{"location":"awesome-transformers/#hasktorch","title":"hasktorch","text":"<p>Hasktorch is a library for tensors and neural networks in Haskell. It is an independent open source community project which leverages the core C++ libraries shared by PyTorch.</p> <p>Keywords: Haskell, Neural Networks</p>"},{"location":"awesome-transformers/#donut","title":"donut","text":"<p>Donut, or Document understanding transformer, is a new method of document understanding that utilizes an OCR-free end-to-end Transformer model.</p> <p>Donut does not require off-the-shelf OCR engines/APIs, yet it shows state-of-the-art performances on various visual document understanding tasks, such as visual document classification or information extraction (a.k.a. document parsing).</p> <p>Keywords: Document Understanding</p>"},{"location":"awesome-transformers/#transformers-interpret","title":"transformers-interpret","text":"<p>Transformers Interpret is a model explainability tool designed to work exclusively with the transformers package.</p> <p>In line with the philosophy of the Transformers package Transformers Interpret allows any transformers model to be explained in just two lines. Explainers are available for both text and computer vision models. Visualizations are also available in notebooks and as savable png and html files</p> <p>Keywords: Model interpretation, Visualization</p>"},{"location":"awesome-transformers/#mlrun","title":"mlrun","text":"<p>MLRun is an open MLOps platform for quickly building and managing continuous ML applications across their lifecycle. MLRun integrates into your development and CI/CD environment and automates the delivery of production data, ML pipelines, and online applications, significantly reducing engineering efforts, time to production, and computation resources. With MLRun, you can choose any IDE on your local machine or on the cloud. MLRun breaks the silos between data, ML, software, and DevOps/MLOps teams, enabling collaboration and fast continuous improvements.</p> <p>Keywords: MLOps</p>"},{"location":"awesome-transformers/#federatedscope","title":"FederatedScope","text":"<p>FederatedScope is a comprehensive federated learning platform that provides convenient usage and flexible customization for various federated learning tasks in both academia and industry. Based on an event-driven architecture, FederatedScope integrates rich collections of functionalities to satisfy the burgeoning demands from federated learning, and aims to build up an easy-to-use platform for promoting learning safely and effectively.</p> <p>Keywords: Federated learning, Event-driven</p>"},{"location":"awesome-transformers/#pythainlp","title":"pythainlp","text":"<p>PyThaiNLP is a Python package for text processing and linguistic analysis, similar to NLTK with focus on Thai language.</p> <p>Keywords: Thai, NLP, NLTK</p>"},{"location":"awesome-transformers/#flagai","title":"FlagAI","text":"<p>FlagAI (Fast LArge-scale General AI models) is a fast, easy-to-use and extensible toolkit for large-scale model. Our goal is to support training, fine-tuning, and deployment of large-scale models on various downstream tasks with multi-modality.</p> <p>Keywords: Large models, Training, Fine-tuning, Deployment, Multi-modal</p>"},{"location":"awesome-transformers/#pyserini","title":"pyserini","text":"<p>pyserini is a Python toolkit for reproducible information retrieval research with sparse and dense representations. Retrieval using sparse representations is provided via integration with the group's Anserini IR toolkit. Retrieval using dense representations is provided via integration with Facebook's Faiss library.</p> <p>Keywords: IR, Information Retrieval, Dense, Sparse</p>"},{"location":"awesome-transformers/#baal","title":"baal","text":"<p>baal is an active learning library that supports both industrial applications and research usecases. baal currently supports Monte-Carlo Dropout, MCDropConnect, deep ensembles, and semi-supervised learning.</p> <p>Keywords: Active Learning, Research, Labeling</p>"},{"location":"awesome-transformers/#cleanlab","title":"cleanlab","text":"<p>cleanlab is the standard data-centric AI package for data quality and machine learning with messy, real-world data and labels. For text, image, tabular, audio (among others) datasets, you can use cleanlab to automatically: detect data issues (outliers, label errors, near duplicates, etc), train robust ML models, infer consensus + annotator-quality for multi-annotator data, suggest data to (re)label next (active learning).</p> <p>Keywords: Data-Centric AI, Data Quality, Noisy Labels, Outlier Detection, Active Learning  </p>"},{"location":"awesome-transformers/#bentoml","title":"BentoML","text":"<p>BentoML is the unified framework for for building, shipping, and scaling production-ready AI applications incorporating traditional ML, pre-trained AI models, Generative and Large Language Models.  All Hugging Face models and pipelines can be seamlessly integrated into BentoML applications, enabling the running of models on the most suitable hardware and independent scaling based on usage.</p> <p>Keywords: BentoML, Framework, Deployment, AI Applications</p>"},{"location":"awesome-transformers/#llama-efficient-tuning","title":"LLaMA-Efficient-Tuning","text":"<p>LLaMA-Efficient-Tuning offers a user-friendly fine-tuning framework that incorporates PEFT. The repository includes training(fine-tuning) and inference examples for LLaMA-2, BLOOM, Falcon, Baichuan, Qwen, and other LLMs. A ChatGLM version is also available in ChatGLM-Efficient-Tuning.</p> <p>Keywords: PEFT, fine-tuning, LLaMA-2, ChatGLM, Qwen</p>"},{"location":"big_models/","title":"Big models","text":""},{"location":"big_models/#_1","title":"\u5b9e\u4f8b\u200b\u5316\u200b\u5927\u578b\u200b\u6a21\u578b","text":"<p>\u200b\u5f53\u200b\u4f60\u200b\u60f3\u200b\u4f7f\u7528\u200b\u4e00\u4e2a\u200b\u975e\u5e38\u200b\u5927\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u4e00\u4e2a\u200b\u6311\u6218\u200b\u662f\u200b\u5c3d\u91cf\u51cf\u5c11\u200b\u5bf9\u200b\u5185\u5b58\u200b\u7684\u200b\u4f7f\u7528\u200b\u3002\u200b\u901a\u5e38\u200b\u4ece\u200bPyTorch\u200b\u5f00\u59cb\u200b\u7684\u200b\u5de5\u4f5c\u200b\u6d41\u7a0b\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u7528\u200b\u968f\u673a\u200b\u6743\u91cd\u200b\u521b\u5efa\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u3002</li> <li>\u200b\u52a0\u8f7d\u200b\u4f60\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\u3002</li> <li>\u200b\u5c06\u200b\u8fd9\u4e9b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\u653e\u5165\u200b\u4f60\u200b\u7684\u200b\u968f\u673a\u200b\u6a21\u578b\u200b\u4e2d\u200b\u3002</li> </ol> <p>\u200b\u6b65\u9aa4\u200b1\u200b\u548c\u200b2\u200b\u90fd\u200b\u9700\u8981\u200b\u5b8c\u6574\u200b\u7248\u672c\u200b\u7684\u200b\u6a21\u578b\u200b\u5728\u200b\u5185\u5b58\u200b\u4e2d\u200b\uff0c\u200b\u8fd9\u200b\u5728\u200b\u5927\u591a\u6570\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4e0d\u662f\u200b\u95ee\u9898\u200b\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u5f00\u59cb\u200b\u8fbe\u5230\u200b\u51e0\u4e2a\u200bGB\u200b\u7684\u200b\u5927\u5c0f\u200b\uff0c\u200b\u8fd9\u200b\u4e24\u4e2a\u200b\u526f\u672c\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u8ba9\u200b\u4f60\u200b\u8d85\u51fa\u200b\u5185\u5b58\u200b\u7684\u200b\u9650\u5236\u200b\u3002\u200b\u66f4\u200b\u7cdf\u7cd5\u200b\u7684\u200b\u662f\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u4f7f\u7528\u200b<code>torch.distributed</code>\u200b\u6765\u200b\u542f\u52a8\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u8fdb\u7a0b\u200b\u90fd\u200b\u4f1a\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u5e76\u200b\u5c06\u200b\u8fd9\u200b\u4e24\u4e2a\u200b\u526f\u672c\u200b\u5b58\u50a8\u200b\u5728\u200b\u5185\u5b58\u200b\u4e2d\u200b\u3002</p> <p> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u968f\u673a\u200b\u521b\u5efa\u200b\u7684\u200b\u6a21\u578b\u200b\u4f7f\u7528\u200b\u201c\u200b\u7a7a\u200b\u201d\u200b\u5f20\u91cf\u200b\u8fdb\u884c\u200b\u521d\u59cb\u5316\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u5f20\u91cf\u200b\u5360\u7528\u200b\u5185\u5b58\u7a7a\u95f4\u200b\u4f46\u200b\u4e0d\u200b\u586b\u5145\u200b\u5b83\u200b\uff08\u200b\u56e0\u6b64\u200b\u968f\u673a\u200b\u503c\u200b\u662f\u200b\u7ed9\u5b9a\u200b\u65f6\u95f4\u200b\u5185\u8be5\u200b\u5185\u5b58\u200b\u5757\u200b\u4e2d\u200b\u7684\u200b\u4efb\u4f55\u200b\u5185\u5bb9\u200b\uff09\u3002\u200b\u5728\u200b\u7b2c\u200b3\u200b\u6b65\u200b\u4e4b\u540e\u200b\uff0c\u200b\u5bf9\u200b\u672a\u200b\u521d\u59cb\u5316\u200b\u7684\u200b\u6743\u91cd\u200b\u6267\u884c\u200b\u9002\u5408\u200b\u6a21\u578b\u200b/\u200b\u53c2\u6570\u200b\u79cd\u7c7b\u200b\u7684\u200b\u968f\u673a\u200b\u521d\u59cb\u5316\u200b\uff08\u200b\u4f8b\u5982\u200b\u6b63\u6001\u5206\u5e03\u200b\uff09\uff0c\u200b\u4ee5\u200b\u5c3d\u53ef\u80fd\u200b\u63d0\u9ad8\u200b\u901f\u5ea6\u200b\uff01</p> <p></p> <p>\u200b\u5728\u200b\u672c\u200b\u6307\u5357\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u63a2\u8ba8\u200b Transformers \u200b\u63d0\u4f9b\u200b\u7684\u200b\u89e3\u51b3\u65b9\u6848\u200b\u6765\u200b\u5904\u7406\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\u3002\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u79ef\u6781\u200b\u5f00\u53d1\u200b\u7684\u200b\u9886\u57df\u200b\uff0c\u200b\u56e0\u6b64\u200b\u8fd9\u91cc\u200b\u89e3\u91ca\u200b\u7684\u200bAPI\u200b\u5728\u200b\u5c06\u6765\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u7565\u6709\u200b\u53d8\u5316\u200b\u3002</p>"},{"location":"big_models/#checkpoints","title":"\u5206\u7247\u200bcheckpoints","text":"<p>\u200b\u81ea\u200b4.18.0\u200b\u7248\u672c\u200b\u8d77\u200b\uff0c\u200b\u5360\u7528\u200b\u7a7a\u95f4\u200b\u8d85\u8fc7\u200b10GB\u200b\u7684\u200b\u6a21\u578b\u200b\u68c0\u67e5\u70b9\u200b\u5c06\u200b\u81ea\u52a8\u200b\u5206\u6210\u200b\u8f83\u200b\u5c0f\u200b\u7684\u200b\u7247\u6bb5\u200b\u3002\u200b\u5728\u200b\u4f7f\u7528\u200b<code>model.save_pretrained(save_dir)</code>\u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u6700\u7ec8\u200b\u4f1a\u200b\u5f97\u5230\u200b\u51e0\u4e2a\u200b\u90e8\u5206\u200b<code>checkpoints</code>\uff08\u200b\u6bcf\u4e2a\u200b\u7684\u200b\u5927\u5c0f\u200b\u90fd\u200b\u5c0f\u4e8e\u200b10GB\uff09\u200b\u4ee5\u53ca\u200b\u4e00\u4e2a\u200b\u7d22\u5f15\u200b\uff0c\u200b\u8be5\u200b\u7d22\u5f15\u200b\u5c06\u200b\u53c2\u6570\u200b\u540d\u79f0\u200b\u6620\u5c04\u200b\u5230\u200b\u5b58\u50a8\u200b\u5b83\u4eec\u200b\u7684\u200b\u6587\u4ef6\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b<code>max_shard_size</code>\u200b\u53c2\u6570\u200b\u6765\u200b\u63a7\u5236\u200b\u5206\u7247\u200b\u4e4b\u524d\u200b\u7684\u200b\u6700\u5927\u200b\u5927\u5c0f\u200b\u3002\u200b\u4e3a\u4e86\u200b\u793a\u4f8b\u200b\u7684\u200b\u76ee\u7684\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4f7f\u7528\u200b\u5177\u6709\u200b\u8f83\u200b\u5c0f\u200b\u5206\u7247\u200b\u5927\u5c0f\u200b\u7684\u200b\u666e\u901a\u200b\u5927\u5c0f\u200b\u7684\u200b\u6a21\u578b\u200b\uff1a\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4ee5\u200b\u4f20\u7edf\u200b\u7684\u200bBERT\u200b\u6a21\u578b\u200b\u4e3a\u4f8b\u200b\u3002</p> <pre><code>from transformers import AutoModel\n\nmodel = AutoModel.from_pretrained(\"bert-base-cased\")\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u4f7f\u7528\u200b <code>PreTrainedModel.save_pretrained</code> \u200b\u8fdb\u884c\u200b\u4fdd\u5b58\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u5f97\u5230\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b\u6587\u4ef6\u5939\u200b\uff0c\u200b\u5176\u4e2d\u200b\u5305\u542b\u200b\u4e24\u4e2a\u200b\u6587\u4ef6\u200b\uff1a\u200b\u6a21\u578b\u200b\u7684\u200b\u914d\u7f6e\u200b\u548c\u200b\u6743\u91cd\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; import os\n&gt;&gt;&gt; import tempfile\n\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmp_dir:\n...     model.save_pretrained(tmp_dir)\n...     print(sorted(os.listdir(tmp_dir)))\n['config.json', 'pytorch_model.bin']\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b\u6700\u5927\u200b\u5206\u7247\u200b\u5927\u5c0f\u200b\u4e3a\u200b200MB\uff1a</p> <pre><code>&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmp_dir:\n...     model.save_pretrained(tmp_dir, max_shard_size=\"200MB\")\n...     print(sorted(os.listdir(tmp_dir)))\n['config.json', 'pytorch_model-00001-of-00003.bin', 'pytorch_model-00002-of-00003.bin', 'pytorch_model-00003-of-00003.bin', 'pytorch_model.bin.index.json']\n</code></pre> <p>\u200b\u5728\u200b\u6a21\u578b\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u6700\u200b\u4e0a\u65b9\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200b\u4e09\u4e2a\u200b\u4e0d\u540c\u200b\u7684\u200b\u6743\u91cd\u200b\u6587\u4ef6\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u4e00\u4e2a\u200b<code>index.json</code>\u200b\u7d22\u5f15\u200b\u6587\u4ef6\u200b\u3002\u200b\u8fd9\u6837\u200b\u7684\u200b<code>checkpoint</code>\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b<code>[~PreTrainedModel.from_pretrained]</code>\u200b\u65b9\u6cd5\u200b\u5b8c\u5168\u200b\u91cd\u65b0\u200b\u52a0\u8f7d\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmp_dir:\n...     model.save_pretrained(tmp_dir, max_shard_size=\"200MB\")\n...     new_model = AutoModel.from_pretrained(tmp_dir)\n</code></pre> <p>\u200b\u5bf9\u4e8e\u200b\u5927\u578b\u200b\u6a21\u578b\u200b\u6765\u8bf4\u200b\uff0c\u200b\u8fd9\u6837\u200b\u505a\u200b\u7684\u200b\u4e3b\u8981\u200b\u4f18\u70b9\u200b\u662f\u200b\u5728\u200b\u4e0a\u8ff0\u200b\u5de5\u4f5c\u200b\u6d41\u7a0b\u200b\u7684\u200b\u6b65\u9aa4\u200b2\u200b\u4e2d\u200b\uff0c\u200b\u6bcf\u4e2a\u200b<code>checkpoint</code>\u200b\u7684\u200b\u5206\u7247\u200b\u5728\u200b\u524d\u200b\u4e00\u4e2a\u200b\u5206\u7247\u200b\u4e4b\u540e\u200b\u52a0\u8f7d\u200b\uff0c\u200b\u4ece\u800c\u200b\u5c06\u200b\u5185\u5b58\u200b\u4e2d\u200b\u7684\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u9650\u5236\u200b\u5728\u200b\u6a21\u578b\u200b\u5927\u5c0f\u200b\u52a0\u4e0a\u200b\u6700\u5927\u200b\u5206\u7247\u200b\u7684\u200b\u5927\u5c0f\u200b\u3002</p> <p>\u200b\u5728\u200b\u540e\u53f0\u200b\uff0c\u200b\u7d22\u5f15\u200b\u6587\u4ef6\u200b\u7528\u4e8e\u200b\u786e\u5b9a\u200b<code>checkpoint</code>\u200b\u4e2d\u200b\u5305\u542b\u200b\u54ea\u4e9b\u200b\u952e\u200b\u4ee5\u53ca\u200b\u76f8\u5e94\u200b\u7684\u200b\u6743\u91cd\u200b\u5b58\u50a8\u200b\u5728\u200b\u54ea\u91cc\u200b\u3002\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u50cf\u200b\u52a0\u8f7d\u200b\u4efb\u4f55\u200bjson\u200b\u4e00\u6837\u200b\u52a0\u8f7d\u200b\u8be5\u200b\u7d22\u5f15\u200b\uff0c\u200b\u5e76\u200b\u83b7\u5f97\u200b\u4e00\u4e2a\u200b\u5b57\u5178\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; import json\n\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmp_dir:\n...     model.save_pretrained(tmp_dir, max_shard_size=\"200MB\")\n...     with open(os.path.join(tmp_dir, \"pytorch_model.bin.index.json\"), \"r\") as f:\n...         index = json.load(f)\n\n&gt;&gt;&gt; print(index.keys())\ndict_keys(['metadata', 'weight_map'])\n</code></pre> <p>\u200b\u76ee\u524d\u200b\u5143\u200b\u6570\u636e\u200b\u4ec5\u200b\u5305\u62ec\u200b\u6a21\u578b\u200b\u7684\u200b\u603b\u200b\u5927\u5c0f\u200b\u3002\u200b\u6211\u4eec\u200b\u8ba1\u5212\u200b\u5728\u200b\u5c06\u6765\u200b\u6dfb\u52a0\u200b\u5176\u4ed6\u200b\u4fe1\u606f\u200b\uff1a <pre><code>&gt;&gt;&gt; index[\"metadata\"]\n{'total_size': 433245184}\n</code></pre></p> <p>\u200b\u6743\u91cd\u200b\u6620\u5c04\u200b\u662f\u200b\u8be5\u200b\u7d22\u5f15\u200b\u7684\u200b\u4e3b\u8981\u200b\u90e8\u5206\u200b\uff0c\u200b\u5b83\u200b\u5c06\u200b\u6bcf\u4e2a\u200b\u53c2\u6570\u200b\u7684\u200b\u540d\u79f0\u200b\uff08\u200b\u901a\u5e38\u200b\u5728\u200bPyTorch\u200b\u6a21\u578b\u200b\u7684\u200b<code>state_dict</code>\u200b\u4e2d\u200b\u627e\u5230\u200b\uff09\u200b\u6620\u5c04\u200b\u5230\u200b\u5b58\u50a8\u200b\u8be5\u200b\u53c2\u6570\u200b\u7684\u200b\u6587\u4ef6\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; index[\"weight_map\"]\n{'embeddings.LayerNorm.bias': 'pytorch_model-00001-of-00003.bin',\n 'embeddings.LayerNorm.weight': 'pytorch_model-00001-of-00003.bin',\n ...\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u76f4\u63a5\u200b\u5728\u200b\u6a21\u578b\u200b\u5185\u90e8\u200b\u52a0\u8f7d\u200b\u8fd9\u6837\u200b\u7684\u200b\u5206\u7247\u200b<code>checkpoint</code>\uff0c\u200b\u800c\u200b\u4e0d\u200b\u4f7f\u7528\u200b <code>PreTrainedModel.from_pretrained</code>\uff0c\u200b\u60a8\u200b\u5e94\u8be5\u200b\u4f7f\u7528\u200b [<code>modeling_utils.load_sharded_checkpoint</code>]\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers.modeling_utils import load_sharded_checkpoint\n\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmp_dir:\n...     model.save_pretrained(tmp_dir, max_shard_size=\"200MB\")\n...     load_sharded_checkpoint(model, tmp_dir)\n</code></pre>"},{"location":"big_models/#_2","title":"\u4f4e\u200b\u5185\u5b58\u200b\u52a0\u8f7d","text":"<p>\u200b\u5206\u7247\u200b<code>checkpoints</code>\u200b\u5728\u200b\u4e0a\u8ff0\u200b\u5de5\u4f5c\u200b\u6d41\u200b\u7684\u200b\u7b2c\u200b2\u200b\u6b65\u4e2d\u200b\u964d\u4f4e\u200b\u4e86\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\uff0c\u200b\u4f46\u200b\u4e3a\u4e86\u200b\u5728\u200b\u4f4e\u200b\u5185\u5b58\u200b\u73af\u5883\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u8be5\u200b\u6a21\u578b\u200b\uff0c\u200b\u6211\u4eec\u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200b\u57fa\u4e8e\u200b Accelerate \u200b\u5e93\u200b\u7684\u200b\u5de5\u5177\u200b\u3002</p> <p>\u200b\u8bf7\u200b\u9605\u8bfb\u200b\u4ee5\u4e0b\u200b\u6307\u5357\u200b\u4ee5\u200b\u83b7\u53d6\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff1a\u200b\u4f7f\u7528\u200b Accelerate \u200b\u8fdb\u884c\u200b\u5927\u200b\u6a21\u578b\u200b\u52a0\u8f7d\u200b</p>"},{"location":"debugging/","title":"Debugging","text":""},{"location":"debugging/#_1","title":"\u8c03\u8bd5","text":""},{"location":"debugging/#gpu","title":"\u591a\u200bGPU\u200b\u7f51\u7edc\u200b\u95ee\u9898\u200b\u8c03\u8bd5","text":"<p>\u200b\u5f53\u200b\u4f7f\u7528\u200b<code>DistributedDataParallel</code>\u200b\u548c\u200b\u591a\u4e2a\u200bGPU\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u6216\u200b\u63a8\u7406\u200b\u65f6\u200b\uff0c\u200b\u5982\u679c\u200b\u9047\u5230\u200b\u8fdb\u7a0b\u200b\u548c\u200b\uff08\u200b\u6216\u200b\uff09\u200b\u8282\u70b9\u200b\u4e4b\u95f4\u200b\u7684\u200b\u4e92\u8054\u200b\u95ee\u9898\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u811a\u672c\u200b\u6765\u200b\u8bca\u65ad\u200b\u7f51\u7edc\u200b\u95ee\u9898\u200b\u3002</p> <pre><code>wget https://raw.githubusercontent.com/huggingface/transformers/main/scripts/distributed/torch-distributed-gpu-test.py\n</code></pre> <p>\u200b\u4f8b\u5982\u200b\uff0c\u200b\u8981\u200b\u6d4b\u8bd5\u200b\u4e24\u4e2a\u200bGPU\u200b\u4e4b\u95f4\u200b\u7684\u200b\u4e92\u8054\u200b\uff0c\u200b\u8bf7\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\uff1a</p> <pre><code>python -m torch.distributed.run --nproc_per_node 2 --nnodes 1 torch-distributed-gpu-test.py\n</code></pre> <p>\u200b\u5982\u679c\u200b\u4e24\u4e2a\u200b\u8fdb\u7a0b\u200b\u80fd\u591f\u200b\u76f8\u4e92\u200b\u901a\u4fe1\u200b\u5e76\u200b\u5206\u914d\u200bGPU\u200b\u5185\u5b58\u200b\uff0c\u200b\u5b83\u4eec\u200b\u5404\u81ea\u200b\u5c06\u200b\u6253\u5370\u200b\u51fa\u200b \"OK\" \u200b\u72b6\u6001\u200b\u3002</p> <p>\u200b\u5bf9\u4e8e\u200b\u66f4\u200b\u591a\u200b\u7684\u200bGPU\u200b\u6216\u200b\u8282\u70b9\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u6839\u636e\u200b\u811a\u672c\u200b\u4e2d\u200b\u7684\u200b\u53c2\u6570\u200b\u8fdb\u884c\u200b\u8c03\u6574\u200b\u3002</p> <p>\u200b\u5728\u200b\u8bca\u65ad\u200b\u811a\u672c\u200b\u5185\u90e8\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u627e\u5230\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u751a\u81f3\u200b\u6709\u5173\u200b\u5982\u4f55\u200b\u5728\u200bSLURM\u200b\u73af\u5883\u4e2d\u8fd0\u884c\u200b\u5b83\u200b\u7684\u200b\u8bf4\u660e\u200b\u3002</p> <p>\u200b\u53e6\u200b\u4e00\u79cd\u200b\u7ea7\u522b\u200b\u7684\u200b\u8c03\u8bd5\u200b\u662f\u200b\u6dfb\u52a0\u200b <code>NCCL_DEBUG=INFO</code> \u200b\u73af\u5883\u53d8\u91cf\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>NCCL_DEBUG=INFO python -m torch.distributed.run --nproc_per_node 2 --nnodes 1 torch-distributed-gpu-test.py\n</code></pre> <p>\u200b\u8fd9\u200b\u5c06\u200b\u4ea7\u751f\u200b\u5927\u91cf\u200b\u4e0e\u200bNCCL\u200b\u76f8\u5173\u200b\u7684\u200b\u8c03\u8bd5\u4fe1\u606f\u200b\uff0c\u200b\u5982\u679c\u200b\u53d1\u73b0\u200b\u6709\u200b\u95ee\u9898\u200b\u62a5\u544a\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u7ebf\u200b\u641c\u7d22\u200b\u4ee5\u200b\u83b7\u53d6\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u3002\u200b\u6216\u8005\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u4e0d\u200b\u786e\u5b9a\u200b\u5982\u4f55\u200b\u89e3\u91ca\u200b\u8f93\u51fa\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5728\u200b<code>issue</code>\u200b\u4e2d\u200b\u5206\u4eab\u200b\u65e5\u5fd7\u200b\u6587\u4ef6\u200b\u3002</p>"},{"location":"debugging/#_2","title":"\u4e0b\u6ea2\u200b\u548c\u200b\u4e0a\u6ea2\u200b\u68c0\u6d4b","text":"<p> <p>\u200b\u76ee\u524d\u200b\uff0c\u200b\u6b64\u200b\u529f\u80fd\u200b\u4ec5\u200b\u9002\u7528\u200b\u4e8e\u200bPyTorch\u3002</p> <p></p> <p> <p>\u200b\u5bf9\u4e8e\u200b\u591a\u200bGPU\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u5b83\u200b\u9700\u8981\u200b\u4f7f\u7528\u200bDDP\uff08<code>torch.distributed.launch</code>\uff09\u3002</p> <p></p> <p> <p>\u200b\u6b64\u200b\u529f\u80fd\u200b\u53ef\u4ee5\u200b\u4e0e\u200b\u4efb\u4f55\u200b\u57fa\u4e8e\u200b<code>nn.Module</code>\u200b\u7684\u200b\u6a21\u578b\u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\u3002</p> <p></p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u5f00\u59cb\u200b\u53d1\u73b0\u200b<code>loss=NaN</code>\u200b\u6216\u200b\u6a21\u578b\u200b\u56e0\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u6216\u200b\u6743\u91cd\u200b\u4e2d\u200b\u7684\u200b<code>inf</code>\u200b\u6216\u200b<code>nan</code>\u200b\u800c\u200b\u51fa\u73b0\u200b\u4e00\u4e9b\u200b\u5f02\u5e38\u200b\u884c\u4e3a\u200b\uff0c\u200b\u5c31\u200b\u9700\u8981\u200b\u53d1\u73b0\u200b\u7b2c\u4e00\u4e2a\u200b\u4e0b\u6ea2\u200b\u6216\u200b\u4e0a\u6ea2\u200b\u53d1\u751f\u200b\u7684\u200b\u5730\u65b9\u200b\u4ee5\u53ca\u200b\u5bfc\u81f4\u200b\u5b83\u200b\u7684\u200b\u539f\u56e0\u200b\u3002\u200b\u5e78\u8fd0\u200b\u7684\u200b\u662f\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u6fc0\u6d3b\u200b\u4e00\u4e2a\u200b\u7279\u6b8a\u200b\u6a21\u5757\u200b\u6765\u200b\u81ea\u52a8\u200b\u8fdb\u884c\u200b\u68c0\u6d4b\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u6b63\u5728\u200b\u4f7f\u7528\u200b[<code>Trainer</code>]\uff0c\u200b\u53ea\u200b\u9700\u200b\u628a\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a</p> <pre><code>--debug underflow_overflow\n</code></pre> <p>\u200b\u6dfb\u52a0\u200b\u5230\u200b\u5e38\u89c4\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u4e2d\u200b\uff0c\u200b\u6216\u200b\u5728\u200b\u521b\u5efa\u200b[<code>TrainingArguments</code>]\u200b\u5bf9\u8c61\u200b\u65f6\u200b\u4f20\u9012\u200b <code>debug=\"underflow_overflow\"</code>\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u6b63\u5728\u200b\u4f7f\u7528\u200b\u81ea\u5df1\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u6216\u200b\u5176\u4ed6\u200bTrainer\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u5b9e\u73b0\u200b\u76f8\u540c\u200b\u7684\u200b\u529f\u80fd\u200b\uff1a</p> <pre><code>from transformers.debug_utils import DebugUnderflowOverflow\n\ndebug_overflow = DebugUnderflowOverflow(model)\n</code></pre> <p>[<code>debug_utils.DebugUnderflowOverflow</code>] \u200b\u5c06\u200b<code>hooks</code>\u200b\u63d2\u5165\u200b\u6a21\u578b\u200b\uff0c\u200b\u7d27\u8ddf\u200b\u5728\u200b\u6bcf\u6b21\u200b\u524d\u5411\u200b\u8c03\u7528\u200b\u4e4b\u540e\u200b\uff0c\u200b\u8fdb\u800c\u200b\u6d4b\u8bd5\u200b\u8f93\u5165\u200b\u548c\u200b\u8f93\u51fa\u200b\u53d8\u91cf\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u76f8\u5e94\u200b\u6a21\u5757\u200b\u7684\u200b\u6743\u91cd\u200b\u3002\u200b\u4e00\u65e6\u200b\u5728\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u6216\u200b\u6743\u91cd\u200b\u7684\u200b\u81f3\u5c11\u200b\u4e00\u4e2a\u200b\u5143\u7d20\u200b\u4e2d\u200b\u68c0\u6d4b\u200b\u5230\u200b<code>inf</code>\u200b\u6216\u200b<code>nan</code>\uff0c\u200b\u7a0b\u5e8f\u200b\u5c06\u200b\u6267\u884c\u200b<code>assert</code>\u200b\u5e76\u6253\u5370\u200b\u62a5\u544a\u200b\uff0c\u200b\u5c31\u200b\u50cf\u200b\u8fd9\u6837\u200b\uff08\u200b\u8fd9\u200b\u662f\u200b\u5728\u200b<code>google/mt5-small</code>\u200b\u4e0b\u200b\u4f7f\u7528\u200bfp16\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u6355\u83b7\u200b\u7684\u200b\uff09\uff1a</p> <pre><code>Detected inf/nan during batch_number=0\nLast 21 forward frames:\nabs min  abs max  metadata\n                  encoder.block.1.layer.1.DenseReluDense.dropout Dropout\n0.00e+00 2.57e+02 input[0]\n0.00e+00 2.85e+02 output\n[...]\n                  encoder.block.2.layer.0 T5LayerSelfAttention\n6.78e-04 3.15e+03 input[0]\n2.65e-04 3.42e+03 output[0]\n             None output[1]\n2.25e-01 1.00e+04 output[2]\n                  encoder.block.2.layer.1.layer_norm T5LayerNorm\n8.69e-02 4.18e-01 weight\n2.65e-04 3.42e+03 input[0]\n1.79e-06 4.65e+00 output\n                  encoder.block.2.layer.1.DenseReluDense.wi_0 Linear\n2.17e-07 4.50e+00 weight\n1.79e-06 4.65e+00 input[0]\n2.68e-06 3.70e+01 output\n                  encoder.block.2.layer.1.DenseReluDense.wi_1 Linear\n8.08e-07 2.66e+01 weight\n1.79e-06 4.65e+00 input[0]\n1.27e-04 2.37e+02 output\n                  encoder.block.2.layer.1.DenseReluDense.dropout Dropout\n0.00e+00 8.76e+03 input[0]\n0.00e+00 9.74e+03 output\n                  encoder.block.2.layer.1.DenseReluDense.wo Linear\n1.01e-06 6.44e+00 weight\n0.00e+00 9.74e+03 input[0]\n3.18e-04 6.27e+04 output\n                  encoder.block.2.layer.1.DenseReluDense T5DenseGatedGeluDense\n1.79e-06 4.65e+00 input[0]\n3.18e-04 6.27e+04 output\n                  encoder.block.2.layer.1.dropout Dropout\n3.18e-04 6.27e+04 input[0]\n0.00e+00      inf output\n</code></pre> <p>\u200b\u7531\u4e8e\u200b\u7bc7\u5e45\u200b\u539f\u56e0\u200b\uff0c\u200b\u793a\u4f8b\u200b\u8f93\u51fa\u200b\u4e2d\u95f4\u200b\u7684\u200b\u90e8\u5206\u200b\u5df2\u7ecf\u200b\u88ab\u200b\u7f29\u51cf\u200b\u3002</p> <p>\u200b\u7b2c\u4e8c\u5217\u200b\u663e\u793a\u200b\u4e86\u200b\u7edd\u5bf9\u200b\u6700\u5927\u200b\u5143\u7d20\u200b\u7684\u200b\u503c\u200b\uff0c\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u4ed4\u7ec6\u200b\u67e5\u770b\u200b\u6700\u540e\u200b<code>frame</code>\uff0c\u200b\u8f93\u5165\u200b\u548c\u200b\u8f93\u51fa\u200b\u90fd\u200b\u5728\u200b<code>1e4</code>\u200b\u7684\u200b\u8303\u56f4\u200b\u5185\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5728\u200b\u4f7f\u7528\u200bfp16\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u65f6\u200b\uff0c\u200b\u6700\u540e\u200b\u4e00\u6b65\u200b\u53d1\u751f\u200b\u4e86\u200b\u6ea2\u51fa\u200b\uff08\u200b\u56e0\u4e3a\u200b\u5728\u200b<code>fp16</code>\u200b\u4e0b\u200b\uff0c\u200b\u5728\u200b<code>inf</code>\u200b\u4e4b\u524d\u200b\u7684\u200b\u6700\u5927\u200b\u6570\u5b57\u200b\u662f\u200b<code>64e3</code>\uff09\u3002\u200b\u4e3a\u4e86\u200b\u907f\u514d\u200b\u5728\u200b<code>fp16</code>\u200b\u4e0b\u200b\u53d1\u751f\u200b\u6ea2\u51fa\u200b\uff0c\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u5fc5\u987b\u200b\u4fdd\u6301\u200b\u4f4e\u4e8e\u200b<code>1e4</code>\uff0c\u200b\u56e0\u4e3a\u200b<code>1e4 * 1e4 = 1e8</code>\uff0c\u200b\u56e0\u6b64\u200b\u4efb\u4f55\u200b\u5177\u6709\u200b\u5927\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u7684\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b\u90fd\u200b\u4f1a\u200b\u5bfc\u81f4\u200b\u6570\u503c\u200b\u6ea2\u51fa\u200b\u3002</p> <p>\u200b\u5728\u200b\u8ddf\u8e2a\u200b\u7684\u200b\u5f00\u59cb\u200b\u5904\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u53d1\u73b0\u200b\u95ee\u9898\u200b\u53d1\u751f\u200b\u5728\u200b\u54ea\u4e2a\u200b\u6279\u6b21\u200b\uff08\u200b\u8fd9\u91cc\u200b\u7684\u200b<code>Detected inf/nan during batch_number=0</code>\u200b\u8868\u793a\u200b\u95ee\u9898\u200b\u53d1\u751f\u200b\u5728\u200b\u7b2c\u4e00\u4e2a\u200b\u6279\u6b21\u200b\uff09\u3002</p> <p>\u200b\u6bcf\u4e2a\u200b\u62a5\u544a\u200b\u7684\u200b<code>frame</code>\u200b\u90fd\u200b\u4ee5\u200b\u58f0\u660e\u200b\u76f8\u5e94\u200b\u6a21\u5757\u200b\u7684\u200b\u5c42\u200b\u4fe1\u606f\u200b\u4e3a\u200b\u5f00\u5934\u200b\uff0c\u200b\u8bf4\u660e\u200b\u8fd9\u4e00\u200b<code>frame</code>\u200b\u662f\u200b\u4e3a\u200b\u54ea\u4e2a\u200b\u6a21\u5757\u200b\u62a5\u544a\u200b\u7684\u200b\u3002\u200b\u5982\u679c\u200b\u53ea\u200b\u770b\u200b\u8fd9\u4e2a\u200b<code>frame</code>\uff1a</p> <pre><code>                  encoder.block.2.layer.1.layer_norm T5LayerNorm\n8.69e-02 4.18e-01 weight\n2.65e-04 3.42e+03 input[0]\n1.79e-06 4.65e+00 output\n</code></pre> <p>\u200b\u5728\u200b\u8fd9\u91cc\u200b\uff0c<code>encoder.block.2.layer.1.layer_norm</code> \u200b\u8868\u793a\u200b\u5b83\u200b\u662f\u200b\u7f16\u7801\u5668\u200b\u7684\u200b\u7b2c\u4e8c\u4e2a\u200b\u5757\u200b\u4e2d\u200b\u7b2c\u4e00\u5c42\u200b\u7684\u200b<code>layer norm</code>\u3002\u200b\u800c\u200b <code>forward</code> \u200b\u7684\u200b\u5177\u4f53\u200b\u8c03\u7528\u200b\u662f\u200b <code>T5LayerNorm</code>\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u770b\u770b\u200b\u8be5\u200b\u62a5\u544a\u200b\u7684\u200b\u6700\u540e\u200b\u51e0\u4e2a\u200b<code>frame</code>\uff1a</p> <pre><code>Detected inf/nan during batch_number=0\nLast 21 forward frames:\nabs min  abs max  metadata\n[...]\n                  encoder.block.2.layer.1.DenseReluDense.wi_0 Linear\n2.17e-07 4.50e+00 weight\n1.79e-06 4.65e+00 input[0]\n2.68e-06 3.70e+01 output\n                  encoder.block.2.layer.1.DenseReluDense.wi_1 Linear\n8.08e-07 2.66e+01 weight\n1.79e-06 4.65e+00 input[0]\n1.27e-04 2.37e+02 output\n                  encoder.block.2.layer.1.DenseReluDense.wo Linear\n1.01e-06 6.44e+00 weight\n0.00e+00 9.74e+03 input[0]\n3.18e-04 6.27e+04 output\n                  encoder.block.2.layer.1.DenseReluDense T5DenseGatedGeluDense\n1.79e-06 4.65e+00 input[0]\n3.18e-04 6.27e+04 output\n                  encoder.block.2.layer.1.dropout Dropout\n3.18e-04 6.27e+04 input[0]\n0.00e+00      inf output\n</code></pre> <p>\u200b\u6700\u540e\u200b\u4e00\u4e2a\u200b<code>frame</code>\u200b\u62a5\u544a\u200b\u4e86\u200b<code>Dropout.forward</code>\u200b\u51fd\u6570\u200b\uff0c\u200b\u7b2c\u4e00\u4e2a\u200b\u6761\u76ee\u200b\u662f\u200b\u552f\u4e00\u200b\u7684\u200b\u8f93\u5165\u200b\uff0c\u200b\u7b2c\u4e8c\u4e2a\u200b\u6761\u76ee\u200b\u662f\u200b\u552f\u4e00\u200b\u7684\u200b\u8f93\u51fa\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200b\uff0c\u200b\u5b83\u200b\u662f\u4ece\u200b<code>DenseReluDense</code>\u200b\u7c7b\u5185\u200b\u7684\u200b\u5c5e\u6027\u200b<code>dropout</code>\u200b\u4e2d\u200b\u8c03\u7528\u200b\u7684\u200b\u3002\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200b\u5b83\u200b\u53d1\u751f\u200b\u5728\u200b\u7b2c\u200b2\u200b\u4e2a\u5757\u200b\u7684\u200b\u7b2c\u200b1\u200b\u5c42\u200b\uff0c\u200b\u4e5f\u200b\u5c31\u662f\u200b\u5728\u200b\u7b2c\u4e00\u4e2a\u200b\u6279\u6b21\u200b\u671f\u95f4\u200b\u3002\u200b\u6700\u540e\u200b\uff0c\u200b\u7edd\u5bf9\u200b\u6700\u5927\u200b\u7684\u200b\u8f93\u5165\u200b\u5143\u7d20\u200b\u503c\u4e3a\u200b<code>6.27e+04</code>\uff0c\u200b\u8f93\u51fa\u200b\u4e5f\u200b\u662f\u200b<code>inf</code>\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u8fd9\u91cc\u200b\u770b\u5230\u200b\uff0c<code>T5DenseGatedGeluDense.forward</code>\u200b\u4ea7\u751f\u200b\u4e86\u200b\u8f93\u51fa\u200b\u6fc0\u6d3b\u200b\u503c\u200b\uff0c\u200b\u5176\u200b\u7edd\u5bf9\u200b\u6700\u5927\u503c\u200b\u7ea6\u200b\u4e3a\u200b62.7K\uff0c\u200b\u975e\u5e38\u200b\u63a5\u8fd1\u200bfp16\u200b\u7684\u200b\u4e0a\u9650\u200b64K\u3002\u200b\u5728\u200b\u4e0b\u200b\u4e00\u4e2a\u200b<code>frame</code>\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u6709\u200b<code>Dropout</code>\u200b\u5bf9\u200b\u6743\u91cd\u200b\u8fdb\u884c\u200b\u91cd\u65b0\u200b\u5f52\u4e00\u5316\u200b\uff0c\u200b\u4e4b\u540e\u200b\u5c06\u200b\u67d0\u4e9b\u200b\u5143\u7d20\u200b\u5f52\u96f6\u200b\uff0c\u200b\u5c06\u200b\u7edd\u5bf9\u200b\u6700\u5927\u503c\u200b\u63a8\u5230\u200b\u4e86\u200b64K\u200b\u4ee5\u4e0a\u200b\uff0c\u200b\u5bfc\u81f4\u200b\u6ea2\u51fa\u200b\uff08<code>inf</code>\uff09\u3002</p> <p>\u200b\u6b63\u5982\u200b\u4f60\u200b\u6240\u200b\u770b\u5230\u200b\u7684\u200b\uff0c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u67e5\u770b\u200b\u524d\u9762\u200b\u7684\u200b<code>frame</code>, \u200b\u4ece\u200b\u90a3\u91cc\u200bfp16\u200b\u6570\u5b57\u200b\u5f00\u59cb\u200b\u53d8\u5f97\u200b\u975e\u5e38\u200b\u5927\u200b\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5c06\u200b\u62a5\u544a\u200b\u4e0e\u200b<code>models/t5/modeling_t5.py</code>\u200b\u4e2d\u200b\u7684\u200b\u4ee3\u7801\u200b\u5339\u914d\u200b\uff1a</p> <pre><code>class T5DenseGatedGeluDense(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.wi_0 = nn.Linear(config.d_model, config.d_ff, bias=False)\n        self.wi_1 = nn.Linear(config.d_model, config.d_ff, bias=False)\n        self.wo = nn.Linear(config.d_ff, config.d_model, bias=False)\n        self.dropout = nn.Dropout(config.dropout_rate)\n        self.gelu_act = ACT2FN[\"gelu_new\"]\n\n    def forward(self, hidden_states):\n        hidden_gelu = self.gelu_act(self.wi_0(hidden_states))\n        hidden_linear = self.wi_1(hidden_states)\n        hidden_states = hidden_gelu * hidden_linear\n        hidden_states = self.dropout(hidden_states)\n        hidden_states = self.wo(hidden_states)\n        return hidden_states\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u5f88\u200b\u5bb9\u6613\u200b\u770b\u5230\u200b<code>dropout</code>\u200b\u8c03\u7528\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u6240\u6709\u200b\u4e4b\u524d\u200b\u7684\u200b\u8c03\u7528\u200b\u3002</p> <p>\u200b\u7531\u4e8e\u200b\u68c0\u6d4b\u200b\u662f\u200b\u5728\u200b\u524d\u200b\u5411\u200b<code>hook</code>\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u7684\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u62a5\u544a\u200b\u5c06\u200b\u7acb\u5373\u200b\u5728\u200b\u6bcf\u4e2a\u200b<code>forward</code>\u200b\u8fd4\u56de\u200b\u540e\u200b\u6253\u5370\u200b\u51fa\u6765\u200b\u3002</p> <p>\u200b\u56de\u5230\u200b\u5b8c\u6574\u200b\u7684\u200b\u62a5\u544a\u200b\uff0c\u200b\u8981\u200b\u91c7\u53d6\u63aa\u65bd\u200b\u5e76\u200b\u89e3\u51b3\u95ee\u9898\u200b\uff0c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u5f80\u56de\u200b\u770b\u200b\u51e0\u4e2a\u200b<code>frame</code>\uff0c\u200b\u5728\u200b\u90a3\u91cc\u200b\u6570\u5b57\u200b\u5f00\u59cb\u200b\u4e0a\u5347\u200b\uff0c\u200b\u5e76\u4e14\u200b\u6700\u6709\u200b\u53ef\u80fd\u200b\u5207\u6362\u200b\u5230\u200bfp32\u200b\u6a21\u5f0f\u200b\u4ee5\u4fbf\u200b\u5728\u200b\u4e58\u6cd5\u200b\u6216\u200b\u6c42\u548c\u200b\u65f6\u200b\u6570\u5b57\u200b\u4e0d\u4f1a\u200b\u6ea2\u51fa\u200b\u3002\u200b\u5f53\u7136\u200b\uff0c\u200b\u53ef\u80fd\u200b\u8fd8\u6709\u200b\u5176\u4ed6\u200b\u89e3\u51b3\u65b9\u6848\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u542f\u7528\u200b\u4e86\u200b<code>amp</code>\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5c06\u200b\u539f\u59cb\u200b<code>forward</code>\u200b\u79fb\u200b\u5230\u200b<code>helper wrapper</code>\u200b\u4e2d\u540e\u200b\uff0c\u200b\u6682\u65f6\u200b\u5173\u95ed\u200b\u5b83\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>def _forward(self, hidden_states):\n    hidden_gelu = self.gelu_act(self.wi_0(hidden_states))\n    hidden_linear = self.wi_1(hidden_states)\n    hidden_states = hidden_gelu * hidden_linear\n    hidden_states = self.dropout(hidden_states)\n    hidden_states = self.wo(hidden_states)\n    return hidden_states\n\n\nimport torch\n\n\ndef forward(self, hidden_states):\n    if torch.is_autocast_enabled():\n        with torch.cuda.amp.autocast(enabled=False):\n            return self._forward(hidden_states)\n    else:\n        return self._forward(hidden_states)\n</code></pre> <p>\u200b\u7531\u4e8e\u200b\u81ea\u52a8\u200b\u68c0\u6d4b\u5668\u200b\u4ec5\u200b\u62a5\u544a\u200b\u5b8c\u6574\u200b<code>frame</code>\u200b\u7684\u200b\u8f93\u5165\u200b\u548c\u200b\u8f93\u51fa\u200b\uff0c\u200b\u4e00\u65e6\u200b\u77e5\u9053\u200b\u5728\u200b\u54ea\u91cc\u200b\u67e5\u627e\u200b\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u8fd8\u200b\u5e0c\u671b\u200b\u5206\u6790\u200b\u7279\u5b9a\u200b<code>forward</code>\u200b\u51fd\u6570\u200b\u7684\u200b\u4e2d\u95f4\u200b\u9636\u6bb5\u200b\u3002\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b<code>detect_overflow</code>\u200b\u8f85\u52a9\u200b\u51fd\u6570\u200b\u5c06\u200b\u68c0\u6d4b\u5668\u200b\u653e\u5230\u200b\u5e0c\u671b\u200b\u7684\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u4f8b\u5982\u200b\uff1a</p> <pre><code>from debug_utils import detect_overflow\n\n\nclass T5LayerFF(nn.Module):\n    [...]\n\n    def forward(self, hidden_states):\n        forwarded_states = self.layer_norm(hidden_states)\n        detect_overflow(forwarded_states, \"after layer_norm\")\n        forwarded_states = self.DenseReluDense(forwarded_states)\n        detect_overflow(forwarded_states, \"after DenseReluDense\")\n        return hidden_states + self.dropout(forwarded_states)\n</code></pre> <p>\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200b\uff0c\u200b\u6211\u4eec\u200b\u6dfb\u52a0\u200b\u4e86\u200b2\u200b\u4e2a\u200b\u68c0\u6d4b\u5668\u200b\uff0c\u200b\u73b0\u5728\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u8ddf\u8e2a\u200b\u662f\u5426\u200b\u5728\u200b<code>forwarded_states</code>\u200b\u4e2d\u95f4\u200b\u7684\u200b\u67d0\u4e2a\u200b\u5730\u65b9\u200b\u68c0\u6d4b\u200b\u5230\u200b\u4e86\u200b<code>inf</code>\u200b\u6216\u200b<code>nan</code>\u3002</p> <p>\u200b\u5b9e\u9645\u4e0a\u200b\uff0c\u200b\u68c0\u6d4b\u5668\u200b\u5df2\u7ecf\u200b\u62a5\u544a\u200b\u4e86\u200b\u8fd9\u4e9b\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u4e0a\u9762\u200b\u793a\u4f8b\u200b\u4e2d\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u8c03\u7528\u200b\u90fd\u200b\u662f\u200b\u4e00\u4e2a\u200b<code>nn.Module</code>\uff0c\u200b\u4f46\u200b\u5047\u8bbe\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200b\u4e00\u4e9b\u200b\u672c\u5730\u200b\u7684\u200b\u76f4\u63a5\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u8fd9\u200b\u5c31\u662f\u200b\u60a8\u200b\u5c06\u200b\u5982\u4f55\u200b\u6267\u884c\u200b\u7684\u200b\u65b9\u5f0f\u200b\u3002</p> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u5728\u200b\u81ea\u5df1\u200b\u7684\u200b\u4ee3\u7801\u200b\u4e2d\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u8c03\u8bd5\u5668\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8c03\u6574\u200b\u4ece\u200b\u5176\u200b\u9ed8\u8ba4\u200b\u6253\u5370\u200b\u7684\u200b<code>frame</code>\u200b\u6570\u200b\uff0c\u200b\u4f8b\u5982\u200b\uff1a</p> <pre><code>from transformers.debug_utils import DebugUnderflowOverflow\n\ndebug_overflow = DebugUnderflowOverflow(model, max_frames_to_save=100)\n</code></pre>"},{"location":"debugging/#_3","title":"\u7279\u5b9a\u200b\u6279\u6b21\u200b\u7684\u200b\u7edd\u5bf9\u200b\u6700\u5c0f\u503c\u200b\u548c\u200b\u6700\u5927\u503c\u200b\u8ddf\u8e2a","text":"<p>\u200b\u5f53\u200b\u5173\u95ed\u200b\u4e0b\u6ea2\u200b/\u200b\u4e0a\u6ea2\u200b\u68c0\u6d4b\u200b\u529f\u80fd\u200b, \u200b\u540c\u6837\u200b\u7684\u200b\u8c03\u8bd5\u200b\u7c7b\u200b\u53ef\u4ee5\u200b\u7528\u4e8e\u200b\u6279\u5904\u7406\u200b\u8ddf\u8e2a\u200b\u3002</p> <p>\u200b\u5047\u8bbe\u200b\u60a8\u200b\u60f3\u8981\u200b\u76d1\u89c6\u200b\u7ed9\u5b9a\u200b\u6279\u6b21\u200b\u7684\u200b\u6bcf\u4e2a\u200b<code>forward</code>\u200b\u8c03\u7528\u200b\u7684\u200b\u6240\u6709\u200b\u6210\u5206\u200b\u7684\u200b\u7edd\u5bf9\u200b\u6700\u5c0f\u503c\u200b\u548c\u200b\u6700\u5927\u503c\u200b\uff0c\u200b\u5e76\u4e14\u200b\u4ec5\u200b\u5bf9\u200b\u6279\u6b21\u200b1\u200b\u548c\u200b3\u200b\u6267\u884c\u200b\u6b64\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8fd9\u6837\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u8fd9\u4e2a\u200b\u7c7b\u200b\uff1a</p> <pre><code>debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[1, 3])\n</code></pre> <p>\u200b\u73b0\u5728\u200b\uff0c\u200b\u5b8c\u6574\u200b\u7684\u200b\u6279\u6b21\u200b1\u200b\u548c\u200b3\u200b\u5c06\u200b\u4ee5\u200b\u4e0e\u200b\u4e0b\u6ea2\u200b/\u200b\u4e0a\u6ea2\u200b\u68c0\u6d4b\u5668\u200b\u76f8\u540c\u200b\u7684\u200b\u683c\u5f0f\u200b\u8fdb\u884c\u200b\u8ddf\u8e2a\u200b\u3002</p> <p>\u200b\u6279\u6b21\u200b\u4ece\u200b0\u200b\u5f00\u59cb\u200b\u8ba1\u6570\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u77e5\u9053\u200b\u7a0b\u5e8f\u200b\u5728\u200b\u67d0\u4e2a\u200b\u6279\u6b21\u200b\u7f16\u53f7\u200b\u4e4b\u540e\u200b\u5f00\u59cb\u200b\u51fa\u73b0\u200b\u95ee\u9898\u200b\uff0c\u200b\u90a3\u4e48\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u5feb\u200b\u8fdb\u5230\u200b\u8be5\u200b\u533a\u57df\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u4e00\u4e2a\u200b\u622a\u53d6\u200b\u7684\u200b\u914d\u7f6e\u200b\u793a\u4f8b\u200b\u8f93\u51fa\u200b\uff1a</p> <pre><code>                  *** Starting batch number=1 ***\nabs min  abs max  metadata\n                  shared Embedding\n1.01e-06 7.92e+02 weight\n0.00e+00 2.47e+04 input[0]\n5.36e-05 7.92e+02 output\n[...]\n                  decoder.dropout Dropout\n1.60e-07 2.27e+01 input[0]\n0.00e+00 2.52e+01 output\n                  decoder T5Stack\n     not a tensor output\n                  lm_head Linear\n1.01e-06 7.92e+02 weight\n0.00e+00 1.11e+00 input[0]\n6.06e-02 8.39e+01 output\n                   T5ForConditionalGeneration\n     not a tensor output\n\n                  *** Starting batch number=3 ***\nabs min  abs max  metadata\n                  shared Embedding\n1.01e-06 7.92e+02 weight\n0.00e+00 2.78e+04 input[0]\n5.36e-05 7.92e+02 output\n[...]\n</code></pre> <p>\u200b\u5728\u200b\u8fd9\u91cc\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u83b7\u5f97\u200b\u5927\u91cf\u200b\u7684\u200b<code>frame</code>\u200b\u88ab\u200b<code>dump</code> - \u200b\u4e0e\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u4e2d\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u8c03\u7528\u200b\u4e00\u6837\u200b\u591a\u200b\uff0c\u200b\u5b83\u200b\u6709\u200b\u53ef\u80fd\u200b\u7b26\u5408\u200b\u4e5f\u200b\u53ef\u80fd\u200b\u4e0d\u200b\u7b26\u5408\u200b\u60a8\u200b\u7684\u200b\u8981\u6c42\u200b\uff0c\u200b\u4f46\u200b\u6709\u65f6\u200b\u5bf9\u4e8e\u200b\u8c03\u8bd5\u200b\u76ee\u7684\u200b\u6765\u8bf4\u200b\uff0c\u200b\u5b83\u200b\u53ef\u80fd\u200b\u6bd4\u200b\u6b63\u5e38\u200b\u7684\u200b\u8c03\u8bd5\u5668\u200b\u66f4\u200b\u5bb9\u6613\u200b\u4f7f\u7528\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u95ee\u9898\u200b\u5f00\u59cb\u200b\u53d1\u751f\u200b\u5728\u200b\u6279\u6b21\u200b\u53f7\u200b150\u200b\u4e0a\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b<code>dump</code>\u200b\u6279\u6b21\u200b149\u200b\u548c\u200b150\u200b\u7684\u200b\u8ddf\u8e2a\u200b\uff0c\u200b\u5e76\u200b\u6bd4\u8f83\u200b\u6570\u5b57\u200b\u5f00\u59cb\u200b\u53d1\u6563\u200b\u7684\u200b\u5730\u65b9\u200b\u3002</p> <p>\u200b\u4f60\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u6307\u5b9a\u200b\u505c\u6b62\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6279\u6b21\u200b\u53f7\u200b\uff1a</p> <pre><code>debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[1, 3], abort_after_batch_num=3)\n</code></pre>"},{"location":"hpo_train/","title":"Hpo train","text":""},{"location":"hpo_train/#trainer-api","title":"\u4f7f\u7528\u200bTrainer API\u200b\u8fdb\u884c\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22","text":"<p>\ud83e\udd17 Transformers\u200b\u5e93\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u4f18\u5316\u200b\u8fc7\u200b\u7684\u200b[<code>Trainer</code>]\u200b\u7c7b\u200b\uff0c\u200b\u7528\u4e8e\u200b\u8bad\u7ec3\u200b\ud83e\udd17 Transformers\u200b\u6a21\u578b\u200b\uff0c\u200b\u76f8\u6bd4\u200b\u4e8e\u200b\u624b\u52a8\u200b\u7f16\u5199\u200b\u81ea\u5df1\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\uff0c\u200b\u8fd9\u200b\u66f4\u200b\u5bb9\u6613\u200b\u5f00\u59cb\u200b\u8bad\u7ec3\u200b\u3002[<code>Trainer</code>]\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22\u200b\u7684\u200bAPI\u3002\u200b\u672c\u200b\u6587\u6863\u200b\u5c55\u793a\u200b\u4e86\u200b\u5982\u4f55\u200b\u5728\u200b\u793a\u4f8b\u200b\u4e2d\u200b\u542f\u7528\u200b\u5b83\u200b\u3002 </p>"},{"location":"hpo_train/#_1","title":"\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22\u200b\u540e\u200b\u7aef","text":"<p>[<code>Trainer</code>] \u200b\u76ee\u524d\u200b\u652f\u6301\u200b\u56db\u79cd\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22\u200b\u540e\u200b\u7aef\u200b\uff1aoptuna\uff0csigopt\uff0craytune\uff0cwandb</p> <p>\u200b\u5728\u200b\u4f7f\u7528\u200b\u5b83\u4eec\u200b\u4e4b\u524d\u200b\uff0c\u200b\u60a8\u200b\u5e94\u8be5\u200b\u5148\u200b\u5b89\u88c5\u200b\u5b83\u4eec\u200b\u4f5c\u4e3a\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22\u200b\u540e\u200b\u7aef\u200b\u3002</p> <pre><code>pip install optuna/sigopt/wandb/ray[tune] \n</code></pre>"},{"location":"hpo_train/#_2","title":"\u5982\u4f55\u200b\u5728\u200b\u793a\u4f8b\u200b\u4e2d\u200b\u542f\u7528\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22","text":"<p>\u200b\u5b9a\u4e49\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22\u200b\u7a7a\u95f4\u200b\uff0c\u200b\u4e0d\u540c\u200b\u7684\u200b\u540e\u200b\u7aef\u200b\u9700\u8981\u200b\u4e0d\u540c\u200b\u7684\u200b\u683c\u5f0f\u200b\u3002</p> <p>\u200b\u5bf9\u4e8e\u200bsigopt\uff0c\u200b\u8bf7\u53c2\u9605\u200bsigopt object_parameter\uff0c\u200b\u5b83\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; def sigopt_hp_space(trial):\n...     return [\n...         {\"bounds\": {\"min\": 1e-6, \"max\": 1e-4}, \"name\": \"learning_rate\", \"type\": \"double\"},\n...         {\n...             \"categorical_values\": [\"16\", \"32\", \"64\", \"128\"],\n...             \"name\": \"per_device_train_batch_size\",\n...             \"type\": \"categorical\",\n...         },\n...     ]\n</code></pre> <p>\u200b\u5bf9\u4e8e\u200boptuna\uff0c\u200b\u8bf7\u53c2\u9605\u200boptuna object_parameter\uff0c\u200b\u5b83\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; def optuna_hp_space(trial):\n...     return {\n...         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n...         \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32, 64, 128]),\n...     }\n</code></pre> <p>Optuna\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u591a\u200b\u76ee\u6807\u200bHPO\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b<code>hyperparameter_search</code>\u200b\u4e2d\u200b\u4f20\u9012\u200b<code>direction</code>\u200b\u53c2\u6570\u200b\uff0c\u200b\u5e76\u200b\u5b9a\u4e49\u200b\u81ea\u5df1\u200b\u7684\u200b<code>compute_objective</code>\u200b\u4ee5\u200b\u8fd4\u56de\u200b\u591a\u4e2a\u200b\u76ee\u6807\u503c\u200b\u3002\u200b\u5728\u200b<code>hyperparameter_search</code>\u200b\u4e2d\u5c06\u200b\u8fd4\u56de\u200bPareto Front\uff08<code>List[BestRun]</code>\uff09\uff0c\u200b\u60a8\u200b\u5e94\u8be5\u200b\u53c2\u8003\u200btest_trainer\u200b\u4e2d\u200b\u7684\u200b\u6d4b\u8bd5\u7528\u4f8b\u200b<code>TrainerHyperParameterMultiObjectOptunaIntegrationTest</code>\u3002\u200b\u5b83\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; best_trials = trainer.hyperparameter_search(\n...     direction=[\"minimize\", \"maximize\"],\n...     backend=\"optuna\",\n...     hp_space=optuna_hp_space,\n...     n_trials=20,\n...     compute_objective=compute_objective,\n... )\n</code></pre> <p>\u200b\u5bf9\u4e8e\u200braytune\uff0c\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200braytune\u200b\u7684\u200bobject_parameter\uff0c\u200b\u5b83\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; def ray_hp_space(trial):\n...     return {\n...         \"learning_rate\": tune.loguniform(1e-6, 1e-4),\n...         \"per_device_train_batch_size\": tune.choice([16, 32, 64, 128]),\n...     }\n</code></pre> <p>\u200b\u5bf9\u4e8e\u200bwandb\uff0c\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200bwandb\u200b\u7684\u200bobject_parameter\uff0c\u200b\u5b83\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; def wandb_hp_space(trial):\n...     return {\n...         \"method\": \"random\",\n...         \"metric\": {\"name\": \"objective\", \"goal\": \"minimize\"},\n...         \"parameters\": {\n...             \"learning_rate\": {\"distribution\": \"uniform\", \"min\": 1e-6, \"max\": 1e-4},\n...             \"per_device_train_batch_size\": {\"values\": [16, 32, 64, 128]},\n...         },\n...     }\n</code></pre> <p>\u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200b<code>model_init</code>\u200b\u51fd\u6570\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u4f20\u9012\u200b\u7ed9\u200b[Trainer]\uff0c\u200b\u4f5c\u4e3a\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; def model_init(trial):\n...     return AutoModelForSequenceClassification.from_pretrained(\n...         model_args.model_name_or_path,\n...         from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n...         config=config,\n...         cache_dir=model_args.cache_dir,\n...         revision=model_args.model_revision,\n...         use_auth_token=True if model_args.use_auth_token else None,\n...     )\n</code></pre> <p>\u200b\u4f7f\u7528\u200b\u4f60\u200b\u7684\u200b<code>model_init</code>\u200b\u51fd\u6570\u200b\u3001\u200b\u8bad\u7ec3\u200b\u53c2\u6570\u200b\u3001\u200b\u8bad\u7ec3\u200b\u548c\u200b\u6d4b\u8bd5\u6570\u636e\u200b\u96c6\u200b\u4ee5\u53ca\u200b\u8bc4\u4f30\u200b\u51fd\u6570\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b[<code>Trainer</code>]\u3002</p> <pre><code>&gt;&gt;&gt; trainer = Trainer(\n...     model=None,\n...     args=training_args,\n...     train_dataset=small_train_dataset,\n...     eval_dataset=small_eval_dataset,\n...     compute_metrics=compute_metrics,\n...     tokenizer=tokenizer,\n...     model_init=model_init,\n...     data_collator=data_collator,\n... )\n</code></pre> <p>\u200b\u8c03\u7528\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22\u200b\uff0c\u200b\u83b7\u53d6\u200b\u6700\u4f73\u200b\u8bd5\u9a8c\u200b\u53c2\u6570\u200b\uff0c\u200b\u540e\u200b\u7aef\u200b\u53ef\u4ee5\u200b\u662f\u200b<code>\"optuna\"</code>/<code>\"sigopt\"</code>/<code>\"wandb\"</code>/<code>\"ray\"</code>\u3002\u200b\u65b9\u5411\u200b\u53ef\u4ee5\u200b\u662f\u200b<code>\"minimize\"</code>\u200b\u6216\u200b<code>\"maximize\"</code>\uff0c\u200b\u8868\u793a\u200b\u662f\u5426\u200b\u4f18\u5316\u200b\u66f4\u5927\u200b\u6216\u200b\u66f4\u200b\u4f4e\u200b\u7684\u200b\u76ee\u6807\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5b9a\u4e49\u200b\u81ea\u5df1\u200b\u7684\u200bcompute_objective\u200b\u51fd\u6570\u200b\uff0c\u200b\u5982\u679c\u200b\u6ca1\u6709\u200b\u5b9a\u4e49\u200b\uff0c\u200b\u5c06\u200b\u8c03\u7528\u200b\u9ed8\u8ba4\u200b\u7684\u200bcompute_objective\uff0c\u200b\u5e76\u200b\u5c06\u200b\u8bc4\u4f30\u200b\u6307\u6807\u200b\uff08\u200b\u5982\u200bf1\uff09\u200b\u4e4b\u200b\u548c\u200b\u4f5c\u4e3a\u200b\u76ee\u6807\u503c\u200b\u8fd4\u56de\u200b\u3002</p> <pre><code>&gt;&gt;&gt; best_trial = trainer.hyperparameter_search(\n...     direction=\"maximize\",\n...     backend=\"optuna\",\n...     hp_space=optuna_hp_space,\n...     n_trials=20,\n...     compute_objective=compute_objective,\n... )\n</code></pre>"},{"location":"hpo_train/#ddp","title":"\u9488\u5bf9\u200bDDP\u200b\u5fae\u8c03\u200b\u7684\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22","text":"<p>\u200b\u76ee\u524d\u200b\uff0cOptuna\u200b\u548c\u200bSigopt\u200b\u5df2\u200b\u542f\u7528\u200b\u9488\u5bf9\u200bDDP\u200b\u7684\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22\u200b\u3002\u200b\u53ea\u6709\u200brank-zero\u200b\u8fdb\u7a0b\u200b\u4f1a\u200b\u8fdb\u884c\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22\u200b\u5e76\u200b\u5c06\u200b\u53c2\u6570\u4f20\u9012\u200b\u7ed9\u200b\u5176\u4ed6\u200b\u8fdb\u7a0b\u200b\u3002</p>"},{"location":"llm_tutorial/","title":"Llm tutorial","text":""},{"location":"llm_tutorial/#llms","title":"\u4f7f\u7528\u200bLLMs\u200b\u8fdb\u884c\u200b\u751f\u6210","text":"<p>[[open-in-colab]]</p> <p>LLMs\uff0c\u200b\u5373\u5927\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u662f\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u80cc\u540e\u200b\u7684\u200b\u5173\u952e\u200b\u7ec4\u6210\u90e8\u5206\u200b\u3002\u200b\u7b80\u5355\u200b\u6765\u8bf4\u200b\uff0c\u200b\u5b83\u4eec\u200b\u5305\u542b\u200b\u7ecf\u8fc7\u200b\u5927\u89c4\u6a21\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200btransformer\u200b\u6a21\u578b\u200b\uff0c\u200b\u7528\u4e8e\u200b\u6839\u636e\u200b\u7ed9\u5b9a\u200b\u7684\u200b\u8f93\u5165\u200b\u6587\u672c\u200b\u9884\u6d4b\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u8bcd\u200b\uff08\u200b\u6216\u200b\u66f4\u200b\u51c6\u786e\u200b\u5730\u8bf4\u200b\uff0c\u200b\u4e0b\u200b\u4e00\u4e2a\u200b<code>token</code>\uff09\u3002\u200b\u7531\u4e8e\u200b\u5b83\u4eec\u200b\u4e00\u6b21\u200b\u53ea\u200b\u9884\u6d4b\u200b\u4e00\u4e2a\u200b<code>token</code>\uff0c\u200b\u56e0\u6b64\u200b\u9664\u4e86\u200b\u8c03\u7528\u200b\u6a21\u578b\u200b\u4e4b\u5916\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u6267\u884c\u200b\u66f4\u200b\u590d\u6742\u200b\u7684\u200b\u64cd\u4f5c\u200b\u6765\u200b\u751f\u6210\u200b\u65b0\u200b\u7684\u200b\u53e5\u5b50\u200b\u2014\u2014\u200b\u60a8\u200b\u9700\u8981\u200b\u8fdb\u884c\u200b\u81ea\u200b\u56de\u5f52\u200b\u751f\u6210\u200b\u3002</p> <p>\u200b\u81ea\u200b\u56de\u5f52\u200b\u751f\u6210\u200b\u662f\u200b\u5728\u200b\u7ed9\u5b9a\u200b\u4e00\u4e9b\u200b\u521d\u59cb\u200b\u8f93\u5165\u200b\uff0c\u200b\u901a\u8fc7\u200b\u8fed\u4ee3\u200b\u8c03\u7528\u200b\u6a21\u578b\u200b\u53ca\u5176\u200b\u81ea\u8eab\u200b\u7684\u200b\u751f\u6210\u200b\u8f93\u51fa\u200b\u6765\u200b\u751f\u6210\u200b\u6587\u672c\u200b\u7684\u200b\u63a8\u7406\u200b\u8fc7\u7a0b\u200b\uff0c\u3002\u200b\u5728\u200b\ud83e\udd17 Transformers\u200b\u4e2d\u200b\uff0c\u200b\u8fd9\u200b\u7531\u200b[<code>~generation.GenerationMixin.generate</code>]\u200b\u65b9\u6cd5\u200b\u5904\u7406\u200b\uff0c\u200b\u6240\u6709\u200b\u5177\u6709\u200b\u751f\u6210\u200b\u80fd\u529b\u200b\u7684\u200b\u6a21\u578b\u200b\u90fd\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u3002</p> <p>\u200b\u672c\u200b\u6559\u7a0b\u200b\u5c06\u200b\u5411\u200b\u60a8\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\uff1a</p> <ul> <li>\u200b\u4f7f\u7528\u200bLLM\u200b\u751f\u6210\u200b\u6587\u672c\u200b</li> <li>\u200b\u907f\u514d\u200b\u5e38\u89c1\u200b\u7684\u200b\u9677\u9631\u200b</li> <li>\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u5145\u5206\u5229\u7528\u200bLLM\u200b\u4e0b\u200b\u4e00\u6b65\u200b\u6307\u5bfc\u200b</li> </ul> <p>\u200b\u5728\u200b\u5f00\u59cb\u200b\u4e4b\u524d\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200b\u5df2\u200b\u5b89\u88c5\u200b\u6240\u6709\u200b\u5fc5\u8981\u200b\u7684\u200b\u5e93\u200b\uff1a</p> <pre><code>pip install transformers bitsandbytes&gt;=0.39.0 -q\n</code></pre>"},{"location":"llm_tutorial/#_1","title":"\u751f\u6210\u200b\u6587\u672c","text":"<p>\u200b\u4e00\u4e2a\u200b\u7528\u4e8e\u200b\u56e0\u679c\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\u8bad\u7ec3\u200b\u7684\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u5c06\u200b\u6587\u672c\u200b<code>tokens</code>\u200b\u5e8f\u5217\u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\uff0c\u200b\u5e76\u200b\u8fd4\u56de\u200b\u4e0b\u200b\u4e00\u4e2a\u200b<code>token</code>\u200b\u7684\u200b\u6982\u7387\u5206\u5e03\u200b\u3002</p> \"LLM\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u4f20\u9012\u200b\" <p>\u200b\u4f7f\u7528\u200bLLM\u200b\u8fdb\u884c\u200b\u81ea\u200b\u56de\u5f52\u200b\u751f\u6210\u200b\u7684\u200b\u4e00\u4e2a\u200b\u5173\u952e\u200b\u65b9\u9762\u200b\u662f\u200b\u5982\u4f55\u200b\u4ece\u200b\u8fd9\u4e2a\u200b\u6982\u7387\u5206\u5e03\u200b\u4e2d\u200b\u9009\u62e9\u200b\u4e0b\u200b\u4e00\u4e2a\u200b<code>token</code>\u3002\u200b\u8fd9\u4e2a\u200b\u6b65\u9aa4\u200b\u53ef\u4ee5\u200b\u968f\u610f\u200b\u8fdb\u884c\u200b\uff0c\u200b\u53ea\u8981\u200b\u6700\u7ec8\u200b\u5f97\u5230\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u8fed\u4ee3\u200b\u7684\u200b<code>token</code>\u3002\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u53ef\u4ee5\u200b\u7b80\u5355\u200b\u7684\u200b\u4ece\u200b\u6982\u7387\u5206\u5e03\u200b\u4e2d\u200b\u9009\u62e9\u200b\u6700\u200b\u53ef\u80fd\u200b\u7684\u200b<code>token</code>\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u590d\u6742\u200b\u7684\u200b\u5728\u200b\u5bf9\u200b\u7ed3\u679c\u200b\u5206\u5e03\u200b\u8fdb\u884c\u200b\u91c7\u6837\u200b\u4e4b\u524d\u200b\u5e94\u7528\u200b\u591a\u79cd\u200b\u53d8\u6362\u200b\uff0c\u200b\u8fd9\u200b\u53d6\u51b3\u4e8e\u200b\u4f60\u200b\u7684\u200b\u9700\u6c42\u200b\u3002</p> \"\u200b\u81ea\u200b\u56de\u5f52\u200b\u751f\u6210\u200b\u8fed\u4ee3\u200b\u5730\u200b\u4ece\u200b\u6982\u7387\u5206\u5e03\u200b\u4e2d\u200b\u9009\u62e9\u200b\u4e0b\u200b\u4e00\u4e2a\u200btoken\u200b\u4ee5\u200b\u751f\u6210\u200b\u6587\u672c\u200b\" <p>\u200b\u4e0a\u8ff0\u200b\u8fc7\u7a0b\u200b\u662f\u200b\u8fed\u4ee3\u200b\u91cd\u590d\u200b\u7684\u200b\uff0c\u200b\u76f4\u5230\u200b\u8fbe\u5230\u200b\u67d0\u4e2a\u200b\u505c\u6b62\u200b\u6761\u4ef6\u200b\u3002\u200b\u7406\u60f3\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u505c\u6b62\u200b\u6761\u4ef6\u200b\u7531\u200b\u6a21\u578b\u200b\u51b3\u5b9a\u200b\uff0c\u200b\u8be5\u200b\u6a21\u578b\u200b\u5e94\u200b\u5b66\u4f1a\u200b\u5728\u200b\u4f55\u65f6\u200b\u8f93\u51fa\u200b\u4e00\u4e2a\u200b\u7ed3\u675f\u200b\u5e8f\u5217\u200b\uff08<code>EOS</code>\uff09\u200b\u6807\u8bb0\u200b\u3002\u200b\u5982\u679c\u200b\u4e0d\u662f\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\uff0c\u200b\u751f\u6210\u200b\u5c06\u200b\u5728\u200b\u8fbe\u5230\u200b\u67d0\u4e2a\u200b\u9884\u5b9a\u200b\u4e49\u200b\u7684\u200b\u6700\u5927\u200b\u957f\u5ea6\u200b\u65f6\u200b\u505c\u6b62\u200b\u3002</p> <p>\u200b\u6b63\u786e\u200b\u8bbe\u7f6e\u200b<code>token</code>\u200b\u9009\u62e9\u200b\u6b65\u9aa4\u200b\u548c\u200b\u505c\u6b62\u200b\u6761\u4ef6\u200b\u5bf9\u4e8e\u200b\u8ba9\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u6309\u7167\u200b\u9884\u671f\u200b\u7684\u200b\u65b9\u5f0f\u200b\u6267\u884c\u200b\u4efb\u52a1\u200b\u81f3\u5173\u91cd\u8981\u200b\u3002\u200b\u8fd9\u200b\u5c31\u662f\u200b\u4e3a\u4ec0\u4e48\u200b\u6211\u4eec\u200b\u4e3a\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u90fd\u200b\u6709\u200b\u4e00\u4e2a\u200b[~generation.GenerationConfig]\u200b\u6587\u4ef6\u200b\uff0c\u200b\u5b83\u200b\u5305\u542b\u200b\u4e00\u4e2a\u200b\u6548\u679c\u200b\u4e0d\u9519\u200b\u7684\u200b\u9ed8\u8ba4\u200b\u751f\u6210\u200b\u53c2\u6570\u200b\u914d\u7f6e\u200b\uff0c\u200b\u5e76\u200b\u4e0e\u200b\u60a8\u200b\u6a21\u578b\u200b\u4e00\u8d77\u200b\u52a0\u8f7d\u200b\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u8c08\u8c08\u200b\u4ee3\u7801\u200b\uff01</p> <p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u5bf9\u200b\u57fa\u672c\u200b\u7684\u200bLLM\u200b\u4f7f\u7528\u200b\u611f\u5174\u8da3\u200b\uff0c\u200b\u6211\u4eec\u200b\u9ad8\u7ea7\u200b\u7684\u200b<code>Pipeline</code>\u200b\u63a5\u53e3\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5f88\u200b\u597d\u200b\u7684\u200b\u8d77\u70b9\u200b\u3002\u200b\u7136\u800c\u200b\uff0cLLMs\u200b\u901a\u5e38\u200b\u9700\u8981\u200b\u50cf\u200b<code>quantization</code>\u200b\u548c\u200b<code>token\u200b\u9009\u62e9\u200b\u6b65\u9aa4\u200b\u7684\u200b\u7cbe\u7ec6\u200b\u63a7\u5236\u200b</code>\u200b\u7b49\u200b\u9ad8\u7ea7\u200b\u529f\u80fd\u200b\uff0c\u200b\u8fd9\u200b\u6700\u597d\u200b\u901a\u8fc7\u200b[<code>~generation.GenerationMixin.generate</code>]\u200b\u6765\u200b\u5b8c\u6210\u200b\u3002\u200b\u4f7f\u7528\u200bLLM\u200b\u8fdb\u884c\u200b\u81ea\u200b\u56de\u5f52\u200b\u751f\u6210\u200b\u4e5f\u200b\u662f\u200b\u8d44\u6e90\u200b\u5bc6\u96c6\u578b\u200b\u7684\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u5e94\u8be5\u200b\u5728\u200bGPU\u200b\u4e0a\u200b\u6267\u884c\u200b\u4ee5\u200b\u83b7\u5f97\u200b\u8db3\u591f\u200b\u7684\u200b\u541e\u5410\u91cf\u200b\u3002</p> <p></p> <p>\u200b\u9996\u5148\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from transformers import AutoModelForCausalLM\n\n&gt;&gt;&gt; model = AutoModelForCausalLM.from_pretrained(\n...     \"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", load_in_4bit=True\n... )\n</code></pre> <p>\u200b\u60a8\u200b\u5c06\u200b\u4f1a\u200b\u6ce8\u610f\u200b\u5230\u200b\u5728\u200b<code>from_pretrained</code>\u200b\u8c03\u7528\u200b\u4e2d\u200b\u7684\u200b\u4e24\u4e2a\u200b\u6807\u5fd7\u200b\uff1a</p> <ul> <li><code>device_map</code>\u200b\u786e\u4fdd\u200b\u6a21\u578b\u200b\u88ab\u200b\u79fb\u52a8\u200b\u5230\u200b\u60a8\u200b\u7684\u200bGPU(s)\u200b\u4e0a\u200b</li> <li><code>load_in_4bit</code>\u200b\u5e94\u7528\u200b4\u200b\u4f4d\u200b\u52a8\u6001\u200b\u91cf\u5316\u200b\u6765\u200b\u6781\u5927\u200b\u5730\u200b\u51cf\u5c11\u200b\u8d44\u6e90\u200b\u9700\u6c42\u200b</li> </ul> <p>\u200b\u8fd8\u6709\u200b\u5176\u4ed6\u200b\u65b9\u5f0f\u200b\u6765\u200b\u521d\u59cb\u5316\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\uff0c\u200b\u4f46\u200b\u8fd9\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5f00\u59cb\u200b\u4f7f\u7528\u200bLLM\u200b\u5f88\u200b\u597d\u200b\u7684\u200b\u8d77\u70b9\u200b\u3002</p> <p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u4e00\u4e2a\u200btokenizer\u200b\u6765\u200b\u9884\u5904\u7406\u200b\u4f60\u200b\u7684\u200b\u6587\u672c\u200b\u8f93\u5165\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", padding_side=\"left\")\n&gt;&gt;&gt; model_inputs = tokenizer([\"A list of colors: red, blue\"], return_tensors=\"pt\").to(\"cuda\")\n</code></pre> <p><code>model_inputs</code>\u200b\u53d8\u91cf\u200b\u4fdd\u5b58\u200b\u7740\u200b\u5206\u8bcd\u200b\u540e\u200b\u7684\u200b\u6587\u672c\u200b\u8f93\u5165\u200b\u4ee5\u53ca\u200b\u6ce8\u610f\u529b\u200b\u63a9\u7801\u200b\u3002\u200b\u5c3d\u7ba1\u200b[<code>~generation.GenerationMixin.generate</code>]\u200b\u5728\u200b\u672a\u200b\u4f20\u9012\u200b\u6ce8\u610f\u529b\u200b\u63a9\u7801\u200b\u65f6\u4f1a\u200b\u5c3d\u5176\u6240\u80fd\u200b\u63a8\u65ad\u51fa\u200b\u6ce8\u610f\u529b\u200b\u63a9\u7801\u200b\uff0c\u200b\u4f46\u200b\u5efa\u8bae\u200b\u5c3d\u53ef\u80fd\u200b\u4f20\u9012\u200b\u5b83\u200b\u4ee5\u200b\u83b7\u5f97\u6700\u4f73\u200b\u7ed3\u679c\u200b\u3002</p> <p>\u200b\u5728\u200b\u5bf9\u200b\u8f93\u5165\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\u540e\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u8c03\u7528\u200b[<code>~generation.GenerationMixin.generate</code>]\u200b\u65b9\u6cd5\u200b\u6765\u200b\u8fd4\u56de\u200b\u751f\u6210\u200b\u7684\u200b<code>tokens</code>\u3002\u200b\u751f\u6210\u200b\u7684\u200b<code>tokens</code>\u200b\u5e94\u8be5\u200b\u5728\u200b\u6253\u5370\u200b\u4e4b\u524d\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6587\u672c\u200b\u3002</p> <pre><code>&gt;&gt;&gt; generated_ids = model.generate(**model_inputs)\n&gt;&gt;&gt; tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n'A list of colors: red, blue, green, yellow, orange, purple, pink,'\n</code></pre> <p>\u200b\u6700\u540e\u200b\uff0c\u200b\u60a8\u200b\u4e0d\u200b\u9700\u8981\u200b\u4e00\u6b21\u200b\u5904\u7406\u200b\u4e00\u4e2a\u200b\u5e8f\u5217\u200b\uff01\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u6279\u91cf\u200b\u8f93\u5165\u200b\uff0c\u200b\u8fd9\u200b\u5c06\u200b\u5728\u200b\u5c0f\u200b\u5ef6\u8fdf\u200b\u548c\u200b\u4f4e\u200b\u5185\u5b58\u200b\u6210\u672c\u200b\u4e0b\u200b\u663e\u8457\u200b\u63d0\u9ad8\u200b\u541e\u5410\u91cf\u200b\u3002\u200b\u60a8\u200b\u53ea\u200b\u9700\u8981\u200b\u786e\u4fdd\u200b\u6b63\u786e\u200b\u5730\u200b\u586b\u5145\u200b\u60a8\u200b\u7684\u200b\u8f93\u5165\u200b\uff08\u200b\u8be6\u89c1\u200b\u4e0b\u6587\u200b\uff09\u3002</p> <pre><code>&gt;&gt;&gt; tokenizer.pad_token = tokenizer.eos_token  # Most LLMs don't have a pad token by default\n&gt;&gt;&gt; model_inputs = tokenizer(\n...     [\"A list of colors: red, blue\", \"Portugal is\"], return_tensors=\"pt\", padding=True\n... ).to(\"cuda\")\n&gt;&gt;&gt; generated_ids = model.generate(**model_inputs)\n&gt;&gt;&gt; tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n['A list of colors: red, blue, green, yellow, orange, purple, pink,',\n'Portugal is a country in southwestern Europe, on the Iber']\n</code></pre> <p>\u200b\u5c31\u662f\u200b\u8fd9\u6837\u200b\uff01\u200b\u5728\u200b\u51e0\u884c\u200b\u4ee3\u7801\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u5229\u7528\u200bLLM\u200b\u7684\u200b\u5f3a\u5927\u200b\u529f\u80fd\u200b\u3002</p>"},{"location":"llm_tutorial/#_2","title":"\u5e38\u89c1\u200b\u9677\u9631","text":"<p>\u200b\u6709\u200b\u8bb8\u591a\u200b\u751f\u6210\u200b\u7b56\u7565\u200b\uff0c\u200b\u6709\u65f6\u200b\u9ed8\u8ba4\u503c\u200b\u53ef\u80fd\u200b\u4e0d\u200b\u9002\u5408\u200b\u60a8\u200b\u7684\u200b\u7528\u4f8b\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u8f93\u51fa\u200b\u4e0e\u200b\u60a8\u200b\u671f\u671b\u200b\u7684\u200b\u7ed3\u679c\u200b\u4e0d\u200b\u5339\u914d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5df2\u7ecf\u200b\u521b\u5efa\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u6700\u200b\u5e38\u89c1\u200b\u7684\u200b\u9677\u9631\u200b\u5217\u8868\u200b\u4ee5\u53ca\u200b\u5982\u4f55\u200b\u907f\u514d\u200b\u5b83\u4eec\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from transformers import AutoModelForCausalLM, AutoTokenizer\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n&gt;&gt;&gt; tokenizer.pad_token = tokenizer.eos_token  # Most LLMs don't have a pad token by default\n&gt;&gt;&gt; model = AutoModelForCausalLM.from_pretrained(\n...     \"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", load_in_4bit=True\n... )\n</code></pre>"},{"location":"llm_tutorial/#_3","title":"\u751f\u6210\u200b\u7684\u200b\u8f93\u51fa\u200b\u592a\u77ed\u200b/\u200b\u592a\u200b\u957f","text":"<p>\u200b\u5982\u679c\u200b\u5728\u200b[<code>~generation.GenerationConfig</code>]\u200b\u6587\u4ef6\u200b\u4e2d\u200b\u6ca1\u6709\u200b\u6307\u5b9a\u200b\uff0c<code>generate</code>\u200b\u9ed8\u8ba4\u200b\u8fd4\u56de\u200b20\u200b\u4e2a\u200btokens\u3002\u200b\u6211\u4eec\u200b\u5f3a\u70c8\u5efa\u8bae\u200b\u5728\u200b\u60a8\u200b\u7684\u200b<code>generate</code>\u200b\u8c03\u7528\u200b\u4e2d\u200b\u624b\u52a8\u200b\u8bbe\u7f6e\u200b<code>max_new_tokens</code>\u200b\u4ee5\u200b\u63a7\u5236\u200b\u5b83\u200b\u53ef\u4ee5\u200b\u8fd4\u56de\u200b\u7684\u200b\u6700\u5927\u200b\u65b0\u200btokens\u200b\u6570\u91cf\u200b\u3002\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0cLLMs\uff08\u200b\u66f4\u200b\u51c6\u786e\u200b\u5730\u8bf4\u200b\uff0c\u200b\u4ec5\u200b\u89e3\u7801\u5668\u200b\u6a21\u578b\u200b\uff09\u200b\u4e5f\u200b\u5c06\u200b\u8f93\u5165\u200b\u63d0\u793a\u200b\u4f5c\u4e3a\u200b\u8f93\u51fa\u200b\u7684\u200b\u4e00\u90e8\u5206\u200b\u8fd4\u56de\u200b\u3002</p> <pre><code>&gt;&gt;&gt; model_inputs = tokenizer([\"A sequence of numbers: 1, 2\"], return_tensors=\"pt\").to(\"cuda\")\n\n&gt;&gt;&gt; # By default, the output will contain up to 20 tokens\n&gt;&gt;&gt; generated_ids = model.generate(**model_inputs)\n&gt;&gt;&gt; tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n'A sequence of numbers: 1, 2, 3, 4, 5'\n\n&gt;&gt;&gt; # Setting `max_new_tokens` allows you to control the maximum length\n&gt;&gt;&gt; generated_ids = model.generate(**model_inputs, max_new_tokens=50)\n&gt;&gt;&gt; tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n'A sequence of numbers: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,'\n</code></pre>"},{"location":"llm_tutorial/#_4","title":"\u9519\u8bef\u200b\u7684\u200b\u751f\u6210\u200b\u6a21\u5f0f","text":"<p>\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u9664\u975e\u200b\u5728\u200b[<code>~generation.GenerationConfig</code>]\u200b\u6587\u4ef6\u200b\u4e2d\u200b\u6307\u5b9a\u200b\uff0c\u200b\u5426\u5219\u200b<code>generate</code>\u200b\u4f1a\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u8fed\u4ee3\u200b\u4e2d\u200b\u9009\u62e9\u200b\u6700\u200b\u53ef\u80fd\u200b\u7684\u200btoken\uff08\u200b\u8d2a\u5a6a\u200b\u89e3\u7801\u200b\uff09\u3002\u200b\u5bf9\u4e8e\u200b\u60a8\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u8fd9\u200b\u53ef\u80fd\u200b\u662f\u200b\u4e0d\u200b\u7406\u60f3\u200b\u7684\u200b\uff1b\u200b\u50cf\u200b\u804a\u5929\u200b\u673a\u5668\u4eba\u200b\u6216\u200b\u5199\u4f5c\u200b\u6587\u7ae0\u200b\u8fd9\u6837\u200b\u7684\u200b\u521b\u9020\u6027\u200b\u4efb\u52a1\u200b\u53d7\u76ca\u200b\u4e8e\u200b\u91c7\u6837\u200b\u3002\u200b\u53e6\u4e00\u65b9\u9762\u200b\uff0c\u200b\u50cf\u200b\u97f3\u9891\u200b\u8f6c\u5f55\u200b\u6216\u200b\u7ffb\u8bd1\u200b\u8fd9\u6837\u200b\u7684\u200b\u57fa\u4e8e\u200b\u8f93\u5165\u200b\u7684\u200b\u4efb\u52a1\u200b\u53d7\u76ca\u200b\u4e8e\u200b\u8d2a\u5a6a\u200b\u89e3\u7801\u200b\u3002\u200b\u901a\u8fc7\u200b\u5c06\u200b<code>do_sample=True</code>\u200b\u542f\u7528\u200b\u91c7\u6837\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u8fd9\u7bc7\u200b\u535a\u5ba2\u200b\u6587\u7ae0\u200b\u4e2d\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b\u8fd9\u4e2a\u200b\u8bdd\u9898\u200b\u7684\u200b\u4fe1\u606f\u200b\u3002</p> <pre><code>&gt;&gt;&gt; # Set seed or reproducibility -- you don't need this unless you want full reproducibility\n&gt;&gt;&gt; from transformers import set_seed\n&gt;&gt;&gt; set_seed(42)\n\n&gt;&gt;&gt; model_inputs = tokenizer([\"I am a cat.\"], return_tensors=\"pt\").to(\"cuda\")\n\n&gt;&gt;&gt; # LLM + greedy decoding = repetitive, boring output\n&gt;&gt;&gt; generated_ids = model.generate(**model_inputs)\n&gt;&gt;&gt; tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n'I am a cat. I am a cat. I am a cat. I am a cat'\n\n&gt;&gt;&gt; # With sampling, the output becomes more creative!\n&gt;&gt;&gt; generated_ids = model.generate(**model_inputs, do_sample=True)\n&gt;&gt;&gt; tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n'I am a cat.  Specifically, I am an indoor-only cat.  I'\n</code></pre>"},{"location":"llm_tutorial/#_5","title":"\u9519\u8bef\u200b\u7684\u200b\u586b\u5145\u200b\u4f4d\u7f6e","text":"<p>LLMs\u200b\u662f\u200b\u4ec5\u200b\u89e3\u7801\u5668\u200b\u67b6\u6784\u200b\uff0c\u200b\u610f\u5473\u7740\u200b\u5b83\u4eec\u200b\u4f1a\u200b\u6301\u7eed\u200b\u8fed\u4ee3\u200b\u60a8\u200b\u7684\u200b\u8f93\u5165\u200b\u63d0\u793a\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u8f93\u5165\u200b\u957f\u5ea6\u200b\u4e0d\u200b\u76f8\u540c\u200b\uff0c\u200b\u5219\u200b\u9700\u8981\u200b\u5bf9\u200b\u5b83\u4eec\u200b\u8fdb\u884c\u200b\u586b\u5145\u200b\u3002\u200b\u7531\u4e8e\u200bLLMs\u200b\u6ca1\u6709\u200b\u63a5\u53d7\u200b\u8fc7\u200b\u4ece\u200b<code>pad tokens</code>\u200b\u7ee7\u7eed\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u56e0\u6b64\u200b\u60a8\u200b\u7684\u200b\u8f93\u5165\u200b\u9700\u8981\u200b\u5de6\u200b\u586b\u5145\u200b\u3002\u200b\u786e\u4fdd\u200b\u5728\u200b\u751f\u6210\u200b\u65f6\u200b\u4e0d\u8981\u200b\u5fd8\u8bb0\u200b\u4f20\u9012\u200b\u6ce8\u610f\u529b\u200b\u63a9\u7801\u200b\uff01</p> <pre><code>&gt;&gt;&gt; # The tokenizer initialized above has right-padding active by default: the 1st sequence,\n&gt;&gt;&gt; # which is shorter, has padding on the right side. Generation fails to capture the logic.\n&gt;&gt;&gt; model_inputs = tokenizer(\n...     [\"1, 2, 3\", \"A, B, C, D, E\"], padding=True, return_tensors=\"pt\"\n... ).to(\"cuda\")\n&gt;&gt;&gt; generated_ids = model.generate(**model_inputs)\n&gt;&gt;&gt; tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n'1, 2, 33333333333'\n\n&gt;&gt;&gt; # With left-padding, it works as expected!\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", padding_side=\"left\")\n&gt;&gt;&gt; tokenizer.pad_token = tokenizer.eos_token  # Most LLMs don't have a pad token by default\n&gt;&gt;&gt; model_inputs = tokenizer(\n...     [\"1, 2, 3\", \"A, B, C, D, E\"], padding=True, return_tensors=\"pt\"\n... ).to(\"cuda\")\n&gt;&gt;&gt; generated_ids = model.generate(**model_inputs)\n&gt;&gt;&gt; tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n'1, 2, 3, 4, 5, 6,'\n</code></pre>"},{"location":"llm_tutorial/#_6","title":"\u9519\u8bef\u200b\u7684\u200b\u63d0\u793a","text":"<p>\u200b\u4e00\u4e9b\u200b\u6a21\u578b\u200b\u548c\u200b\u4efb\u52a1\u200b\u671f\u671b\u200b\u67d0\u79cd\u200b\u8f93\u5165\u200b\u63d0\u793a\u200b\u683c\u5f0f\u200b\u624d\u80fd\u200b\u6b63\u5e38\u200b\u5de5\u4f5c\u200b\u3002\u200b\u5f53\u672a\u200b\u5e94\u7528\u200b\u6b64\u200b\u683c\u5f0f\u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u83b7\u5f97\u200b\u6084\u7136\u200b\u7684\u200b\u6027\u80fd\u200b\u4e0b\u964d\u200b\uff1a\u200b\u6a21\u578b\u200b\u80fd\u200b\u5de5\u4f5c\u200b\uff0c\u200b\u4f46\u200b\u4e0d\u5982\u200b\u9884\u671f\u200b\u63d0\u793a\u200b\u90a3\u6837\u200b\u597d\u200b\u3002\u200b\u6709\u5173\u200b\u63d0\u793a\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u5305\u62ec\u200b\u54ea\u4e9b\u200b\u6a21\u578b\u200b\u548c\u200b\u4efb\u52a1\u200b\u9700\u8981\u200b\u5c0f\u5fc3\u200b\uff0c\u200b\u53ef\u200b\u5728\u200b\u6307\u5357\u200b\u4e2d\u200b\u627e\u5230\u200b\u3002\u200b\u8ba9\u200b\u6211\u4eec\u200b\u770b\u200b\u4e00\u4e2a\u200b\u4f7f\u7528\u200b\u804a\u5929\u200b\u6a21\u677f\u200b\u7684\u200b\u804a\u5929\u200bLLM\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\")\n&gt;&gt;&gt; model = AutoModelForCausalLM.from_pretrained(\n...     \"HuggingFaceH4/zephyr-7b-alpha\", device_map=\"auto\", load_in_4bit=True\n... )\n&gt;&gt;&gt; set_seed(0)\n&gt;&gt;&gt; prompt = \"\"\"How many helicopters can a human eat in one sitting? Reply as a thug.\"\"\"\n&gt;&gt;&gt; model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n&gt;&gt;&gt; input_length = model_inputs.input_ids.shape[1]\n&gt;&gt;&gt; generated_ids = model.generate(**model_inputs, max_new_tokens=20)\n&gt;&gt;&gt; print(tokenizer.batch_decode(generated_ids[:, input_length:], skip_special_tokens=True)[0])\n\"I'm not a thug, but i can tell you that a human cannot eat\"\n&gt;&gt;&gt; # Oh no, it did not follow our instruction to reply as a thug! Let's see what happens when we write\n&gt;&gt;&gt; # a better prompt and use the right template for this model (through `tokenizer.apply_chat_template`)\n\n&gt;&gt;&gt; set_seed(0)\n&gt;&gt;&gt; messages = [\n...     {\n...         \"role\": \"system\",\n...         \"content\": \"You are a friendly chatbot who always responds in the style of a thug\",\n...     },\n...     {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n... ]\n&gt;&gt;&gt; model_inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n&gt;&gt;&gt; input_length = model_inputs.shape[1]\n&gt;&gt;&gt; generated_ids = model.generate(model_inputs, do_sample=True, max_new_tokens=20)\n&gt;&gt;&gt; print(tokenizer.batch_decode(generated_ids[:, input_length:], skip_special_tokens=True)[0])\n'None, you thug. How bout you try to focus on more useful questions?'\n&gt;&gt;&gt; # As we can see, it followed a proper thug style \ud83d\ude0e\n</code></pre>"},{"location":"llm_tutorial/#_7","title":"\u66f4\u200b\u591a\u200b\u8d44\u6e90","text":"<p>\u200b\u867d\u7136\u200b\u81ea\u200b\u56de\u5f52\u200b\u751f\u6210\u200b\u8fc7\u7a0b\u200b\u76f8\u5bf9\u200b\u7b80\u5355\u200b\uff0c\u200b\u4f46\u200b\u8981\u200b\u5145\u5206\u5229\u7528\u200bLLM\u200b\u53ef\u80fd\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5177\u6709\u200b\u6311\u6218\u6027\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5f88\u591a\u200b\u7ec4\u4ef6\u200b\u590d\u6742\u200b\u4e14\u200b\u5bc6\u5207\u200b\u5173\u8054\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u6df1\u5165\u200b\u4e86\u89e3\u200bLLM\u200b\u4f7f\u7528\u200b\u548c\u200b\u7406\u89e3\u200b\u7684\u200b\u4e0b\u200b\u4e00\u6b65\u200b\uff1a</p>"},{"location":"llm_tutorial/#_8","title":"\u9ad8\u7ea7\u200b\u751f\u6210\u200b\u7528\u6cd5","text":"<ol> <li>\u200b\u6307\u5357\u200b\uff0c\u200b\u4ecb\u7ecd\u200b\u5982\u4f55\u200b\u63a7\u5236\u200b\u4e0d\u540c\u200b\u7684\u200b\u751f\u6210\u200b\u65b9\u6cd5\u200b\u3001\u200b\u5982\u4f55\u200b\u8bbe\u7f6e\u200b\u751f\u6210\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4ee5\u53ca\u200b\u5982\u4f55\u200b\u8fdb\u884c\u200b\u8f93\u51fa\u200b\u6d41\u5f0f\u200b\u4f20\u8f93\u200b\uff1b</li> <li>\u200b\u6307\u5357\u200b\uff0c\u200b\u4ecb\u7ecd\u200b\u804a\u5929\u200bLLMs\u200b\u7684\u200b\u63d0\u793a\u200b\u6a21\u677f\u200b\uff1b</li> <li>\u200b\u6307\u5357\u200b\uff0c\u200b\u4ecb\u7ecd\u200b\u5982\u4f55\u200b\u5145\u5206\u5229\u7528\u200b\u63d0\u793a\u200b\u8bbe\u8ba1\u200b\uff1b</li> <li>API\u200b\u53c2\u8003\u200b\u6587\u6863\u200b\uff0c\u200b\u5305\u62ec\u200b[<code>~generation.GenerationConfig</code>]\u3001[<code>~generation.GenerationMixin.generate</code>]\u200b\u548c\u200b\u4e0e\u200b\u751f\u6210\u200b\u76f8\u5173\u200b\u7684\u200b\u7c7b\u200b\u3002</li> </ol>"},{"location":"llm_tutorial/#llm","title":"LLM\u200b\u6392\u884c\u699c","text":"<ol> <li>Open LLM Leaderboard, \u200b\u4fa7\u91cd\u4e8e\u200b\u5f00\u6e90\u200b\u6a21\u578b\u200b\u7684\u200b\u8d28\u91cf\u200b;</li> <li>Open LLM-Perf Leaderboard, \u200b\u4fa7\u91cd\u4e8e\u200bLLM\u200b\u7684\u200b\u541e\u5410\u91cf\u200b.</li> </ol>"},{"location":"llm_tutorial/#_9","title":"\u5ef6\u8fdf\u200b\u3001\u200b\u541e\u5410\u91cf\u200b\u548c\u200b\u5185\u5b58\u200b\u5229\u7528\u7387","text":"<ol> <li>\u200b\u6307\u5357\u200b,\u200b\u5982\u4f55\u200b\u4f18\u5316\u200bLLMs\u200b\u4ee5\u200b\u63d0\u9ad8\u200b\u901f\u5ea6\u200b\u548c\u200b\u5185\u5b58\u200b\u5229\u7528\u200b\uff1b</li> <li>\u200b\u6307\u5357\u200b, \u200b\u5173\u4e8e\u200b<code>quantization</code>\uff0c\u200b\u5982\u200bbitsandbytes\u200b\u548c\u200bautogptq\u200b\u7684\u200b\u6307\u5357\u200b\uff0c\u200b\u6559\u200b\u60a8\u200b\u5982\u4f55\u200b\u5927\u5e45\u200b\u964d\u4f4e\u200b\u5185\u5b58\u200b\u9700\u6c42\u200b\u3002</li> </ol>"},{"location":"llm_tutorial/#_10","title":"\u76f8\u5173\u200b\u5e93","text":"<ol> <li><code>text-generation-inference</code>, \u200b\u4e00\u4e2a\u200b\u9762\u5411\u200b\u751f\u4ea7\u200b\u7684\u200bLLM\u200b\u670d\u52a1\u5668\u200b\uff1b</li> <li><code>optimum</code>, \u200b\u4e00\u4e2a\u200b\ud83e\udd17 Transformers\u200b\u7684\u200b\u6269\u5c55\u200b\uff0c\u200b\u4f18\u5316\u200b\u7279\u5b9a\u200b\u786c\u4ef6\u200b\u8bbe\u5907\u200b\u7684\u200b\u6027\u80fd\u200b</li> </ol>"},{"location":"model_sharing/","title":"Model sharing","text":""},{"location":"model_sharing/#_1","title":"\u5206\u4eab\u200b\u6a21\u578b","text":"<p>\u200b\u6700\u540e\u200b\u4e24\u4e2a\u200b\u6559\u7a0b\u200b\u5c55\u793a\u200b\u4e86\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200bPyTorch\u3001Keras\u200b\u548c\u200b \ud83e\udd17 Accelerate\u200b\u8fdb\u884c\u200b\u5206\u5e03\u5f0f\u200b\u8bbe\u7f6e\u200b\u6765\u200b\u5fae\u8c03\u200b\u6a21\u578b\u200b\u3002\u200b\u4e0b\u200b\u4e00\u6b65\u200b\u662f\u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u4e0e\u200b\u793e\u533a\u200b\u5206\u4eab\u200b\uff01\u200b\u5728\u200bHugging Face\uff0c\u200b\u6211\u4eec\u200b\u76f8\u4fe1\u200b\u516c\u5f00\u200b\u5206\u4eab\u200b\u77e5\u8bc6\u200b\u548c\u200b\u8d44\u6e90\u200b\uff0c\u200b\u80fd\u200b\u5b9e\u73b0\u200b\u4eba\u5de5\u667a\u80fd\u200b\u7684\u200b\u666e\u53ca\u5316\u200b\uff0c\u200b\u8ba9\u200b\u6bcf\u4e2a\u200b\u4eba\u200b\u90fd\u200b\u80fd\u200b\u53d7\u76ca\u200b\u3002\u200b\u6211\u4eec\u200b\u9f13\u52b1\u200b\u60a8\u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u4e0e\u200b\u793e\u533a\u200b\u5206\u4eab\u200b\uff0c\u200b\u4ee5\u200b\u5e2e\u52a9\u200b\u4ed6\u4eba\u200b\u8282\u7701\u65f6\u95f4\u200b\u548c\u200b\u7cbe\u529b\u200b\u3002</p> <p>\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u5b66\u4e60\u200b\u4e24\u79cd\u200b\u5728\u200bModel Hub\u200b\u4e0a\u200b\u5171\u4eab\u200b\u8bad\u7ec3\u200b\u597d\u200b\u7684\u200b\u6216\u200b\u5fae\u8c03\u200b\u7684\u200b\u6a21\u578b\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff1a</p> <ul> <li>\u200b\u901a\u8fc7\u200b\u7f16\u7a0b\u200b\u5c06\u200b\u6587\u4ef6\u200b\u63a8\u9001\u200b\u5230\u200bHub\u3002</li> <li>\u200b\u4f7f\u7528\u200bWeb\u200b\u754c\u9762\u200b\u5c06\u200b\u6587\u4ef6\u200b\u62d6\u200b\u653e\u5230\u200bHub\u3002</li> </ul> <p> <p>\u200b\u8981\u200b\u4e0e\u200b\u793e\u533a\u200b\u5171\u4eab\u200b\u6a21\u578b\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5728\u200bhuggingface.co\u200b\u4e0a\u200b\u62e5\u6709\u200b\u4e00\u4e2a\u200b\u5e10\u6237\u200b\u3002\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u52a0\u5165\u200b\u73b0\u6709\u200b\u7684\u200b\u7ec4\u7ec7\u200b\u6216\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b\u7ec4\u7ec7\u200b\u3002</p> <p></p>"},{"location":"model_sharing/#_2","title":"\u4ed3\u5e93\u200b\u529f\u80fd","text":"<p>Model Hub\u200b\u4e0a\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u4ed3\u5e93\u200b\u90fd\u200b\u50cf\u662f\u200b\u4e00\u4e2a\u200b\u5178\u578b\u200b\u7684\u200bGitHub\u200b\u4ed3\u5e93\u200b\u3002\u200b\u6211\u4eec\u200b\u7684\u200b\u4ed3\u5e93\u200b\u63d0\u4f9b\u200b\u7248\u672c\u63a7\u5236\u200b\u3001\u200b\u63d0\u4ea4\u200b\u5386\u53f2\u8bb0\u5f55\u200b\u4ee5\u53ca\u200b\u53ef\u89c6\u5316\u200b\u5dee\u5f02\u200b\u7684\u200b\u80fd\u529b\u200b\u3002</p> <p>Model Hub\u200b\u7684\u200b\u5185\u7f6e\u200b\u7248\u672c\u63a7\u5236\u200b\u57fa\u4e8e\u200bgit\u200b\u548c\u200bgit-lfs\u3002\u200b\u6362\u53e5\u8bdd\u8bf4\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u89c6\u4e3a\u200b\u4e00\u4e2a\u200b\u4ed3\u5e93\u200b\uff0c\u200b\u4ece\u800c\u200b\u5b9e\u73b0\u200b\u66f4\u597d\u200b\u7684\u200b\u8bbf\u95ee\u63a7\u5236\u200b\u548c\u200b\u53ef\u6269\u5c55\u6027\u200b\u3002\u200b\u7248\u672c\u63a7\u5236\u200b\u5141\u8bb8\u200b\u4f7f\u7528\u200b\u4fee\u8ba2\u200b\u65b9\u6cd5\u200b\u6765\u200b\u56fa\u5b9a\u200b\u7279\u5b9a\u200b\u7248\u672c\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u63d0\u4ea4\u200b\u54c8\u5e0c\u200b\u503c\u200b\u3001\u200b\u6807\u7b7e\u200b\u6216\u200b\u5206\u652f\u200b\u6765\u200b\u6807\u8bb0\u200b\u3002</p> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b<code>revision</code>\u200b\u53c2\u6570\u200b\u52a0\u8f7d\u200b\u7279\u5b9a\u200b\u7684\u200b\u6a21\u578b\u200b\u7248\u672c\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; model = AutoModel.from_pretrained(\n...     \"julien-c/EsperBERTo-small\", revision=\"v2.0.1\"  # tag name, or branch name, or commit hash\n... )\n</code></pre> <p>\u200b\u6587\u4ef6\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u5730\u200b\u5728\u200b\u4ed3\u5e93\u200b\u4e2d\u200b\u7f16\u8f91\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u67e5\u770b\u200b\u63d0\u4ea4\u200b\u5386\u53f2\u8bb0\u5f55\u200b\u4ee5\u53ca\u200b\u5dee\u5f02\u200b\uff1a </p>"},{"location":"model_sharing/#_3","title":"\u8bbe\u7f6e","text":"<p>\u200b\u5728\u200b\u5c06\u200b\u6a21\u578b\u200b\u5171\u4eab\u200b\u5230\u200bHub\u200b\u4e4b\u524d\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u62e5\u6709\u200bHugging Face\u200b\u7684\u200b\u51ed\u8bc1\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200b\u8bbf\u95ee\u200b\u7ec8\u7aef\u200b\u7684\u200b\u6743\u9650\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b\u5b89\u88c5\u200b\ud83e\udd17 Transformers\u200b\u7684\u200b\u865a\u62df\u200b\u73af\u5883\u4e2d\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u3002\u200b\u8fd9\u200b\u5c06\u200b\u5728\u200b\u60a8\u200b\u7684\u200bHugging Face\u200b\u7f13\u5b58\u200b\u6587\u4ef6\u5939\u200b\uff08\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b<code>~/.cache/</code>\uff09\u200b\u4e2d\u200b\u5b58\u50a8\u200b\u60a8\u200b\u7684\u200b<code>access token</code>\uff1a</p> <pre><code>huggingface-cli login\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u6b63\u5728\u200b\u4f7f\u7528\u200b\u50cf\u200bJupyter\u200b\u6216\u200bColaboratory\u200b\u8fd9\u6837\u200b\u7684\u200b<code>notebook</code>\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u60a8\u200b\u5df2\u200b\u5b89\u88c5\u200b\u4e86\u200b<code>huggingface_hub</code>\u200b\u5e93\u200b\u3002\u200b\u8be5\u5e93\u200b\u5141\u8bb8\u200b\u60a8\u200b\u4ee5\u200b\u7f16\u7a0b\u200b\u65b9\u5f0f\u200b\u4e0e\u200bHub\u200b\u8fdb\u884c\u200b\u4ea4\u4e92\u200b\u3002</p> <p><pre><code>pip install huggingface_hub\n</code></pre> \u200b\u7136\u540e\u200b\u4f7f\u7528\u200b<code>notebook_login</code>\u200b\u767b\u5f55\u200b\u5230\u200bHub\uff0c\u200b\u5e76\u200b\u6309\u7167\u200b\u8fd9\u91cc\u200b\u7684\u200b\u94fe\u63a5\u200b\u751f\u6210\u200b\u4e00\u4e2a\u200btoken\u200b\u8fdb\u884c\u200b\u767b\u5f55\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from huggingface_hub import notebook_login\n\n&gt;&gt;&gt; notebook_login()\n</code></pre>"},{"location":"model_sharing/#_4","title":"\u8f6c\u6362\u200b\u6a21\u578b\u200b\u9002\u7528\u200b\u4e8e\u200b\u6240\u6709\u200b\u6846\u67b6","text":"<p>\u200b\u4e3a\u200b\u786e\u4fdd\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u4f7f\u7528\u200b\u4e0d\u540c\u200b\u6846\u67b6\u200b\u7684\u200b\u4eba\u200b\u4f7f\u7528\u200b\uff0c\u200b\u6211\u4eec\u200b\u5efa\u8bae\u60a8\u200b\u5c06\u200bPyTorch\u200b\u548c\u200bTensorFlow <code>checkpoints</code>\u200b\u90fd\u200b\u8f6c\u6362\u200b\u5e76\u200b\u4e0a\u4f20\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u8df3\u200b\u8fc7\u200b\u6b64\u200b\u6b65\u9aa4\u200b\uff0c\u200b\u7528\u6237\u200b\u4ecd\u7136\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u5176\u4ed6\u200b\u6846\u67b6\u200b\u52a0\u8f7d\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u4f46\u200b\u901f\u5ea6\u200b\u4f1a\u200b\u53d8\u6162\u200b\uff0c\u200b\u56e0\u4e3a\u200b\ud83e\udd17 Transformers\u200b\u9700\u8981\u200b\u5b9e\u65f6\u200b\u8f6c\u6362\u200b<code>checkpoints</code>\u3002</p> <p>\u200b\u4e3a\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u6846\u67b6\u200b\u8f6c\u6362\u200b<code>checkpoints</code>\u200b\u5f88\u200b\u5bb9\u6613\u200b\u3002\u200b\u786e\u4fdd\u60a8\u200b\u5df2\u200b\u5b89\u88c5\u200bPyTorch\u200b\u548c\u200bTensorFlow\uff08\u200b\u8bf7\u53c2\u9605\u200b\u6b64\u5904\u200b\u7684\u200b\u5b89\u88c5\u200b\u8bf4\u660e\u200b\uff09\uff0c\u200b\u7136\u540e\u200b\u5728\u200b\u5176\u4ed6\u200b\u6846\u67b6\u200b\u4e2d\u200b\u627e\u5230\u200b\u9002\u5408\u200b\u60a8\u200b\u4efb\u52a1\u200b\u7684\u200b\u7279\u5b9a\u200b\u6a21\u578b\u200b\u3002</p> <p> <p>\u200b\u6307\u5b9a\u200b<code>from_tf=True</code>\u200b\u5c06\u200bcheckpoint\u200b\u4ece\u200bTensorFlow\u200b\u8f6c\u6362\u200b\u4e3a\u200bPyTorch\u3002</p> <p><pre><code>&gt;&gt;&gt; pt_model = DistilBertForSequenceClassification.from_pretrained(\"path/to/awesome-name-you-picked\", from_tf=True)\n&gt;&gt;&gt; pt_model.save_pretrained(\"path/to/awesome-name-you-picked\")\n</code></pre> <p>\u200b\u6307\u5b9a\u200b<code>from_pt=True</code>\u200b\u5c06\u200bcheckpoint\u200b\u4ece\u200bPyTorch\u200b\u8f6c\u6362\u200b\u4e3a\u200bTensorFlow\u3002</p> <pre><code>&gt;&gt;&gt; tf_model = TFDistilBertForSequenceClassification.from_pretrained(\"path/to/awesome-name-you-picked\", from_pt=True)\n</code></pre> <p>\u200b\u7136\u540e\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u65b0\u200b\u7684\u200bcheckpoint\u200b\u4fdd\u5b58\u200b\u60a8\u200b\u7684\u200b\u65b0\u200bTensorFlow\u200b\u6a21\u578b\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; tf_model.save_pretrained(\"path/to/awesome-name-you-picked\")\n</code></pre> <p>\u200b\u5982\u679c\u200b\u6a21\u578b\u200b\u5728\u200bFlax\u200b\u4e2d\u200b\u53ef\u7528\u200b\uff0c\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u5c06\u200bPyTorch checkpoint\u200b\u8f6c\u6362\u200b\u4e3a\u200bFlax\uff1a</p> <p><pre><code>&gt;&gt;&gt; flax_model = FlaxDistilBertForSequenceClassification.from_pretrained(\n...     \"path/to/awesome-name-you-picked\", from_pt=True\n... )\n</code></pre> </p>"},{"location":"model_sharing/#_5","title":"\u5728\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u63a8\u9001\u200b\u6a21\u578b","text":"<p> <p>\u200b\u5c06\u200b\u6a21\u578b\u200b\u5206\u4eab\u200b\u5230\u200bHub\u200b\u5c31\u200b\u50cf\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u989d\u5916\u200b\u7684\u200b\u53c2\u6570\u200b\u6216\u200b\u56de\u8c03\u200b\u51fd\u6570\u200b\u4e00\u6837\u200b\u7b80\u5355\u200b\u3002\u200b\u8bf7\u200b\u8bb0\u4f4f\u200b\uff0c\u200b\u5728\u200b\u5fae\u8c03\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c<code>TrainingArguments</code>\u200b\u7c7b\u200b\u662f\u200b\u60a8\u200b\u6307\u5b9a\u200b\u8d85\u200b\u53c2\u6570\u200b\u548c\u200b\u9644\u52a0\u200b\u8bad\u7ec3\u200b\u9009\u9879\u200b\u7684\u200b\u5730\u65b9\u200b\u3002\u200b\u5176\u4e2d\u200b\u4e00\u9879\u200b\u8bad\u7ec3\u200b\u9009\u9879\u200b\u5305\u62ec\u200b\u76f4\u63a5\u200b\u5c06\u200b\u6a21\u578b\u200b\u63a8\u9001\u200b\u5230\u200bHub\u200b\u7684\u200b\u80fd\u529b\u200b\u3002\u200b\u5728\u200b\u60a8\u200b\u7684\u200b<code>TrainingArguments</code>\u200b\u4e2d\u200b\u8bbe\u7f6e\u200b<code>push_to_hub=True</code>\uff1a</p> <pre><code>&gt;&gt;&gt; training_args = TrainingArguments(output_dir=\"my-awesome-model\", push_to_hub=True)\n</code></pre> <p>\u200b\u50cf\u200b\u5f80\u5e38\u200b\u4e00\u6837\u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u53c2\u6570\u4f20\u9012\u200b\u7ed9\u200b[<code>Trainer</code>]\uff1a</p> <pre><code>&gt;&gt;&gt; trainer = Trainer(\n...     model=model,\n...     args=training_args,\n...     train_dataset=small_train_dataset,\n...     eval_dataset=small_eval_dataset,\n...     compute_metrics=compute_metrics,\n... )\n</code></pre> <p>\u200b\u5728\u200b\u60a8\u200b\u5fae\u8c03\u200b\u5b8c\u200b\u6a21\u578b\u200b\u540e\u200b\uff0c\u200b\u5728\u200b[<code>Trainer</code>]\u200b\u4e0a\u200b\u8c03\u7528\u200b[<code>~transformers.Trainer.push_to_hub</code>]\u200b\u5c06\u200b\u8bad\u7ec3\u200b\u597d\u200b\u7684\u200b\u6a21\u578b\u200b\u63a8\u9001\u200b\u5230\u200bHub\u3002\ud83e\udd17 Transformers\u200b\u751a\u81f3\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u5c06\u200b\u8bad\u7ec3\u200b\u8d85\u200b\u53c2\u6570\u200b\u3001\u200b\u8bad\u7ec3\u200b\u7ed3\u679c\u200b\u548c\u200b\u6846\u67b6\u200b\u7248\u672c\u200b\u6dfb\u52a0\u200b\u5230\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u5361\u7247\u200b\u4e2d\u200b\uff01</p> <p><pre><code>&gt;&gt;&gt; trainer.push_to_hub()\n</code></pre> <p>\u200b\u4f7f\u7528\u200b[<code>PushToHubCallback</code>]\u200b\u5c06\u200b\u6a21\u578b\u200b\u5206\u4eab\u200b\u5230\u200bHub\u3002\u200b\u5728\u200b[<code>PushToHubCallback</code>]\u200b\u51fd\u6570\u200b\u4e2d\u200b\uff0c\u200b\u6dfb\u52a0\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a</p> <ul> <li>\u200b\u4e00\u4e2a\u200b\u7528\u4e8e\u200b\u5b58\u50a8\u200b\u6a21\u578b\u200b\u7684\u200b\u8f93\u51fa\u200b\u76ee\u5f55\u200b\u3002</li> <li>\u200b\u4e00\u4e2a\u200btokenizer\u3002</li> <li><code>hub_model_id</code>\uff0c\u200b\u5373\u200b\u60a8\u200b\u7684\u200bHub\u200b\u7528\u6237\u540d\u200b\u548c\u200b\u6a21\u578b\u200b\u540d\u79f0\u200b\u3002</li> </ul> <pre><code>&gt;&gt;&gt; from transformers import PushToHubCallback\n\n&gt;&gt;&gt; push_to_hub_callback = PushToHubCallback(\n...     output_dir=\"./your_model_save_path\", tokenizer=tokenizer, hub_model_id=\"your-username/my-awesome-model\"\n... )\n</code></pre> <p>\u200b\u5c06\u200b\u56de\u8c03\u200b\u51fd\u6570\u200b\u6dfb\u52a0\u200b\u5230\u200b <code>fit</code>\u200b\u4e2d\u200b\uff0c\u200b\u7136\u540e\u200b\ud83e\udd17 Transformers \u200b\u4f1a\u200b\u5c06\u200b\u8bad\u7ec3\u200b\u597d\u200b\u7684\u200b\u6a21\u578b\u200b\u63a8\u9001\u200b\u5230\u200b Hub\uff1a</p> <p><pre><code>&gt;&gt;&gt; model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3, callbacks=push_to_hub_callback)\n</code></pre> </p>"},{"location":"model_sharing/#push_to_hub","title":"\u4f7f\u7528\u200b<code>push_to_hub</code>\u200b\u529f\u80fd","text":"<p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u4e0a\u200b\u8c03\u7528\u200b<code>push_to_hub</code>\u200b\u6765\u200b\u5c06\u200b\u5176\u200b\u4e0a\u200b\u4f20\u5230\u200bHub\u3002</p> <p>\u200b\u5728\u200b<code>push_to_hub</code>\u200b\u4e2d\u200b\u6307\u5b9a\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u540d\u79f0\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; pt_model.push_to_hub(\"my-awesome-model\")\n</code></pre> <p>\u200b\u8fd9\u4f1a\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u7528\u6237\u540d\u200b\u4e0b\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u540d\u4e3a\u200b<code>my-awesome-model</code>\u200b\u7684\u200b\u4ed3\u5e93\u200b\u3002\u200b\u7528\u6237\u200b\u73b0\u5728\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b<code>from_pretrained</code>\u200b\u51fd\u6570\u200b\u52a0\u8f7d\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoModel\n\n&gt;&gt;&gt; model = AutoModel.from_pretrained(\"your_username/my-awesome-model\")\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u5c5e\u4e8e\u200b\u4e00\u4e2a\u200b\u7ec4\u7ec7\u200b\uff0c\u200b\u5e76\u200b\u5e0c\u671b\u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u63a8\u9001\u200b\u5230\u200b\u7ec4\u7ec7\u200b\u540d\u79f0\u200b\u4e0b\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u5c06\u200b\u5176\u200b\u6dfb\u52a0\u200b\u5230\u200b<code>repo_id</code>\u200b\u4e2d\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; pt_model.push_to_hub(\"my-awesome-org/my-awesome-model\")\n</code></pre> <p><code>push_to_hub</code>\u200b\u51fd\u6570\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u7528\u4e8e\u200b\u5411\u200b\u6a21\u578b\u200b\u4ed3\u5e93\u200b\u6dfb\u52a0\u200b\u5176\u4ed6\u200b\u6587\u4ef6\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5411\u200b\u6a21\u578b\u200b\u4ed3\u5e93\u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b<code>tokenizer</code>\uff1a</p> <pre><code>&gt;&gt;&gt; tokenizer.push_to_hub(\"my-awesome-model\")\n</code></pre> <p>\u200b\u6216\u8005\u200b\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u5e0c\u671b\u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u5fae\u8c03\u200b\u540e\u200b\u7684\u200bPyTorch\u200b\u6a21\u578b\u200b\u7684\u200bTensorFlow\u200b\u7248\u672c\u200b\u6dfb\u52a0\u200b\u8fdb\u53bb\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; tf_model.push_to_hub(\"my-awesome-model\")\n</code></pre> \u200b\u73b0\u5728\u200b\uff0c\u200b\u5f53\u200b\u60a8\u200b\u5bfc\u822a\u200b\u5230\u200b\u60a8\u200b\u7684\u200bHugging Face\u200b\u4e2a\u4eba\u8d44\u6599\u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u5e94\u8be5\u200b\u770b\u5230\u200b\u60a8\u200b\u65b0\u521b\u5efa\u200b\u7684\u200b\u6a21\u578b\u200b\u4ed3\u5e93\u200b\u3002\u200b\u70b9\u51fb\u200b\u6587\u4ef6\u200b\u9009\u9879\u5361\u200b\u5c06\u200b\u663e\u793a\u200b\u60a8\u200b\u5df2\u200b\u4e0a\u200b\u4f20\u5230\u200b\u4ed3\u5e93\u200b\u7684\u200b\u6240\u6709\u200b\u6587\u4ef6\u200b\u3002</p> <p>\u200b\u6709\u5173\u200b\u5982\u4f55\u200b\u521b\u5efa\u200b\u548c\u200b\u4e0a\u4f20\u200b\u6587\u4ef6\u200b\u5230\u200b\u4ed3\u5e93\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u8003\u200bHub\u200b\u6587\u6863\u200b\u8fd9\u91cc\u200b\u3002</p>"},{"location":"model_sharing/#web","title":"\u4f7f\u7528\u200bWeb\u200b\u754c\u9762\u200b\u4e0a\u4f20","text":"<p>\u200b\u559c\u6b22\u200b\u65e0\u200b\u4ee3\u7801\u200b\u65b9\u6cd5\u200b\u7684\u200b\u7528\u6237\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200bHugging Face\u200b\u7684\u200bWeb\u200b\u754c\u9762\u200b\u4e0a\u4f20\u200b\u6a21\u578b\u200b\u3002\u200b\u8bbf\u95ee\u200bhuggingface.co/new\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b\u4ed3\u5e93\u200b\uff1a</p> <p></p> <p>\u200b\u4ece\u200b\u8fd9\u91cc\u200b\u5f00\u59cb\u200b\uff0c\u200b\u6dfb\u52a0\u200b\u4e00\u4e9b\u200b\u5173\u4e8e\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u7684\u200b\u4fe1\u606f\u200b\uff1a</p> <ul> <li>\u200b\u9009\u62e9\u200b\u4ed3\u5e93\u200b\u7684\u200b\u6240\u6709\u8005\u200b\u3002\u200b\u8fd9\u200b\u53ef\u4ee5\u200b\u662f\u200b\u60a8\u200b\u672c\u4eba\u200b\u6216\u8005\u200b\u60a8\u200b\u6240\u5c5e\u200b\u7684\u200b\u4efb\u4f55\u200b\u7ec4\u7ec7\u200b\u3002</li> <li>\u200b\u4e3a\u200b\u60a8\u200b\u7684\u200b\u9879\u76ee\u9009\u62e9\u200b\u4e00\u4e2a\u200b\u540d\u79f0\u200b\uff0c\u200b\u8be5\u200b\u540d\u79f0\u200b\u4e5f\u200b\u5c06\u200b\u6210\u4e3a\u200b\u4ed3\u5e93\u200b\u7684\u200b\u540d\u79f0\u200b\u3002</li> <li>\u200b\u9009\u62e9\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u662f\u200b\u516c\u5f00\u200b\u8fd8\u662f\u200b\u79c1\u6709\u200b\u3002</li> <li>\u200b\u6307\u5b9a\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u7684\u200b\u8bb8\u53ef\u8bc1\u200b\u4f7f\u7528\u200b\u60c5\u51b5\u200b\u3002</li> </ul> <p>\u200b\u73b0\u5728\u200b\u70b9\u51fb\u200b\u6587\u4ef6\u200b\u9009\u9879\u5361\u200b\uff0c\u200b\u7136\u540e\u200b\u70b9\u51fb\u200b\u6dfb\u52a0\u200b\u6587\u4ef6\u200b\u6309\u94ae\u200b\u5c06\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u6587\u4ef6\u200b\u4e0a\u200b\u4f20\u5230\u200b\u4f60\u200b\u7684\u200b\u4ed3\u5e93\u200b\u3002\u200b\u63a5\u7740\u200b\u62d6\u653e\u200b\u4e00\u4e2a\u200b\u6587\u4ef6\u200b\u8fdb\u884c\u200b\u4e0a\u4f20\u200b\uff0c\u200b\u5e76\u200b\u6dfb\u52a0\u200b\u63d0\u4ea4\u200b\u4fe1\u606f\u200b\u3002</p> <p></p>"},{"location":"model_sharing/#_6","title":"\u6dfb\u52a0\u200b\u6a21\u578b\u200b\u5361\u7247","text":"<p>\u200b\u4e3a\u4e86\u200b\u786e\u4fdd\u200b\u7528\u6237\u200b\u4e86\u89e3\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u7684\u200b\u80fd\u529b\u200b\u3001\u200b\u9650\u5236\u200b\u3001\u200b\u6f5c\u5728\u200b\u504f\u5dee\u200b\u548c\u200b\u4f26\u7406\u200b\u8003\u8651\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b\u4ed3\u5e93\u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u5361\u7247\u200b\u3002\u200b\u6a21\u578b\u200b\u5361\u7247\u200b\u5728\u200b<code>README.md</code>\u200b\u6587\u4ef6\u200b\u4e2d\u200b\u5b9a\u4e49\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u6dfb\u52a0\u200b\u6a21\u578b\u200b\u5361\u7247\u200b\uff1a</p> <ul> <li>\u200b\u624b\u52a8\u200b\u521b\u5efa\u200b\u5e76\u200b\u4e0a\u4f20\u200b\u4e00\u4e2a\u200b<code>README.md</code>\u200b\u6587\u4ef6\u200b\u3002</li> <li>\u200b\u5728\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u4ed3\u5e93\u200b\u4e2d\u200b\u70b9\u51fb\u200b\u7f16\u8f91\u200b\u6a21\u578b\u200b\u5361\u7247\u200b\u6309\u94ae\u200b\u3002</li> </ul> <p>\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200bDistilBert\u200b\u7684\u200b\u6a21\u578b\u200b\u5361\u7247\u200b\u6765\u200b\u4e86\u89e3\u200b\u6a21\u578b\u200b\u5361\u7247\u200b\u5e94\u8be5\u200b\u5305\u542b\u200b\u7684\u200b\u4fe1\u606f\u200b\u7c7b\u578b\u200b\u3002\u200b\u6709\u5173\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b<code>README.md</code>\u200b\u6587\u4ef6\u200b\u4e2d\u200b\u63a7\u5236\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u9009\u9879\u200b\u7684\u200b\u7ec6\u8282\u200b\uff0c\u200b\u4f8b\u5982\u200b\u6a21\u578b\u200b\u7684\u200b\u78b3\u200b\u8db3\u8ff9\u200b\u6216\u200b\u5c0f\u200b\u90e8\u4ef6\u200b\u793a\u4f8b\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u8003\u200b\u6587\u6863\u200b\u8fd9\u91cc\u200b\u3002</p>"},{"location":"peft/","title":"Peft","text":""},{"location":"peft/#peft-adapters","title":"\u4f7f\u7528\u200b \ud83e\udd17 PEFT \u200b\u52a0\u8f7d\u200badapters","text":"<p>[[open-in-colab]]</p> <p>\u200b\u53c2\u6570\u200b\u9ad8\u6548\u200b\u5fae\u8c03\u200b\uff08PEFT\uff09\u200b\u65b9\u6cd5\u200b\u5728\u200b\u5fae\u8c03\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u51bb\u7ed3\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u5176\u200b\u9876\u90e8\u200b\u6dfb\u52a0\u200b\u5c11\u91cf\u200b\u53ef\u200b\u8bad\u7ec3\u200b\u53c2\u6570\u200b\uff08adapters\uff09\u3002adapters\u200b\u88ab\u200b\u8bad\u7ec3\u200b\u4ee5\u200b\u5b66\u4e60\u200b\u7279\u5b9a\u200b\u4efb\u52a1\u200b\u7684\u200b\u4fe1\u606f\u200b\u3002\u200b\u8fd9\u79cd\u200b\u65b9\u6cd5\u200b\u5df2\u200b\u88ab\u200b\u8bc1\u660e\u200b\u975e\u5e38\u200b\u8282\u7701\u200b\u5185\u5b58\u200b\uff0c\u200b\u540c\u65f6\u200b\u5177\u6709\u200b\u8f83\u200b\u4f4e\u200b\u7684\u200b\u8ba1\u7b97\u200b\u4f7f\u7528\u91cf\u200b\uff0c\u200b\u540c\u65f6\u200b\u4ea7\u751f\u200b\u4e0e\u200b\u5b8c\u5168\u200b\u5fae\u8c03\u200b\u6a21\u578b\u200b\u76f8\u5f53\u200b\u7684\u200b\u7ed3\u679c\u200b\u3002</p> <p>\u200b\u4f7f\u7528\u200bPEFT\u200b\u8bad\u7ec3\u200b\u7684\u200badapters\u200b\u901a\u5e38\u200b\u6bd4\u200b\u5b8c\u6574\u200b\u6a21\u578b\u200b\u5c0f\u200b\u4e00\u4e2a\u200b\u6570\u91cf\u7ea7\u200b\uff0c\u200b\u4f7f\u200b\u5176\u200b\u65b9\u4fbf\u200b\u5171\u4eab\u200b\u3001\u200b\u5b58\u50a8\u200b\u548c\u200b\u52a0\u8f7d\u200b\u3002</p> \u200b\u4e0e\u200b\u5b8c\u6574\u200b\u5c3a\u5bf8\u200b\u7684\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\uff08\u200b\u7ea6\u200b\u4e3a\u200b700MB\uff09\u200b\u76f8\u6bd4\u200b\uff0c\u200b\u5b58\u50a8\u200b\u5728\u200bHub\u200b\u4e0a\u200b\u7684\u200bOPTForCausalLM\u200b\u6a21\u578b\u200b\u7684\u200badapter\u200b\u6743\u91cd\u200b\u4ec5\u4e3a\u200b~6MB\u3002 <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u5bf9\u200b\u5b66\u4e60\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b\ud83e\udd17 PEFT\u200b\u5e93\u200b\u611f\u5174\u8da3\u200b\uff0c\u200b\u8bf7\u200b\u67e5\u770b\u200b\u6587\u6863\u200b\u3002</p>"},{"location":"peft/#_1","title":"\u8bbe\u7f6e","text":"<p>\u200b\u9996\u5148\u200b\u5b89\u88c5\u200b \ud83e\udd17 PEFT\uff1a</p> <pre><code>pip install peft\n</code></pre> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u200b\u5c1d\u8bd5\u200b\u5168\u65b0\u200b\u7684\u200b\u7279\u6027\u200b\uff0c\u200b\u4f60\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u6709\u200b\u5174\u8da3\u200b\u4ece\u200b\u6e90\u4ee3\u7801\u200b\u5b89\u88c5\u200b\u8fd9\u4e2a\u200b\u5e93\u200b\uff1a</p> <pre><code>pip install git+https://github.com/huggingface/peft.git\n</code></pre>"},{"location":"peft/#peft","title":"\u652f\u6301\u200b\u7684\u200b PEFT \u200b\u6a21\u578b","text":"<p>Transformers\u200b\u539f\u751f\u200b\u652f\u6301\u200b\u4e00\u4e9b\u200bPEFT\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u52a0\u8f7d\u200b\u672c\u5730\u200b\u5b58\u50a8\u200b\u6216\u200b\u5728\u200bHub\u200b\u4e0a\u200b\u7684\u200badapter\u200b\u6743\u91cd\u200b\uff0c\u200b\u5e76\u200b\u4f7f\u7528\u200b\u51e0\u884c\u200b\u4ee3\u7801\u200b\u8f7b\u677e\u200b\u8fd0\u884c\u200b\u6216\u200b\u8bad\u7ec3\u200b\u5b83\u4eec\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u53d7\u200b\u652f\u6301\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff1a</p> <ul> <li>Low Rank Adapters</li> <li>IA3</li> <li>AdaLoRA</li> </ul> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u200b\u4f7f\u7528\u200b\u5176\u4ed6\u200bPEFT\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u4f8b\u5982\u200b\u63d0\u793a\u200b\u5b66\u4e60\u200b\u6216\u200b\u63d0\u793a\u200b\u5fae\u8c03\u200b\uff0c\u200b\u6216\u8005\u200b\u5173\u4e8e\u200b\u901a\u7528\u200b\u7684\u200b \ud83e\udd17 PEFT\u200b\u5e93\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u6587\u6863\u200b\u3002</p>"},{"location":"peft/#peft-adapter","title":"\u52a0\u8f7d\u200b PEFT adapter","text":"<p>\u200b\u8981\u200b\u4ece\u200bhuggingface\u200b\u7684\u200bTransformers\u200b\u5e93\u4e2d\u200b\u52a0\u8f7d\u200b\u5e76\u200b\u4f7f\u7528\u200bPEFTadapter\u200b\u6a21\u578b\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200bHub\u200b\u4ed3\u5e93\u200b\u6216\u200b\u672c\u5730\u200b\u76ee\u5f55\u200b\u5305\u542b\u200b\u4e00\u4e2a\u200b<code>adapter_config.json</code>\u200b\u6587\u4ef6\u200b\u548c\u200badapter\u200b\u6743\u91cd\u200b\uff0c\u200b\u5982\u4e0a\u4f8b\u200b\u6240\u793a\u200b\u3002\u200b\u7136\u540e\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b<code>AutoModelFor</code>\u200b\u7c7b\u200b\u52a0\u8f7d\u200bPEFT adapter\u200b\u6a21\u578b\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u8981\u200b\u4e3a\u200b\u56e0\u679c\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200bPEFT adapter\u200b\u6a21\u578b\u200b\uff1a</p> <ol> <li>\u200b\u6307\u5b9a\u200bPEFT\u200b\u6a21\u578b\u200bid</li> <li>\u200b\u5c06\u200b\u5176\u200b\u4f20\u9012\u200b\u7ed9\u200b[<code>AutoModelForCausalLM</code>]\u200b\u7c7b\u200b</li> </ol> <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer\n\npeft_model_id = \"ybelkada/opt-350m-lora\"\nmodel = AutoModelForCausalLM.from_pretrained(peft_model_id)\n</code></pre> <p> <p>\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b<code>AutoModelFor</code>\u200b\u7c7b\u200b\u6216\u200b\u57fa\u7840\u200b\u6a21\u578b\u200b\u7c7b\u200b\uff08\u200b\u5982\u200b<code>OPTForCausalLM</code>\u200b\u6216\u200b<code>LlamaForCausalLM</code>\uff09\u200b\u6765\u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200bPEFT adapter\u3002</p> <p></p> <p>\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b<code>load_adapter</code>\u200b\u65b9\u6cd5\u200b\u6765\u200b\u52a0\u8f7d\u200b PEFT adapter\u3002</p> <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_id = \"facebook/opt-350m\"\npeft_model_id = \"ybelkada/opt-350m-lora\"\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\nmodel.load_adapter(peft_model_id)\n</code></pre>"},{"location":"peft/#8bit4bit","title":"\u57fa\u4e8e\u200b8bit\u200b\u6216\u200b4bit\u200b\u8fdb\u884c\u200b\u52a0\u8f7d","text":"<p><code>bitsandbytes</code>\u200b\u96c6\u6210\u200b\u652f\u6301\u200b8bit\u200b\u548c\u200b4bit\u200b\u7cbe\u5ea6\u200b\u6570\u636e\u7c7b\u578b\u200b\uff0c\u200b\u8fd9\u200b\u5bf9\u4e8e\u200b\u52a0\u8f7d\u200b\u5927\u200b\u6a21\u578b\u200b\u975e\u5e38\u200b\u6709\u7528\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u53ef\u4ee5\u200b\u8282\u7701\u200b\u5185\u5b58\u200b\uff08\u200b\u8bf7\u53c2\u9605\u200b<code>bitsandbytes</code>\u200b\u6307\u5357\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff09\u3002\u200b\u8981\u200b\u6709\u6548\u200b\u5730\u200b\u5c06\u200b\u6a21\u578b\u200b\u5206\u914d\u200b\u5230\u200b\u60a8\u200b\u7684\u200b\u786c\u4ef6\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b[<code>~PreTrainedModel.from_pretrained</code>]\u200b\u4e2d\u200b\u6dfb\u52a0\u200b<code>load_in_8bit</code>\u200b\u6216\u200b<code>load_in_4bit</code>\u200b\u53c2\u6570\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200b<code>device_map=\"auto\"</code>\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\uff1a</p> <pre><code>from transformers import AutoModelForCausalLM, AutoTokenizer\n\npeft_model_id = \"ybelkada/opt-350m-lora\"\nmodel = AutoModelForCausalLM.from_pretrained(peft_model_id, device_map=\"auto\", load_in_8bit=True)\n</code></pre>"},{"location":"peft/#adapter","title":"\u6dfb\u52a0\u200b\u65b0\u200b\u7684\u200badapter","text":"<p>\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b[<code>~peft.PeftModel.add_adapter</code>]\u200b\u65b9\u6cd5\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u5df2\u6709\u200badapter\u200b\u7684\u200b\u6a21\u578b\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200badapter\uff0c\u200b\u53ea\u8981\u200b\u65b0\u200badapter\u200b\u7684\u200b\u7c7b\u578b\u200b\u4e0e\u200b\u5f53\u524d\u200badapter\u200b\u76f8\u540c\u200b\u5373\u53ef\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u6709\u200b\u4e00\u4e2a\u200b\u9644\u52a0\u200b\u5230\u200b\u6a21\u578b\u200b\u4e0a\u200b\u7684\u200bLoRA adapter\uff1a</p> <pre><code>from transformers import AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer\nfrom peft import PeftConfig\n\nmodel_id = \"facebook/opt-350m\"\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\nlora_config = LoraConfig(\n    target_modules=[\"q_proj\", \"k_proj\"],\n    init_lora_weights=False\n)\n\nmodel.add_adapter(lora_config, adapter_name=\"adapter_1\")\n</code></pre> <p>\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200badapter\uff1a</p> <p><pre><code># attach new adapter with same config\nmodel.add_adapter(lora_config, adapter_name=\"adapter_2\")\n</code></pre> \u200b\u73b0\u5728\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b[<code>~peft.PeftModel.set_adapter</code>]\u200b\u6765\u200b\u8bbe\u7f6e\u200b\u8981\u200b\u4f7f\u7528\u200b\u7684\u200badapter\u3002</p> <pre><code># use adapter_1\nmodel.set_adapter(\"adapter_1\")\noutput = model.generate(**inputs)\nprint(tokenizer.decode(output_disabled[0], skip_special_tokens=True))\n\n# use adapter_2\nmodel.set_adapter(\"adapter_2\")\noutput_enabled = model.generate(**inputs)\nprint(tokenizer.decode(output_enabled[0], skip_special_tokens=True))\n</code></pre>"},{"location":"peft/#adapters","title":"\u542f\u7528\u200b\u548c\u200b\u7981\u7528\u200badapters","text":"<p>\u200b\u4e00\u65e6\u200b\u60a8\u200b\u5c06\u200badapter\u200b\u6dfb\u52a0\u200b\u5230\u200b\u6a21\u578b\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u542f\u7528\u200b\u6216\u200b\u7981\u7528\u200badapter\u200b\u6a21\u5757\u200b\u3002\u200b\u8981\u200b\u542f\u7528\u200badapter\u200b\u6a21\u5757\u200b\uff1a</p> <p><pre><code>from transformers import AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer\nfrom peft import PeftConfig\n\nmodel_id = \"facebook/opt-350m\"\nadapter_model_id = \"ybelkada/opt-350m-lora\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntext = \"Hello\"\ninputs = tokenizer(text, return_tensors=\"pt\")\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\npeft_config = PeftConfig.from_pretrained(adapter_model_id)\n\n# to initiate with random weights\npeft_config.init_lora_weights = False\n\nmodel.add_adapter(peft_config)\nmodel.enable_adapters()\noutput = model.generate(**inputs)\n</code></pre> \u200b\u8981\u200b\u7981\u7528\u200badapter\u200b\u6a21\u5757\u200b\uff1a</p> <pre><code>model.disable_adapters()\noutput = model.generate(**inputs)\n</code></pre>"},{"location":"peft/#peft-adapter_1","title":"\u8bad\u7ec3\u200b\u4e00\u4e2a\u200b PEFT adapter","text":"<p>PEFT\u200b\u9002\u914d\u5668\u200b\u53d7\u200b[<code>Trainer</code>]\u200b\u7c7b\u200b\u652f\u6301\u200b\uff0c\u200b\u56e0\u6b64\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4e3a\u200b\u60a8\u200b\u7684\u200b\u7279\u5b9a\u200b\u7528\u4f8b\u200b\u8bad\u7ec3\u200b\u9002\u914d\u5668\u200b\u3002\u200b\u5b83\u200b\u53ea\u200b\u9700\u8981\u200b\u6dfb\u52a0\u200b\u51e0\u884c\u200b\u4ee3\u7801\u200b\u5373\u53ef\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u8981\u200b\u8bad\u7ec3\u200b\u4e00\u4e2a\u200bLoRA adapter\uff1a</p> <p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u4e0d\u200b\u719f\u6089\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b[<code>Trainer</code>]\u200b\u5fae\u8c03\u200b\u6a21\u578b\u200b\uff0c\u200b\u8bf7\u200b\u67e5\u770b\u200b\u5fae\u8c03\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u6559\u7a0b\u200b\u3002</p> <p></p> <ol> <li>\u200b\u4f7f\u7528\u200b\u4efb\u52a1\u200b\u7c7b\u578b\u200b\u548c\u200b\u8d85\u200b\u53c2\u6570\u200b\u5b9a\u4e49\u200badapter\u200b\u914d\u7f6e\u200b\uff08\u200b\u53c2\u89c1\u200b[<code>~peft.LoraConfig</code>]\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u8d85\u200b\u53c2\u6570\u200b\u7684\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff09\u3002</li> </ol> <pre><code>from peft import LoraConfig\n\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n</code></pre> <ol> <li>\u200b\u5c06\u200badapter\u200b\u6dfb\u52a0\u200b\u5230\u200b\u6a21\u578b\u200b\u4e2d\u200b\u3002</li> </ol> <pre><code>model.add_adapter(peft_config)\n</code></pre> <ol> <li>\u200b\u73b0\u5728\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u6a21\u578b\u200b\u4f20\u9012\u200b\u7ed9\u200b[<code>Trainer</code>]\u200b\u4e86\u200b\uff01</li> </ol> <pre><code>trainer = Trainer(model=model, ...)\ntrainer.train()\n</code></pre> <p>\u200b\u8981\u200b\u4fdd\u5b58\u200b\u8bad\u7ec3\u200b\u597d\u200b\u7684\u200badapter\u200b\u5e76\u200b\u91cd\u65b0\u200b\u52a0\u8f7d\u200b\u5b83\u200b\uff1a</p> <pre><code>model.save_pretrained(save_dir)\nmodel = AutoModelForCausalLM.from_pretrained(save_dir)\n</code></pre>"},{"location":"perf_hardware/","title":"Perf hardware","text":""},{"location":"perf_hardware/#_1","title":"\u8bad\u7ec3\u200b\u7528\u200b\u7684\u200b\u5b9a\u5236\u200b\u786c\u4ef6","text":"<p>\u200b\u60a8\u200b\u7528\u6765\u200b\u8fd0\u884c\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u548c\u200b\u63a8\u65ad\u200b\u7684\u200b\u786c\u4ef6\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5bf9\u200b\u6027\u80fd\u200b\u4ea7\u751f\u200b\u91cd\u5927\u200b\u5f71\u54cd\u200b\u3002\u200b\u8981\u200b\u6df1\u5165\u200b\u4e86\u89e3\u200b GPU\uff0c\u200b\u52a1\u5fc5\u200b\u67e5\u770b\u200b Tim Dettmer \u200b\u51fa\u8272\u200b\u7684\u200b\u535a\u6587\u200b\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u6765\u770b\u200b\u4e00\u4e9b\u200b\u5173\u4e8e\u200b GPU \u200b\u914d\u7f6e\u200b\u7684\u200b\u5b9e\u7528\u200b\u5efa\u8bae\u200b\u3002</p>"},{"location":"perf_hardware/#gpu","title":"GPU","text":"<p>\u200b\u5f53\u200b\u4f60\u200b\u8bad\u7ec3\u200b\u66f4\u5927\u200b\u7684\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u57fa\u672c\u4e0a\u200b\u6709\u200b\u4e09\u79cd\u200b\u9009\u62e9\u200b\uff1a</p> <ul> <li>\u200b\u66f4\u5927\u200b\u7684\u200b GPU</li> <li>\u200b\u66f4\u200b\u591a\u200b\u7684\u200b GPU</li> <li>\u200b\u66f4\u200b\u591a\u200b\u7684\u200b CPU \u200b\u548c\u200b NVMe\uff08\u200b\u901a\u8fc7\u200bDeepSpeed-Infinity\u200b\u5b9e\u73b0\u200b\uff09</li> </ul> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4ece\u200b\u53ea\u6709\u200b\u4e00\u5757\u200bGPU\u200b\u7684\u200b\u60c5\u51b5\u200b\u5f00\u59cb\u200b\u3002</p>"},{"location":"perf_hardware/#_2","title":"\u4f9b\u7535\u200b\u548c\u200b\u6563\u70ed","text":"<p>\u200b\u5982\u679c\u200b\u60a8\u200b\u8d2d\u4e70\u200b\u4e86\u200b\u6602\u8d35\u200b\u7684\u200b\u9ad8\u7aef\u200bGPU\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200b\u4e3a\u200b\u5176\u200b\u63d0\u4f9b\u200b\u6b63\u786e\u200b\u7684\u200b\u4f9b\u7535\u200b\u548c\u200b\u8db3\u591f\u200b\u7684\u200b\u6563\u70ed\u200b\u3002</p> <p>\u200b\u4f9b\u7535\u200b\uff1a</p> <p>\u200b\u4e00\u4e9b\u200b\u9ad8\u7aef\u200b\u6d88\u8d39\u8005\u200b\u7ea7\u200bGPU\u200b\u5361\u200b\u5177\u6709\u200b2\u200b\u4e2a\u200b\uff0c\u200b\u6709\u65f6\u200b\u751a\u81f3\u200b3\u200b\u4e2a\u200bPCI-E-8\u200b\u9488\u200b\u7535\u6e90\u200b\u63d2\u53e3\u200b\u3002\u200b\u8bf7\u200b\u786e\u4fdd\u200b\u5c06\u200b\u4e0e\u200b\u63d2\u53e3\u200b\u6570\u91cf\u200b\u76f8\u540c\u200b\u7684\u200b\u72ec\u7acb\u200b12V PCI-E-8\u200b\u9488\u7ebf\u200b\u7f06\u200b\u63d2\u5165\u200b\u5361\u4e2d\u200b\u3002\u200b\u4e0d\u8981\u200b\u4f7f\u7528\u200b\u540c\u200b\u4e00\u6839\u200b\u7ebf\u7f06\u200b\u4e24\u7aef\u200b\u7684\u200b2\u200b\u4e2a\u200b\u5206\u53c9\u200b\uff08\u200b\u4e5f\u200b\u79f0\u4e3a\u200bpigtail cable\uff09\u3002\u200b\u4e5f\u5c31\u662f\u8bf4\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200bGPU\u200b\u4e0a\u200b\u6709\u200b2\u200b\u4e2a\u200b\u63d2\u53e3\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b2\u200b\u6761\u200bPCI-E-8\u200b\u9488\u7ebf\u200b\u7f06\u200b\u8fde\u63a5\u200b\u7535\u6e90\u200b\u548c\u200b\u5361\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u4f7f\u7528\u200b\u4e00\u6761\u200b\u672b\u7aef\u200b\u6709\u200b2\u200b\u4e2a\u200bPCI-E-8\u200b\u9488\u200b\u8fde\u63a5\u5668\u200b\u7684\u200b\u7ebf\u7f06\u200b\uff01\u200b\u5426\u5219\u200b\uff0c\u200b\u60a8\u200b\u65e0\u6cd5\u200b\u5145\u5206\u53d1\u6325\u200b\u5361\u200b\u7684\u200b\u6027\u80fd\u200b\u3002</p> <p>\u200b\u6bcf\u4e2a\u200bPCI-E-8\u200b\u9488\u200b\u7535\u6e90\u200b\u7ebf\u7f06\u200b\u9700\u8981\u200b\u63d2\u5165\u200b\u7535\u6e90\u200b\u4fa7\u200b\u7684\u200b12V\u200b\u8f68\u4e0a\u200b\uff0c\u200b\u5e76\u4e14\u200b\u53ef\u4ee5\u200b\u63d0\u4f9b\u200b\u6700\u200b\u591a\u200b150W\u200b\u7684\u200b\u529f\u7387\u200b\u3002</p> <p>\u200b\u5176\u4ed6\u200b\u4e00\u4e9b\u200b\u5361\u200b\u53ef\u80fd\u200b\u4f7f\u7528\u200bPCI-E-12\u200b\u9488\u200b\u8fde\u63a5\u5668\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u8fde\u63a5\u5668\u200b\u53ef\u4ee5\u200b\u63d0\u4f9b\u200b\u6700\u200b\u591a\u200b500-600W\u200b\u7684\u200b\u529f\u7387\u200b\u3002</p> <p>\u200b\u4f4e\u7aef\u200b\u5361\u200b\u53ef\u80fd\u200b\u4f7f\u7528\u200b6\u200b\u9488\u200b\u8fde\u63a5\u5668\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u8fde\u63a5\u5668\u200b\u53ef\u200b\u63d0\u4f9b\u200b\u6700\u200b\u591a\u200b75W\u200b\u7684\u200b\u529f\u7387\u200b\u3002</p> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u9009\u62e9\u200b\u5177\u6709\u200b\u7a33\u5b9a\u200b\u7535\u538b\u200b\u7684\u200b\u9ad8\u7aef\u200b\u7535\u6e90\u200b\u3002\u200b\u4e00\u4e9b\u200b\u8d28\u91cf\u200b\u8f83\u200b\u4f4e\u200b\u7684\u200b\u7535\u6e90\u200b\u53ef\u80fd\u200b\u65e0\u6cd5\u200b\u4e3a\u200b\u5361\u200b\u63d0\u4f9b\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u7a33\u5b9a\u200b\u7535\u538b\u200b\u4ee5\u200b\u53d1\u6325\u200b\u5176\u200b\u6700\u5927\u200b\u6027\u80fd\u200b\u3002</p> <p>\u200b\u5f53\u7136\u200b\uff0c\u200b\u7535\u6e90\u200b\u8fd8\u200b\u9700\u8981\u200b\u6709\u200b\u8db3\u591f\u200b\u7684\u200b\u672a\u200b\u4f7f\u7528\u200b\u7684\u200b\u74e6\u6570\u200b\u6765\u200b\u4e3a\u200b\u5361\u200b\u4f9b\u7535\u200b\u3002</p> <p>\u200b\u6563\u70ed\u200b\uff1a</p> <p>\u200b\u5f53\u200bGPU\u200b\u8fc7\u70ed\u200b\u65f6\u200b\uff0c\u200b\u5b83\u200b\u5c06\u200b\u5f00\u59cb\u200b\u964d\u9891\u200b\uff0c\u200b\u4e0d\u4f1a\u200b\u63d0\u4f9b\u200b\u5b8c\u6574\u200b\u7684\u200b\u6027\u80fd\u200b\u3002\u200b\u5982\u679c\u200b\u6e29\u5ea6\u200b\u8fc7\u9ad8\u200b\uff0c\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u7f29\u77ed\u200bGPU\u200b\u7684\u200b\u4f7f\u7528\u5bff\u547d\u200b\u3002</p> <p>\u200b\u5f53\u200bGPU\u200b\u8d1f\u8f7d\u200b\u5f88\u200b\u91cd\u65f6\u200b\uff0c\u200b\u5f88\u96be\u200b\u786e\u5b9a\u200b\u6700\u4f73\u200b\u6e29\u5ea6\u200b\u662f\u200b\u591a\u5c11\u200b\uff0c\u200b\u4f46\u200b\u4efb\u4f55\u200b\u4f4e\u4e8e\u200b+80\u200b\u5ea6\u200b\u7684\u200b\u6e29\u5ea6\u200b\u90fd\u200b\u662f\u200b\u597d\u200b\u7684\u200b\uff0c\u200b\u8d8a\u4f4e\u200b\u8d8a\u200b\u597d\u200b\uff0c\u200b\u4e5f\u8bb8\u200b\u5728\u200b70-75\u200b\u5ea6\u200b\u4e4b\u95f4\u200b\u662f\u200b\u4e00\u4e2a\u200b\u975e\u5e38\u200b\u597d\u200b\u7684\u200b\u8303\u56f4\u200b\u3002\u200b\u964d\u9891\u200b\u53ef\u80fd\u200b\u4ece\u200b\u5927\u7ea6\u200b84-90\u200b\u5ea6\u200b\u5f00\u59cb\u200b\u3002\u200b\u4f46\u662f\u200b\u9664\u4e86\u200b\u964d\u9891\u200b\u5916\u200b\uff0c\u200b\u6301\u7eed\u200b\u7684\u200b\u9ad8\u6e29\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u7f29\u77ed\u200bGPU\u200b\u7684\u200b\u4f7f\u7528\u5bff\u547d\u200b\u3002</p> <p>\u200b\u63a5\u4e0b\u6765\u200b\u8ba9\u200b\u6211\u4eec\u200b\u770b\u200b\u4e00\u4e0b\u200b\u62e5\u6709\u200b\u591a\u4e2a\u200bGPU\u200b\u65f6\u200b\u6700\u200b\u91cd\u8981\u200b\u7684\u200b\u65b9\u9762\u200b\u4e4b\u4e00\u200b\uff1a\u200b\u8fde\u63a5\u200b\u3002</p>"},{"location":"perf_hardware/#gpu_1","title":"\u591a\u200bGPU\u200b\u8fde\u63a5","text":"<p>\u200b\u5982\u679c\u200b\u60a8\u200b\u4f7f\u7528\u200b\u591a\u4e2a\u200bGPU\uff0c\u200b\u5219\u200b\u5361\u200b\u4e4b\u95f4\u200b\u7684\u200b\u4e92\u8fde\u200b\u65b9\u5f0f\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5bf9\u200b\u603b\u200b\u8bad\u7ec3\u200b\u65f6\u95f4\u200b\u4ea7\u751f\u200b\u5de8\u5927\u200b\u5f71\u54cd\u200b\u3002\u200b\u5982\u679c\u200bGPU\u200b\u4f4d\u4e8e\u200b\u540c\u4e00\u200b\u7269\u7406\u200b\u8282\u70b9\u200b\u4e0a\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u4ee3\u7801\u200b\uff1a</p> <pre><code>nvidia-smi topo -m\n</code></pre> <p>\u200b\u5b83\u200b\u5c06\u200b\u544a\u8bc9\u60a8\u200bGPU\u200b\u5982\u4f55\u200b\u4e92\u8fde\u200b\u3002\u200b\u5728\u200b\u5177\u6709\u200b\u53cc\u200bGPU\u200b\u5e76\u200b\u901a\u8fc7\u200bNVLink\u200b\u8fde\u63a5\u200b\u7684\u200b\u673a\u5668\u200b\u4e0a\u200b\uff0c\u200b\u60a8\u200b\u6700\u200b\u6709\u200b\u53ef\u80fd\u200b\u770b\u5230\u200b\u7c7b\u4f3c\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a</p> <pre><code>        GPU0    GPU1    CPU Affinity    NUMA Affinity\nGPU0     X      NV2     0-23            N/A\nGPU1    NV2      X      0-23            N/A\n</code></pre> <p>\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200b\u673a\u5668\u200b\u4e0a\u200b\uff0c\u200b\u5982\u679c\u200b\u6ca1\u6709\u200bNVLink\uff0c\u200b\u6211\u4eec\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u770b\u5230\u200b\uff1a <pre><code>        GPU0    GPU1    CPU Affinity    NUMA Affinity\nGPU0     X      PHB     0-11            N/A\nGPU1    PHB      X      0-11            N/A\n</code></pre></p> <p>\u200b\u8fd9\u4e2a\u200b\u62a5\u544a\u200b\u5305\u62ec\u200b\u4e86\u200b\u8fd9\u4e2a\u200b\u8f93\u51fa\u200b\uff1a</p> <pre><code>  X    = Self\n  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)\n  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node\n  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)\n  PIX  = Connection traversing at most a single PCIe bridge\n  NV#  = Connection traversing a bonded set of # NVLinks\n</code></pre> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u7b2c\u4e00\u4e2a\u200b\u62a5\u544a\u200b<code>NV2</code>\u200b\u544a\u8bc9\u200b\u6211\u4eec\u200bGPU\u200b\u901a\u8fc7\u200b2\u200b\u4e2a\u200bNVLink\u200b\u4e92\u8fde\u200b\uff0c\u200b\u800c\u200b\u7b2c\u4e8c\u4e2a\u200b\u62a5\u544a\u200b<code>PHB</code>\u200b\u5c55\u793a\u200b\u4e86\u200b\u5178\u578b\u200b\u7684\u200b\u6d88\u8d39\u8005\u200b\u7ea7\u200bPCIe+Bridge\u200b\u8bbe\u7f6e\u200b\u3002</p> <p>\u200b\u68c0\u67e5\u200b\u4f60\u200b\u7684\u200b\u8bbe\u7f6e\u200b\u4e2d\u200b\u5177\u6709\u200b\u54ea\u200b\u79cd\u200b\u8fde\u63a5\u200b\u7c7b\u578b\u200b\u3002\u200b\u5176\u4e2d\u200b\u4e00\u4e9b\u200b\u4f1a\u200b\u4f7f\u200b\u5361\u200b\u4e4b\u95f4\u200b\u7684\u200b\u901a\u4fe1\u200b\u66f4\u200b\u5feb\u200b\uff08\u200b\u4f8b\u5982\u200bNVLink\uff09\uff0c\u200b\u800c\u200b\u5176\u4ed6\u200b\u5219\u200b\u8f83\u6162\u200b\uff08\u200b\u4f8b\u5982\u200bPHB\uff09\u3002</p> <p>\u200b\u6839\u636e\u200b\u4f7f\u7528\u200b\u7684\u200b\u6269\u5c55\u200b\u89e3\u51b3\u65b9\u6848\u200b\u7684\u200b\u7c7b\u578b\u200b\uff0c\u200b\u8fde\u63a5\u200b\u901f\u5ea6\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u4ea7\u751f\u200b\u91cd\u5927\u200b\u6216\u200b\u8f83\u200b\u5c0f\u200b\u7684\u200b\u5f71\u54cd\u200b\u3002\u200b\u5982\u679c\u200bGPU\u200b\u5f88\u5c11\u200b\u9700\u8981\u200b\u540c\u6b65\u200b\uff0c\u200b\u5c31\u200b\u50cf\u200b\u5728\u200bDDP\u200b\u4e2d\u200b\u4e00\u6837\u200b\uff0c\u200b\u90a3\u4e48\u200b\u8f83\u6162\u200b\u7684\u200b\u8fde\u63a5\u200b\u7684\u200b\u5f71\u54cd\u200b\u5c06\u200b\u4e0d\u200b\u90a3\u4e48\u200b\u663e\u8457\u200b\u3002\u200b\u5982\u679c\u200bGPU\u200b\u7ecf\u5e38\u200b\u9700\u8981\u200b\u76f8\u4e92\u200b\u53d1\u9001\u200b\u6d88\u606f\u200b\uff0c\u200b\u5c31\u200b\u50cf\u200b\u5728\u200bZeRO-DP\u200b\u4e2d\u200b\u4e00\u6837\u200b\uff0c\u200b\u90a3\u4e48\u200b\u66f4\u5feb\u200b\u7684\u200b\u8fde\u63a5\u200b\u5bf9\u4e8e\u200b\u5b9e\u73b0\u200b\u66f4\u5feb\u200b\u7684\u200b\u8bad\u7ec3\u200b\u53d8\u5f97\u200b\u975e\u5e38\u200b\u91cd\u8981\u200b\u3002</p>"},{"location":"perf_hardware/#nvlink","title":"NVlink","text":"<p>NVLink\u200b\u662f\u200b\u7531\u200bNvidia\u200b\u5f00\u53d1\u200b\u7684\u200b\u4e00\u79cd\u200b\u57fa\u4e8e\u200b\u7ebf\u7f06\u200b\u7684\u200b\u4e32\u884c\u200b\u591a\u901a\u9053\u200b\u8fd1\u7a0b\u200b\u901a\u4fe1\u200b\u94fe\u63a5\u200b\u3002</p> <p>\u200b\u6bcf\u4e2a\u200b\u65b0\u4e00\u4ee3\u200b\u63d0\u4f9b\u200b\u66f4\u5feb\u200b\u7684\u200b\u5e26\u5bbd\u200b\uff0c\u200b\u4f8b\u5982\u200b\u5728\u200bNvidia Ampere GA102 GPU\u200b\u67b6\u6784\u200b\u4e2d\u6709\u200b\u8fd9\u6837\u200b\u7684\u200b\u5f15\u8ff0\u200b\uff1a</p> <p>Third-Generation NVLink\u00ae GA102 GPUs utilize NVIDIA\u2019s third-generation NVLink interface, which includes four x4 links, with each link providing 14.0625 GB/sec bandwidth in each direction between two GPUs. Four links provide 56.25 GB/sec bandwidth in each direction, and 112.5 GB/sec total bandwidth between two GPUs. Two RTX 3090 GPUs can be connected together for SLI using NVLink. (Note that 3-Way and 4-Way SLI configurations are not supported.)</p> <p>\u200b\u6240\u4ee5\u200b\uff0c\u200b\u5728\u200b<code>nvidia-smi topo -m</code>\u200b\u8f93\u51fa\u200b\u7684\u200b<code>NVX</code>\u200b\u62a5\u544a\u200b\u4e2d\u200b\u83b7\u53d6\u200b\u5230\u200b\u7684\u200b\u66f4\u200b\u9ad8\u200b\u7684\u200b<code>X</code>\u200b\u503c\u200b\u610f\u5473\u7740\u200b\u66f4\u597d\u200b\u7684\u200b\u6027\u80fd\u200b\u3002\u200b\u751f\u6210\u200b\u7684\u200b\u7ed3\u679c\u200b\u5c06\u200b\u53d6\u51b3\u4e8e\u200b\u60a8\u200b\u7684\u200bGPU\u200b\u67b6\u6784\u200b\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u6bd4\u8f83\u200b\u5728\u200b\u5c0f\u200b\u6837\u672c\u200bwikitext\u200b\u4e0a\u200b\u8bad\u7ec3\u200bgpt2\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u7684\u200b\u6267\u884c\u200b\u7ed3\u679c\u200b\u3002</p> <p>\u200b\u7ed3\u679c\u200b\u662f\u200b\uff1a</p> NVlink Time Y 101s N 131s <p>\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200b\uff0cNVLink\u200b\u4f7f\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\u63d0\u9ad8\u200b\u4e86\u200b\u7ea6\u200b23%\u3002\u200b\u5728\u200b\u7b2c\u4e8c\u4e2a\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b<code>NCCL_P2P_DISABLE=1</code>\u200b\u544a\u8bc9\u200bGPU\u200b\u4e0d\u8981\u200b\u4f7f\u7528\u200bNVLink\u3002</p> <p>\u200b\u8fd9\u91cc\u200b\u662f\u200b\u5b8c\u6574\u200b\u7684\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u4ee3\u7801\u200b\u548c\u200b\u8f93\u51fa\u200b\uff1a</p> <pre><code># DDP w/ NVLink\n\nrm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch \\\n--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path gpt2 \\\n--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train \\\n--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200\n\n{'train_runtime': 101.9003, 'train_samples_per_second': 1.963, 'epoch': 0.69}\n\n# DDP w/o NVLink\n\nrm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 NCCL_P2P_DISABLE=1 python -m torch.distributed.launch \\\n--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path gpt2 \\\n--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train\n--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200\n\n{'train_runtime': 131.4367, 'train_samples_per_second': 1.522, 'epoch': 0.69}\n</code></pre> <p>\u200b\u786c\u4ef6\u200b: 2x TITAN RTX 24GB each + NVlink with 2 NVLinks (<code>NV2</code> in <code>nvidia-smi topo -m</code>) \u200b\u8f6f\u4ef6\u200b: <code>pytorch-1.8-to-be</code> + <code>cuda-11.0</code> / <code>transformers==4.3.0.dev0</code></p>"},{"location":"perf_torch_compile/","title":"Perf torch compile","text":""},{"location":"perf_torch_compile/#torchcompile","title":"\u4f7f\u7528\u200b torch.compile() \u200b\u4f18\u5316\u200b\u63a8\u7406","text":"<p>\u200b\u672c\u200b\u6307\u5357\u200b\u65e8\u5728\u200b\u4e3a\u200b\u4f7f\u7528\u200b<code>torch.compile()</code>\u200b\u5728\u200b\ud83e\udd17 Transformers\u200b\u4e2d\u200b\u7684\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u6a21\u578b\u200b\u4e2d\u200b\u5f15\u5165\u200b\u7684\u200b\u63a8\u7406\u200b\u901f\u5ea6\u200b\u63d0\u5347\u200b\u63d0\u4f9b\u200b\u4e00\u4e2a\u200b\u57fa\u51c6\u200b\u3002</p>"},{"location":"perf_torch_compile/#torchcompile_1","title":"torch.compile \u200b\u7684\u200b\u4f18\u52bf","text":"<p>\u200b\u6839\u636e\u200b\u6a21\u578b\u200b\u548c\u200bGPU\u200b\u7684\u200b\u4e0d\u540c\u200b\uff0c<code>torch.compile()</code>\u200b\u5728\u200b\u63a8\u7406\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u53ef\u4ee5\u200b\u63d0\u9ad8\u200b\u591a\u8fbe\u200b30%\u200b\u7684\u200b\u901f\u5ea6\u200b\u3002\u200b\u8981\u200b\u4f7f\u7528\u200b<code>torch.compile()</code>\uff0c\u200b\u53ea\u200b\u9700\u200b\u5b89\u88c5\u200b2.0\u200b\u53ca\u200b\u4ee5\u4e0a\u200b\u7248\u672c\u200b\u7684\u200b<code>torch</code>\u200b\u5373\u53ef\u200b\u3002</p> <p>\u200b\u7f16\u8bd1\u200b\u6a21\u578b\u200b\u9700\u8981\u200b\u65f6\u95f4\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5982\u679c\u200b\u60a8\u200b\u53ea\u200b\u9700\u8981\u200b\u7f16\u8bd1\u200b\u4e00\u6b21\u200b\u6a21\u578b\u200b\u800c\u200b\u4e0d\u662f\u200b\u6bcf\u6b21\u200b\u63a8\u7406\u200b\u90fd\u200b\u7f16\u8bd1\u200b\uff0c\u200b\u90a3\u4e48\u200b\u5b83\u200b\u975e\u5e38\u200b\u6709\u7528\u200b\u3002 \u200b\u8981\u200b\u7f16\u8bd1\u200b\u60a8\u200b\u9009\u62e9\u200b\u7684\u200b\u4efb\u4f55\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u6a21\u578b\u200b\uff0c\u200b\u8bf7\u200b\u6309\u7167\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u8c03\u7528\u200b<code>torch.compile()</code>\uff1a</p> <pre><code>from transformers import AutoModelForImageClassification\n\nmodel = AutoModelForImageClassification.from_pretrained(MODEL_ID).to(\"cuda\")\n+ model = torch.compile(model)\n</code></pre> <p><code>compile()</code> \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u591a\u79cd\u200b\u7f16\u8bd1\u200b\u6a21\u5f0f\u200b\uff0c\u200b\u5b83\u4eec\u200b\u5728\u200b\u7f16\u8bd1\u200b\u65f6\u95f4\u200b\u548c\u200b\u63a8\u7406\u200b\u5f00\u9500\u200b\u4e0a\u200b\u6709\u6240\u4e0d\u540c\u200b\u3002<code>max-autotune</code> \u200b\u6bd4\u200b <code>reduce-overhead</code> \u200b\u9700\u8981\u200b\u66f4\u957f\u200b\u7684\u200b\u65f6\u95f4\u200b\uff0c\u200b\u4f46\u4f1a\u200b\u5f97\u5230\u200b\u66f4\u5feb\u200b\u7684\u200b\u63a8\u7406\u200b\u901f\u5ea6\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u6a21\u5f0f\u200b\u5728\u200b\u7f16\u8bd1\u200b\u65f6\u200b\u6700\u5feb\u200b\uff0c\u200b\u4f46\u200b\u5728\u200b\u63a8\u7406\u200b\u65f6\u95f4\u200b\u4e0a\u200b\u4e0e\u200b <code>reduce-overhead</code> \u200b\u76f8\u6bd4\u200b\u6548\u7387\u200b\u8f83\u200b\u4f4e\u200b\u3002\u200b\u5728\u200b\u672c\u200b\u6307\u5357\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b\u4e86\u200b\u9ed8\u8ba4\u200b\u6a21\u5f0f\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u8fd9\u91cc\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u5728\u200b PyTorch 2.0.1 \u200b\u7248\u672c\u200b\u4e0a\u200b\u4f7f\u7528\u200b\u4e0d\u540c\u200b\u7684\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u6a21\u578b\u200b\u3001\u200b\u4efb\u52a1\u200b\u3001\u200b\u786c\u4ef6\u200b\u7c7b\u578b\u200b\u548c\u200b\u6570\u636e\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\u5bf9\u200b <code>torch.compile</code> \u200b\u8fdb\u884c\u200b\u4e86\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b\u3002</p>"},{"location":"perf_torch_compile/#_1","title":"\u57fa\u51c6\u200b\u6d4b\u8bd5\u4ee3\u7801","text":"<p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u6bcf\u4e2a\u200b\u4efb\u52a1\u200b\u7684\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u4ee3\u7801\u200b\u3002\u200b\u6211\u4eec\u200b\u5728\u200b\u63a8\u7406\u200b\u4e4b\u524d\u200b\u201d\u200b\u9884\u70ed\u200b\u201cGPU\uff0c\u200b\u5e76\u53d6\u200b300\u200b\u6b21\u200b\u63a8\u7406\u200b\u7684\u200b\u5e73\u5747\u503c\u200b\uff0c\u200b\u6bcf\u6b21\u200b\u4f7f\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u56fe\u50cf\u200b\u3002</p>"},{"location":"perf_torch_compile/#vit","title":"\u4f7f\u7528\u200b ViT \u200b\u8fdb\u884c\u200b\u56fe\u50cf\u200b\u5206\u7c7b","text":"<pre><code>import torch\nfrom PIL import Image\nimport requests\nimport numpy as np\nfrom transformers import AutoImageProcessor, AutoModelForImageClassification\n\nurl = 'http://images.cocodataset.org/val2017/000000039769.jpg'\nimage = Image.open(requests.get(url, stream=True).raw)\n\nprocessor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\nmodel = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\").to(\"cuda\")\nmodel = torch.compile(model)\n\nprocessed_input = processor(image, return_tensors='pt').to(device=\"cuda\")\n\nwith torch.no_grad():\n    _ = model(**processed_input)\n</code></pre>"},{"location":"perf_torch_compile/#detr","title":"\u4f7f\u7528\u200b DETR \u200b\u8fdb\u884c\u200b\u76ee\u6807\u200b\u68c0\u6d4b","text":"<pre><code>from transformers import AutoImageProcessor, AutoModelForObjectDetection\n\nprocessor = AutoImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\nmodel = AutoModelForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\").to(\"cuda\")\nmodel = torch.compile(model)\n\ntexts = [\"a photo of a cat\", \"a photo of a dog\"]\ninputs = processor(text=texts, images=image, return_tensors=\"pt\").to(\"cuda\")\n\nwith torch.no_grad():\n    _ = model(**inputs)\n</code></pre>"},{"location":"perf_torch_compile/#segformer","title":"\u4f7f\u7528\u200b Segformer \u200b\u8fdb\u884c\u200b\u56fe\u50cf\u200b\u5206\u5272","text":"<pre><code>from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n\nprocessor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\nmodel = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\").to(\"cuda\")\nmodel = torch.compile(model)\nseg_inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n\nwith torch.no_grad():\n    _ = model(**seg_inputs)\n</code></pre> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u6211\u4eec\u200b\u8fdb\u884c\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b\u7684\u200b\u6a21\u578b\u200b\u5217\u8868\u200b\u3002</p> <p>\u200b\u56fe\u50cf\u200b\u5206\u7c7b\u200b  - google/vit-base-patch16-224 - microsoft/beit-base-patch16-224-pt22k-ft22k - facebook/convnext-large-224 - microsoft/resnet-50</p> <p>\u200b\u56fe\u50cf\u200b\u5206\u5272\u200b  - nvidia/segformer-b0-finetuned-ade-512-512 - facebook/mask2former-swin-tiny-coco-panoptic - facebook/maskformer-swin-base-ade - google/deeplabv3_mobilenet_v2_1.0_513</p> <p>\u200b\u76ee\u6807\u200b\u68c0\u6d4b\u200b  - google/owlvit-base-patch32 - facebook/detr-resnet-101 - microsoft/conditional-detr-resnet-50</p> <p>\u200b\u4e0b\u9762\u200b\u662f\u200b\u4f7f\u7528\u200b\u548c\u200b\u4e0d\u200b\u4f7f\u7528\u200b<code>torch.compile()</code>\u200b\u7684\u200b\u63a8\u7406\u200b\u6301\u7eed\u65f6\u95f4\u200b\u53ef\u89c6\u5316\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u5728\u200b\u4e0d\u540c\u200b\u786c\u4ef6\u200b\u548c\u200b\u6570\u636e\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\u4e0b\u200b\u7684\u200b\u6539\u8fdb\u200b\u767e\u5206\u6bd4\u200b\u3002</p> <p></p> <p></p> <p>\u200b\u4e0b\u9762\u200b\u53ef\u4ee5\u200b\u627e\u5230\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u4f7f\u7528\u200b\u548c\u200b\u4e0d\u200b\u4f7f\u7528\u200b<code>compile()</code>\u200b\u7684\u200b\u63a8\u7406\u200b\u65f6\u95f4\u200b\uff08\u200b\u6beb\u79d2\u200b\uff09\u3002\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0cOwlViT\u200b\u5728\u200b\u5927\u6279\u91cf\u200b\u5927\u5c0f\u200b\u4e0b\u4f1a\u200b\u5bfc\u81f4\u200b\u5185\u5b58\u200b\u6ea2\u51fa\u200b\u3002</p>"},{"location":"perf_torch_compile/#a100-batch-size-1","title":"A100 (batch size: 1)","text":"Task/Model torch 2.0 - no compile torch 2.0 - compile Image Classification/ViT 9.325 7.584 Image Segmentation/Segformer 11.759 10.500 Object Detection/OwlViT 24.978 18.420 Image Classification/BeiT 11.282 8.448 Object Detection/DETR 34.619 19.040 Image Classification/ConvNeXT 10.410 10.208 Image Classification/ResNet 6.531 4.124 Image Segmentation/Mask2former 60.188 49.117 Image Segmentation/Maskformer 75.764 59.487 Image Segmentation/MobileNet 8.583 3.974 Object Detection/Resnet-101 36.276 18.197 Object Detection/Conditional-DETR 31.219 17.993"},{"location":"perf_torch_compile/#a100-batch-size-4","title":"A100 (batch size: 4)","text":"Task/Model torch 2.0 - no compile torch 2.0 - compile Image Classification/ViT 14.832 14.499 Image Segmentation/Segformer 18.838 16.476 Image Classification/BeiT 13.205 13.048 Object Detection/DETR 48.657 32.418 Image Classification/ConvNeXT 22.940 21.631 Image Classification/ResNet 6.657 4.268 Image Segmentation/Mask2former 74.277 61.781 Image Segmentation/Maskformer 180.700 159.116 Image Segmentation/MobileNet 14.174 8.515 Object Detection/Resnet-101 68.101 44.998 Object Detection/Conditional-DETR 56.470 35.552"},{"location":"perf_torch_compile/#a100-batch-size-16","title":"A100 (batch size: 16)","text":"Task/Model torch 2.0 - no compile torch 2.0 - compile Image Classification/ViT 40.944 40.010 Image Segmentation/Segformer 37.005 31.144 Image Classification/BeiT 41.854 41.048 Object Detection/DETR 164.382 161.902 Image Classification/ConvNeXT 82.258 75.561 Image Classification/ResNet 7.018 5.024 Image Segmentation/Mask2former 178.945 154.814 Image Segmentation/Maskformer 638.570 579.826 Image Segmentation/MobileNet 51.693 30.310 Object Detection/Resnet-101 232.887 155.021 Object Detection/Conditional-DETR 180.491 124.032"},{"location":"perf_torch_compile/#v100-batch-size-1","title":"V100 (batch size: 1)","text":"Task/Model torch 2.0 - no compile torch 2.0 - compile Image Classification/ViT 10.495 6.00 Image Segmentation/Segformer 13.321 5.862 Object Detection/OwlViT 25.769 22.395 Image Classification/BeiT 11.347 7.234 Object Detection/DETR 33.951 19.388 Image Classification/ConvNeXT 11.623 10.412 Image Classification/ResNet 6.484 3.820 Image Segmentation/Mask2former 64.640 49.873 Image Segmentation/Maskformer 95.532 72.207 Image Segmentation/MobileNet 9.217 4.753 Object Detection/Resnet-101 52.818 28.367 Object Detection/Conditional-DETR 39.512 20.816"},{"location":"perf_torch_compile/#v100-batch-size-4","title":"V100 (batch size: 4)","text":"Task/Model torch 2.0 - no compile torch 2.0 - compile Image Classification/ViT 15.181 14.501 Image Segmentation/Segformer 16.787 16.188 Image Classification/BeiT 15.171 14.753 Object Detection/DETR 88.529 64.195 Image Classification/ConvNeXT 29.574 27.085 Image Classification/ResNet 6.109 4.731 Image Segmentation/Mask2former 90.402 76.926 Image Segmentation/Maskformer 234.261 205.456 Image Segmentation/MobileNet 24.623 14.816 Object Detection/Resnet-101 134.672 101.304 Object Detection/Conditional-DETR 97.464 69.739"},{"location":"perf_torch_compile/#v100-batch-size-16","title":"V100 (batch size: 16)","text":"Task/Model torch 2.0 - no compile torch 2.0 - compile Image Classification/ViT 52.209 51.633 Image Segmentation/Segformer 61.013 55.499 Image Classification/BeiT 53.938 53.581 Object Detection/DETR OOM OOM Image Classification/ConvNeXT 109.682 100.771 Image Classification/ResNet 14.857 12.089 Image Segmentation/Mask2former 249.605 222.801 Image Segmentation/Maskformer 831.142 743.645 Image Segmentation/MobileNet 93.129 55.365 Object Detection/Resnet-101 482.425 361.843 Object Detection/Conditional-DETR 344.661 255.298"},{"location":"perf_torch_compile/#t4-batch-size-1","title":"T4 (batch size: 1)","text":"Task/Model torch 2.0 - no compile torch 2.0 - compile Image Classification/ViT 16.520 15.786 Image Segmentation/Segformer 16.116 14.205 Object Detection/OwlViT 53.634 51.105 Image Classification/BeiT 16.464 15.710 Object Detection/DETR 73.100 53.99 Image Classification/ConvNeXT 32.932 30.845 Image Classification/ResNet 6.031 4.321 Image Segmentation/Mask2former 79.192 66.815 Image Segmentation/Maskformer 200.026 188.268 Image Segmentation/MobileNet 18.908 11.997 Object Detection/Resnet-101 106.622 82.566 Object Detection/Conditional-DETR 77.594 56.984"},{"location":"perf_torch_compile/#t4-batch-size-4","title":"T4 (batch size: 4)","text":"Task/Model torch 2.0 - no compile torch 2.0 - compile Image Classification/ViT 43.653 43.626 Image Segmentation/Segformer 45.327 42.445 Image Classification/BeiT 52.007 51.354 Object Detection/DETR 277.850 268.003 Image Classification/ConvNeXT 119.259 105.580 Image Classification/ResNet 13.039 11.388 Image Segmentation/Mask2former 201.540 184.670 Image Segmentation/Maskformer 764.052 711.280 Image Segmentation/MobileNet 74.289 48.677 Object Detection/Resnet-101 421.859 357.614 Object Detection/Conditional-DETR 289.002 226.945"},{"location":"perf_torch_compile/#t4-batch-size-16","title":"T4 (batch size: 16)","text":"Task/Model torch 2.0 - no compile torch 2.0 - compile Image Classification/ViT 163.914 160.907 Image Segmentation/Segformer 192.412 163.620 Image Classification/BeiT 188.978 187.976 Object Detection/DETR OOM OOM Image Classification/ConvNeXT 422.886 388.078 Image Classification/ResNet 44.114 37.604 Image Segmentation/Mask2former 756.337 695.291 Image Segmentation/Maskformer 2842.940 2656.88 Image Segmentation/MobileNet 299.003 201.942 Object Detection/Resnet-101 1619.505 1262.758 Object Detection/Conditional-DETR 1137.513 897.390"},{"location":"perf_torch_compile/#pytorch-nightly","title":"PyTorch Nightly","text":"<p>\u200b\u6211\u4eec\u200b\u8fd8\u200b\u5728\u200b PyTorch Nightly \u200b\u7248\u672c\u200b\uff082.1.0dev\uff09\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u4e86\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5728\u200b\u8fd9\u91cc\u200b\u627e\u5230\u200b Nightly \u200b\u7248\u672c\u200b\u7684\u200b\u5b89\u88c5\u5305\u200b\uff0c\u200b\u5e76\u200b\u89c2\u5bdf\u200b\u5230\u200b\u4e86\u200b\u672a\u200b\u7f16\u8bd1\u200b\u548c\u200b\u7f16\u8bd1\u200b\u6a21\u578b\u200b\u7684\u200b\u5ef6\u8fdf\u200b\u6027\u80fd\u200b\u6539\u5584\u200b\u3002</p>"},{"location":"perf_torch_compile/#a100","title":"A100","text":"Task/Model Batch Size torch 2.0 - no compile torch 2.0 - compile Image Classification/BeiT Unbatched 12.462 6.954 Image Classification/BeiT 4 14.109 12.851 Image Classification/BeiT 16 42.179 42.147 Object Detection/DETR Unbatched 30.484 15.221 Object Detection/DETR 4 46.816 30.942 Object Detection/DETR 16 163.749 163.706"},{"location":"perf_torch_compile/#t4","title":"T4","text":"Task/Model Batch Size torch 2.0 - no compile torch 2.0 - compile Image Classification/BeiT Unbatched 14.408 14.052 Image Classification/BeiT 4 47.381 46.604 Image Classification/BeiT 16 42.179 42.147 Object Detection/DETR Unbatched 68.382 53.481 Object Detection/DETR 4 269.615 204.785 Object Detection/DETR 16 OOM OOM"},{"location":"perf_torch_compile/#v100","title":"V100","text":"Task/Model Batch Size torch 2.0 - no compile torch 2.0 - compile Image Classification/BeiT Unbatched 13.477 7.926 Image Classification/BeiT 4 15.103 14.378 Image Classification/BeiT 16 52.517 51.691 Object Detection/DETR Unbatched 28.706 19.077 Object Detection/DETR 4 88.402 62.949 Object Detection/DETR 16 OOM OOM"},{"location":"perf_torch_compile/#_2","title":"\u964d\u4f4e\u200b\u5f00\u9500","text":"<p>\u200b\u6211\u4eec\u200b\u5728\u200b PyTorch Nightly \u200b\u7248\u672c\u200b\u4e2d\u4e3a\u200b A100 \u200b\u548c\u200b T4 \u200b\u8fdb\u884c\u200b\u4e86\u200b <code>reduce-overhead</code> \u200b\u7f16\u8bd1\u200b\u6a21\u5f0f\u200b\u7684\u200b\u6027\u80fd\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b\u3002</p>"},{"location":"perf_torch_compile/#a100_1","title":"A100","text":"Task/Model Batch Size torch 2.0 - no compile torch 2.0 - compile Image Classification/ConvNeXT Unbatched 11.758 7.335 Image Classification/ConvNeXT 4 23.171 21.490 Image Classification/ResNet Unbatched 7.435 3.801 Image Classification/ResNet 4 7.261 2.187 Object Detection/Conditional-DETR Unbatched 32.823 11.627 Object Detection/Conditional-DETR 4 50.622 33.831 Image Segmentation/MobileNet Unbatched 9.869 4.244 Image Segmentation/MobileNet 4 14.385 7.946"},{"location":"perf_torch_compile/#t4_1","title":"T4","text":"Task/Model Batch Size torch 2.0 - no compile torch 2.0 - compile Image Classification/ConvNeXT Unbatched 32.137 31.84 Image Classification/ConvNeXT 4 120.944 110.209 Image Classification/ResNet Unbatched 9.761 7.698 Image Classification/ResNet 4 15.215 13.871 Object Detection/Conditional-DETR Unbatched 72.150 57.660 Object Detection/Conditional-DETR 4 301.494 247.543 Image Segmentation/MobileNet Unbatched 22.266 19.339 Image Segmentation/MobileNet 4 78.311 50.983"},{"location":"performance/","title":"Performance","text":""},{"location":"performance/#_1","title":"\u6027\u80fd\u200b\u4e0e\u200b\u53ef\u6269\u5c55\u6027","text":"<p>\u200b\u8bad\u7ec3\u200b\u5927\u578b\u200btransformer\u200b\u6a21\u578b\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u90e8\u7f72\u200b\u5230\u200b\u751f\u4ea7\u200b\u73af\u5883\u200b\u4f1a\u200b\u9762\u4e34\u200b\u5404\u79cd\u200b\u6311\u6218\u200b\u3002 \u200b\u5728\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6a21\u578b\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u6bd4\u200b\u53ef\u7528\u200b\u7684\u200bGPU\u200b\u5185\u5b58\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u8d44\u6e90\u200b\uff0c\u200b\u6216\u8005\u200b\u8868\u73b0\u200b\u51fa\u200b\u8f83\u6162\u200b\u7684\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\u3002\u200b\u5728\u200b\u90e8\u7f72\u200b\u9636\u6bb5\u200b\uff0c\u200b\u6a21\u578b\u200b\u53ef\u80fd\u200b\u5728\u200b\u751f\u4ea7\u200b\u73af\u5883\u200b\u4e2d\u200b\u96be\u4ee5\u200b\u5904\u7406\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u541e\u5410\u91cf\u200b\u3002</p> <p>\u200b\u672c\u200b\u6587\u6863\u200b\u65e8\u5728\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u514b\u670d\u200b\u8fd9\u4e9b\u200b\u6311\u6218\u200b\uff0c\u200b\u5e76\u200b\u627e\u5230\u200b\u9002\u5408\u200b\u60a8\u200b\u4f7f\u7528\u200b\u573a\u666f\u200b\u7684\u200b\u6700\u4f73\u200b\u8bbe\u7f6e\u200b\u3002\u200b\u6559\u7a0b\u200b\u5206\u4e3a\u200b\u8bad\u7ec3\u200b\u548c\u200b\u63a8\u7406\u200b\u90e8\u5206\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6bcf\u4e2a\u200b\u90e8\u5206\u200b\u90fd\u200b\u6709\u200b\u4e0d\u540c\u200b\u7684\u200b\u6311\u6218\u200b\u548c\u200b\u89e3\u51b3\u65b9\u6848\u200b\u3002\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u90e8\u5206\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u627e\u5230\u200b\u9488\u5bf9\u200b\u4e0d\u540c\u200b\u786c\u4ef6\u200b\u914d\u7f6e\u200b\u7684\u200b\u5355\u72ec\u200b\u6307\u5357\u200b\uff0c\u200b\u4f8b\u5982\u200b\u5355\u200bGPU\u200b\u4e0e\u200b\u591a\u200bGPU\u200b\u7528\u4e8e\u200b\u8bad\u7ec3\u200b\u6216\u200bCPU\u200b\u4e0e\u200bGPU\u200b\u7528\u4e8e\u200b\u63a8\u7406\u200b\u3002</p> <p>\u200b\u5c06\u200b\u6b64\u200b\u6587\u6863\u200b\u4f5c\u4e3a\u200b\u60a8\u200b\u7684\u200b\u8d77\u70b9\u200b\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u5bfc\u822a\u200b\u5230\u200b\u4e0e\u200b\u60a8\u200b\u7684\u200b\u60c5\u51b5\u200b\u5339\u914d\u200b\u7684\u200b\u65b9\u6cd5\u200b\u3002</p>"},{"location":"performance/#_2","title":"\u8bad\u7ec3","text":"<p>\u200b\u9ad8\u6548\u200b\u8bad\u7ec3\u200b\u5927\u578b\u200btransformer\u200b\u6a21\u578b\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u52a0\u901f\u5668\u200b\u786c\u4ef6\u200b\uff0c\u200b\u5982\u200bGPU\u200b\u6216\u200bTPU\u3002\u200b\u6700\u200b\u5e38\u89c1\u200b\u7684\u200b\u60c5\u51b5\u200b\u662f\u200b\u60a8\u200b\u53ea\u6709\u200b\u4e00\u4e2a\u200bGPU\u3002\u200b\u60a8\u200b\u5e94\u7528\u200b\u4e8e\u200b\u5355\u4e2a\u200bGPU\u200b\u4e0a\u200b\u63d0\u9ad8\u200b\u8bad\u7ec3\u200b\u6548\u7387\u200b\u7684\u200b\u65b9\u6cd5\u200b\u53ef\u4ee5\u200b\u6269\u5c55\u200b\u5230\u200b\u5176\u4ed6\u200b\u8bbe\u7f6e\u200b\uff0c\u200b\u5982\u200b\u591a\u4e2a\u200bGPU\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u4e5f\u200b\u6709\u200b\u4e00\u4e9b\u200b\u7279\u5b9a\u200b\u4e8e\u200b\u591a\u200bGPU\u200b\u6216\u200bCPU\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6280\u672f\u200b\u3002\u200b\u6211\u4eec\u200b\u5728\u200b\u5355\u72ec\u200b\u7684\u200b\u90e8\u5206\u200b\u4e2d\u200b\u4ecb\u7ecd\u200b\u5b83\u4eec\u200b\u3002</p> <ul> <li>\u200b\u5728\u200b\u5355\u4e2a\u200bGPU\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u9ad8\u6548\u200b\u8bad\u7ec3\u200b\u7684\u200b\u65b9\u6cd5\u200b\u548c\u200b\u5de5\u5177\u200b\uff1a\u200b\u4ece\u200b\u8fd9\u91cc\u200b\u5f00\u59cb\u200b\u5b66\u4e60\u200b\u5e38\u89c1\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5e2e\u52a9\u200b\u4f18\u5316\u200bGPU\u200b\u5185\u5b58\u200b\u5229\u7528\u7387\u200b\u3001\u200b\u52a0\u5feb\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\u6216\u200b\u4e24\u8005\u200b\u517c\u5907\u200b\u3002</li> <li>\u200b\u591a\u200bGPU\u200b\u8bad\u7ec3\u200b\u90e8\u5206\u200b\uff1a\u200b\u63a2\u7d22\u200b\u6b64\u200b\u90e8\u5206\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u9002\u7528\u200b\u4e8e\u200b\u591a\u200bGPU\u200b\u8bbe\u7f6e\u200b\u7684\u200b\u8fdb\u4e00\u6b65\u200b\u4f18\u5316\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u4f8b\u5982\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u3001\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u548c\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200b\u3002</li> <li>CPU\u200b\u8bad\u7ec3\u200b\u90e8\u5206\u200b\uff1a\u200b\u4e86\u89e3\u200b\u5728\u200bCPU\u200b\u4e0a\u200b\u7684\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u3002</li> <li>\u200b\u5728\u200b\u591a\u4e2a\u200bCPU\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u9ad8\u6548\u200b\u8bad\u7ec3\u200b\uff1a\u200b\u4e86\u89e3\u200b\u5206\u5e03\u5f0f\u200bCPU\u200b\u8bad\u7ec3\u200b\u3002</li> <li>\u200b\u4f7f\u7528\u200bTensorFlow\u200b\u5728\u200bTPU\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\uff1a\u200b\u5982\u679c\u200b\u60a8\u200b\u5bf9\u200bTPU\u200b\u8fd8\u200b\u4e0d\u200b\u719f\u6089\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u8003\u200b\u6b64\u200b\u90e8\u5206\u200b\uff0c\u200b\u4e86\u89e3\u200b\u6709\u5173\u200b\u5728\u200bTPU\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u548c\u200b\u4f7f\u7528\u200bXLA\u200b\u7684\u200b\u5efa\u8bae\u6027\u200b\u4ecb\u7ecd\u200b\u3002</li> <li>\u200b\u81ea\u5b9a\u4e49\u200b\u786c\u4ef6\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\uff1a\u200b\u5728\u200b\u6784\u5efa\u200b\u81ea\u5df1\u200b\u7684\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u673a\u5668\u200b\u65f6\u200b\u67e5\u627e\u200b\u6280\u5de7\u200b\u548c\u200b\u7a8d\u95e8\u200b\u3002</li> <li>\u200b\u4f7f\u7528\u200bTrainer API\u200b\u8fdb\u884c\u200b\u8d85\u200b\u53c2\u6570\u200b\u641c\u7d22\u200b</li> </ul>"},{"location":"performance/#_3","title":"\u63a8\u7406","text":"<p>\u200b\u5728\u200b\u751f\u4ea7\u200b\u73af\u5883\u200b\u4e2d\u200b\u5bf9\u200b\u5927\u578b\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u9ad8\u6548\u200b\u63a8\u7406\u200b\u53ef\u80fd\u200b\u4e0e\u200b\u8bad\u7ec3\u200b\u5b83\u4eec\u200b\u4e00\u6837\u200b\u5177\u6709\u200b\u6311\u6218\u6027\u200b\u3002\u200b\u5728\u200b\u63a5\u4e0b\u6765\u200b\u7684\u200b\u90e8\u5206\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u8be6\u7ec6\u200b\u4ecb\u7ecd\u200b\u5982\u4f55\u200b\u5728\u200bCPU\u200b\u548c\u200b\u5355\u200b/\u200b\u591a\u200bGPU\u200b\u8bbe\u7f6e\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\u7684\u200b\u6b65\u9aa4\u200b\u3002</p> <ul> <li>\u200b\u5728\u200b\u5355\u4e2a\u200bCPU\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b</li> <li>\u200b\u5728\u200b\u5355\u4e2a\u200bGPU\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b</li> <li>\u200b\u591a\u200bGPU\u200b\u63a8\u7406\u200b</li> <li>TensorFlow\u200b\u6a21\u578b\u200b\u7684\u200bXLA\u200b\u96c6\u6210\u200b</li> </ul>"},{"location":"performance/#_4","title":"\u8bad\u7ec3\u200b\u548c\u200b\u63a8\u7406","text":"<p>\u200b\u5728\u200b\u8fd9\u91cc\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u627e\u5230\u200b\u9002\u7528\u200b\u4e8e\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u6216\u200b\u4f7f\u7528\u200b\u5b83\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\u7684\u200b\u6280\u5de7\u200b\u3001\u200b\u7a8d\u95e8\u200b\u548c\u200b\u6280\u5de7\u200b\u3002</p> <ul> <li>\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u5927\u578b\u200b\u6a21\u578b\u200b</li> <li>\u200b\u89e3\u51b3\u200b\u6027\u80fd\u200b\u95ee\u9898\u200b</li> </ul>"},{"location":"performance/#_5","title":"\u8d21\u732e","text":"<p>\u200b\u8fd9\u4efd\u200b\u6587\u6863\u200b\u8fd8\u200b\u8fdc\u8fdc\u200b\u6ca1\u6709\u200b\u5b8c\u6210\u200b\uff0c\u200b\u8fd8\u6709\u200b\u5f88\u591a\u200b\u9700\u8981\u200b\u6dfb\u52a0\u200b\u7684\u200b\u5185\u5bb9\u200b\uff0c\u200b\u6240\u4ee5\u200b\u5982\u679c\u200b\u4f60\u200b\u6709\u200b\u8865\u5145\u200b\u6216\u200b\u66f4\u6b63\u200b\u7684\u200b\u5185\u5bb9\u200b\uff0c\u200b\u8bf7\u200b\u6beb\u4e0d\u72b9\u8c6b\u200b\u5730\u200b\u63d0\u4ea4\u200b\u4e00\u4e2a\u200bPR\uff08Pull Request\uff09\uff0c\u200b\u6216\u8005\u200b\u5982\u679c\u200b\u4f60\u200b\u4e0d\u200b\u786e\u5b9a\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200bIssue\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u5728\u200b\u90a3\u91cc\u200b\u8ba8\u8bba\u200b\u7ec6\u8282\u200b\u3002</p> <p>\u200b\u5728\u200b\u505a\u51fa\u200b\u8d21\u732e\u200b\u65f6\u200b\uff0c\u200b\u5982\u679c\u200bA\u200b\u6bd4\u200bB\u200b\u66f4\u597d\u200b\uff0c\u200b\u8bf7\u200b\u5c3d\u91cf\u200b\u5305\u542b\u200b\u53ef\u200b\u91cd\u590d\u200b\u7684\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b\u548c\u200b(\u200b\u6216\u200b)\u200b\u8be5\u200b\u4fe1\u606f\u200b\u6765\u6e90\u200b\u7684\u200b\u94fe\u63a5\u200b\uff08\u200b\u9664\u975e\u200b\u5b83\u200b\u76f4\u63a5\u200b\u6765\u81ea\u200b\u60a8\u200b\uff09\u3002</p>"},{"location":"run_scripts/","title":"Run scripts","text":""},{"location":"run_scripts/#_1","title":"\u4f7f\u7528\u200b\u811a\u672c\u200b\u8fdb\u884c\u200b\u8bad\u7ec3","text":"<p>\u200b\u9664\u4e86\u200b \ud83e\udd17 Transformers notebooks\uff0c\u200b\u8fd8\u6709\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\u6f14\u793a\u200b\u4e86\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200bPyTorch\u3001TensorFlow\u200b\u6216\u200bJAX/Flax\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4ee5\u200b\u89e3\u51b3\u200b\u7279\u5b9a\u200b\u4efb\u52a1\u200b\u3002</p> <p>\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u8fd9\u4e9b\u200b\u793a\u4f8b\u200b\u4e2d\u200b\u627e\u5230\u200b\u6211\u4eec\u200b\u5728\u200b\u7814\u7a76\u200b\u9879\u76ee\u200b\u548c\u200b\u9057\u7559\u200b\u793a\u4f8b\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u8fc7\u200b\u7684\u200b\u811a\u672c\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u811a\u672c\u200b\u4e3b\u8981\u200b\u662f\u200b\u7531\u200b\u793e\u533a\u200b\u8d21\u732e\u200b\u7684\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u811a\u672c\u200b\u5df2\u200b\u4e0d\u518d\u200b\u88ab\u200b\u79ef\u6781\u200b\u7ef4\u62a4\u200b\uff0c\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u7279\u5b9a\u200b\u7248\u672c\u200b\u7684\u200b\ud83e\udd17 Transformers\uff0c \u200b\u53ef\u80fd\u200b\u4e0e\u200b\u5e93\u200b\u7684\u200b\u6700\u65b0\u200b\u7248\u672c\u200b\u4e0d\u200b\u517c\u5bb9\u200b\u3002</p> <p>\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\u53ef\u80fd\u200b\u65e0\u6cd5\u200b\u5728\u200b\u521d\u59cb\u200b\u914d\u7f6e\u200b\u4e0b\u200b\u76f4\u63a5\u200b\u89e3\u51b3\u200b\u6bcf\u4e2a\u200b\u95ee\u9898\u200b\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u6839\u636e\u200b\u8981\u200b\u89e3\u51b3\u200b\u7684\u200b\u95ee\u9898\u200b\u8c03\u6574\u200b\u811a\u672c\u200b\u3002\u200b\u4e3a\u4e86\u200b\u5e2e\u52a9\u200b\u60a8\u200b\uff0c\u200b\u5927\u591a\u6570\u200b\u811a\u672c\u200b\u90fd\u200b\u5b8c\u5168\u200b\u66b4\u9732\u200b\u4e86\u200b\u6570\u636e\u200b\u9884\u5904\u7406\u200b\u7684\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u5141\u8bb8\u200b\u60a8\u200b\u6839\u636e\u200b\u9700\u8981\u200b\u5bf9\u200b\u5176\u200b\u8fdb\u884c\u200b\u7f16\u8f91\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u5728\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\u4e2d\u200b\u5b9e\u73b0\u200b\u4efb\u4f55\u200b\u529f\u80fd\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b\u8bba\u575b\u200b\u6216\u200bissue\u200b\u4e0a\u200b\u8ba8\u8bba\u200b\uff0c\u200b\u7136\u540e\u200b\u518d\u200b\u63d0\u4ea4\u200bPull Request\u3002\u200b\u867d\u7136\u200b\u6211\u4eec\u200b\u6b22\u8fce\u200b\u4fee\u590d\u200b\u9519\u8bef\u200b\uff0c\u200b\u4f46\u200b\u4e0d\u592a\u53ef\u80fd\u200b\u5408\u5e76\u200b\u6dfb\u52a0\u200b\u66f4\u200b\u591a\u529f\u80fd\u200b\u7684\u200bPull Request\uff0c\u200b\u56e0\u4e3a\u200b\u8fd9\u4f1a\u200b\u964d\u4f4e\u200b\u53ef\u8bfb\u6027\u200b\u3002</p> <p>\u200b\u672c\u200b\u6307\u5357\u200b\u5c06\u200b\u5411\u200b\u60a8\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\u5728\u200bPyTorch\u200b\u548c\u200bTensorFlow\u200b\u4e2d\u200b\u8fd0\u884c\u200b\u793a\u4f8b\u200b\u6458\u8981\u200b\u8bad\u7ec3\u200b\u811a\u672c\u200b\u3002\u200b\u9664\u975e\u200b\u53e6\u6709\u200b\u8bf4\u660e\u200b\uff0c\u200b\u5426\u5219\u200b\u6240\u6709\u200b\u793a\u4f8b\u200b\u90fd\u200b\u53ef\u4ee5\u200b\u5728\u200b\u4e24\u4e2a\u200b\u6846\u67b6\u200b\u4e2d\u200b\u5de5\u4f5c\u200b\u3002</p>"},{"location":"run_scripts/#_2","title":"\u8bbe\u7f6e","text":"<p>\u200b\u8981\u200b\u6210\u529f\u200b\u8fd0\u884c\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\u7684\u200b\u6700\u65b0\u200b\u7248\u672c\u200b\uff0c\u200b\u60a8\u200b\u5fc5\u987b\u200b\u5728\u200b\u65b0\u200b\u865a\u62df\u73af\u5883\u200b\u4e2d\u200b\u4ece\u200b\u6e90\u4ee3\u7801\u200b\u5b89\u88c5\u200b \ud83e\udd17 Transformers\uff1a</p> <pre><code>git clone https://github.com/huggingface/transformers\ncd transformers\npip install .\n</code></pre> <p>\u200b\u5bf9\u4e8e\u200b\u65e7\u7248\u672c\u200b\u7684\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\uff0c\u200b\u8bf7\u200b\u70b9\u51fb\u200b\u4e0b\u9762\u200b\u7684\u200b\u5207\u6362\u200b\u6309\u94ae\u200b\uff1a</p> \u200b\u8001\u200b\u7248\u672c\u200b\ud83e\udd17 Transformers\u200b\u793a\u4f8b\u200b  <ul> <li>v4.5.1</li> <li>v4.4.2</li> <li>v4.3.3</li> <li>v4.2.2</li> <li>v4.1.1</li> <li>v4.0.1</li> <li>v3.5.1</li> <li>v3.4.0</li> <li>v3.3.1</li> <li>v3.2.0</li> <li>v3.1.0</li> <li>v3.0.2</li> <li>v2.11.0</li> <li>v2.10.0</li> <li>v2.9.1</li> <li>v2.8.0</li> <li>v2.7.0</li> <li>v2.6.0</li> <li>v2.5.1</li> <li>v2.4.0</li> <li>v2.3.0</li> <li>v2.2.0</li> <li>v2.1.1</li> <li>v2.0.0</li> <li>v1.2.0</li> <li>v1.1.0</li> <li>v1.0.0</li> </ul> <p>\u200b\u7136\u540e\u200b\u5207\u6362\u200b\u60a8\u200bclone\u200b\u7684\u200b \ud83e\udd17 Transformers \u200b\u4ed3\u5230\u200b\u7279\u5b9a\u200b\u7684\u200b\u7248\u672c\u200b\uff0c\u200b\u4f8b\u5982\u200bv3.5.1\uff1a</p> <pre><code>git checkout tags/v3.5.1\n</code></pre> <p>\u200b\u5728\u200b\u5b89\u88c5\u200b\u4e86\u200b\u6b63\u786e\u200b\u7684\u200b\u5e93\u200b\u7248\u672c\u200b\u540e\u200b\uff0c\u200b\u8fdb\u5165\u200b\u60a8\u200b\u9009\u62e9\u200b\u7684\u200b\u7248\u672c\u200b\u7684\u200b<code>example</code>\u200b\u6587\u4ef6\u5939\u200b\u5e76\u200b\u5b89\u88c5\u200b\u4f8b\u5b50\u200b\u8981\u6c42\u200b\u7684\u200b\u73af\u5883\u200b\uff1a</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"run_scripts/#_3","title":"\u8fd0\u884c\u200b\u811a\u672c","text":"<p> <p>\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\u4ece\u200b\ud83e\udd17 Datasets\u200b\u5e93\u200b\u4e0b\u8f7d\u200b\u5e76\u200b\u9884\u5904\u7406\u200b\u6570\u636e\u200b\u96c6\u200b\u3002\u200b\u7136\u540e\u200b\uff0c\u200b\u811a\u672c\u200b\u901a\u8fc7\u200bTrainer\u200b\u4f7f\u7528\u200b\u652f\u6301\u200b\u6458\u8981\u200b\u4efb\u52a1\u200b\u7684\u200b\u67b6\u6784\u200b\u5bf9\u200b\u6570\u636e\u200b\u96c6\u200b\u8fdb\u884c\u200b\u5fae\u8c03\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u793a\u4f8b\u200b\u5c55\u793a\u200b\u4e86\u200b\u5982\u4f55\u200b\u5728\u200bCNN/DailyMail\u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u5fae\u8c03\u200bT5-small\u3002\u200b\u7531\u4e8e\u200bT5\u200b\u6a21\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u5b83\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b\u989d\u5916\u200b\u7684\u200b<code>source_prefix</code>\u200b\u53c2\u6570\u200b\u3002\u200b\u8fd9\u4e2a\u200b\u63d0\u793a\u200b\u8ba9\u200bT5\u200b\u77e5\u9053\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u6458\u8981\u200b\u4efb\u52a1\u200b\u3002</p> <p><pre><code>python examples/pytorch/summarization/run_summarization.py \\\n    --model_name_or_path t5-small \\\n    --do_train \\\n    --do_eval \\\n    --dataset_name cnn_dailymail \\\n    --dataset_config \"3.0.0\" \\\n    --source_prefix \"summarize: \" \\\n    --output_dir /tmp/tst-summarization \\\n    --per_device_train_batch_size=4 \\\n    --per_device_eval_batch_size=4 \\\n    --overwrite_output_dir \\\n    --predict_with_generate\n</code></pre> <p>\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\u4ece\u200b  \ud83e\udd17 Datasets \u200b\u5e93\u200b\u4e0b\u8f7d\u200b\u5e76\u200b\u9884\u5904\u7406\u200b\u6570\u636e\u200b\u96c6\u200b\u3002\u200b\u7136\u540e\u200b\uff0c\u200b\u811a\u672c\u200b\u4f7f\u7528\u200b Keras \u200b\u5728\u200b\u652f\u6301\u200b\u6458\u8981\u200b\u7684\u200b\u67b6\u6784\u200b\u4e0a\u200b\u5fae\u8c03\u200b\u6570\u636e\u200b\u96c6\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u793a\u4f8b\u200b\u5c55\u793a\u200b\u4e86\u200b\u5982\u4f55\u200b\u5728\u200b CNN/DailyMail \u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u5fae\u8c03\u200b T5-small\u3002T5 \u200b\u6a21\u578b\u200b\u7531\u4e8e\u200b\u8bad\u7ec3\u200b\u65b9\u5f0f\u200b\u9700\u8981\u200b\u989d\u5916\u200b\u7684\u200b <code>source_prefix</code> \u200b\u53c2\u6570\u200b\u3002\u200b\u8fd9\u4e2a\u200b\u63d0\u793a\u200b\u8ba9\u200b T5 \u200b\u77e5\u9053\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u6458\u8981\u200b\u4efb\u52a1\u200b\u3002</p> <p><pre><code>python examples/tensorflow/summarization/run_summarization.py  \\\n    --model_name_or_path t5-small \\\n    --dataset_name cnn_dailymail \\\n    --dataset_config \"3.0.0\" \\\n    --output_dir /tmp/tst-summarization  \\\n    --per_device_train_batch_size 8 \\\n    --per_device_eval_batch_size 16 \\\n    --num_train_epochs 3 \\\n    --do_train \\\n    --do_eval\n</code></pre> </p>"},{"location":"run_scripts/#_4","title":"\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u548c\u200b\u6df7\u5408\u200b\u7cbe\u5ea6","text":"<p>Trainer \u200b\u652f\u6301\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u548c\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\uff0c\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u4f60\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u5728\u200b\u811a\u672c\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u5b83\u200b\u3002\u200b\u8981\u200b\u542f\u7528\u200b\u8fd9\u200b\u4e24\u4e2a\u200b\u529f\u80fd\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u505a\u200b\u5982\u4e0b\u200b\u8bbe\u7f6e\u200b\uff1a</p> <ul> <li>\u200b\u6dfb\u52a0\u200b <code>fp16</code> \u200b\u53c2\u6570\u200b\u4ee5\u200b\u542f\u7528\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u3002</li> <li>\u200b\u4f7f\u7528\u200b <code>nproc_per_node</code> \u200b\u53c2\u6570\u8bbe\u7f6e\u200b\u4f7f\u7528\u200b\u7684\u200bGPU\u200b\u6570\u91cf\u200b\u3002</li> </ul> <pre><code>python -m torch.distributed.launch \\\n    --nproc_per_node 8 pytorch/summarization/run_summarization.py \\\n    --fp16 \\\n    --model_name_or_path t5-small \\\n    --do_train \\\n    --do_eval \\\n    --dataset_name cnn_dailymail \\\n    --dataset_config \"3.0.0\" \\\n    --source_prefix \"summarize: \" \\\n    --output_dir /tmp/tst-summarization \\\n    --per_device_train_batch_size=4 \\\n    --per_device_eval_batch_size=4 \\\n    --overwrite_output_dir \\\n    --predict_with_generate\n</code></pre> <p>TensorFlow\u200b\u811a\u672c\u200b\u4f7f\u7528\u200b<code>MirroredStrategy</code>\u200b\u8fdb\u884c\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u60a8\u200b\u65e0\u9700\u200b\u5728\u200b\u8bad\u7ec3\u200b\u811a\u672c\u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u4efb\u4f55\u200b\u5176\u4ed6\u200b\u53c2\u6570\u200b\u3002\u200b\u5982\u679c\u200b\u53ef\u7528\u200b\uff0cTensorFlow\u200b\u811a\u672c\u200b\u5c06\u200b\u9ed8\u8ba4\u200b\u4f7f\u7528\u200b\u591a\u4e2a\u200bGPU\u3002</p>"},{"location":"run_scripts/#tpu","title":"\u5728\u200bTPU\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u811a\u672c","text":"<p> <p>\u200b\u5f20\u91cf\u200b\u5904\u7406\u5355\u5143\u200b\uff08TPUs\uff09\u200b\u662f\u200b\u4e13\u95e8\u200b\u8bbe\u8ba1\u200b\u7528\u4e8e\u200b\u52a0\u901f\u200b\u6027\u80fd\u200b\u7684\u200b\u3002PyTorch\u200b\u4f7f\u7528\u200bXLA\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u7f16\u8bd1\u5668\u200b\u652f\u6301\u200bTPU\uff08\u200b\u66f4\u200b\u591a\u200b\u7ec6\u8282\u200b\u8bf7\u200b\u53c2\u89c1\u200b\u8fd9\u91cc\u200b\uff09\u3002\u200b\u8981\u200b\u4f7f\u7528\u200bTPU\uff0c\u200b\u8bf7\u200b\u542f\u52a8\u200b<code>xla_spawn.py</code>\u200b\u811a\u672c\u200b\u5e76\u200b\u4f7f\u7528\u200b<code>num_cores</code>\u200b\u53c2\u6570\u8bbe\u7f6e\u200b\u8981\u200b\u4f7f\u7528\u200b\u7684\u200bTPU\u200b\u6838\u5fc3\u200b\u6570\u91cf\u200b\u3002</p> <p><pre><code>python xla_spawn.py --num_cores 8 \\\n    summarization/run_summarization.py \\\n    --model_name_or_path t5-small \\\n    --do_train \\\n    --do_eval \\\n    --dataset_name cnn_dailymail \\\n    --dataset_config \"3.0.0\" \\\n    --source_prefix \"summarize: \" \\\n    --output_dir /tmp/tst-summarization \\\n    --per_device_train_batch_size=4 \\\n    --per_device_eval_batch_size=4 \\\n    --overwrite_output_dir \\\n    --predict_with_generate\n</code></pre> <p>\u200b\u5f20\u91cf\u200b\u5904\u7406\u5355\u5143\u200b\uff08TPUs\uff09\u200b\u662f\u200b\u4e13\u95e8\u200b\u8bbe\u8ba1\u200b\u7528\u4e8e\u200b\u52a0\u901f\u200b\u6027\u80fd\u200b\u7684\u200b\u3002TensorFlow\u200b\u811a\u672c\u200b\u4f7f\u7528\u200b<code>TPUStrategy</code>\u200b\u5728\u200bTPU\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u3002\u200b\u8981\u200b\u4f7f\u7528\u200bTPU\uff0c\u200b\u8bf7\u200b\u5c06\u200bTPU\u200b\u8d44\u6e90\u200b\u7684\u200b\u540d\u79f0\u200b\u4f20\u9012\u200b\u7ed9\u200b<code>tpu</code>\u200b\u53c2\u6570\u200b\u3002</p> <p><pre><code>python run_summarization.py  \\\n    --tpu name_of_tpu_resource \\\n    --model_name_or_path t5-small \\\n    --dataset_name cnn_dailymail \\\n    --dataset_config \"3.0.0\" \\\n    --output_dir /tmp/tst-summarization  \\\n    --per_device_train_batch_size 8 \\\n    --per_device_eval_batch_size 16 \\\n    --num_train_epochs 3 \\\n    --do_train \\\n    --do_eval\n</code></pre> </p>"},{"location":"run_scripts/#accelerate","title":"\u57fa\u4e8e\u200b\ud83e\udd17 Accelerate\u200b\u8fd0\u884c\u200b\u811a\u672c","text":"<p>\ud83e\udd17 Accelerate \u200b\u662f\u200b\u4e00\u4e2a\u200b\u4ec5\u200b\u652f\u6301\u200b PyTorch \u200b\u7684\u200b\u5e93\u200b\uff0c\u200b\u5b83\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u79cd\u200b\u7edf\u4e00\u200b\u7684\u200b\u65b9\u6cd5\u200b\u6765\u200b\u5728\u200b\u4e0d\u540c\u200b\u7c7b\u578b\u200b\u7684\u200b\u8bbe\u7f6e\u200b\uff08\u200b\u4ec5\u200b CPU\u3001\u200b\u591a\u4e2a\u200b GPU\u3001\u200b\u591a\u4e2a\u200bTPU\uff09\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff0c\u200b\u540c\u65f6\u200b\u4fdd\u6301\u200b\u5bf9\u200b PyTorch \u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u7684\u200b\u5b8c\u5168\u200b\u53ef\u89c1\u200b\u6027\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u8fd8\u200b\u6ca1\u6709\u200b\u5b89\u88c5\u200b \ud83e\udd17 Accelerate\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200b\u4f60\u200b\u5df2\u7ecf\u200b\u5b89\u88c5\u200b\u4e86\u200b\u5b83\u200b\uff1a</p> <p>\u200b\u6ce8\u610f\u200b\uff1a\u200b\u7531\u4e8e\u200b Accelerate \u200b\u6b63\u5728\u200b\u5feb\u901f\u200b\u53d1\u5c55\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5fc5\u987b\u200b\u5b89\u88c5\u200b git \u200b\u7248\u672c\u200b\u7684\u200b accelerate \u200b\u6765\u200b\u8fd0\u884c\u200b\u811a\u672c\u200b\u3002</p> <pre><code>pip install git+https://github.com/huggingface/accelerate\n</code></pre> <p>\u200b\u4f60\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b<code>run_summarization_no_trainer.py</code>\u200b\u811a\u672c\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b<code>run_summarization.py</code>\u200b\u811a\u672c\u200b\u3002\ud83e\udd17 Accelerate\u200b\u652f\u6301\u200b\u7684\u200b\u811a\u672c\u200b\u9700\u8981\u200b\u5728\u200b\u6587\u4ef6\u5939\u200b\u4e2d\u6709\u200b\u4e00\u4e2a\u200b<code>task_no_trainer.py</code>\u200b\u6587\u4ef6\u200b\u3002\u200b\u9996\u5148\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u4ee5\u200b\u521b\u5efa\u200b\u5e76\u200b\u4fdd\u5b58\u200b\u914d\u7f6e\u6587\u4ef6\u200b\uff1a</p> <p><pre><code>accelerate config\n</code></pre> \u200b\u68c0\u6d4b\u200b\u60a8\u200b\u7684\u200b\u8bbe\u7f6e\u200b\u4ee5\u200b\u786e\u4fdd\u200b\u914d\u7f6e\u200b\u6b63\u786e\u200b\uff1a</p> <pre><code>accelerate test\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5f00\u59cb\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4e86\u200b\uff1a</p> <pre><code>accelerate launch run_summarization_no_trainer.py \\\n    --model_name_or_path t5-small \\\n    --dataset_name cnn_dailymail \\\n    --dataset_config \"3.0.0\" \\\n    --source_prefix \"summarize: \" \\\n    --output_dir ~/tmp/tst-summarization\n</code></pre>"},{"location":"run_scripts/#_5","title":"\u4f7f\u7528\u200b\u81ea\u200b\u5b9a\u4e49\u6570\u636e\u200b\u96c6","text":"<p>\u200b\u6458\u8981\u200b\u811a\u672c\u200b\u652f\u6301\u200b\u81ea\u200b\u5b9a\u4e49\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u53ea\u8981\u200b\u5b83\u4eec\u200b\u662f\u200bCSV\u200b\u6216\u200bJSON Line\u200b\u6587\u4ef6\u200b\u3002\u200b\u5f53\u200b\u4f60\u200b\u4f7f\u7528\u200b\u81ea\u5df1\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u65f6\u200b\uff0c\u200b\u9700\u8981\u200b\u6307\u5b9a\u200b\u4e00\u4e9b\u200b\u989d\u5916\u200b\u7684\u200b\u53c2\u6570\u200b\uff1a - <code>train_file</code> \u200b\u548c\u200b <code>validation_file</code> \u200b\u5206\u522b\u200b\u6307\u5b9a\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u548c\u200b\u9a8c\u8bc1\u200b\u6587\u4ef6\u200b\u7684\u200b\u8def\u5f84\u200b\u3002 - <code>text_column</code> \u200b\u662f\u200b\u8f93\u5165\u200b\u8981\u200b\u8fdb\u884c\u200b\u6458\u8981\u200b\u7684\u200b\u6587\u672c\u200b\u3002 - <code>summary_column</code> \u200b\u662f\u200b\u76ee\u6807\u200b\u8f93\u51fa\u200b\u7684\u200b\u6587\u672c\u200b\u3002</p> <p>\u200b\u4f7f\u7528\u200b\u81ea\u200b\u5b9a\u4e49\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u6458\u8981\u200b\u811a\u672c\u200b\u770b\u8d77\u6765\u200b\u662f\u200b\u8fd9\u6837\u200b\u7684\u200b\uff1a</p> <pre><code>python examples/pytorch/summarization/run_summarization.py \\\n    --model_name_or_path t5-small \\\n    --do_train \\\n    --do_eval \\\n    --train_file path_to_csv_or_jsonlines_file \\\n    --validation_file path_to_csv_or_jsonlines_file \\\n    --text_column text_column_name \\\n    --summary_column summary_column_name \\\n    --source_prefix \"summarize: \" \\\n    --output_dir /tmp/tst-summarization \\\n    --overwrite_output_dir \\\n    --per_device_train_batch_size=4 \\\n    --per_device_eval_batch_size=4 \\\n    --predict_with_generate\n</code></pre>"},{"location":"run_scripts/#_6","title":"\u6d4b\u8bd5\u200b\u811a\u672c","text":"<p>\u200b\u901a\u5e38\u200b\uff0c\u200b\u5728\u200b\u63d0\u4ea4\u200b\u6574\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\u4e4b\u524d\u200b\uff0c\u200b\u6700\u597d\u200b\u5148\u200b\u5728\u200b\u8f83\u200b\u5c11\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u793a\u4f8b\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u811a\u672c\u200b\uff0c\u200b\u4ee5\u200b\u786e\u4fdd\u200b\u4e00\u5207\u200b\u6309\u200b\u9884\u671f\u200b\u5de5\u4f5c\u200b,\u200b\u56e0\u4e3a\u200b\u5b8c\u6574\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u5904\u7406\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u82b1\u8d39\u200b\u51e0\u4e2a\u200b\u5c0f\u65f6\u200b\u7684\u200b\u65f6\u95f4\u200b\u3002\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u53c2\u6570\u200b\u5c06\u200b\u6570\u636e\u200b\u96c6\u200b\u622a\u65ad\u200b\u4e3a\u200b\u6700\u5927\u200b\u6837\u672c\u6570\u200b\uff1a</p> <ul> <li><code>max_train_samples</code></li> <li><code>max_eval_samples</code></li> <li><code>max_predict_samples</code></li> </ul> <pre><code>python examples/pytorch/summarization/run_summarization.py \\\n    --model_name_or_path t5-small \\\n    --max_train_samples 50 \\\n    --max_eval_samples 50 \\\n    --max_predict_samples 50 \\\n    --do_train \\\n    --do_eval \\\n    --dataset_name cnn_dailymail \\\n    --dataset_config \"3.0.0\" \\\n    --source_prefix \"summarize: \" \\\n    --output_dir /tmp/tst-summarization \\\n    --per_device_train_batch_size=4 \\\n    --per_device_eval_batch_size=4 \\\n    --overwrite_output_dir \\\n    --predict_with_generate\n</code></pre> <p>\u200b\u5e76\u975e\u200b\u6240\u6709\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\u90fd\u200b\u652f\u6301\u200b<code>max_predict_samples</code>\u200b\u53c2\u6570\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u4e0d\u200b\u786e\u5b9a\u200b\u60a8\u200b\u7684\u200b\u811a\u672c\u200b\u662f\u5426\u200b\u652f\u6301\u200b\u6b64\u53c2\u6570\u200b\uff0c\u200b\u8bf7\u200b\u6dfb\u52a0\u200b<code>-h</code>\u200b\u53c2\u6570\u200b\u8fdb\u884c\u200b\u68c0\u67e5\u200b\uff1a</p> <pre><code>examples/pytorch/summarization/run_summarization.py -h\n</code></pre>"},{"location":"run_scripts/#checkpoint","title":"\u4ece\u200bcheckpoint\u200b\u6062\u590d\u200b\u8bad\u7ec3","text":"<p>\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u6709\u7528\u200b\u7684\u200b\u9009\u9879\u200b\u662f\u4ece\u200b\u4e4b\u524d\u200b\u7684\u200bcheckpoint\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\u3002\u200b\u8fd9\u200b\u5c06\u200b\u786e\u4fdd\u200b\u5728\u200b\u8bad\u7ec3\u200b\u4e2d\u65ad\u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u4e4b\u524d\u200b\u505c\u6b62\u200b\u7684\u200b\u5730\u65b9\u200b\u7ee7\u7eed\u200b\u8fdb\u884c\u200b\uff0c\u200b\u800c\u200b\u65e0\u9700\u200b\u91cd\u65b0\u200b\u5f00\u59cb\u200b\u3002\u200b\u6709\u200b\u4e24\u79cd\u200b\u65b9\u6cd5\u200b\u53ef\u4ee5\u200b\u4ece\u200bcheckpoint\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\u3002</p> <p>\u200b\u7b2c\u4e00\u79cd\u200b\u65b9\u6cd5\u200b\u4f7f\u7528\u200b<code>output_dir previous_output_dir</code>\u200b\u53c2\u6570\u200b\u4ece\u200b\u5b58\u50a8\u200b\u5728\u200b<code>output_dir</code>\u200b\u4e2d\u200b\u7684\u200b\u6700\u65b0\u200b\u7684\u200bcheckpoint\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\u3002\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u5e94\u8be5\u200b\u5220\u9664\u200b<code>overwrite_output_dir</code>\uff1a</p> <pre><code>python examples/pytorch/summarization/run_summarization.py\n    --model_name_or_path t5-small \\\n    --do_train \\\n    --do_eval \\\n    --dataset_name cnn_dailymail \\\n    --dataset_config \"3.0.0\" \\\n    --source_prefix \"summarize: \" \\\n    --output_dir /tmp/tst-summarization \\\n    --per_device_train_batch_size=4 \\\n    --per_device_eval_batch_size=4 \\\n    --output_dir previous_output_dir \\\n    --predict_with_generate\n</code></pre> <p>\u200b\u7b2c\u4e8c\u79cd\u200b\u65b9\u6cd5\u200b\u4f7f\u7528\u200b<code>resume_from_checkpoint path_to_specific_checkpoint</code>\u200b\u53c2\u6570\u200b\u4ece\u200b\u7279\u5b9a\u200b\u7684\u200bcheckpoint\u200b\u6587\u4ef6\u5939\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\u3002</p> <pre><code>python examples/pytorch/summarization/run_summarization.py\n    --model_name_or_path t5-small \\\n    --do_train \\\n    --do_eval \\\n    --dataset_name cnn_dailymail \\\n    --dataset_config \"3.0.0\" \\\n    --source_prefix \"summarize: \" \\\n    --output_dir /tmp/tst-summarization \\\n    --per_device_train_batch_size=4 \\\n    --per_device_eval_batch_size=4 \\\n    --overwrite_output_dir \\\n    --resume_from_checkpoint path_to_specific_checkpoint \\\n    --predict_with_generate\n</code></pre>"},{"location":"run_scripts/#_7","title":"\u5206\u4eab\u200b\u6a21\u578b","text":"<p>\u200b\u6240\u6709\u200b\u811a\u672c\u200b\u90fd\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u6700\u7ec8\u200b\u6a21\u578b\u200b\u4e0a\u200b\u4f20\u5230\u200bModel Hub\u3002\u200b\u5728\u200b\u5f00\u59cb\u200b\u4e4b\u524d\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u60a8\u200b\u5df2\u200b\u767b\u5f55\u200bHugging Face\uff1a</p> <pre><code>huggingface-cli login\n</code></pre> <p>\u200b\u7136\u540e\u200b\uff0c\u200b\u5728\u200b\u811a\u672c\u200b\u4e2d\u200b\u6dfb\u52a0\u200b<code>push_to_hub</code>\u200b\u53c2\u6570\u200b\u3002\u200b\u8fd9\u4e2a\u200b\u53c2\u6570\u200b\u4f1a\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u5e26\u6709\u200b\u60a8\u200bHugging Face\u200b\u7528\u6237\u540d\u200b\u548c\u200b<code>output_dir</code>\u200b\u4e2d\u200b\u6307\u5b9a\u200b\u7684\u200b\u6587\u4ef6\u5939\u200b\u540d\u79f0\u200b\u7684\u200b\u4ed3\u5e93\u200b\u3002</p> <p>\u200b\u4e3a\u4e86\u200b\u7ed9\u200b\u60a8\u200b\u7684\u200b\u4ed3\u5e93\u200b\u6307\u5b9a\u200b\u4e00\u4e2a\u200b\u7279\u5b9a\u200b\u7684\u200b\u540d\u79f0\u200b\uff0c\u200b\u4f7f\u7528\u200b<code>push_to_hub_model_id</code>\u200b\u53c2\u6570\u200b\u6765\u200b\u6dfb\u52a0\u200b\u5b83\u200b\u3002\u200b\u8be5\u200b\u4ed3\u5e93\u200b\u5c06\u200b\u81ea\u52a8\u200b\u5217\u51fa\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u547d\u540d\u200b\u7a7a\u95f4\u200b\u4e0b\u200b\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u793a\u4f8b\u200b\u5c55\u793a\u200b\u4e86\u200b\u5982\u4f55\u200b\u4e0a\u4f20\u200b\u5177\u6709\u200b\u7279\u5b9a\u200b\u4ed3\u5e93\u200b\u540d\u79f0\u200b\u7684\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>python examples/pytorch/summarization/run_summarization.py\n    --model_name_or_path t5-small \\\n    --do_train \\\n    --do_eval \\\n    --dataset_name cnn_dailymail \\\n    --dataset_config \"3.0.0\" \\\n    --source_prefix \"summarize: \" \\\n    --push_to_hub \\\n    --push_to_hub_model_id finetuned-t5-cnn_dailymail \\\n    --output_dir /tmp/tst-summarization \\\n    --per_device_train_batch_size=4 \\\n    --per_device_eval_batch_size=4 \\\n    --overwrite_output_dir \\\n    --predict_with_generate\n</code></pre>"},{"location":"tf_xla/","title":"Tf xla","text":""},{"location":"tf_xla/#tensorflow-xla","title":"\u7528\u4e8e\u200b TensorFlow \u200b\u6a21\u578b\u200b\u7684\u200b XLA \u200b\u96c6\u6210","text":"<p>[[open-in-colab]]</p> <p>\u200b\u52a0\u901f\u200b\u7ebf\u6027\u4ee3\u6570\u200b\uff0c\u200b\u4e5f\u200b\u79f0\u4e3a\u200bXLA\uff0c\u200b\u662f\u200b\u4e00\u4e2a\u200b\u7528\u4e8e\u200b\u52a0\u901f\u200bTensorFlow\u200b\u6a21\u578b\u200b\u8fd0\u884c\u200b\u65f6\u95f4\u200b\u7684\u200b\u7f16\u8bd1\u5668\u200b\u3002\u200b\u4ece\u200b\u5b98\u65b9\u200b\u6587\u6863\u200b\u4e2d\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200b\uff1a</p> <p>XLA\uff08\u200b\u52a0\u901f\u200b\u7ebf\u6027\u4ee3\u6570\u200b\uff09\u200b\u662f\u200b\u4e00\u79cd\u200b\u9488\u5bf9\u200b\u7ebf\u6027\u4ee3\u6570\u200b\u7684\u200b\u7279\u5b9a\u200b\u9886\u57df\u200b\u7f16\u8bd1\u5668\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5728\u200b\u53ef\u80fd\u200b\u4e0d\u200b\u9700\u8981\u200b\u66f4\u6539\u200b\u6e90\u4ee3\u7801\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u52a0\u901f\u200bTensorFlow\u200b\u6a21\u578b\u200b\u3002</p> <p>\u200b\u5728\u200bTensorFlow\u200b\u4e2d\u200b\u4f7f\u7528\u200bXLA\u200b\u975e\u5e38\u7b80\u5355\u200b\u2014\u2014\u200b\u5b83\u200b\u5305\u542b\u200b\u5728\u200b<code>tensorflow</code>\u200b\u5e93\u4e2d\u200b\uff0c\u200b\u5e76\u4e14\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4efb\u4f55\u200b\u56fe\u200b\u521b\u5efa\u200b\u51fd\u6570\u200b\u4e2d\u200b\u7684\u200b<code>jit_compile</code>\u200b\u53c2\u6570\u200b\u6765\u200b\u89e6\u53d1\u200b\uff0c\u200b\u4f8b\u5982\u200b<code>tf.function</code>\u3002\u200b\u5728\u200b\u4f7f\u7528\u200bKeras\u200b\u65b9\u6cd5\u200b\u5982\u200b<code>fit()</code>\u200b\u548c\u200b<code>predict()</code>\u200b\u65f6\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u5c06\u200b<code>jit_compile</code>\u200b\u53c2\u6570\u4f20\u9012\u200b\u7ed9\u200b<code>model.compile()</code>\u200b\u5373\u53ef\u200b\u542f\u7528\u200bXLA\u3002\u200b\u7136\u800c\u200b\uff0cXLA\u200b\u4e0d\u4ec5\u200b\u9650\u4e8e\u200b\u8fd9\u4e9b\u200b\u65b9\u6cd5\u200b - \u200b\u5b83\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u7528\u4e8e\u200b\u52a0\u901f\u200b\u4efb\u4f55\u200b\u4efb\u610f\u200b\u7684\u200b<code>tf.function</code>\u3002</p> <p>\u200b\u5728\u200b\ud83e\udd17 Transformers\u200b\u4e2d\u200b\uff0c\u200b\u51e0\u4e2a\u200bTensorFlow\u200b\u65b9\u6cd5\u200b\u5df2\u7ecf\u200b\u88ab\u200b\u91cd\u5199\u200b\u4e3a\u200b\u4e0e\u200bXLA\u200b\u517c\u5bb9\u200b\uff0c\u200b\u5305\u62ec\u200bGPT2\u3001T5\u200b\u548c\u200bOPT\u200b\u7b49\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u6a21\u578b\u200b\uff0c\u200b\u4ee5\u53ca\u200bWhisper\u200b\u7b49\u200b\u8bed\u97f3\u200b\u5904\u7406\u200b\u6a21\u578b\u200b\u3002</p> <p>\u200b\u867d\u7136\u200b\u786e\u5207\u200b\u7684\u200b\u52a0\u901f\u200b\u500d\u6570\u200b\u5f88\u5927\u200b\u7a0b\u5ea6\u200b\u4e0a\u200b\u53d6\u51b3\u4e8e\u200b\u6a21\u578b\u200b\uff0c\u200b\u4f46\u200b\u5bf9\u4e8e\u200b\ud83e\udd17 Transformers\u200b\u4e2d\u200b\u7684\u200bTensorFlow\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u6a21\u578b\u200b\uff0c\u200b\u6211\u4eec\u200b\u6ce8\u610f\u200b\u5230\u200b\u901f\u5ea6\u200b\u63d0\u9ad8\u200b\u4e86\u200b\u7ea6\u200b100\u200b\u500d\u200b\u3002\u200b\u672c\u200b\u6587\u6863\u200b\u5c06\u200b\u89e3\u91ca\u200b\u5982\u4f55\u200b\u5728\u200b\u8fd9\u4e9b\u200b\u6a21\u578b\u200b\u4e0a\u200b\u4f7f\u7528\u200bXLA\u200b\u83b7\u5f97\u200b\u6700\u5927\u200b\u7684\u200b\u6027\u80fd\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200b\u5174\u8da3\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b\u548c\u200b\u6211\u4eec\u200b\u5728\u200bXLA\u200b\u96c6\u6210\u200b\u80cc\u540e\u200b\u7684\u200b\u8bbe\u8ba1\u200b\u54f2\u5b66\u200b\u7684\u200b\u4fe1\u606f\u200b\uff0c\u200b\u6211\u4eec\u200b\u8fd8\u200b\u5c06\u200b\u63d0\u4f9b\u200b\u989d\u5916\u200b\u7684\u200b\u8d44\u6e90\u200b\u94fe\u63a5\u200b\u3002</p>"},{"location":"tf_xla/#xla-tensorflow","title":"\u4f7f\u7528\u200b XLA \u200b\u8fd0\u884c\u200b TensorFlow \u200b\u51fd\u6570","text":"<p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u8003\u8651\u200b\u4ee5\u4e0b\u200bTensorFlow \u200b\u4e2d\u200b\u7684\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>import tensorflow as tf\n\nmodel = tf.keras.Sequential(\n    [tf.keras.layers.Dense(10, input_shape=(10,), activation=\"relu\"), tf.keras.layers.Dense(5, activation=\"softmax\")]\n)\n</code></pre> <p>\u200b\u4e0a\u8ff0\u200b\u6a21\u578b\u200b\u63a5\u53d7\u200b\u7ef4\u5ea6\u200b\u4e3a\u200b <code>(10,)</code> \u200b\u7684\u200b\u8f93\u5165\u200b\u3002\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u50cf\u200b\u4e0b\u9762\u200b\u8fd9\u6837\u200b\u4f7f\u7528\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u524d\u5411\u200b\u4f20\u64ad\u200b\uff1a</p> <pre><code># Generate random inputs for the model.\nbatch_size = 16\ninput_vector_dim = 10\nrandom_inputs = tf.random.normal((batch_size, input_vector_dim))\n\n# Run a forward pass.\n_ = model(random_inputs)\n</code></pre> <p>\u200b\u4e3a\u4e86\u200b\u4f7f\u7528\u200b XLA \u200b\u7f16\u8bd1\u200b\u7684\u200b\u51fd\u6570\u200b\u8fd0\u884c\u200b\u524d\u5411\u200b\u4f20\u64ad\u200b\uff0c\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\uff1a</p> <pre><code>xla_fn = tf.function(model, jit_compile=True)\n_ = xla_fn(random_inputs)\n</code></pre> <p><code>model</code>\u200b\u7684\u200b\u9ed8\u8ba4\u200b<code>call()</code>\u200b\u51fd\u6570\u200b\u7528\u4e8e\u200b\u7f16\u8bd1\u200bXLA\u200b\u56fe\u200b\u3002\u200b\u4f46\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u200b\u5c06\u200b\u5176\u4ed6\u200b\u6a21\u578b\u200b\u51fd\u6570\u200b\u7f16\u8bd1\u6210\u200bXLA\uff0c\u200b\u4e5f\u200b\u662f\u200b\u53ef\u4ee5\u200b\u7684\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>my_xla_fn = tf.function(model.my_xla_fn, jit_compile=True)\n</code></pre>"},{"location":"tf_xla/#transformersxlatensorflow","title":"\u5728\u200b\ud83e\udd17 Transformers\u200b\u5e93\u4e2d\u200b\u4f7f\u7528\u200bXLA\u200b\u8fd0\u884c\u200bTensorFlow\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u6a21\u578b","text":"<p>\u200b\u8981\u200b\u5728\u200b\ud83e\udd17 Transformers\u200b\u4e2d\u200b\u542f\u7528\u200bXLA\u200b\u52a0\u901f\u200b\u751f\u6210\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5b89\u88c5\u200b\u6700\u65b0\u200b\u7248\u672c\u200b\u7684\u200b<code>transformers</code>\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u6765\u200b\u5b89\u88c5\u200b\u5b83\u200b\uff1a</p> <pre><code>pip install transformers --upgrade\n</code></pre> <p>\u200b\u7136\u540e\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u4ee3\u7801\u200b\uff1a</p> <pre><code>import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForCausalLM\n\n# Will error if the minimal version of Transformers is not installed.\nfrom transformers.utils import check_min_version\n\ncheck_min_version(\"4.21.0\")\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\", padding_side=\"left\", pad_token=\"&lt;/s&gt;\")\nmodel = TFAutoModelForCausalLM.from_pretrained(\"gpt2\")\ninput_string = [\"TensorFlow is\"]\n\n# One line to create an XLA generation function\nxla_generate = tf.function(model.generate, jit_compile=True)\n\ntokenized_input = tokenizer(input_string, return_tensors=\"tf\")\ngenerated_tokens = xla_generate(**tokenized_input, num_beams=2)\n\ndecoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\nprint(f\"Generated -- {decoded_text}\")\n# Generated -- TensorFlow is an open-source, open-source, distributed-source application # framework for the\n</code></pre> <p>\u200b\u6b63\u5982\u200b\u60a8\u200b\u6240\u200b\u6ce8\u610f\u200b\u5230\u200b\u7684\u200b\uff0c\u200b\u5728\u200b<code>generate()</code>\u200b\u4e0a\u200b\u542f\u7528\u200bXLA\u200b\u53ea\u200b\u9700\u8981\u200b\u4e00\u884c\u200b\u4ee3\u7801\u200b\u3002\u200b\u5176\u4f59\u90e8\u5206\u200b\u4ee3\u7801\u200b\u4fdd\u6301\u200b\u4e0d\u53d8\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u4e0a\u9762\u200b\u7684\u200b\u4ee3\u7801\u200b\u7247\u6bb5\u200b\u4e2d\u6709\u200b\u4e00\u4e9b\u200b\u4e0e\u200bXLA\u200b\u76f8\u5173\u200b\u7684\u200b\u6ce8\u610f\u4e8b\u9879\u200b\u3002\u200b\u60a8\u200b\u9700\u8981\u200b\u4e86\u89e3\u200b\u8fd9\u4e9b\u200b\u6ce8\u610f\u4e8b\u9879\u200b\uff0c\u200b\u4ee5\u200b\u5145\u5206\u5229\u7528\u200bXLA\u200b\u53ef\u80fd\u200b\u5e26\u6765\u200b\u7684\u200b\u6027\u80fd\u200b\u63d0\u5347\u200b\u3002\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b\u4e0b\u9762\u200b\u7684\u200b\u90e8\u5206\u200b\u8ba8\u8bba\u200b\u8fd9\u4e9b\u200b\u5185\u5bb9\u200b\u3002</p>"},{"location":"tf_xla/#_1","title":"\u9700\u8981\u200b\u5173\u6ce8\u200b\u7684\u200b\u6ce8\u610f\u4e8b\u9879","text":"<p>\u200b\u5f53\u200b\u60a8\u200b\u9996\u6b21\u200b\u6267\u884c\u200b\u542f\u7528\u200bXLA\u200b\u7684\u200b\u51fd\u6570\u200b\uff08\u200b\u5982\u200b\u4e0a\u9762\u200b\u7684\u200b<code>xla_generate()</code>\uff09\u200b\u65f6\u200b\uff0c\u200b\u5b83\u200b\u5c06\u200b\u5728\u200b\u5185\u90e8\u200b\u5c1d\u8bd5\u200b\u63a8\u65ad\u200b\u8ba1\u7b97\u200b\u56fe\u200b\uff0c\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u8017\u65f6\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u3002\u200b\u8fd9\u4e2a\u200b\u8fc7\u7a0b\u200b\u88ab\u200b\u79f0\u4e3a\u200b\u201ctracing\u201d\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u6ce8\u610f\u200b\u5230\u200b\u751f\u6210\u200b\u65f6\u95f4\u200b\u5e76\u200b\u4e0d\u5feb\u200b\u3002\u200b\u8fde\u7eed\u200b\u8c03\u7528\u200b<code>xla_generate()</code>\uff08\u200b\u6216\u200b\u4efb\u4f55\u200b\u5176\u4ed6\u200b\u542f\u7528\u200b\u4e86\u200bXLA\u200b\u7684\u200b\u51fd\u6570\u200b\uff09\u200b\u4e0d\u200b\u9700\u8981\u200b\u518d\u6b21\u200b\u63a8\u65ad\u200b\u8ba1\u7b97\u200b\u56fe\u200b\uff0c\u200b\u53ea\u8981\u200b\u51fd\u6570\u200b\u7684\u200b\u8f93\u5165\u200b\u4e0e\u200b\u6700\u521d\u200b\u6784\u5efa\u200b\u8ba1\u7b97\u200b\u56fe\u65f6\u200b\u7684\u200b\u5f62\u72b6\u200b\u76f8\u5339\u914d\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u5177\u6709\u200b\u56fa\u5b9a\u200b\u8f93\u5165\u200b\u5f62\u72b6\u200b\u7684\u200b\u6a21\u6001\u200b\uff08\u200b\u4f8b\u5982\u200b\u56fe\u50cf\u200b\uff09\uff0c\u200b\u8fd9\u200b\u4e0d\u662f\u200b\u95ee\u9898\u200b\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u60a8\u200b\u6b63\u5728\u200b\u5904\u7406\u200b\u5177\u6709\u200b\u53ef\u53d8\u200b\u8f93\u5165\u200b\u5f62\u72b6\u200b\u7684\u200b\u6a21\u6001\u200b\uff08\u200b\u4f8b\u5982\u200b\u6587\u672c\u200b\uff09\uff0c\u200b\u5219\u200b\u5fc5\u987b\u200b\u6ce8\u610f\u200b\u3002</p> <p>\u200b\u4e3a\u4e86\u200b\u786e\u4fdd\u200b<code>xla_generate()</code>\u200b\u59cb\u7ec8\u200b\u4f7f\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u8f93\u5165\u200b\u5f62\u72b6\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u8c03\u7528\u200b<code>tokenizer</code>\u200b\u65f6\u200b\u6307\u5b9a\u200b<code>padding</code>\u200b\u53c2\u6570\u200b\u3002</p> <pre><code>import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\", padding_side=\"left\", pad_token=\"&lt;/s&gt;\")\nmodel = TFAutoModelForCausalLM.from_pretrained(\"gpt2\")\ninput_string = [\"TensorFlow is\"]\n\nxla_generate = tf.function(model.generate, jit_compile=True)\n\n# Here, we call the tokenizer with padding options.\ntokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors=\"tf\")\n\ngenerated_tokens = xla_generate(**tokenized_input, num_beams=2)\ndecoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\nprint(f\"Generated -- {decoded_text}\")\n</code></pre> <p>\u200b\u901a\u8fc7\u200b\u8fd9\u79cd\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u786e\u4fdd\u200b<code>xla_generate()</code>\u200b\u7684\u200b\u8f93\u5165\u200b\u59cb\u7ec8\u200b\u5177\u6709\u200b\u5b83\u200b\u8ddf\u8e2a\u200b\u7684\u200b\u5f62\u72b6\u200b\uff0c\u200b\u4ece\u800c\u200b\u52a0\u901f\u200b\u751f\u6210\u200b\u65f6\u95f4\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u4ee3\u7801\u200b\u6765\u200b\u9a8c\u8bc1\u200b\u8fd9\u200b\u4e00\u70b9\u200b\uff1a</p> <pre><code>import time\nimport tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\", padding_side=\"left\", pad_token=\"&lt;/s&gt;\")\nmodel = TFAutoModelForCausalLM.from_pretrained(\"gpt2\")\n\nxla_generate = tf.function(model.generate, jit_compile=True)\n\nfor input_string in [\"TensorFlow is\", \"TensorFlow is a\", \"TFLite is a\"]:\n    tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors=\"tf\")\n    start = time.time_ns()\n    generated_tokens = xla_generate(**tokenized_input, num_beams=2)\n    end = time.time_ns()\n    print(f\"Execution time -- {(end - start) / 1e6:.1f} ms\\n\")\n</code></pre> <p>\u200b\u5728\u200bTesla T4 GPU\u200b\u4e0a\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u671f\u671b\u200b\u5982\u4e0b\u200b\u7684\u200b\u8f93\u51fa\u200b\uff1a</p> <pre><code>Execution time -- 30819.6 ms\n\nExecution time -- 79.0 ms\n\nExecution time -- 78.9 ms\n</code></pre> <p>\u200b\u7b2c\u4e00\u6b21\u200b\u8c03\u7528\u200b<code>xla_generate()</code>\u200b\u4f1a\u200b\u56e0\u4e3a\u200b<code>tracing</code>\u200b\u800c\u200b\u8017\u65f6\u200b\uff0c\u200b\u4f46\u200b\u540e\u7eed\u200b\u7684\u200b\u8c03\u7528\u200b\u4f1a\u200b\u5feb\u5f97\u591a\u200b\u3002\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u4efb\u4f55\u200b\u65f6\u5019\u200b\u5bf9\u200b\u751f\u6210\u200b\u9009\u9879\u200b\u7684\u200b\u66f4\u6539\u200b\u90fd\u200b\u4f1a\u200b\u89e6\u53d1\u200b\u91cd\u65b0\u200b<code>tracing</code>\uff0c\u200b\u4ece\u800c\u200b\u5bfc\u81f4\u200b\u751f\u6210\u200b\u65f6\u95f4\u200b\u51cf\u6162\u200b\u3002</p> <p>\u200b\u5728\u200b\u672c\u200b\u6587\u6863\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u6ca1\u6709\u200b\u6db5\u76d6\u200b\ud83e\udd17 Transformers\u200b\u63d0\u4f9b\u200b\u7684\u200b\u6240\u6709\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u9009\u9879\u200b\u3002\u200b\u6211\u4eec\u200b\u9f13\u52b1\u200b\u60a8\u200b\u9605\u8bfb\u200b\u6587\u6863\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u9ad8\u7ea7\u200b\u7528\u4f8b\u200b\u3002</p>"},{"location":"tf_xla/#_2","title":"\u9644\u52a0\u200b\u8d44\u6e90","text":"<p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u4e00\u4e9b\u200b\u9644\u52a0\u200b\u8d44\u6e90\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u6df1\u5165\u200b\u4e86\u89e3\u200b\u5728\u200b\ud83e\udd17 Transformers\u200b\u548c\u200b\u5176\u4ed6\u200b\u5e93\u4e0b\u200b\u4f7f\u7528\u200bXLA\uff1a</p> <ul> <li> <p>\u200b\u8fd9\u4e2a\u200bColab Notebook \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u4e92\u52a8\u200b\u6f14\u793a\u200b\uff0c\u200b\u8ba9\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c1d\u8bd5\u200b\u4f7f\u7528\u200bXLA\u200b\u517c\u5bb9\u200b\u7684\u200b\u7f16\u7801\u5668\u200b-\u200b\u89e3\u7801\u5668\u200b\uff08\u200b\u4f8b\u5982\u200bT5\uff09\u200b\u548c\u200b\u4ec5\u200b\u89e3\u7801\u5668\u200b\uff08\u200b\u4f8b\u5982\u200bGPT2\uff09\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u6a21\u578b\u200b\u3002</p> </li> <li> <p>\u200b\u8fd9\u7bc7\u200b\u535a\u5ba2\u200b\u6587\u7ae0\u200b \u200b\u63d0\u4f9b\u200b\u4e86\u200bXLA\u200b\u517c\u5bb9\u200b\u6a21\u578b\u200b\u7684\u200b\u6bd4\u8f83\u200b\u57fa\u51c6\u200b\u6982\u8ff0\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u5173\u4e8e\u200b\u5728\u200bTensorFlow\u200b\u4e2d\u200b\u4f7f\u7528\u200bXLA\u200b\u7684\u200b\u53cb\u597d\u200b\u4ecb\u7ecd\u200b\u3002</p> </li> <li> <p>\u200b\u8fd9\u7bc7\u200b\u535a\u5ba2\u200b\u6587\u7ae0\u200b \u200b\u8ba8\u8bba\u200b\u4e86\u200b\u6211\u4eec\u200b\u5728\u200b\ud83e\udd17 Transformers\u200b\u4e2d\u4e3a\u200bTensorFlow\u200b\u6a21\u578b\u200b\u6dfb\u52a0\u200bXLA\u200b\u652f\u6301\u200b\u7684\u200b\u8bbe\u8ba1\u200b\u7406\u5ff5\u200b\u3002</p> </li> <li> <p>\u200b\u63a8\u8350\u200b\u7528\u4e8e\u200b\u66f4\u200b\u591a\u200b\u5b66\u4e60\u200bXLA\u200b\u548c\u200bTensorFlow\u200b\u56fe\u200b\u7684\u200b\u8d44\u6e90\u200b\uff1a</p> <ul> <li>XLA\uff1a\u200b\u9762\u5411\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u7684\u200b\u4f18\u5316\u200b\u7f16\u8bd1\u5668\u200b</li> <li>\u200b\u56fe\u200b\u548c\u200btf.function\u200b\u7b80\u4ecb\u200b</li> <li>\u200b\u4f7f\u7528\u200btf.function\u200b\u83b7\u5f97\u200b\u66f4\u597d\u200b\u7684\u200b\u6027\u80fd\u200b</li> </ul> </li> </ul>"},{"location":"tokenizer_summary/","title":"Tokenizer summary","text":""},{"location":"tokenizer_summary/#_1","title":"\u5206\u8bcd\u5668\u200b\u7684\u200b\u6458\u8981","text":"<p>[[open-in-colab]]</p> <p>\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u9875\u9762\u200b\uff0c\u200b\u6211\u4eec\u200b\u6765\u200b\u4ed4\u7ec6\u200b\u7814\u7a76\u200b\u5206\u8bcd\u200b\u7684\u200b\u77e5\u8bc6\u200b\u3002 </p> <p>\u200b\u6b63\u5982\u200b\u6211\u4eec\u200b\u5728\u200bthe preprocessing tutorial\u200b\u6240\u200b\u770b\u5230\u200b\u7684\u200b\u90a3\u6837\u200b\uff0c\u200b\u5bf9\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\u5c31\u662f\u200b\u5c06\u200b\u4e00\u6bb5\u200b\u6587\u672c\u200b\u5206\u5272\u200b\u6210\u200b\u5f88\u591a\u200b\u5355\u8bcd\u200b\u6216\u8005\u200b\u5b50\u200b\u5355\u8bcd\u200b\uff0c \u200b\u8fd9\u4e9b\u200b\u5355\u8bcd\u200b\u6216\u8005\u200b\u5b50\u200b\u5355\u8bcd\u200b\u7136\u540e\u200b\u4f1a\u200b\u901a\u8fc7\u200b\u4e00\u4e2a\u200b\u67e5\u8be2\u200b\u8868\u683c\u200b\u88ab\u200b\u8f6c\u6362\u200b\u5230\u200bid\uff0c\u200b\u5c06\u200b\u5355\u8bcd\u200b\u6216\u8005\u200b\u5b50\u200b\u5355\u8bcd\u200b\u8f6c\u6362\u200b\u5230\u200bid\u200b\u662f\u200b\u5f88\u200b\u76f4\u622a\u4e86\u5f53\u200b\u7684\u200b\uff0c\u200b\u4e5f\u200b\u5c31\u662f\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u6620\u5c04\u200b\uff0c \u200b\u6240\u4ee5\u200b\u8fd9\u4e48\u200b\u6765\u770b\u200b\uff0c\u200b\u6211\u4eec\u200b\u4e3b\u8981\u200b\u5173\u6ce8\u200b\u5c06\u200b\u4e00\u6bb5\u200b\u6587\u672c\u200b\u5206\u5272\u200b\u6210\u200b\u5f88\u591a\u200b\u5355\u8bcd\u200b\u6216\u8005\u200b\u5f88\u591a\u200b\u5b50\u200b\u5355\u8bcd\u200b\uff08\u200b\u50cf\u200b\uff1a\u200b\u5bf9\u200b\u4e00\u6bb5\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\uff09\uff0c\u200b\u66f4\u52a0\u200b\u51c6\u786e\u200b\u7684\u200b\u6765\u8bf4\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u5173\u6ce8\u200b \u200b\u5728\u200b\ud83e\udd17 Transformers\u200b\u5185\u200b\u7528\u5230\u200b\u7684\u200b\u4e09\u79cd\u200b\u4e3b\u8981\u200b\u7c7b\u578b\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\uff1aByte-Pair Encoding (BPE), WordPiece,  and SentencePiece\uff0c\u200b\u5e76\u4e14\u200b\u7ed9\u51fa\u200b\u4e86\u200b\u793a\u4f8b\u200b\uff0c\u200b\u54ea\u4e2a\u200b\u6a21\u578b\u200b\u7528\u5230\u200b\u4e86\u200b\u54ea\u79cd\u200b\u7c7b\u578b\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\u3002</p> <p>\u200b\u6ce8\u610f\u200b\u5230\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u7684\u200b\u4e3b\u9875\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u67e5\u770b\u200b\u6587\u6863\u200b\u4e0a\u200b\u76f8\u5173\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u77e5\u9053\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4f7f\u7528\u200b\u4e86\u200b\u54ea\u79cd\u200b\u7c7b\u578b\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\u3002 \u200b\u4e3e\u4e2a\u200b\u4f8b\u5b50\u200b\uff0c\u200b\u5982\u679c\u200b\u6211\u4eec\u200b\u67e5\u770b\u200b[<code>BertTokenizer</code>]\uff0c\u200b\u6211\u4eec\u200b\u5c31\u200b\u80fd\u200b\u770b\u5230\u200b\u6a21\u578b\u200b\u4f7f\u7528\u200b\u4e86\u200bWordPiece\u3002</p>"},{"location":"tokenizer_summary/#_2","title":"\u4ecb\u7ecd","text":"<p>\u200b\u5c06\u200b\u4e00\u6bb5\u200b\u6587\u672c\u200b\u5206\u8bcd\u200b\u5230\u200b\u5c0f\u5757\u200b\u662f\u200b\u4e00\u4e2a\u200b\u6bd4\u200b\u5b83\u200b\u770b\u8d77\u6765\u200b\u66f4\u52a0\u200b\u56f0\u96be\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u5e76\u4e14\u200b\u6709\u200b\u5f88\u591a\u200b\u65b9\u5f0f\u200b\u6765\u200b\u5b9e\u73b0\u200b\u5206\u8bcd\u200b\uff0c\u200b\u4e3e\u4e2a\u200b\u4f8b\u5b50\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u770b\u770b\u200b\u8fd9\u4e2a\u200b\u53e5\u5b50\u200b <code>\"Don't you love \ud83e\udd17 Transformers? We sure do.\"</code></p> <p></p> <p>\u200b\u5bf9\u200b\u8fd9\u6bb5\u200b\u6587\u672c\u200b\u5206\u8bcd\u200b\u7684\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u5c31\u662f\u200b\u4f7f\u7528\u200b\u7a7a\u683c\u200b\u6765\u200b\u5206\u8bcd\u200b\uff0c\u200b\u5f97\u5230\u200b\u7684\u200b\u7ed3\u679c\u200b\u662f\u200b\uff1a</p> <pre><code>[\"Don't\", \"you\", \"love\", \"\ud83e\udd17\", \"Transformers?\", \"We\", \"sure\", \"do.\"]\n</code></pre> <p>\u200b\u4e0a\u9762\u200b\u7684\u200b\u5206\u8bcd\u200b\u662f\u200b\u4e00\u4e2a\u200b\u660e\u667a\u200b\u7684\u200b\u5f00\u59cb\u200b\uff0c\u200b\u4f46\u662f\u200b\u5982\u679c\u200b\u6211\u4eec\u200b\u67e5\u770b\u200btoken <code>\"Transformers?\"</code> \u200b\u548c\u200b <code>\"do.\"</code>\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u89c2\u5bdf\u200b\u5230\u200b\u6807\u70b9\u7b26\u53f7\u200b\u9644\u5728\u200b\u5355\u8bcd\u200b<code>\"Transformer\"</code>  \u200b\u548c\u200b <code>\"do\"</code>\u200b\u7684\u200b\u540e\u9762\u200b\uff0c\u200b\u8fd9\u200b\u5e76\u200b\u4e0d\u662f\u200b\u6700\u200b\u7406\u60f3\u200b\u7684\u200b\u60c5\u51b5\u200b\u3002\u200b\u6211\u4eec\u200b\u5e94\u8be5\u200b\u5c06\u200b\u6807\u70b9\u7b26\u53f7\u200b\u8003\u8651\u200b\u8fdb\u6765\u200b\uff0c\u200b\u8fd9\u6837\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u5c31\u200b\u6ca1\u200b\u5fc5\u8981\u200b\u5b66\u4e60\u200b\u4e00\u4e2a\u200b\u5355\u8bcd\u200b\u548c\u200b\u6bcf\u4e2a\u200b\u53ef\u80fd\u200b\u8ddf\u200b\u5728\u200b\u540e\u9762\u200b\u7684\u200b \u200b\u6807\u70b9\u7b26\u53f7\u200b\u7684\u200b\u4e0d\u540c\u200b\u7684\u200b\u7ec4\u5408\u200b\uff0c\u200b\u8fd9\u4e48\u200b\u7ec4\u5408\u200b\u7684\u8bdd\u200b\uff0c\u200b\u6a21\u578b\u200b\u9700\u8981\u200b\u5b66\u4e60\u200b\u7684\u200b\u7ec4\u5408\u200b\u7684\u200b\u6570\u91cf\u200b\u4f1a\u200b\u6025\u5267\u200b\u4e0a\u5347\u200b\u3002\u200b\u5c06\u200b\u6807\u70b9\u7b26\u53f7\u200b\u4e5f\u200b\u8003\u8651\u200b\u8fdb\u6765\u200b\uff0c\u200b\u5bf9\u200b\u8303\u4f8b\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\u7684\u200b\u7ed3\u679c\u200b\u5c31\u662f\u200b\uff1a</p> <pre><code>[\"Don\", \"'\", \"t\", \"you\", \"love\", \"\ud83e\udd17\", \"Transformers\", \"?\", \"We\", \"sure\", \"do\", \".\"]\n</code></pre> <p>\u200b\u5206\u8bcd\u200b\u7684\u200b\u7ed3\u679c\u200b\u66f4\u597d\u200b\u4e86\u200b\uff0c\u200b\u7136\u800c\u200b\uff0c\u200b\u8fd9\u4e48\u200b\u505a\u200b\u4e5f\u200b\u662f\u200b\u4e0d\u597d\u200b\u7684\u200b\uff0c\u200b\u5206\u8bcd\u200b\u600e\u4e48\u200b\u5904\u7406\u200b\u5355\u8bcd\u200b<code>\"Don't\"</code>\uff0c<code>\"Don't\"</code>\u200b\u7684\u200b\u542b\u4e49\u200b\u662f\u200b<code>\"do not\"</code>\uff0c\u200b\u6240\u4ee5\u200b\u8fd9\u4e48\u200b\u5206\u8bcd\u200b<code>[\"Do\", \"n't\"]</code> \u200b\u4f1a\u200b\u66f4\u597d\u200b\u3002\u200b\u73b0\u5728\u200b\u5f00\u59cb\u200b\u4e8b\u60c5\u200b\u5c31\u200b\u5f00\u59cb\u200b\u53d8\u5f97\u590d\u6742\u200b\u8d77\u6765\u200b\u4e86\u200b\uff0c\u200b\u90e8\u5206\u200b\u7684\u200b\u539f\u56e0\u200b\u662f\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u90fd\u200b\u6709\u200b\u5b83\u200b\u81ea\u5df1\u200b\u7684\u200b\u5206\u8bcd\u200b\u7c7b\u578b\u200b\u3002\u200b\u4f9d\u8d56\u4e8e\u200b\u6211\u4eec\u200b\u5e94\u7528\u200b\u5728\u200b\u6587\u672c\u200b\u5206\u8bcd\u200b\u4e0a\u200b\u7684\u200b\u89c4\u5219\u200b\uff0c \u200b\u76f8\u540c\u200b\u7684\u200b\u6587\u672c\u200b\u4f1a\u200b\u4ea7\u751f\u200b\u4e0d\u540c\u200b\u7684\u200b\u5206\u8bcd\u200b\u8f93\u51fa\u200b\u3002\u200b\u7528\u200b\u5728\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u4e0a\u200b\u7684\u200b\u5206\u8bcd\u200b\u89c4\u5219\u200b\uff0c\u200b\u88ab\u200b\u7528\u6765\u200b\u5bf9\u200b\u8f93\u5165\u200b\u505a\u200b\u5206\u8bcd\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u4e00\u4e2a\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u624d\u200b\u4f1a\u200b\u6b63\u786e\u200b\u7684\u200b\u6267\u884c\u200b\u3002</p> <p>spaCy and Moses \u200b\u662f\u200b\u4e24\u4e2a\u200b\u53d7\u6b22\u8fce\u200b\u7684\u200b\u57fa\u4e8e\u200b\u89c4\u5219\u200b\u7684\u200b \u200b\u5206\u8bcd\u5668\u200b\u3002\u200b\u5c06\u200b\u8fd9\u200b\u4e24\u4e2a\u200b\u5206\u8bcd\u5668\u200b\u5e94\u7528\u200b\u5728\u200b\u793a\u4f8b\u200b\u6587\u672c\u200b\u4e0a\u200b\uff0cspaCy \u200b\u548c\u200b Moses\u200b\u4f1a\u200b\u8f93\u51fa\u200b\u7c7b\u4f3c\u200b\u4e0b\u9762\u200b\u7684\u200b\u7ed3\u679c\u200b\uff1a</p> <pre><code>[\"Do\", \"n't\", \"you\", \"love\", \"\ud83e\udd17\", \"Transformers\", \"?\", \"We\", \"sure\", \"do\", \".\"]\n</code></pre> <p>\u200b\u53ef\u89c1\u200b\u4e0a\u9762\u200b\u7684\u200b\u5206\u8bcd\u200b\u4f7f\u7528\u200b\u5230\u200b\u4e86\u200b\u7a7a\u683c\u200b\u548c\u200b\u6807\u70b9\u7b26\u53f7\u200b\u7684\u200b\u5206\u8bcd\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u57fa\u4e8e\u200b\u89c4\u5219\u200b\u7684\u200b\u5206\u8bcd\u200b\u65b9\u5f0f\u200b\u3002\u200b\u7a7a\u683c\u200b\u548c\u200b\u6807\u70b9\u7b26\u53f7\u200b\u5206\u8bcd\u200b\u4ee5\u53ca\u200b\u57fa\u4e8e\u200b\u89c4\u5219\u200b\u7684\u200b\u5206\u8bcd\u200b\u90fd\u200b\u662f\u200b\u5355\u8bcd\u200b\u5206\u8bcd\u200b\u7684\u200b\u4f8b\u5b50\u200b\u3002 \u200b\u4e0d\u200b\u90a3\u4e48\u200b\u4e25\u683c\u200b\u7684\u200b\u6765\u8bf4\u200b\uff0c\u200b\u5355\u8bcd\u200b\u5206\u8bcd\u200b\u7684\u200b\u5b9a\u4e49\u200b\u5c31\u662f\u200b\u5c06\u200b\u53e5\u5b50\u200b\u5206\u5272\u200b\u5230\u200b\u5f88\u591a\u200b\u5355\u8bcd\u200b\u3002\u200b\u7136\u800c\u200b\u5c06\u200b\u6587\u672c\u200b\u5206\u5272\u200b\u5230\u200b\u66f4\u200b\u5c0f\u200b\u7684\u200b\u5757\u200b\u662f\u200b\u7b26\u5408\u200b\u76f4\u89c9\u200b\u7684\u200b\uff0c\u200b\u5f53\u200b\u5904\u7406\u200b\u5927\u578b\u200b\u6587\u672c\u200b\u8bed\u6599\u5e93\u200b\u65f6\u200b\uff0c\u200b\u4e0a\u9762\u200b\u7684\u200b \u200b\u5206\u8bcd\u200b\u65b9\u6cd5\u200b\u4f1a\u200b\u5bfc\u81f4\u200b\u5f88\u591a\u200b\u95ee\u9898\u200b\u3002\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u7a7a\u683c\u200b\u548c\u200b\u6807\u70b9\u7b26\u53f7\u200b\u5206\u8bcd\u200b\u901a\u5e38\u200b\u4f1a\u200b\u4ea7\u751f\u200b\u4e00\u4e2a\u200b\u975e\u5e38\u200b\u5927\u200b\u7684\u200b\u8bcd\u5178\u200b\uff08\u200b\u4f7f\u7528\u200b\u5230\u200b\u7684\u200b\u6240\u6709\u200b\u4e0d\u200b\u91cd\u590d\u200b\u7684\u200b\u5355\u8bcd\u200b\u548c\u200btokens\u200b\u7684\u200b\u96c6\u5408\u200b\uff09\u3002 \u200b\u50cf\u200b\uff1aTransformer XL\u200b\u4f7f\u7528\u200b\u7a7a\u683c\u200b\u548c\u200b\u6807\u70b9\u7b26\u53f7\u200b\u5206\u8bcd\u200b\uff0c\u200b\u7ed3\u679c\u200b\u4f1a\u200b\u4ea7\u751f\u200b\u4e00\u4e2a\u200b\u5927\u5c0f\u200b\u662f\u200b267,735\u200b\u7684\u200b\u8bcd\u5178\u200b\uff01</p> <p>\u200b\u8fd9\u4e48\u200b\u5927\u200b\u7684\u200b\u4e00\u4e2a\u200b\u8bcd\u5178\u200b\u5bb9\u91cf\u200b\uff0c\u200b\u8feb\u4f7f\u200b\u6a21\u578b\u200b\u6709\u7740\u200b\u4e00\u4e2a\u200b\u5de8\u5927\u200b\u7684\u200bembedding\u200b\u77e9\u9635\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u5de8\u5927\u200b\u7684\u200b\u8f93\u5165\u200b\u548c\u200b\u8f93\u51fa\u200b\u5c42\u200b\uff0c\u200b\u8fd9\u4f1a\u200b\u589e\u52a0\u200b\u5185\u5b58\u200b\u4f7f\u7528\u91cf\u200b\uff0c\u200b\u4e5f\u200b\u4f1a\u200b\u63d0\u9ad8\u200b\u65f6\u95f4\u200b\u590d\u6742\u5ea6\u200b\u3002\u200b\u901a\u5e38\u200b \u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0ctransformers\u200b\u6a21\u578b\u200b\u51e0\u4e4e\u200b\u6ca1\u6709\u200b\u8bcd\u5178\u200b\u5bb9\u91cf\u200b\u5927\u4e8e\u200b50,000\u200b\u7684\u200b\uff0c\u200b\u7279\u522b\u200b\u662f\u200b\u53ea\u200b\u5728\u200b\u4e00\u79cd\u200b\u8bed\u8a00\u200b\u4e0a\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u3002</p> <p>\u200b\u6240\u4ee5\u200b\u5982\u679c\u200b\u7b80\u5355\u200b\u7684\u200b\u7a7a\u683c\u200b\u548c\u200b\u6807\u70b9\u7b26\u53f7\u200b\u5206\u8bcd\u200b\u8ba9\u200b\u4eba\u200b\u4e0d\u200b\u6ee1\u610f\u200b\uff0c\u200b\u4e3a\u4ec0\u4e48\u200b\u4e0d\u200b\u7b80\u5355\u200b\u7684\u200b\u5bf9\u200b\u5b57\u7b26\u200b\u5206\u8bcd\u200b\uff1f</p> <p></p> <p>\u200b\u5c3d\u7ba1\u200b\u5b57\u7b26\u200b\u5206\u8bcd\u200b\u662f\u200b\u975e\u5e38\u7b80\u5355\u200b\u7684\u200b\uff0c\u200b\u5e76\u4e14\u200b\u80fd\u200b\u6781\u5927\u200b\u7684\u200b\u51cf\u5c11\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\uff0c\u200b\u964d\u4f4e\u200b\u65f6\u95f4\u200b\u590d\u6742\u5ea6\u200b\uff0c\u200b\u4f46\u662f\u200b\u8fd9\u6837\u200b\u505a\u4f1a\u200b\u8ba9\u200b\u6a21\u578b\u200b\u5f88\u96be\u200b\u5b66\u5230\u200b\u6709\u200b\u610f\u4e49\u200b\u7684\u200b\u8f93\u5165\u200b\u8868\u8fbe\u200b\u3002\u200b\u50cf\u200b\uff1a \u200b\u6bd4\u8d77\u200b\u5b66\u5230\u200b\u5355\u8bcd\u200b<code>\"today\"</code>\u200b\u7684\u200b\u4e00\u4e2a\u200b\u6709\u200b\u610f\u4e49\u200b\u7684\u200b\u4e0a\u4e0b\u6587\u200b\u72ec\u7acb\u200b\u7684\u200b\u8868\u8fbe\u200b\uff0c\u200b\u5b66\u5230\u200b\u5b57\u6bcd\u200b<code>\"t\"</code>\u200b\u7684\u200b\u4e00\u4e2a\u200b\u6709\u200b\u610f\u4e49\u200b\u7684\u200b\u4e0a\u4e0b\u6587\u200b\u72ec\u7acb\u200b\u7684\u200b\u8868\u8fbe\u200b\u662f\u200b\u76f8\u5f53\u200b\u56f0\u96be\u200b\u7684\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c \u200b\u5b57\u7b26\u200b\u5206\u8bcd\u200b\u7ecf\u5e38\u200b\u4f1a\u200b\u4f34\u968f\u200b\u7740\u200b\u6027\u80fd\u200b\u7684\u200b\u4e0b\u964d\u200b\u3002\u200b\u6240\u4ee5\u200b\u4e3a\u4e86\u200b\u83b7\u5f97\u200b\u6700\u597d\u200b\u7684\u200b\u7ed3\u679c\u200b\uff0ctransformers\u200b\u6a21\u578b\u200b\u5728\u200b\u5355\u8bcd\u200b\u7ea7\u522b\u200b\u5206\u8bcd\u200b\u548c\u200b\u5b57\u7b26\u200b\u7ea7\u522b\u200b\u5206\u8bcd\u200b\u4e4b\u95f4\u200b\u4f7f\u7528\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u6298\u4e2d\u200b\u7684\u200b\u65b9\u6848\u200b \u200b\u88ab\u79f0\u4f5c\u200b\u5b50\u8bcd\u200b\u5206\u8bcd\u200b\u3002</p>"},{"location":"tokenizer_summary/#_3","title":"\u5b50\u8bcd\u200b\u5206\u8bcd","text":"<p>\u200b\u5b50\u8bcd\u200b\u5206\u8bcd\u200b\u7b97\u6cd5\u200b\u4f9d\u8d56\u200b\u8fd9\u6837\u200b\u7684\u200b\u539f\u5219\u200b\uff1a\u200b\u9891\u7e41\u200b\u4f7f\u7528\u200b\u7684\u200b\u5355\u8bcd\u200b\u4e0d\u200b\u5e94\u8be5\u200b\u88ab\u200b\u5206\u5272\u200b\u6210\u200b\u66f4\u200b\u5c0f\u200b\u7684\u200b\u5b50\u200b\u8bcd\u200b\uff0c\u200b\u4f46\u662f\u200b\u5f88\u5c11\u200b\u4f7f\u7528\u200b\u7684\u200b\u5355\u8bcd\u200b\u5e94\u8be5\u200b\u88ab\u200b\u5206\u89e3\u200b\u5230\u200b\u6709\u200b\u610f\u4e49\u200b\u7684\u200b\u5b50\u200b\u8bcd\u200b\u3002\u200b\u4e3e\u4e2a\u200b\u4f8b\u5b50\u200b\uff1a <code>\"annoyingly\"</code>\u200b\u80fd\u200b\u88ab\u200b\u770b\u4f5c\u200b\u4e00\u4e2a\u200b\u5f88\u5c11\u200b\u4f7f\u7528\u200b\u7684\u200b\u5355\u8bcd\u200b\uff0c\u200b\u80fd\u200b\u88ab\u200b\u5206\u89e3\u6210\u200b<code>\"annoying\"</code>\u200b\u548c\u200b<code>\"ly\"</code>\u3002<code>\"annoying\"</code>\u200b\u548c\u200b<code>\"ly\"</code>\u200b\u4f5c\u4e3a\u200b\u72ec\u7acb\u200b\u5730\u5b50\u200b\u8bcd\u200b\uff0c\u200b\u51fa\u73b0\u200b \u200b\u7684\u200b\u6b21\u6570\u200b\u90fd\u200b\u5f88\u200b\u9891\u7e41\u200b\uff0c\u200b\u800c\u4e14\u200b\u4e0e\u6b64\u540c\u65f6\u200b\u5355\u8bcd\u200b<code>\"annoyingly\"</code>\u200b\u7684\u200b\u542b\u4e49\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u7ec4\u5408\u200b<code>\"annoying\"</code>\u200b\u548c\u200b<code>\"ly\"</code>\u200b\u7684\u200b\u542b\u4e49\u200b\u6765\u200b\u83b7\u5f97\u200b\u3002\u200b\u5728\u200b\u7c98\u5408\u200b\u548c\u200b\u80f6\u6c34\u200b\u8bed\u8a00\u200b\u4e0a\u200b\uff0c \u200b\u50cf\u200bTurkish\u200b\u8bed\u8a00\u200b\uff0c\u200b\u8fd9\u4e48\u200b\u505a\u200b\u662f\u200b\u76f8\u5f53\u200b\u6709\u7528\u200b\u7684\u200b\uff0c\u200b\u5728\u200b\u8fd9\u6837\u200b\u7684\u200b\u8bed\u8a00\u200b\u91cc\u200b\uff0c\u200b\u901a\u8fc7\u200b\u7ebf\u6027\u7ec4\u5408\u200b\u5b50\u8bcd\u200b\uff0c\u200b\u5927\u591a\u6570\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4f60\u200b\u80fd\u200b\u5f62\u6210\u200b\u4efb\u610f\u200b\u957f\u200b\u7684\u200b\u590d\u6742\u200b\u7684\u200b\u5355\u8bcd\u200b\u3002</p> <p>\u200b\u5b50\u8bcd\u200b\u5206\u8bcd\u200b\u5141\u8bb8\u200b\u6a21\u578b\u200b\u6709\u200b\u4e00\u4e2a\u200b\u5408\u7406\u200b\u7684\u200b\u8bcd\u5178\u200b\u5927\u5c0f\u200b\uff0c\u200b\u800c\u4e14\u200b\u80fd\u200b\u5b66\u5230\u200b\u6709\u200b\u610f\u4e49\u200b\u7684\u200b\u4e0a\u4e0b\u6587\u200b\u72ec\u7acb\u200b\u5730\u200b\u8868\u8fbe\u200b\u3002\u200b\u9664\u6b64\u4ee5\u5916\u200b\uff0c\u200b\u5b50\u8bcd\u200b\u5206\u8bcd\u200b\u53ef\u4ee5\u200b\u8ba9\u200b\u6a21\u578b\u200b\u5904\u7406\u200b\u4ee5\u524d\u200b\u4ece\u6765\u200b\u6ca1\u89c1\u200b\u8fc7\u200b\u7684\u200b\u5355\u8bcd\u200b\uff0c \u200b\u65b9\u5f0f\u200b\u662f\u200b\u901a\u8fc7\u200b\u5206\u89e3\u200b\u8fd9\u4e9b\u200b\u5355\u8bcd\u200b\u5230\u200b\u5df2\u77e5\u200b\u7684\u200b\u5b50\u200b\u8bcd\u200b\uff0c\u200b\u4e3e\u4e2a\u200b\u4f8b\u5b50\u200b\uff1a[<code>~transformers.BertTokenizer</code>]\u200b\u5bf9\u200b\u53e5\u5b50\u200b<code>\"I have a new GPU!\"</code>\u200b\u5206\u8bcd\u200b\u7684\u200b\u7ed3\u679c\u200b\u5982\u4e0b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import BertTokenizer\n\n&gt;&gt;&gt; tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n&gt;&gt;&gt; tokenizer.tokenize(\"I have a new GPU!\")\n[\"i\", \"have\", \"a\", \"new\", \"gp\", \"##u\", \"!\"]\n</code></pre> <p>\u200b\u56e0\u4e3a\u200b\u6211\u4eec\u200b\u6b63\u5728\u200b\u8003\u8651\u200b\u4e0d\u200b\u533a\u5206\u200b\u5927\u5c0f\u5199\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u53e5\u5b50\u200b\u9996\u5148\u200b\u88ab\u200b\u8f6c\u6362\u6210\u200b\u5c0f\u5199\u5b57\u6bcd\u200b\u5f62\u5f0f\u200b\u3002\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u89c1\u5230\u200b\u5355\u8bcd\u200b<code>[\"i\", \"have\", \"a\", \"new\"]</code>\u200b\u5728\u200b\u5206\u8bcd\u5668\u200b \u200b\u7684\u200b\u8bcd\u5178\u200b\u5185\u200b\uff0c\u200b\u4f46\u662f\u200b\u8fd9\u4e2a\u200b\u5355\u8bcd\u200b<code>\"gpu\"</code>\u200b\u4e0d\u200b\u5728\u200b\u8bcd\u5178\u200b\u5185\u200b\u3002\u200b\u6240\u4ee5\u200b\uff0c\u200b\u5206\u8bcd\u5668\u200b\u5c06\u200b<code>\"gpu\"</code>\u200b\u5206\u5272\u200b\u6210\u200b\u5df2\u77e5\u200b\u7684\u200b\u5b50\u200b\u8bcd\u200b<code>[\"gp\" and \"##u\"]</code>\u3002<code>\"##\"</code>\u200b\u610f\u5473\u7740\u200b\u5269\u4e0b\u200b\u7684\u200b token\u200b\u5e94\u8be5\u200b\u9644\u7740\u200b\u5728\u200b\u524d\u9762\u200b\u90a3\u4e2a\u200btoken\u200b\u7684\u200b\u540e\u9762\u200b\uff0c\u200b\u4e0d\u5e26\u200b\u7a7a\u683c\u200b\u7684\u200b\u9644\u7740\u200b\uff08\u200b\u5206\u8bcd\u200b\u7684\u200b\u89e3\u7801\u200b\u6216\u8005\u200b\u53cd\u5411\u200b\uff09\u3002</p> <p>\u200b\u53e6\u5916\u200b\u4e00\u4e2a\u200b\u4f8b\u5b50\u200b\uff0c[<code>~transformers.XLNetTokenizer</code>]\u200b\u5bf9\u200b\u524d\u9762\u200b\u7684\u200b\u6587\u672c\u200b\u4f8b\u5b50\u200b\u5206\u8bcd\u200b\u7ed3\u679c\u200b\u5982\u4e0b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import XLNetTokenizer\n\n&gt;&gt;&gt; tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n&gt;&gt;&gt; tokenizer.tokenize(\"Don't you love \ud83e\udd17 Transformers? We sure do.\")\n[\"\u2581Don\", \"'\", \"t\", \"\u2581you\", \"\u2581love\", \"\u2581\", \"\ud83e\udd17\", \"\u2581\", \"Transform\", \"ers\", \"?\", \"\u2581We\", \"\u2581sure\", \"\u2581do\", \".\"]\n</code></pre> <p>\u200b\u5f53\u200b\u6211\u4eec\u200b\u67e5\u770b\u200bSentencePiece\u200b\u65f6\u4f1a\u200b\u56de\u8fc7\u5934\u6765\u200b\u89e3\u91ca\u200b\u8fd9\u4e9b\u200b<code>\"\u2581\"</code>\u200b\u7b26\u53f7\u200b\u7684\u200b\u542b\u4e49\u200b\u3002\u200b\u6b63\u5982\u200b\u4f60\u200b\u80fd\u200b\u89c1\u5230\u200b\u7684\u200b\uff0c\u200b\u5f88\u5c11\u200b\u4f7f\u7528\u200b\u7684\u200b\u5355\u8bcd\u200b <code>\"Transformers\"</code>\u200b\u80fd\u200b\u88ab\u200b\u5206\u5272\u200b\u5230\u200b\u66f4\u52a0\u200b\u9891\u7e41\u200b\u4f7f\u7528\u200b\u7684\u200b\u5b50\u200b\u8bcd\u200b<code>\"Transform\"</code>\u200b\u548c\u200b<code>\"ers\"</code>\u3002</p> <p>\u200b\u73b0\u5728\u200b\u8ba9\u200b\u6211\u4eec\u200b\u6765\u200b\u770b\u770b\u200b\u4e0d\u540c\u200b\u7684\u200b\u5b50\u200b\u8bcd\u200b\u5206\u5272\u200b\u7b97\u6cd5\u200b\u662f\u200b\u600e\u4e48\u200b\u5de5\u4f5c\u200b\u7684\u200b\uff0c\u200b\u6ce8\u610f\u200b\u5230\u200b\u6240\u6709\u200b\u7684\u200b\u8fd9\u4e9b\u200b\u5206\u8bcd\u200b\u7b97\u6cd5\u200b\u4f9d\u8d56\u4e8e\u200b\u67d0\u4e9b\u200b\u8bad\u7ec3\u200b\u7684\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u8bad\u7ec3\u200b\u901a\u5e38\u200b\u5728\u200b\u8bed\u6599\u5e93\u200b\u4e0a\u200b\u5b8c\u6210\u200b\uff0c \u200b\u76f8\u5e94\u200b\u7684\u200b\u6a21\u578b\u200b\u4e5f\u200b\u662f\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u8bed\u6599\u5e93\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u7684\u200b\u3002</p> <p></p>"},{"location":"tokenizer_summary/#byte-pair-encoding-bpe","title":"Byte-Pair Encoding (BPE)","text":"<p>Byte-Pair Encoding (BPE)\u200b\u6765\u81ea\u200b\u4e8e\u200bNeural Machine Translation of Rare Words with Subword Units (Sennrich et al., 2015)\u3002BPE\u200b\u4f9d\u8d56\u4e8e\u200b\u4e00\u4e2a\u200b\u9884\u200b\u5206\u8bcd\u5668\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u9884\u200b\u5206\u8bcd\u5668\u200b\u4f1a\u200b\u5c06\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u5206\u5272\u200b\u6210\u200b\u5355\u8bcd\u200b\u3002\u200b\u9884\u5206\u200b\u8bcd\u200b\u53ef\u4ee5\u200b\u662f\u200b\u7b80\u5355\u200b\u7684\u200b \u200b\u7a7a\u683c\u200b\u5206\u8bcd\u200b\uff0c\u200b\u50cf\u200b\uff1a\uff1aGPT-2\uff0cRoBERTa\u3002\u200b\u66f4\u52a0\u200b\u5148\u8fdb\u200b\u7684\u200b\u9884\u5206\u200b\u8bcd\u200b\u65b9\u5f0f\u200b\u5305\u62ec\u200b\u4e86\u200b\u57fa\u4e8e\u200b\u89c4\u5219\u200b\u7684\u200b\u5206\u8bcd\u200b\uff0c\u200b\u50cf\u200b\uff1a XLM\uff0cFlauBERT\uff0cFlauBERT\u200b\u5728\u200b\u5927\u591a\u6570\u200b\u8bed\u8a00\u200b\u4f7f\u7528\u200b\u4e86\u200bMoses\uff0c\u200b\u6216\u8005\u200bGPT\uff0cGPT \u200b\u4f7f\u7528\u200b\u4e86\u200bSpacy\u200b\u548c\u200bftfy\uff0c\u200b\u7edf\u8ba1\u200b\u4e86\u200b\u8bad\u7ec3\u200b\u8bed\u6599\u5e93\u200b\u4e2d\u200b\u6bcf\u4e2a\u200b\u5355\u8bcd\u200b\u7684\u200b\u9891\u6b21\u200b\u3002</p> <p>\u200b\u5728\u200b\u9884\u5206\u200b\u8bcd\u200b\u4ee5\u540e\u200b\uff0c\u200b\u751f\u6210\u200b\u4e86\u200b\u5355\u8bcd\u200b\u7684\u200b\u96c6\u5408\u200b\uff0c\u200b\u4e5f\u200b\u786e\u5b9a\u200b\u4e86\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u4e2d\u200b\u6bcf\u4e2a\u200b\u5355\u8bcd\u200b\u51fa\u73b0\u200b\u7684\u200b\u9891\u6b21\u200b\u3002\u200b\u4e0b\u200b\u4e00\u6b65\u200b\uff0cBPE\u200b\u4ea7\u751f\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\uff0c\u200b\u5305\u542b\u200b\u4e86\u200b\u96c6\u5408\u200b\u4e2d\u200b\u6240\u6709\u200b\u7684\u200b\u7b26\u53f7\u200b\uff0c BPE\u200b\u5b66\u4e60\u200b\u878d\u5408\u200b\u7684\u200b\u89c4\u5219\u200b-\u200b\u7ec4\u5408\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\u4e2d\u200b\u7684\u200b\u4e24\u4e2a\u200b\u7b26\u53f7\u200b\u6765\u200b\u5f62\u6210\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b\u7b26\u53f7\u200b\u3002BPE\u200b\u4f1a\u200b\u4e00\u76f4\u200b\u5b66\u4e60\u200b\u76f4\u5230\u200b\u8bcd\u5178\u200b\u7684\u200b\u5927\u5c0f\u200b\u6ee1\u8db3\u200b\u4e86\u200b\u671f\u671b\u200b\u7684\u200b\u8bcd\u5178\u200b\u5927\u5c0f\u200b\u7684\u200b\u8981\u6c42\u200b\u3002\u200b\u6ce8\u610f\u200b\u5230\u200b \u200b\u671f\u671b\u200b\u7684\u200b\u8bcd\u5178\u200b\u5927\u5c0f\u200b\u662f\u200b\u4e00\u4e2a\u200b\u8d85\u200b\u53c2\u6570\u200b\uff0c\u200b\u5728\u200b\u8bad\u7ec3\u200b\u8fd9\u4e2a\u200b\u5206\u8bcd\u5668\u200b\u4ee5\u524d\u200b\u5c31\u200b\u9700\u8981\u200b\u4eba\u4e3a\u200b\u6307\u5b9a\u200b\u3002</p> <p>\u200b\u4e3e\u4e2a\u200b\u4f8b\u5b50\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5047\u8bbe\u200b\u5728\u200b\u9884\u5206\u200b\u8bcd\u200b\u4ee5\u540e\u200b\uff0c\u200b\u4e0b\u9762\u200b\u7684\u200b\u5355\u8bcd\u200b\u96c6\u5408\u200b\u4ee5\u53ca\u200b\u4ed6\u4eec\u200b\u7684\u200b\u9891\u6b21\u200b\u90fd\u200b\u5df2\u7ecf\u200b\u786e\u5b9a\u200b\u597d\u200b\u4e86\u200b\uff1a</p> <pre><code>(\"hug\", 10), (\"pug\", 5), (\"pun\", 12), (\"bun\", 4), (\"hugs\", 5)\n</code></pre> <p>\u200b\u6240\u4ee5\u200b\uff0c\u200b\u57fa\u7840\u200b\u7684\u200b\u8bcd\u5178\u200b\u662f\u200b<code>[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\"]</code>\u3002\u200b\u5c06\u200b\u6240\u6709\u200b\u5355\u8bcd\u200b\u5206\u5272\u200b\u6210\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\u5185\u200b\u7684\u200b\u7b26\u53f7\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u83b7\u5f97\u200b\uff1a</p> <p><pre><code>(\"h\" \"u\" \"g\", 10), (\"p\" \"u\" \"g\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"u\" \"g\" \"s\", 5)\n</code></pre> BPE\u200b\u63a5\u7740\u200b\u4f1a\u200b\u7edf\u8ba1\u200b\u6bcf\u4e2a\u200b\u53ef\u80fd\u200b\u7684\u200b\u7b26\u53f7\u200b\u5bf9\u200b\u7684\u200b\u9891\u6b21\u200b\uff0c\u200b\u7136\u540e\u200b\u6311\u51fa\u200b\u51fa\u73b0\u200b\u6700\u200b\u9891\u7e41\u200b\u7684\u200b\u7684\u200b\u7b26\u53f7\u200b\u5bf9\u200b\uff0c\u200b\u5728\u200b\u4e0a\u9762\u200b\u7684\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\uff0c<code>\"h\"</code>\u200b\u8ddf\u200b\u4e86\u200b<code>\"u\"</code>\u200b\u51fa\u73b0\u200b\u4e86\u200b10 + 5 = 15\u200b\u6b21\u200b \uff0810\u200b\u6b21\u200b\u662f\u200b\u51fa\u73b0\u200b\u4e86\u200b10\u200b\u6b21\u200b<code>\"hug\"</code>\uff0c5\u200b\u6b21\u200b\u662f\u200b\u51fa\u73b0\u200b\u4e86\u200b5\u200b\u6b21\u200b<code>\"hugs\"</code>\uff09\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u6700\u200b\u9891\u7e41\u200b\u7684\u200b\u7b26\u53f7\u200b\u5bf9\u200b\u662f\u200b<code>\"u\"</code>\u200b\u540e\u9762\u200b\u8ddf\u200b\u4e86\u200b\u4e2a\u200b<code>\"g\"</code>\uff0c\u200b\u603b\u5171\u200b\u51fa\u73b0\u200b\u4e86\u200b10 + 5 + 5 = 20\u200b\u6b21\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5206\u8bcd\u5668\u200b\u5b66\u5230\u200b\u7684\u200b\u7b2c\u4e00\u4e2a\u200b\u878d\u5408\u200b\u89c4\u5219\u200b\u662f\u200b\u7ec4\u5408\u200b\u6240\u6709\u200b\u7684\u200b<code>\"u\"</code>\u200b\u540e\u9762\u200b\u8ddf\u200b\u4e86\u200b\u4e2a\u200b<code>\"g\"</code>\u200b\u7b26\u53f7\u200b\u3002\u200b\u4e0b\u200b\u4e00\u6b65\u200b\uff0c<code>\"ug\"</code>\u200b\u88ab\u200b\u52a0\u5165\u200b\u5230\u200b\u4e86\u200b\u8bcd\u5178\u200b\u5185\u200b\u3002\u200b\u5355\u8bcd\u200b\u7684\u200b\u96c6\u5408\u200b \u200b\u5c31\u200b\u53d8\u6210\u200b\u4e86\u200b\uff1a</p> <pre><code>(\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"ug\" \"s\", 5)\n</code></pre> <p>BPE\u200b\u63a5\u7740\u200b\u4f1a\u200b\u7edf\u8ba1\u200b\u51fa\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u6700\u200b\u666e\u904d\u200b\u7684\u200b\u51fa\u73b0\u200b\u9891\u6b21\u200b\u6700\u5927\u200b\u7684\u200b\u7b26\u53f7\u200b\u5bf9\u200b\u3002\u200b\u4e5f\u200b\u5c31\u662f\u200b<code>\"u\"</code>\u200b\u540e\u9762\u200b\u8ddf\u200b\u4e86\u200b\u4e2a\u200b<code>\"n\"</code>\uff0c\u200b\u51fa\u73b0\u200b\u4e86\u200b16\u200b\u6b21\u200b\u3002<code>\"u\"</code>\uff0c<code>\"n\"</code>\u200b\u88ab\u200b\u878d\u5408\u200b\u6210\u200b\u4e86\u200b<code>\"un\"</code>\u3002 \u200b\u4e5f\u200b\u88ab\u200b\u52a0\u5165\u200b\u5230\u200b\u4e86\u200b\u8bcd\u5178\u200b\u4e2d\u200b\uff0c\u200b\u518d\u4e0b\u200b\u4e00\u4e2a\u200b\u51fa\u73b0\u200b\u9891\u6b21\u200b\u6700\u5927\u200b\u7684\u200b\u7b26\u53f7\u200b\u5bf9\u200b\u662f\u200b<code>\"h\"</code>\u200b\u540e\u9762\u200b\u8ddf\u200b\u4e86\u200b\u4e2a\u200b<code>\"ug\"</code>\uff0c\u200b\u51fa\u73b0\u200b\u4e86\u200b15\u200b\u6b21\u200b\u3002\u200b\u53c8\u200b\u4e00\u6b21\u200b\u8fd9\u4e2a\u200b\u7b26\u53f7\u200b\u5bf9\u200b\u88ab\u200b\u878d\u5408\u200b\u6210\u200b\u4e86\u200b<code>\"hug\"</code>\uff0c \u200b\u4e5f\u200b\u88ab\u200b\u52a0\u5165\u200b\u5230\u200b\u4e86\u200b\u8bcd\u5178\u200b\u4e2d\u200b\u3002</p> <p>\u200b\u5728\u200b\u5f53\u524d\u200b\u8fd9\u6b65\u200b\uff0c\u200b\u8bcd\u5178\u200b\u662f\u200b<code>[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"]</code>\uff0c\u200b\u6211\u4eec\u200b\u7684\u200b\u5355\u8bcd\u200b\u96c6\u5408\u200b\u5219\u200b\u662f\u200b\uff1a</p> <pre><code>(\"hug\", 10), (\"p\" \"ug\", 5), (\"p\" \"un\", 12), (\"b\" \"un\", 4), (\"hug\" \"s\", 5)\n</code></pre> <p>\u200b\u5047\u8bbe\u200b\uff0cthe Byte-Pair Encoding\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u65f6\u5019\u200b\u505c\u6b62\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u5b66\u5230\u200b\u7684\u200b\u878d\u5408\u200b\u89c4\u5219\u200b\u5e76\u200b\u5e94\u7528\u200b\u5230\u200b\u5176\u4ed6\u200b\u65b0\u200b\u7684\u200b\u5355\u8bcd\u200b\u4e0a\u200b\uff08\u200b\u53ea\u8981\u200b\u8fd9\u4e9b\u200b\u65b0\u200b\u5355\u8bcd\u200b\u4e0d\u200b\u5305\u62ec\u200b\u4e0d\u200b\u5728\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\u5185\u200b\u7684\u200b\u7b26\u53f7\u200b \u200b\u5c31\u884c\u200b\uff09\u3002\u200b\u4e3e\u4e2a\u200b\u4f8b\u5b50\u200b\uff0c\u200b\u5355\u8bcd\u200b<code>\"bug\"</code>\u200b\u4f1a\u200b\u88ab\u200b\u5206\u8bcd\u200b\u5230\u200b<code>[\"b\", \"ug\"]</code>\uff0c\u200b\u4f46\u662f\u200b<code>\"mug\"</code>\u200b\u4f1a\u200b\u88ab\u200b\u5206\u8bcd\u200b\u5230\u200b<code>[\"&lt;unk&gt;\", \"ug\"]</code>\uff0c\u200b\u56e0\u4e3a\u200b\u7b26\u53f7\u200b<code>\"m\"</code>\u200b\u4e0d\u200b\u5728\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\u5185\u200b\u3002 \u200b\u901a\u5e38\u200b\u6765\u770b\u200b\u7684\u8bdd\u200b\uff0c\u200b\u5355\u4e2a\u200b\u5b57\u6bcd\u200b\u50cf\u200b<code>\"m\"</code>\u200b\u4e0d\u4f1a\u200b\u88ab\u200b<code>\"&lt;unk&gt;\"</code>\u200b\u7b26\u53f7\u200b\u66ff\u6362\u200b\u6389\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u901a\u5e38\u200b\u5305\u62ec\u200b\u4e86\u200b\u6bcf\u4e2a\u200b\u5b57\u6bcd\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u5b57\u6bcd\u200b\u81f3\u5c11\u200b\u51fa\u73b0\u200b\u4e86\u200b\u4e00\u6b21\u200b\uff0c\u200b\u4f46\u662f\u200b\u5728\u200b\u7279\u6b8a\u200b\u7684\u200b\u7b26\u53f7\u200b \u200b\u4e2d\u200b\u4e5f\u200b\u53ef\u80fd\u200b\u53d1\u751f\u200b\u50cf\u200bemojis\u3002</p> <p>\u200b\u5c31\u200b\u50cf\u200b\u4e4b\u524d\u200b\u63d0\u5230\u200b\u7684\u200b\u90a3\u6837\u200b\uff0c\u200b\u8bcd\u5178\u200b\u7684\u200b\u5927\u5c0f\u200b\uff0c\u200b\u4e3e\u4e2a\u200b\u4f8b\u5b50\u200b\uff0c\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\u7684\u200b\u5927\u5c0f\u200b + \u200b\u878d\u5408\u200b\u7684\u200b\u6570\u91cf\u200b\uff0c\u200b\u662f\u200b\u4e00\u4e2a\u200b\u9700\u8981\u200b\u914d\u7f6e\u200b\u7684\u200b\u8d85\u200b\u53c2\u6570\u200b\u3002\u200b\u4e3e\u4e2a\u200b\u4f8b\u5b50\u200b\uff1aGPT \u200b\u7684\u200b\u8bcd\u5178\u200b\u5927\u5c0f\u200b\u662f\u200b40,478\uff0c\u200b\u56e0\u4e3a\u200bGPT\u200b\u6709\u7740\u200b478\u200b\u4e2a\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\u5185\u200b\u7684\u200b\u5b57\u7b26\u200b\uff0c\u200b\u5728\u200b40,000\u200b\u6b21\u200b\u878d\u5408\u200b\u4ee5\u540e\u200b\u9009\u62e9\u200b\u4e86\u200b\u505c\u6b62\u200b\u8bad\u7ec3\u200b\u3002</p>"},{"location":"tokenizer_summary/#byte-level-bpe","title":"Byte-level BPE","text":"<p>\u200b\u4e00\u4e2a\u200b\u5305\u542b\u200b\u4e86\u200b\u6240\u6709\u200b\u53ef\u80fd\u200b\u7684\u200b\u57fa\u7840\u200b\u5b57\u7b26\u200b\u7684\u200b\u57fa\u7840\u200b\u5b57\u5178\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u975e\u5e38\u200b\u5927\u200b\uff0c\u200b\u5982\u679c\u200b\u8003\u8651\u200b\u5c06\u200b\u6240\u6709\u200b\u7684\u200bunicode\u200b\u5b57\u7b26\u200b\u4f5c\u4e3a\u200b\u57fa\u7840\u200b\u5b57\u7b26\u200b\u3002\u200b\u4e3a\u4e86\u200b\u62e5\u6709\u200b\u4e00\u4e2a\u200b\u66f4\u597d\u200b\u7684\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\uff0cGPT-2\u200b\u4f7f\u7528\u200b\u4e86\u200b\u5b57\u8282\u200b \u200b\u4f5c\u4e3a\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\uff0c\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u975e\u5e38\u200b\u806a\u660e\u200b\u7684\u200b\u6280\u5de7\u200b\uff0c\u200b\u8feb\u4f7f\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\u662f\u200b256\u200b\u5927\u5c0f\u200b\uff0c\u200b\u800c\u4e14\u200b\u786e\u4fdd\u200b\u4e86\u200b\u6240\u6709\u200b\u57fa\u7840\u200b\u5b57\u7b26\u200b\u5305\u542b\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u8bcd\u5178\u200b\u5185\u200b\u3002\u200b\u4f7f\u7528\u200b\u4e86\u200b\u5176\u4ed6\u200b\u7684\u200b\u89c4\u5219\u200b \u200b\u6765\u200b\u5904\u7406\u200b\u6807\u70b9\u7b26\u53f7\u200b\uff0c\u200b\u8fd9\u4e2a\u200bGPT2\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\u80fd\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\uff0c\u200b\u4e0d\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u5230\u200b\u7b26\u53f7\u200b\u3002GPT-2\u200b\u6709\u200b\u4e00\u4e2a\u200b\u5927\u5c0f\u200b\u662f\u200b50,257 \u200b\u7684\u200b\u8bcd\u5178\u200b\uff0c\u200b\u5bf9\u5e94\u200b\u5230\u200b256\u200b\u5b57\u8282\u200b\u7684\u200b\u57fa\u7840\u200btokens\uff0c\u200b\u4e00\u4e2a\u200b\u7279\u6b8a\u200b\u7684\u200b\u6587\u672c\u200b\u7ed3\u675f\u200btoken\uff0c\u200b\u8fd9\u4e9b\u200b\u7b26\u53f7\u200b\u7ecf\u8fc7\u200b\u4e86\u200b50,000\u200b\u6b21\u200b\u878d\u5408\u200b\u5b66\u4e60\u200b\u3002 <p></p>"},{"location":"tokenizer_summary/#wordpiece","title":"WordPiece","text":"<p>WordPiece\u200b\u662f\u5b50\u200b\u8bcd\u200b\u5206\u8bcd\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u88ab\u200b\u7528\u200b\u5728\u200bBERT\uff0cDistilBERT\uff0c\u200b\u548c\u200bElectra\u3002 \u200b\u8fd9\u4e2a\u200b\u7b97\u6cd5\u200b\u53d1\u5e03\u200b\u5728\u200bJapanese and Korean Voice Search (Schuster et al., 2012) \u200b\u548c\u200bBPE\u200b\u975e\u5e38\u200b\u76f8\u4f3c\u200b\u3002WordPiece\u200b\u9996\u5148\u200b\u521d\u59cb\u5316\u200b\u4e00\u4e2a\u200b\u8bcd\u5178\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u8bcd\u5178\u200b\u5305\u542b\u200b\u4e86\u200b\u51fa\u73b0\u200b\u5728\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u4e2d\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u5b57\u7b26\u200b\uff0c\u200b\u7136\u540e\u200b\u9012\u8fdb\u200b\u7684\u200b\u5b66\u4e60\u200b\u4e00\u4e2a\u200b\u7ed9\u5b9a\u200b\u6570\u91cf\u200b\u7684\u200b\u878d\u5408\u200b\u89c4\u5219\u200b\u3002\u200b\u548c\u200bBPE\u200b\u76f8\u200b\u6bd4\u8f83\u200b\uff0c WordPiece\u200b\u4e0d\u4f1a\u200b\u9009\u62e9\u200b\u51fa\u73b0\u200b\u9891\u6b21\u200b\u6700\u5927\u200b\u7684\u200b\u7b26\u53f7\u200b\u5bf9\u200b\uff0c\u200b\u800c\u662f\u200b\u9009\u62e9\u200b\u4e86\u200b\u52a0\u5165\u200b\u5230\u200b\u5b57\u5178\u200b\u4ee5\u540e\u200b\u80fd\u200b\u6700\u5927\u5316\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u4f3c\u7136\u503c\u200b\u7684\u200b\u7b26\u53f7\u200b\u5bf9\u200b\u3002</p> <p>\u200b\u6240\u4ee5\u200b\u8fd9\u200b\u5230\u5e95\u200b\u610f\u5473\u7740\u200b\u4ec0\u4e48\u200b\uff1f\u200b\u53c2\u8003\u200b\u524d\u9762\u200b\u7684\u200b\u4f8b\u5b50\u200b\uff0c\u200b\u6700\u5927\u5316\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u7684\u200b\u4f3c\u7136\u503c\u200b\uff0c\u200b\u7b49\u4ef7\u200b\u4e8e\u200b\u627e\u5230\u200b\u4e00\u4e2a\u200b\u7b26\u53f7\u200b\u5bf9\u200b\uff0c\u200b\u5b83\u4eec\u200b\u7684\u200b\u6982\u7387\u200b\u9664\u4ee5\u200b\u8fd9\u4e2a\u200b\u7b26\u53f7\u200b\u5bf9\u200b\u4e2d\u200b\u7b2c\u4e00\u4e2a\u200b\u7b26\u53f7\u200b\u7684\u200b\u6982\u7387\u200b\uff0c \u200b\u63a5\u7740\u200b\u9664\u4ee5\u200b\u7b2c\u4e8c\u4e2a\u200b\u7b26\u53f7\u200b\u7684\u200b\u6982\u7387\u200b\uff0c\u200b\u5728\u200b\u6240\u6709\u200b\u7684\u200b\u7b26\u53f7\u200b\u5bf9\u200b\u4e2d\u5546\u200b\u6700\u5927\u200b\u3002\u200b\u50cf\u200b\uff1a\u200b\u5982\u679c\u200b<code>\"ug\"</code>\u200b\u7684\u200b\u6982\u7387\u200b\u9664\u4ee5\u200b<code>\"u\"</code>\u200b\u9664\u4ee5\u200b<code>\"g\"</code>\u200b\u7684\u200b\u6982\u7387\u200b\u7684\u200b\u5546\u200b\uff0c\u200b\u6bd4\u200b\u5176\u4ed6\u200b\u4efb\u4f55\u200b\u7b26\u53f7\u200b\u5bf9\u200b\u66f4\u200b\u5927\u200b\uff0c \u200b\u8fd9\u4e2a\u200b\u65f6\u5019\u200b\u624d\u80fd\u200b\u878d\u5408\u200b<code>\"u\"</code>\u200b\u548c\u200b<code>\"g\"</code>\u3002\u200b\u76f4\u89c9\u200b\u4e0a\u200b\uff0cWordPiece\uff0c\u200b\u548c\u200bBPE\u200b\u6709\u200b\u70b9\u70b9\u200b\u4e0d\u540c\u200b\uff0cWordPiece\u200b\u662f\u200b\u8bc4\u4f30\u200b\u878d\u5408\u200b\u4e24\u4e2a\u200b\u7b26\u53f7\u200b\u4f1a\u200b\u5931\u53bb\u200b\u7684\u200b\u91cf\u200b\uff0c\u200b\u6765\u200b\u786e\u4fdd\u200b\u8fd9\u4e48\u200b\u505a\u200b\u662f\u200b\u503c\u5f97\u200b\u7684\u200b\u3002</p> <p></p>"},{"location":"tokenizer_summary/#unigram","title":"Unigram","text":"<p>Unigram\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5b50\u8bcd\u200b\u5206\u8bcd\u5668\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u4ecb\u7ecd\u200b\u89c1\u200bSubword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates (Kudo, 2018)\u3002\u200b\u548c\u200bBPE\u200b\u6216\u8005\u200bWordPiece\u200b\u76f8\u200b\u6bd4\u8f83\u200b \uff0cUnigram\u200b\u4f7f\u7528\u200b\u5927\u91cf\u200b\u7684\u200b\u7b26\u53f7\u200b\u6765\u200b\u521d\u59cb\u5316\u200b\u5b83\u200b\u7684\u200b\u57fa\u7840\u200b\u5b57\u5178\u200b\uff0c\u200b\u7136\u540e\u200b\u9010\u6e10\u200b\u7684\u200b\u7cbe\u7b80\u200b\u6bcf\u4e2a\u200b\u7b26\u53f7\u200b\u6765\u200b\u83b7\u5f97\u200b\u4e00\u4e2a\u200b\u66f4\u200b\u5c0f\u200b\u7684\u200b\u8bcd\u5178\u200b\u3002\u200b\u4e3e\u4f8b\u200b\u6765\u770b\u200b\u57fa\u7840\u200b\u8bcd\u5178\u200b\u80fd\u591f\u200b\u5bf9\u5e94\u200b\u6240\u6709\u200b\u7684\u200b\u9884\u5206\u200b\u8bcd\u200b \u200b\u7684\u200b\u5355\u8bcd\u200b\u4ee5\u53ca\u200b\u6700\u200b\u5e38\u89c1\u200b\u7684\u200b\u5b50\u200b\u5b57\u7b26\u4e32\u200b\u3002Unigram\u200b\u6ca1\u6709\u200b\u76f4\u63a5\u200b\u7528\u200b\u5728\u200b\u4efb\u4f55\u200btransformers\u200b\u7684\u200b\u4efb\u4f55\u200b\u6a21\u578b\u200b\u4e2d\u200b\uff0c\u200b\u4f46\u662f\u200b\u548c\u200bSentencePiece\u200b\u4e00\u8d77\u200b\u8054\u5408\u200b\u4f7f\u7528\u200b\u3002</p> <p>\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6b65\u9aa4\u200b\uff0cUnigram\u200b\u7b97\u6cd5\u200b\u5728\u200b\u5f53\u524d\u200b\u8bcd\u5178\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u4e0a\u200b\u5b9a\u4e49\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\uff08\u200b\u7ecf\u5e38\u200b\u5b9a\u4e49\u200b\u4e3a\u200blog\u200b\u4f3c\u7136\u200b\u51fd\u6570\u200b\u7684\u200b\uff09\uff0c\u200b\u8fd8\u200b\u5b9a\u4e49\u200b\u4e86\u200b\u4e00\u4e2a\u200bunigram\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u3002 \u200b\u7136\u540e\u200b\uff0c\u200b\u5bf9\u200b\u8bcd\u5178\u200b\u5185\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u7b26\u53f7\u200b\uff0c\u200b\u7b97\u6cd5\u200b\u4f1a\u200b\u8ba1\u7b97\u200b\u5982\u679c\u200b\u8fd9\u4e2a\u200b\u7b26\u53f7\u200b\u4ece\u200b\u8bcd\u5178\u200b\u5185\u200b\u79fb\u9664\u200b\uff0c\u200b\u603b\u200b\u7684\u200b\u635f\u5931\u200b\u4f1a\u200b\u5347\u9ad8\u200b\u591a\u5c11\u200b\u3002Unigram\u200b\u7136\u540e\u200b\u4f1a\u200b\u79fb\u9664\u200b\u767e\u5206\u4e4b\u200bp\u200b\u7684\u200b\u7b26\u53f7\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u7b26\u53f7\u200b\u7684\u200bloss \u200b\u5347\u9ad8\u200b\u662f\u200b\u6700\u4f4e\u200b\u7684\u200b\uff08p\u200b\u901a\u5e38\u200b\u662f\u200b10%\u200b\u6216\u8005\u200b20%\uff09\uff0c\u200b\u50cf\u200b\uff1a\u200b\u8fd9\u4e9b\u200b\u5728\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u4e0a\u200b\u5bf9\u200b\u603b\u200b\u7684\u200b\u635f\u5931\u200b\u5f71\u54cd\u200b\u6700\u5c0f\u200b\u7684\u200b\u7b26\u53f7\u200b\u3002\u200b\u91cd\u590d\u200b\u8fd9\u4e2a\u200b\u8fc7\u7a0b\u200b\uff0c\u200b\u76f4\u5230\u200b\u8bcd\u5178\u200b\u5df2\u7ecf\u200b\u8fbe\u5230\u200b\u4e86\u200b\u671f\u671b\u200b\u7684\u200b\u5927\u5c0f\u200b\u3002 \u200b\u4e3a\u4e86\u200b\u4efb\u4f55\u200b\u5355\u8bcd\u200b\u90fd\u200b\u80fd\u200b\u88ab\u200b\u5206\u8bcd\u200b\uff0cUnigram\u200b\u7b97\u6cd5\u200b\u603b\u662f\u200b\u4fdd\u7559\u200b\u57fa\u7840\u200b\u7684\u200b\u5b57\u7b26\u200b\u3002</p> <p>\u200b\u56e0\u4e3a\u200bUnigram\u200b\u4e0d\u662f\u200b\u57fa\u4e8e\u200b\u878d\u5408\u200b\u89c4\u5219\u200b\uff08\u200b\u548c\u200bBPE\u200b\u4ee5\u53ca\u200bWordPiece\u200b\u76f8\u200b\u6bd4\u8f83\u200b\uff09\uff0c\u200b\u5728\u200b\u8bad\u7ec3\u200b\u4ee5\u540e\u200b\u7b97\u6cd5\u200b\u6709\u200b\u51e0\u79cd\u200b\u65b9\u5f0f\u200b\u6765\u200b\u5206\u8bcd\u200b\uff0c\u200b\u5982\u679c\u200b\u4e00\u4e2a\u200b\u8bad\u7ec3\u200b\u597d\u200b\u7684\u200bUnigram\u200b\u5206\u8bcd\u5668\u200b \u200b\u7684\u200b\u8bcd\u5178\u200b\u662f\u200b\u8fd9\u4e2a\u200b\uff1a</p> <p><pre><code>[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"],\n</code></pre> <code>\"hugs\"</code>\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u5206\u8bcd\u200b\u6210\u200b<code>[\"hug\", \"s\"]</code>, <code>[\"h\", \"ug\", \"s\"]</code>\u200b\u6216\u8005\u200b<code>[\"h\", \"u\", \"g\", \"s\"]</code>\u3002\u200b\u6240\u4ee5\u200b\u9009\u62e9\u200b\u54ea\u200b\u4e00\u4e2a\u200b\u5462\u200b\uff1fUnigram\u200b\u5728\u200b\u4fdd\u5b58\u200b \u200b\u8bcd\u5178\u200b\u7684\u200b\u65f6\u5019\u200b\u8fd8\u4f1a\u200b\u4fdd\u5b58\u200b\u8bad\u7ec3\u200b\u8bed\u6599\u5e93\u200b\u5185\u200b\u6bcf\u4e2a\u200btoken\u200b\u7684\u200b\u6982\u7387\u200b\uff0c\u200b\u6240\u4ee5\u200b\u5728\u200b\u8bad\u7ec3\u200b\u4ee5\u540e\u200b\u53ef\u4ee5\u200b\u8ba1\u7b97\u200b\u6bcf\u4e2a\u200b\u53ef\u80fd\u200b\u7684\u200b\u5206\u8bcd\u200b\u7ed3\u679c\u200b\u7684\u200b\u6982\u7387\u200b\u3002\u200b\u5b9e\u9645\u4e0a\u200b\u7b97\u6cd5\u200b\u7b80\u5355\u200b\u7684\u200b\u9009\u62e9\u200b\u6982\u7387\u200b \u200b\u6700\u5927\u200b\u7684\u200b\u90a3\u4e2a\u200b\u5206\u8bcd\u200b\u7ed3\u679c\u200b\uff0c\u200b\u4f46\u662f\u200b\u4e5f\u200b\u4f1a\u200b\u63d0\u4f9b\u200b\u6982\u7387\u200b\u6765\u200b\u6839\u636e\u200b\u5206\u8bcd\u200b\u7ed3\u679c\u200b\u7684\u200b\u6982\u7387\u200b\u6765\u200b\u91c7\u6837\u200b\u4e00\u4e2a\u200b\u53ef\u80fd\u200b\u7684\u200b\u5206\u8bcd\u200b\u7ed3\u679c\u200b\u3002</p> <p>\u200b\u5206\u8bcd\u5668\u200b\u5728\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u5b9a\u4e49\u200b\u4e86\u200b\u8fd9\u4e9b\u200b\u6982\u7387\u200b\u3002\u200b\u5047\u8bbe\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u5305\u542b\u200b\u4e86\u200b\u8fd9\u4e9b\u200b\u5355\u8bcd\u200b \\(x_{1}\\), \\(\\dots\\), \\(x_{N}\\)\uff0c\u200b\u4e00\u4e2a\u200b\u5355\u8bcd\u200b\\(x_{i}\\) \u200b\u7684\u200b\u6240\u6709\u200b\u53ef\u80fd\u200b\u7684\u200b\u5206\u8bcd\u200b\u7ed3\u679c\u200b\u7684\u200b\u96c6\u5408\u200b\u5b9a\u4e49\u200b\u4e3a\u200b\\(S(x_{i})\\)\uff0c\u200b\u7136\u540e\u200b\u603b\u200b\u7684\u200b\u635f\u5931\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u5b9a\u4e49\u200b\u4e3a\u200b\uff1a</p> \\[\\mathcal{L} = -\\sum_{i=1}^{N} \\log \\left ( \\sum_{x \\in S(x_{i})} p(x) \\right )\\] <p></p>"},{"location":"tokenizer_summary/#sentencepiece","title":"SentencePiece","text":"<p>\u200b\u76ee\u524d\u4e3a\u6b62\u200b\u63cf\u8ff0\u200b\u7684\u200b\u6240\u6709\u200b\u5206\u8bcd\u200b\u7b97\u6cd5\u200b\u90fd\u200b\u6709\u200b\u76f8\u540c\u200b\u7684\u200b\u95ee\u9898\u200b\uff1a\u200b\u5b83\u4eec\u200b\u90fd\u200b\u5047\u8bbe\u200b\u8f93\u5165\u200b\u7684\u200b\u6587\u672c\u200b\u4f7f\u7528\u200b\u7a7a\u683c\u200b\u6765\u200b\u5206\u5f00\u200b\u5355\u8bcd\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u4e0d\u662f\u200b\u6240\u6709\u200b\u7684\u200b\u8bed\u8a00\u200b\u90fd\u200b\u4f7f\u7528\u200b\u7a7a\u683c\u200b\u6765\u200b\u5206\u5f00\u200b\u5355\u8bcd\u200b\u3002 \u200b\u4e00\u4e2a\u200b\u53ef\u80fd\u200b\u7684\u200b\u89e3\u51b3\u65b9\u6848\u200b\u662f\u200b\u4f7f\u7528\u200b\u67d0\u79cd\u200b\u8bed\u8a00\u200b\u7279\u5b9a\u200b\u7684\u200b\u9884\u200b\u5206\u8bcd\u5668\u200b\u3002\u200b\u50cf\u200b\uff1aXLM\u200b\u4f7f\u7528\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u7279\u5b9a\u200b\u7684\u200b\u4e2d\u6587\u200b\u3001\u200b\u65e5\u8bed\u200b\u548c\u200bThai\u200b\u7684\u200b\u9884\u200b\u5206\u8bcd\u5668\u200b\u3002 \u200b\u4e3a\u4e86\u200b\u66f4\u52a0\u200b\u5e7f\u6cdb\u200b\u7684\u200b\u89e3\u51b3\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\uff0cSentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing (Kudo et al., 2018) \u200b\u5c06\u200b\u8f93\u5165\u200b\u6587\u672c\u200b\u770b\u4f5c\u200b\u4e00\u4e2a\u200b\u539f\u59cb\u200b\u7684\u200b\u8f93\u5165\u200b\u6d41\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4f7f\u7528\u200b\u7684\u200b\u7b26\u5408\u200b\u96c6\u5408\u200b\u4e2d\u200b\u4e5f\u200b\u5305\u62ec\u200b\u4e86\u200b\u7a7a\u683c\u200b\u3002SentencePiece\u200b\u7136\u540e\u200b\u4f1a\u200b\u4f7f\u7528\u200bBPE\u200b\u6216\u8005\u200bunigram\u200b\u7b97\u6cd5\u200b\u6765\u200b\u4ea7\u751f\u200b\u5408\u9002\u200b\u7684\u200b \u200b\u8bcd\u5178\u200b\u3002</p> <p>\u200b\u4e3e\u4f8b\u6765\u8bf4\u200b\uff0c[<code>XLNetTokenizer</code>]\u200b\u4f7f\u7528\u200b\u4e86\u200bSentencePiece\uff0c\u200b\u8fd9\u200b\u4e5f\u200b\u662f\u200b\u4e3a\u4ec0\u4e48\u200b\u4e0a\u9762\u200b\u7684\u200b\u4f8b\u5b50\u200b\u4e2d\u200b<code>\"\u2581\"</code>\u200b\u7b26\u53f7\u200b\u5305\u542b\u200b\u5728\u200b\u8bcd\u5178\u200b\u5185\u200b\u3002SentencePiece\u200b\u89e3\u7801\u200b\u662f\u200b\u975e\u5e38\u5bb9\u6613\u200b\u7684\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6240\u6709\u200b\u7684\u200btokens\u200b\u80fd\u200b\u88ab\u200bconcatenate\u200b\u8d77\u6765\u200b\uff0c\u200b\u7136\u540e\u200b\u5c06\u200b<code>\"\u2581\"</code>\u200b\u66ff\u6362\u6210\u200b\u7a7a\u683c\u200b\u3002</p> <p>\u200b\u5e93\u5185\u200b\u6240\u6709\u200b\u4f7f\u7528\u200b\u4e86\u200bSentencePiece\u200b\u7684\u200btransformers\u200b\u6a21\u578b\u200b\uff0c\u200b\u4f1a\u200b\u548c\u200bunigram\u200b\u7ec4\u5408\u200b\u8d77\u6765\u200b\u4f7f\u7528\u200b\uff0c\u200b\u50cf\u200b\uff1a\u200b\u4f7f\u7528\u200b\u4e86\u200bSentencePiece\u200b\u7684\u200b\u6a21\u578b\u200b\u662f\u200bALBERT,  XLNet\uff0cMarian\uff0c\u200b\u548c\u200bT5\u3002</p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/","title":"Index","text":""},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/#transformers","title":"\ud83e\udd17 Transformers\u200b\u7b80\u4ecb","text":"<p>\u200b\u4e3a\u200b PyTorch\u3001TensorFlow \u200b\u548c\u200b JAX \u200b\u6253\u9020\u200b\u7684\u200b\u5148\u8fdb\u200b\u7684\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u5de5\u5177\u200b.</p> <p>\ud83e\udd17 Transformers \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u5730\u200b\u4e0b\u8f7d\u200b\u5e76\u4e14\u200b\u8bad\u7ec3\u200b\u5148\u8fdb\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b API \u200b\u548c\u200b\u5de5\u5177\u200b\u3002\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u53ef\u4ee5\u200b\u51cf\u5c11\u200b\u8ba1\u7b97\u200b\u6d88\u8017\u200b\u548c\u200b\u78b3\u200b\u6392\u653e\u200b\uff0c\u200b\u5e76\u4e14\u200b\u8282\u7701\u200b\u4ece\u5934\u200b\u8bad\u7ec3\u200b\u6240\u200b\u9700\u8981\u200b\u7684\u200b\u65f6\u95f4\u200b\u548c\u200b\u8d44\u6e90\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u6a21\u578b\u200b\u652f\u6301\u200b\u4e0d\u540c\u200b\u6a21\u6001\u200b\u4e2d\u200b\u7684\u200b\u5e38\u89c1\u200b\u4efb\u52a1\u200b\uff0c\u200b\u6bd4\u5982\u200b\uff1a</p> <p>\ud83d\udcdd \u200b\u81ea\u7136\u8bed\u8a00\u200b\u5904\u7406\u200b\uff1a\u200b\u6587\u672c\u200b\u5206\u7c7b\u200b\u3001\u200b\u547d\u540d\u200b\u5b9e\u4f53\u200b\u8bc6\u522b\u200b\u3001\u200b\u95ee\u7b54\u200b\u3001\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\u3001\u200b\u6458\u8981\u200b\u3001\u200b\u7ffb\u8bd1\u200b\u3001\u200b\u591a\u9879\u200b\u9009\u62e9\u200b\u548c\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u3002 \ud83d\uddbc\ufe0f \u200b\u673a\u5668\u200b\u89c6\u89c9\u200b\uff1a\u200b\u56fe\u50cf\u200b\u5206\u7c7b\u200b\u3001\u200b\u76ee\u6807\u200b\u68c0\u6d4b\u200b\u548c\u200b\u8bed\u4e49\u200b\u5206\u5272\u200b\u3002 \ud83d\udde3\ufe0f \u200b\u97f3\u9891\u200b\uff1a\u200b\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b\u548c\u200b\u97f3\u9891\u200b\u5206\u7c7b\u200b\u3002 \ud83d\udc19 \u200b\u591a\u200b\u6a21\u6001\u200b\uff1a\u200b\u8868\u683c\u200b\u95ee\u7b54\u200b\u3001\u200b\u5149\u5b66\u200b\u5b57\u7b26\u8bc6\u522b\u200b\u3001\u200b\u4ece\u200b\u626b\u63cf\u200b\u6587\u6863\u200b\u63d0\u53d6\u200b\u4fe1\u606f\u200b\u3001\u200b\u89c6\u9891\u5206\u7c7b\u200b\u548c\u200b\u89c6\u89c9\u200b\u95ee\u7b54\u200b\u3002</p> <p>\ud83e\udd17 Transformers \u200b\u652f\u6301\u200b\u5728\u200b PyTorch\u3001TensorFlow \u200b\u548c\u200b JAX \u200b\u4e0a\u200b\u7684\u200b\u4e92\u64cd\u4f5c\u6027\u200b. \u200b\u8fd9\u200b\u7ed9\u200b\u5728\u200b\u6a21\u578b\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u9636\u6bb5\u200b\u4f7f\u7528\u200b\u4e0d\u540c\u200b\u7684\u200b\u6846\u67b6\u200b\u5e26\u6765\u200b\u4e86\u200b\u7075\u6d3b\u6027\u200b\uff1b\u200b\u5728\u200b\u4e00\u4e2a\u200b\u6846\u67b6\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u51e0\u884c\u200b\u4ee3\u7801\u200b\u8bad\u7ec3\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\uff0c\u200b\u7136\u540e\u200b\u5728\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u6846\u67b6\u200b\u4e2d\u200b\u52a0\u8f7d\u200b\u5b83\u200b\u5e76\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\u3002\u200b\u6a21\u578b\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX \u200b\u548c\u200b TorchScript \u200b\u683c\u5f0f\u200b\uff0c\u200b\u7528\u4e8e\u200b\u5728\u200b\u751f\u4ea7\u200b\u73af\u5883\u200b\u4e2d\u200b\u90e8\u7f72\u200b\u3002</p> <p>\u200b\u9a6c\u4e0a\u200b\u52a0\u5165\u200b\u5728\u200b Hub\u3001\u200b\u8bba\u575b\u200b \u200b\u6216\u8005\u200b Discord \u200b\u4e0a\u200b\u6b63\u5728\u200b\u5feb\u901f\u200b\u53d1\u5c55\u200b\u7684\u200b\u793e\u533a\u200b\u5427\u200b\uff01</p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/#hugging-face","title":"\u5982\u679c\u200b\u4f60\u200b\u9700\u8981\u200b\u6765\u81ea\u200b Hugging Face \u200b\u56e2\u961f\u200b\u7684\u200b\u4e2a\u6027\u5316\u200b\u652f\u6301","text":""},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/#_1","title":"\u76ee\u5f55","text":"<p>\u200b\u8fd9\u7bc7\u200b\u6587\u6863\u200b\u88ab\u200b\u7ec4\u7ec7\u200b\u4e3a\u200b\u4ee5\u4e0b\u200b5\u200b\u4e2a\u200b\u7ae0\u8282\u200b:</p> <ul> <li>\u200b\u5f00\u59cb\u200b\u4f7f\u7528\u200b \u200b\u5305\u542b\u200b\u4e86\u200b\u5e93\u200b\u7684\u200b\u5feb\u901f\u200b\u4e0a\u624b\u200b\u548c\u200b\u5b89\u88c5\u200b\u8bf4\u660e\u200b\uff0c\u200b\u4fbf\u4e8e\u200b\u914d\u7f6e\u200b\u548c\u200b\u8fd0\u884c\u200b\u3002</li> <li>\u200b\u6559\u7a0b\u200b \u200b\u662f\u200b\u4e00\u4e2a\u200b\u521d\u5b66\u8005\u200b\u5f00\u59cb\u200b\u7684\u200b\u597d\u200b\u5730\u65b9\u200b\u3002\u200b\u672c\u200b\u7ae0\u8282\u200b\u5c06\u200b\u5e2e\u52a9\u200b\u4f60\u200b\u83b7\u5f97\u200b\u4f60\u200b\u4f1a\u200b\u7528\u5230\u200b\u7684\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200b\u5e93\u200b\u7684\u200b\u57fa\u672c\u6280\u80fd\u200b\u3002</li> <li>\u200b\u64cd\u4f5c\u200b\u6307\u5357\u200b \u200b\u5411\u200b\u4f60\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\u5b9e\u73b0\u200b\u4e00\u4e2a\u200b\u7279\u5b9a\u200b\u76ee\u6807\u200b\uff0c\u200b\u6bd4\u5982\u200b\u4e3a\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\u5fae\u8c03\u200b\u4e00\u4e2a\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u6216\u8005\u200b\u5982\u4f55\u200b\u521b\u9020\u200b\u5e76\u200b\u5206\u4eab\u200b\u4e2a\u6027\u5316\u200b\u6a21\u578b\u200b\u3002</li> <li>\u200b\u6982\u5ff5\u200b\u6307\u5357\u200b \u200b\u5bf9\u200b \ud83e\udd17 Transformers \u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u4efb\u52a1\u200b\u548c\u200b\u8bbe\u8ba1\u200b\u7406\u5ff5\u200b\u80cc\u540e\u200b\u7684\u200b\u57fa\u672c\u6982\u5ff5\u200b\u548c\u200b\u601d\u60f3\u200b\u505a\u200b\u4e86\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u8ba8\u8bba\u200b\u548c\u200b\u89e3\u91ca\u200b\u3002</li> <li> <p>API \u200b\u4ecb\u7ecd\u200b \u200b\u63cf\u8ff0\u200b\u4e86\u200b\u6240\u6709\u200b\u7684\u200b\u7c7b\u200b\u548c\u200b\u51fd\u6570\u200b\uff1a</p> </li> <li> <p>MAIN CLASSES \u200b\u8be6\u8ff0\u200b\u4e86\u200b\u914d\u7f6e\u200b\uff08configuration\uff09\u3001\u200b\u6a21\u578b\u200b\uff08model\uff09\u3001\u200b\u5206\u8bcd\u5668\u200b\uff08tokenizer\uff09\u200b\u548c\u200b\u6d41\u6c34\u7ebf\u200b\uff08pipeline\uff09\u200b\u8fd9\u200b\u51e0\u4e2a\u200b\u6700\u200b\u91cd\u8981\u200b\u7684\u200b\u7c7b\u200b\u3002</p> </li> <li>MODELS \u200b\u8be6\u8ff0\u200b\u4e86\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u5e93\u4e2d\u200b\u548c\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u5b9e\u73b0\u200b\u6709\u5173\u200b\u7684\u200b\u7c7b\u200b\u548c\u200b\u51fd\u6570\u200b\u3002</li> <li>INTERNAL HELPERS \u200b\u8be6\u8ff0\u200b\u4e86\u200b\u5185\u90e8\u200b\u4f7f\u7528\u200b\u7684\u200b\u5de5\u5177\u200b\u7c7b\u200b\u548c\u200b\u51fd\u6570\u200b\u3002</li> </ul>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/#_2","title":"\u652f\u6301\u200b\u7684\u200b\u6a21\u578b","text":"<ol> <li>ALBERT (from Google Research and the Toyota Technological Institute at Chicago) released with the paper ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut.</li> <li>AltCLIP (from BAAI) released with the paper AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities by Chen, Zhongzhi and Liu, Guang and Zhang, Bo-Wen and Ye, Fulong and Yang, Qinghong and Wu, Ledell.</li> <li>Audio Spectrogram Transformer (from MIT) released with the paper AST: Audio Spectrogram Transformer by Yuan Gong, Yu-An Chung, James Glass.</li> <li>BART (from Facebook) released with the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov and Luke Zettlemoyer.</li> <li>BARThez (from \u00c9cole polytechnique) released with the paper BARThez: a Skilled Pretrained French Sequence-to-Sequence Model by Moussa Kamal Eddine, Antoine J.-P. Tixier, Michalis Vazirgiannis.</li> <li>BARTpho (from VinAI Research) released with the paper BARTpho: Pre-trained Sequence-to-Sequence Models for Vietnamese by Nguyen Luong Tran, Duong Minh Le and Dat Quoc Nguyen.</li> <li>BEiT (from Microsoft) released with the paper BEiT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong, Furu Wei.</li> <li>BERT (from Google) released with the paper BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding by Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova.</li> <li>BERT For Sequence Generation (from Google) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.</li> <li>BERTweet (from VinAI Research) released with the paper BERTweet: A pre-trained language model for English Tweets by Dat Quoc Nguyen, Thanh Vu and Anh Tuan Nguyen.</li> <li>BigBird-Pegasus (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.</li> <li>BigBird-RoBERTa (from Google Research) released with the paper Big Bird: Transformers for Longer Sequences by Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.</li> <li>BioGpt (from Microsoft Research AI4Science) released with the paper BioGPT: generative pre-trained transformer for biomedical text generation and mining by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.</li> <li>BiT (from Google AI) released with the paper Big Transfer (BiT): General Visual Representation Learning by Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby.</li> <li>Blenderbot (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.</li> <li>BlenderbotSmall (from Facebook) released with the paper Recipes for building an open-domain chatbot by Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Kurt Shuster, Eric M. Smith, Y-Lan Boureau, Jason Weston.</li> <li>BLIP (from Salesforce) released with the paper BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation by Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi.</li> <li>BLOOM (from BigScience workshop) released by the BigScience Workshop.</li> <li>BORT (from Alexa) released with the paper Optimal Subarchitecture Extraction For BERT by Adrian de Wynter and Daniel J. Perry.</li> <li>ByT5 (from Google Research) released with the paper ByT5: Towards a token-free future with pre-trained byte-to-byte models by Linting Xue, Aditya Barua, Noah Constant, Rami Al-Rfou, Sharan Narang, Mihir Kale, Adam Roberts, Colin Raffel.</li> <li>CamemBERT (from Inria/Facebook/Sorbonne) released with the paper CamemBERT: a Tasty French Language Model by Louis Martin, Benjamin Muller, Pedro Javier Ortiz Su\u00e1rez*, Yoann Dupont, Laurent Romary, \u00c9ric Villemonte de la Clergerie, Djam\u00e9 Seddah and Beno\u00eet Sagot.</li> <li>CANINE (from Google Research) released with the paper CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation by Jonathan H. Clark, Dan Garrette, Iulia Turc, John Wieting.</li> <li>Chinese-CLIP (from OFA-Sys) released with the paper Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese by An Yang, Junshu Pan, Junyang Lin, Rui Men, Yichang Zhang, Jingren Zhou, Chang Zhou.</li> <li>CLIP (from OpenAI) released with the paper Learning Transferable Visual Models From Natural Language Supervision by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.</li> <li>CLIPSeg (from University of G\u00f6ttingen) released with the paper Image Segmentation Using Text and Image Prompts by Timo L\u00fcddecke and Alexander Ecker.</li> <li>CodeGen (from Salesforce) released with the paper A Conversational Paradigm for Program Synthesis by Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, Caiming Xiong.</li> <li>Conditional DETR (from Microsoft Research Asia) released with the paper Conditional DETR for Fast Training Convergence by Depu Meng, Xiaokang Chen, Zejia Fan, Gang Zeng, Houqiang Li, Yuhui Yuan, Lei Sun, Jingdong Wang.</li> <li>ConvBERT (from YituTech) released with the paper ConvBERT: Improving BERT with Span-based Dynamic Convolution by Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan.</li> <li>ConvNeXT (from Facebook AI) released with the paper A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie.</li> <li>ConvNeXTV2 (from Facebook AI) released with the paper ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders by Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, Saining Xie.</li> <li>CPM (from Tsinghua University) released with the paper CPM: A Large-scale Generative Chinese Pre-trained Language Model by Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun.</li> <li>CTRL (from Salesforce) released with the paper CTRL: A Conditional Transformer Language Model for Controllable Generation by Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong and Richard Socher.</li> <li>CvT (from Microsoft) released with the paper CvT: Introducing Convolutions to Vision Transformers by Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, Lei Zhang.</li> <li>Data2Vec (from Facebook) released with the paper Data2Vec:  A General Framework for Self-supervised Learning in Speech, Vision and Language by Alexei Baevski, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, Michael Auli.</li> <li>DeBERTa (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.</li> <li>DeBERTa-v2 (from Microsoft) released with the paper DeBERTa: Decoding-enhanced BERT with Disentangled Attention by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen.</li> <li>Decision Transformer (from Berkeley/Facebook/Google) released with the paper Decision Transformer: Reinforcement Learning via Sequence Modeling by Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch.</li> <li>Deformable DETR (from SenseTime Research) released with the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai.</li> <li>DeiT (from Facebook) released with the paper Training data-efficient image transformers &amp; distillation through attention by Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, Herv\u00e9 J\u00e9gou.</li> <li>DETR (from Facebook) released with the paper End-to-End Object Detection with Transformers by Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, Sergey Zagoruyko.</li> <li>DialoGPT (from Microsoft Research) released with the paper DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation by Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan.</li> <li>DiNAT (from SHI Labs) released with the paper Dilated Neighborhood Attention Transformer by Ali Hassani and Humphrey Shi.</li> <li>DistilBERT (from HuggingFace), released together with the paper DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter by Victor Sanh, Lysandre Debut and Thomas Wolf. The same method has been applied to compress GPT2 into DistilGPT2, RoBERTa into DistilRoBERTa, Multilingual BERT into DistilmBERT and a German version of DistilBERT.</li> <li>DiT (from Microsoft Research) released with the paper DiT: Self-supervised Pre-training for Document Image Transformer by Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.</li> <li>Donut (from NAVER), released together with the paper OCR-free Document Understanding Transformer by Geewook Kim, Teakgyu Hong, Moonbin Yim, Jeongyeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, Seunghyun Park.</li> <li>DPR (from Facebook) released with the paper Dense Passage Retrieval for Open-Domain Question Answering by Vladimir Karpukhin, Barlas O\u011fuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.</li> <li>DPT (from Intel Labs) released with the paper Vision Transformers for Dense Prediction by Ren\u00e9 Ranftl, Alexey Bochkovskiy, Vladlen Koltun.</li> <li>ELECTRA (from Google Research/Stanford University) released with the paper ELECTRA: Pre-training text encoders as discriminators rather than generators by Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning.</li> <li>EncoderDecoder (from Google Research) released with the paper Leveraging Pre-trained Checkpoints for Sequence Generation Tasks by Sascha Rothe, Shashi Narayan, Aliaksei Severyn.</li> <li>ERNIE (from Baidu) released with the paper ERNIE: Enhanced Representation through Knowledge Integration by Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, Hua Wu.</li> <li>ESM (from Meta AI) are transformer protein language models.  ESM-1b was released with the paper Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences by Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus. ESM-1v was released with the paper Language models enable zero-shot prediction of the effects of mutations on protein function by Joshua Meier, Roshan Rao, Robert Verkuil, Jason Liu, Tom Sercu and Alexander Rives. ESM-2 and ESMFold were released with the paper Language models of protein sequences at the scale of evolution enable accurate structure prediction by Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, Alexander Rives.</li> <li>FLAN-T5 (from Google AI) released in the repository google-research/t5x by Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei</li> <li>FlauBERT (from CNRS) released with the paper FlauBERT: Unsupervised Language Model Pre-training for French by Hang Le, Lo\u00efc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux, Benjamin Lecouteux, Alexandre Allauzen, Beno\u00eet Crabb\u00e9, Laurent Besacier, Didier Schwab.</li> <li>FLAVA (from Facebook AI) released with the paper FLAVA: A Foundational Language And Vision Alignment Model by Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech Galuba, Marcus Rohrbach, and Douwe Kiela.</li> <li>FNet (from Google Research) released with the paper FNet: Mixing Tokens with Fourier Transforms by James Lee-Thorp, Joshua Ainslie, Ilya Eckstein, Santiago Ontanon.</li> <li>Funnel Transformer (from CMU/Google Brain) released with the paper Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing by Zihang Dai, Guokun Lai, Yiming Yang, Quoc V. Le.</li> <li>GIT (from Microsoft Research) released with the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang.</li> <li>GLPN (from KAIST) released with the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Doyeon Kim, Woonghyun Ga, Pyungwhan Ahn, Donggyu Joo, Sehwan Chun, Junmo Kim.</li> <li>GPT (from OpenAI) released with the paper Improving Language Understanding by Generative Pre-Training by Alec Radford, Karthik Narasimhan, Tim Salimans and Ilya Sutskever.</li> <li>GPT Neo (from EleutherAI) released in the repository EleutherAI/gpt-neo by Sid Black, Stella Biderman, Leo Gao, Phil Wang and Connor Leahy.</li> <li>GPT NeoX (from EleutherAI) released with the paper GPT-NeoX-20B: An Open-Source Autoregressive Language Model by Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, USVSN Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach</li> <li>GPT NeoX Japanese (from ABEJA) released by Shinya Otani, Takayoshi Makabe, Anuj Arora, and Kyo Hattori.</li> <li>GPT-2 (from OpenAI) released with the paper Language Models are Unsupervised Multitask Learners by Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei and Ilya Sutskever.</li> <li>GPT-J (from EleutherAI) released in the repository kingoflolz/mesh-transformer-jax by Ben Wang and Aran Komatsuzaki.</li> <li>GPT-Sw3 (from AI-Sweden) released with the paper Lessons Learned from GPT-SW3: Building the First Large-Scale Generative Language Model for Swedish by Ariel Ekgren, Amaru Cuba Gyllensten, Evangelia Gogoulou, Alice Heiman, Severine Verlinden, Joey \u00d6hman, Fredrik Carlsson, Magnus Sahlgren.</li> <li>GroupViT (from UCSD, NVIDIA) released with the paper GroupViT: Semantic Segmentation Emerges from Text Supervision by Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, Xiaolong Wang.</li> <li>Hubert (from Facebook) released with the paper HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.</li> <li>I-BERT (from Berkeley) released with the paper I-BERT: Integer-only BERT Quantization by Sehoon Kim, Amir Gholami, Zhewei Yao, Michael W. Mahoney, Kurt Keutzer.</li> <li>ImageGPT (from OpenAI) released with the paper Generative Pretraining from Pixels by Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, Ilya Sutskever.</li> <li>Jukebox (from OpenAI) released with the paper Jukebox: A Generative Model for Music by Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever.</li> <li>LayoutLM (from Microsoft Research Asia) released with the paper LayoutLM: Pre-training of Text and Layout for Document Image Understanding by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou.</li> <li>LayoutLMv2 (from Microsoft Research Asia) released with the paper LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding by Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou.</li> <li>LayoutLMv3 (from Microsoft Research Asia) released with the paper LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking by Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei.</li> <li>LayoutXLM (from Microsoft Research Asia) released with the paper LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding by Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Furu Wei.</li> <li>LED (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.</li> <li>LeViT (from Meta AI) released with the paper LeViT: A Vision Transformer in ConvNet's Clothing for Faster Inference by Ben Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Herv\u00e9 J\u00e9gou, Matthijs Douze.</li> <li>LiLT (from South China University of Technology) released with the paper LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding by Jiapeng Wang, Lianwen Jin, Kai Ding.</li> <li>Longformer (from AllenAI) released with the paper Longformer: The Long-Document Transformer by Iz Beltagy, Matthew E. Peters, Arman Cohan.</li> <li>LongT5 (from Google AI) released with the paper LongT5: Efficient Text-To-Text Transformer for Long Sequences by Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, Yinfei Yang.</li> <li>LUKE (from Studio Ousia) released with the paper LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention by Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, Yuji Matsumoto.</li> <li>LXMERT (from UNC Chapel Hill) released with the paper LXMERT: Learning Cross-Modality Encoder Representations from Transformers for Open-Domain Question Answering by Hao Tan and Mohit Bansal.</li> <li>M-CTC-T (from Facebook) released with the paper Pseudo-Labeling For Massively Multilingual Speech Recognition by Loren Lugosch, Tatiana Likhomanenko, Gabriel Synnaeve, and Ronan Collobert.</li> <li>M2M100 (from Facebook) released with the paper Beyond English-Centric Multilingual Machine Translation by Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, Naman Goyal, Tom Birch, Vitaliy Liptchinsky, Sergey Edunov, Edouard Grave, Michael Auli, Armand Joulin.</li> <li>MarianMT Machine translation models trained using OPUS data by J\u00f6rg Tiedemann. The Marian Framework is being developed by the Microsoft Translator Team.</li> <li>MarkupLM (from Microsoft Research Asia) released with the paper MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding by Junlong Li, Yiheng Xu, Lei Cui, Furu Wei.</li> <li>Mask2Former (from FAIR and UIUC) released with the paper Masked-attention Mask Transformer for Universal Image Segmentation by Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexander Kirillov, Rohit Girdhar.</li> <li>MaskFormer (from Meta and UIUC) released with the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation by Bowen Cheng, Alexander G. Schwing, Alexander Kirillov.</li> <li>mBART (from Facebook) released with the paper Multilingual Denoising Pre-training for Neural Machine Translation by Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, Sergey Edunov, Marjan Ghazvininejad, Mike Lewis, Luke Zettlemoyer.</li> <li>mBART-50 (from Facebook) released with the paper Multilingual Translation with Extensible Multilingual Pretraining and Finetuning by Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan.</li> <li>Megatron-BERT (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.</li> <li>Megatron-GPT2 (from NVIDIA) released with the paper Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism by Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper and Bryan Catanzaro.</li> <li>mLUKE (from Studio Ousia) released with the paper mLUKE: The Power of Entity Representations in Multilingual Pretrained Language Models by Ryokan Ri, Ikuya Yamada, and Yoshimasa Tsuruoka.</li> <li>MobileBERT (from CMU/Google Brain) released with the paper MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices by Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, and Denny Zhou.</li> <li>MobileNetV1 (from Google Inc.) released with the paper MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam.</li> <li>MobileNetV2 (from Google Inc.) released with the paper MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen.</li> <li>MobileViT (from Apple) released with the paper MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer by Sachin Mehta and Mohammad Rastegari.</li> <li>MPNet (from Microsoft Research) released with the paper MPNet: Masked and Permuted Pre-training for Language Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu.</li> <li>MT5 (from Google AI) released with the paper mT5: A massively multilingual pre-trained text-to-text transformer by Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, Colin Raffel.</li> <li>MVP (from RUC AI Box) released with the paper MVP: Multi-task Supervised Pre-training for Natural Language Generation by Tianyi Tang, Junyi Li, Wayne Xin Zhao and Ji-Rong Wen.</li> <li>NAT (from SHI Labs) released with the paper Neighborhood Attention Transformer by Ali Hassani, Steven Walton, Jiachen Li, Shen Li, and Humphrey Shi.</li> <li>Nezha (from Huawei Noah\u2019s Ark Lab) released with the paper NEZHA: Neural Contextualized Representation for Chinese Language Understanding by Junqiu Wei, Xiaozhe Ren, Xiaoguang Li, Wenyong Huang, Yi Liao, Yasheng Wang, Jiashu Lin, Xin Jiang, Xiao Chen and Qun Liu.</li> <li>NLLB (from Meta) released with the paper No Language Left Behind: Scaling Human-Centered Machine Translation by the NLLB team.</li> <li>Nystr\u00f6mformer (from the University of Wisconsin - Madison) released with the paper Nystr\u00f6mformer: A Nystr\u00f6m-Based Algorithm for Approximating Self-Attention by Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, Vikas Singh.</li> <li>OPT (from Meta AI) released with the paper OPT: Open Pre-trained Transformer Language Models by Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen et al.</li> <li>OWL-ViT (from Google AI) released with the paper Simple Open-Vocabulary Object Detection with Vision Transformers by Matthias Minderer, Alexey Gritsenko, Austin Stone, Maxim Neumann, Dirk Weissenborn, Alexey Dosovitskiy, Aravindh Mahendran, Anurag Arnab, Mostafa Dehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, and Neil Houlsby.</li> <li>Pegasus (from Google) released with the paper PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu.</li> <li>PEGASUS-X (from Google) released with the paper Investigating Efficiently Extending Transformers for Long Input Summarization by Jason Phang, Yao Zhao, and Peter J. Liu.</li> <li>Perceiver IO (from Deepmind) released with the paper Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs by Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, Olivier H\u00e9naff, Matthew M. Botvinick, Andrew Zisserman, Oriol Vinyals, Jo\u00e3o Carreira.</li> <li>PhoBERT (from VinAI Research) released with the paper PhoBERT: Pre-trained language models for Vietnamese by Dat Quoc Nguyen and Anh Tuan Nguyen.</li> <li>PLBart (from UCLA NLP) released with the paper Unified Pre-training for Program Understanding and Generation by Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang.</li> <li>PoolFormer (from Sea AI Labs) released with the paper MetaFormer is Actually What You Need for Vision by Yu, Weihao and Luo, Mi and Zhou, Pan and Si, Chenyang and Zhou, Yichen and Wang, Xinchao and Feng, Jiashi and Yan, Shuicheng.</li> <li>ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.</li> <li>QDQBert (from NVIDIA) released with the paper Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation by Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev and Paulius Micikevicius.</li> <li>RAG (from Facebook) released with the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks by Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, Sebastian Riedel, Douwe Kiela.</li> <li>REALM (from Google Research) released with the paper REALM: Retrieval-Augmented Language Model Pre-Training by Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat and Ming-Wei Chang.</li> <li>Reformer (from Google Research) released with the paper Reformer: The Efficient Transformer by Nikita Kitaev, \u0141ukasz Kaiser, Anselm Levskaya.</li> <li>RegNet (from META Platforms) released with the paper Designing Network Design Space by Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, Piotr Doll\u00e1r.</li> <li>RemBERT (from Google Research) released with the paper Rethinking embedding coupling in pre-trained language models by Hyung Won Chung, Thibault F\u00e9vry, Henry Tsai, M. Johnson, Sebastian Ruder.</li> <li>ResNet (from Microsoft Research) released with the paper Deep Residual Learning for Image Recognition by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.</li> <li>RoBERTa (from Facebook), released together with the paper RoBERTa: A Robustly Optimized BERT Pretraining Approach by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.</li> <li>RoBERTa-PreLayerNorm (from Facebook) released with the paper fairseq: A Fast, Extensible Toolkit for Sequence Modeling by Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli.</li> <li>RoCBert (from WeChatAI) released with the paper RoCBert: Robust Chinese Bert with Multimodal Contrastive Pretraining by HuiSu, WeiweiShi, XiaoyuShen, XiaoZhou, TuoJi, JiaruiFang, JieZhou.</li> <li>RoFormer (from ZhuiyiTechnology), released together with the paper RoFormer: Enhanced Transformer with Rotary Position Embedding by Jianlin Su and Yu Lu and Shengfeng Pan and Bo Wen and Yunfeng Liu.</li> <li>SegFormer (from NVIDIA) released with the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo.</li> <li>SEW (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.</li> <li>SEW-D (from ASAPP) released with the paper Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition by Felix Wu, Kwangyoun Kim, Jing Pan, Kyu Han, Kilian Q. Weinberger, Yoav Artzi.</li> <li>SpeechToTextTransformer (from Facebook), released together with the paper fairseq S2T: Fast Speech-to-Text Modeling with fairseq by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Dmytro Okhonko, Juan Pino.</li> <li>SpeechToTextTransformer2 (from Facebook), released together with the paper Large-Scale Self- and Semi-Supervised Learning for Speech Translation by Changhan Wang, Anne Wu, Juan Pino, Alexei Baevski, Michael Auli, Alexis Conneau.</li> <li>Splinter (from Tel Aviv University), released together with the paper Few-Shot Question Answering by Pretraining Span Selection by Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, Omer Levy.</li> <li>SqueezeBERT (from Berkeley) released with the paper SqueezeBERT: What can computer vision teach NLP about efficient neural networks? by Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, and Kurt W. Keutzer.</li> <li>Swin Transformer (from Microsoft) released with the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo.</li> <li>Swin Transformer V2 (from Microsoft) released with the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo.</li> <li>Swin2SR (from University of W\u00fcrzburg) released with the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Marcos V. Conde, Ui-Jin Choi, Maxime Burchi, Radu Timofte.</li> <li>SwitchTransformers (from Google) released with the paper Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity by William Fedus, Barret Zoph, Noam Shazeer.</li> <li>T5 (from Google AI) released with the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.</li> <li>T5v1.1 (from Google AI) released in the repository google-research/text-to-text-transfer-transformer by Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu.</li> <li>Table Transformer (from Microsoft Research) released with the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Brandon Smock, Rohith Pesala, Robin Abraham.</li> <li>TAPAS (from Google AI) released with the paper TAPAS: Weakly Supervised Table Parsing via Pre-training by Jonathan Herzig, Pawe\u0142 Krzysztof Nowak, Thomas M\u00fcller, Francesco Piccinno and Julian Martin Eisenschlos.</li> <li>TAPEX (from Microsoft Research) released with the paper TAPEX: Table Pre-training via Learning a Neural SQL Executor by Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, Jian-Guang Lou.</li> <li>Time Series Transformer (from HuggingFace).</li> <li>TimeSformer (from Facebook) released with the paper Is Space-Time Attention All You Need for Video Understanding? by Gedas Bertasius, Heng Wang, Lorenzo Torresani.</li> <li>Trajectory Transformer (from the University of California at Berkeley) released with the paper Offline Reinforcement Learning as One Big Sequence Modeling Problem by Michael Janner, Qiyang Li, Sergey Levine</li> <li>Transformer-XL (from Google/CMU) released with the paper Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context by Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V. Le, Ruslan Salakhutdinov.</li> <li>TrOCR (from Microsoft), released together with the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei.</li> <li>UL2 (from Google Research) released with the paper Unifying Language Learning Paradigms by Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald Metzler</li> <li>UniSpeech (from Microsoft Research) released with the paper UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data by Chengyi Wang, Yu Wu, Yao Qian, Kenichi Kumatani, Shujie Liu, Furu Wei, Michael Zeng, Xuedong Huang.</li> <li>UniSpeechSat (from Microsoft Research) released with the paper UNISPEECH-SAT: UNIVERSAL SPEECH REPRESENTATION LEARNING WITH SPEAKER AWARE PRE-TRAINING by Sanyuan Chen, Yu Wu, Chengyi Wang, Zhengyang Chen, Zhuo Chen, Shujie Liu, Jian Wu, Yao Qian, Furu Wei, Jinyu Li, Xiangzhan Yu.</li> <li>UPerNet (from Peking University) released with the paper Unified Perceptual Parsing for Scene Understanding by Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, Jian Sun.</li> <li>VAN (from Tsinghua University and Nankai University) released with the paper Visual Attention Network by Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, Shi-Min Hu.</li> <li>VideoMAE (from Multimedia Computing Group, Nanjing University) released with the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Zhan Tong, Yibing Song, Jue Wang, Limin Wang.</li> <li>ViLT (from NAVER AI Lab/Kakao Enterprise/Kakao Brain) released with the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Wonjae Kim, Bokyung Son, Ildoo Kim.</li> <li>Vision Transformer (ViT) (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.</li> <li>VisualBERT (from UCLA NLP) released with the paper VisualBERT: A Simple and Performant Baseline for Vision and Language by Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang.</li> <li>ViT Hybrid (from Google AI) released with the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby.</li> <li>ViTMAE (from Meta AI) released with the paper Masked Autoencoders Are Scalable Vision Learners by Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, Ross Girshick.</li> <li>ViTMSN (from Meta AI) released with the paper Masked Siamese Networks for Label-Efficient Learning by Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael Rabbat, Nicolas Ballas.</li> <li>Wav2Vec2 (from Facebook AI) released with the paper wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.</li> <li>Wav2Vec2-Conformer (from Facebook AI) released with the paper FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ by Changhan Wang, Yun Tang, Xutai Ma, Anne Wu, Sravya Popuri, Dmytro Okhonko, Juan Pino.</li> <li>Wav2Vec2Phoneme (from Facebook AI) released with the paper Simple and Effective Zero-shot Cross-lingual Phoneme Recognition by Qiantong Xu, Alexei Baevski, Michael Auli.</li> <li>WavLM (from Microsoft Research) released with the paper WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing by Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie Liu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong Xiao, Jian Wu, Long Zhou, Shuo Ren, Yanmin Qian, Yao Qian, Jian Wu, Michael Zeng, Furu Wei.</li> <li>Whisper (from OpenAI) released with the paper Robust Speech Recognition via Large-Scale Weak Supervision by Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever.</li> <li>X-CLIP (from Microsoft Research) released with the paper Expanding Language-Image Pretrained Models for General Video Recognition by Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling.</li> <li>XGLM (From Facebook AI) released with the paper Few-shot Learning with Multilingual Language Models by Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li.</li> <li>XLM (from Facebook) released together with the paper Cross-lingual Language Model Pretraining by Guillaume Lample and Alexis Conneau.</li> <li>XLM-ProphetNet (from Microsoft Research) released with the paper ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training by Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang and Ming Zhou.</li> <li>XLM-RoBERTa (from Facebook AI), released together with the paper Unsupervised Cross-lingual Representation Learning at Scale by Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov.</li> <li>XLM-RoBERTa-XL (from Facebook AI), released together with the paper Larger-Scale Transformers for Multilingual Masked Language Modeling by Naman Goyal, Jingfei Du, Myle Ott, Giri Anantharaman, Alexis Conneau.</li> <li>XLNet (from Google/CMU) released with the paper \u200bXLNet: Generalized Autoregressive Pretraining for Language Understanding by Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le.</li> <li>XLS-R (from Facebook AI) released with the paper XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.</li> <li>XLSR-Wav2Vec2 (from Facebook AI) released with the paper Unsupervised Cross-Lingual Representation Learning For Speech Recognition by Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, Michael Auli.</li> <li>YOLOS (from Huazhong University of Science &amp; Technology) released with the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Yuxin Fang, Bencheng Liao, Xinggang Wang, Jiemin Fang, Jiyang Qi, Rui Wu, Jianwei Niu, Wenyu Liu.</li> <li>YOSO (from the University of Wisconsin - Madison) released with the paper You Only Sample (Almost) Once: Linear Cost Self-Attention Via Bernoulli Sampling by Zhanpeng Zeng, Yunyang Xiong, Sathya N. Ravi, Shailesh Acharya, Glenn Fung, Vikas Singh.</li> </ol>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/#_3","title":"\u652f\u6301\u200b\u7684\u200b\u6846\u67b6","text":"<p>\u200b\u4e0b\u8868\u200b\u5c55\u793a\u200b\u4e86\u200b\u5e93\u200b\u4e2d\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u7684\u200b\u652f\u6301\u200b\u60c5\u51b5\u200b\uff0c\u200b\u5982\u200b\u662f\u5426\u200b\u5177\u6709\u200b Python \u200b\u5206\u8bcd\u5668\u200b\uff08\u200b\u8868\u4e2d\u200b\u7684\u200b\u201cTokenizer slow\u201d\uff09\u3001\u200b\u662f\u5426\u200b\u5177\u6709\u200b\u7531\u200b \ud83e\udd17 Tokenizers \u200b\u5e93\u200b\u652f\u6301\u200b\u7684\u200b\u5feb\u901f\u200b\u5206\u8bcd\u5668\u200b\uff08\u200b\u8868\u4e2d\u200b\u7684\u200b\u201cTokenizer fast\u201d\uff09\u3001\u200b\u662f\u5426\u200b\u652f\u6301\u200b Jax\uff08\u200b\u901a\u8fc7\u200b Flax\uff09\u3001PyTorch \u200b\u4e0e\u200b TensorFlow\u3002</p> Model Tokenizer slow Tokenizer fast PyTorch support TensorFlow support Flax Support ALBERT \u2705 \u2705 \u2705 \u2705 \u2705 AltCLIP \u274c \u274c \u2705 \u274c \u274c Audio Spectrogram Transformer \u274c \u274c \u2705 \u274c \u274c BART \u2705 \u2705 \u2705 \u2705 \u2705 BEiT \u274c \u274c \u2705 \u274c \u2705 BERT \u2705 \u2705 \u2705 \u2705 \u2705 Bert Generation \u2705 \u274c \u2705 \u274c \u274c BigBird \u2705 \u2705 \u2705 \u274c \u2705 BigBird-Pegasus \u274c \u274c \u2705 \u274c \u274c BioGpt \u2705 \u274c \u2705 \u274c \u274c BiT \u274c \u274c \u2705 \u274c \u274c Blenderbot \u2705 \u2705 \u2705 \u2705 \u2705 BlenderbotSmall \u2705 \u2705 \u2705 \u2705 \u2705 BLIP \u274c \u274c \u2705 \u274c \u274c BLOOM \u274c \u2705 \u2705 \u274c \u274c CamemBERT \u2705 \u2705 \u2705 \u2705 \u274c CANINE \u2705 \u274c \u2705 \u274c \u274c Chinese-CLIP \u274c \u274c \u2705 \u274c \u274c CLIP \u2705 \u2705 \u2705 \u2705 \u2705 CLIPSeg \u274c \u274c \u2705 \u274c \u274c CodeGen \u2705 \u2705 \u2705 \u274c \u274c Conditional DETR \u274c \u274c \u2705 \u274c \u274c ConvBERT \u2705 \u2705 \u2705 \u2705 \u274c ConvNeXT \u274c \u274c \u2705 \u2705 \u274c CTRL \u2705 \u274c \u2705 \u2705 \u274c CvT \u274c \u274c \u2705 \u2705 \u274c Data2VecAudio \u274c \u274c \u2705 \u274c \u274c Data2VecText \u274c \u274c \u2705 \u274c \u274c Data2VecVision \u274c \u274c \u2705 \u2705 \u274c DeBERTa \u2705 \u2705 \u2705 \u2705 \u274c DeBERTa-v2 \u2705 \u2705 \u2705 \u2705 \u274c Decision Transformer \u274c \u274c \u2705 \u274c \u274c Deformable DETR \u274c \u274c \u2705 \u274c \u274c DeiT \u274c \u274c \u2705 \u2705 \u274c DETR \u274c \u274c \u2705 \u274c \u274c DiNAT \u274c \u274c \u2705 \u274c \u274c DistilBERT \u2705 \u2705 \u2705 \u2705 \u2705 DonutSwin \u274c \u274c \u2705 \u274c \u274c DPR \u2705 \u2705 \u2705 \u2705 \u274c DPT \u274c \u274c \u2705 \u274c \u274c ELECTRA \u2705 \u2705 \u2705 \u2705 \u2705 Encoder decoder \u274c \u274c \u2705 \u2705 \u2705 ERNIE \u274c \u274c \u2705 \u274c \u274c ESM \u2705 \u274c \u2705 \u2705 \u274c FairSeq Machine-Translation \u2705 \u274c \u2705 \u274c \u274c FlauBERT \u2705 \u274c \u2705 \u2705 \u274c FLAVA \u274c \u274c \u2705 \u274c \u274c FNet \u2705 \u2705 \u2705 \u274c \u274c Funnel Transformer \u2705 \u2705 \u2705 \u2705 \u274c GIT \u274c \u274c \u2705 \u274c \u274c GLPN \u274c \u274c \u2705 \u274c \u274c GPT Neo \u274c \u274c \u2705 \u274c \u2705 GPT NeoX \u274c \u2705 \u2705 \u274c \u274c GPT NeoX Japanese \u2705 \u274c \u2705 \u274c \u274c GPT-J \u274c \u274c \u2705 \u2705 \u2705 GPT-Sw3 \u2705 \u2705 \u2705 \u2705 \u2705 GroupViT \u274c \u274c \u2705 \u2705 \u274c Hubert \u274c \u274c \u2705 \u2705 \u274c I-BERT \u274c \u274c \u2705 \u274c \u274c ImageGPT \u274c \u274c \u2705 \u274c \u274c Jukebox \u2705 \u274c \u2705 \u274c \u274c LayoutLM \u2705 \u2705 \u2705 \u2705 \u274c LayoutLMv2 \u2705 \u2705 \u2705 \u274c \u274c LayoutLMv3 \u2705 \u2705 \u2705 \u2705 \u274c LED \u2705 \u2705 \u2705 \u2705 \u274c LeViT \u274c \u274c \u2705 \u274c \u274c LiLT \u274c \u274c \u2705 \u274c \u274c Longformer \u2705 \u2705 \u2705 \u2705 \u274c LongT5 \u274c \u274c \u2705 \u274c \u2705 LUKE \u2705 \u274c \u2705 \u274c \u274c LXMERT \u2705 \u2705 \u2705 \u2705 \u274c M-CTC-T \u274c \u274c \u2705 \u274c \u274c M2M100 \u2705 \u274c \u2705 \u274c \u274c Marian \u2705 \u274c \u2705 \u2705 \u2705 MarkupLM \u2705 \u2705 \u2705 \u274c \u274c Mask2Former \u274c \u274c \u2705 \u274c \u274c MaskFormer \u274c \u274c \u2705 \u274c \u274c MaskFormerSwin \u274c \u274c \u274c \u274c \u274c mBART \u2705 \u2705 \u2705 \u2705 \u2705 Megatron-BERT \u274c \u274c \u2705 \u274c \u274c MobileBERT \u2705 \u2705 \u2705 \u2705 \u274c MobileNetV1 \u274c \u274c \u2705 \u274c \u274c MobileNetV2 \u274c \u274c \u2705 \u274c \u274c MobileViT \u274c \u274c \u2705 \u2705 \u274c MPNet \u2705 \u2705 \u2705 \u2705 \u274c MT5 \u2705 \u2705 \u2705 \u2705 \u2705 MVP \u2705 \u2705 \u2705 \u274c \u274c NAT \u274c \u274c \u2705 \u274c \u274c Nezha \u274c \u274c \u2705 \u274c \u274c Nystr\u00f6mformer \u274c \u274c \u2705 \u274c \u274c OpenAI GPT \u2705 \u2705 \u2705 \u2705 \u274c OpenAI GPT-2 \u2705 \u2705 \u2705 \u2705 \u2705 OPT \u274c \u274c \u2705 \u2705 \u2705 OWL-ViT \u274c \u274c \u2705 \u274c \u274c Pegasus \u2705 \u2705 \u2705 \u2705 \u2705 PEGASUS-X \u274c \u274c \u2705 \u274c \u274c Perceiver \u2705 \u274c \u2705 \u274c \u274c PLBart \u2705 \u274c \u2705 \u274c \u274c PoolFormer \u274c \u274c \u2705 \u274c \u274c ProphetNet \u2705 \u274c \u2705 \u274c \u274c QDQBert \u274c \u274c \u2705 \u274c \u274c RAG \u2705 \u274c \u2705 \u2705 \u274c REALM \u2705 \u2705 \u2705 \u274c \u274c Reformer \u2705 \u2705 \u2705 \u274c \u274c RegNet \u274c \u274c \u2705 \u2705 \u2705 RemBERT \u2705 \u2705 \u2705 \u2705 \u274c ResNet \u274c \u274c \u2705 \u2705 \u274c RetriBERT \u2705 \u2705 \u2705 \u274c \u274c RoBERTa \u2705 \u2705 \u2705 \u2705 \u2705 RoBERTa-PreLayerNorm \u274c \u274c \u2705 \u2705 \u2705 RoCBert \u2705 \u274c \u2705 \u274c \u274c RoFormer \u2705 \u2705 \u2705 \u2705 \u2705 SegFormer \u274c \u274c \u2705 \u2705 \u274c SEW \u274c \u274c \u2705 \u274c \u274c SEW-D \u274c \u274c \u2705 \u274c \u274c Speech Encoder decoder \u274c \u274c \u2705 \u274c \u2705 Speech2Text \u2705 \u274c \u2705 \u2705 \u274c Speech2Text2 \u2705 \u274c \u274c \u274c \u274c Splinter \u2705 \u2705 \u2705 \u274c \u274c SqueezeBERT \u2705 \u2705 \u2705 \u274c \u274c Swin Transformer \u274c \u274c \u2705 \u2705 \u274c Swin Transformer V2 \u274c \u274c \u2705 \u274c \u274c Swin2SR \u274c \u274c \u2705 \u274c \u274c SwitchTransformers \u274c \u274c \u2705 \u274c \u274c T5 \u2705 \u2705 \u2705 \u2705 \u2705 Table Transformer \u274c \u274c \u2705 \u274c \u274c TAPAS \u2705 \u274c \u2705 \u2705 \u274c Time Series Transformer \u274c \u274c \u2705 \u274c \u274c TimeSformer \u274c \u274c \u2705 \u274c \u274c Trajectory Transformer \u274c \u274c \u2705 \u274c \u274c Transformer-XL \u2705 \u274c \u2705 \u2705 \u274c TrOCR \u274c \u274c \u2705 \u274c \u274c UniSpeech \u274c \u274c \u2705 \u274c \u274c UniSpeechSat \u274c \u274c \u2705 \u274c \u274c UPerNet \u274c \u274c \u2705 \u274c \u274c VAN \u274c \u274c \u2705 \u274c \u274c VideoMAE \u274c \u274c \u2705 \u274c \u274c ViLT \u274c \u274c \u2705 \u274c \u274c Vision Encoder decoder \u274c \u274c \u2705 \u2705 \u2705 VisionTextDualEncoder \u274c \u274c \u2705 \u274c \u2705 VisualBERT \u274c \u274c \u2705 \u274c \u274c ViT \u274c \u274c \u2705 \u2705 \u2705 ViT Hybrid \u274c \u274c \u2705 \u274c \u274c ViTMAE \u274c \u274c \u2705 \u2705 \u274c ViTMSN \u274c \u274c \u2705 \u274c \u274c Wav2Vec2 \u2705 \u274c \u2705 \u2705 \u2705 Wav2Vec2-Conformer \u274c \u274c \u2705 \u274c \u274c WavLM \u274c \u274c \u2705 \u274c \u274c Whisper \u2705 \u274c \u2705 \u2705 \u274c X-CLIP \u274c \u274c \u2705 \u274c \u274c XGLM \u2705 \u2705 \u2705 \u2705 \u2705 XLM \u2705 \u274c \u2705 \u2705 \u274c XLM-ProphetNet \u2705 \u274c \u2705 \u274c \u274c XLM-RoBERTa \u2705 \u2705 \u2705 \u2705 \u2705 XLM-RoBERTa-XL \u274c \u274c \u2705 \u274c \u274c XLNet \u2705 \u2705 \u2705 \u2705 \u274c YOLOS \u274c \u274c \u2705 \u274c \u274c YOSO \u274c \u274c \u2705 \u274c \u274c"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/installation/","title":"Installation","text":""},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/installation/#_1","title":"\u5b89\u88c5","text":"<p>\u200b\u4e3a\u200b\u4f60\u200b\u6b63\u5728\u200b\u4f7f\u7528\u200b\u7684\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6846\u67b6\u200b\u5b89\u88c5\u200b \ud83e\udd17 Transformers\u3001\u200b\u8bbe\u7f6e\u200b\u7f13\u5b58\u200b\uff0c\u200b\u5e76\u200b\u9009\u62e9\u6027\u200b\u914d\u7f6e\u200b \ud83e\udd17 Transformers \u200b\u4ee5\u200b\u79bb\u7ebf\u200b\u8fd0\u884c\u200b\u3002</p> <p>\ud83e\udd17 Transformers \u200b\u5df2\u200b\u5728\u200b Python 3.6+\u3001PyTorch 1.1.0+\u3001TensorFlow 2.0+ \u200b\u4ee5\u53ca\u200b Flax \u200b\u4e0a\u200b\u8fdb\u884c\u200b\u6d4b\u8bd5\u200b\u3002\u200b\u9488\u5bf9\u200b\u4f60\u200b\u4f7f\u7528\u200b\u7684\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6846\u67b6\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u7167\u200b\u4ee5\u4e0b\u200b\u5b89\u88c5\u200b\u8bf4\u660e\u200b\u8fdb\u884c\u200b\u5b89\u88c5\u200b\uff1a</p> <ul> <li>PyTorch \u200b\u5b89\u88c5\u200b\u8bf4\u660e\u200b\u3002</li> <li>TensorFlow 2.0 \u200b\u5b89\u88c5\u200b\u8bf4\u660e\u200b\u3002</li> <li>Flax \u200b\u5b89\u88c5\u200b\u8bf4\u660e\u200b\u3002</li> </ul>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/installation/#pip","title":"\u4f7f\u7528\u200b pip \u200b\u5b89\u88c5","text":"<p>\u200b\u4f60\u200b\u5e94\u8be5\u200b\u4f7f\u7528\u200b \u200b\u865a\u62df\u73af\u5883\u200b \u200b\u5b89\u88c5\u200b \ud83e\udd17 Transformers\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u4e0d\u200b\u719f\u6089\u200b Python \u200b\u865a\u62df\u73af\u5883\u200b\uff0c\u200b\u8bf7\u200b\u67e5\u770b\u200b\u6b64\u200b \u200b\u6559\u7a0b\u200b\u3002\u200b\u4f7f\u7528\u200b\u865a\u62df\u73af\u5883\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u7ba1\u7406\u200b\u4e0d\u540c\u200b\u9879\u76ee\u200b\uff0c\u200b\u907f\u514d\u200b\u4e0d\u540c\u200b\u4f9d\u8d56\u200b\u9879\u200b\u4e4b\u95f4\u200b\u7684\u200b\u517c\u5bb9\u6027\u95ee\u9898\u200b\u3002</p> <p>\u200b\u9996\u5148\u200b\uff0c\u200b\u5728\u200b\u9879\u76ee\u200b\u76ee\u5f55\u200b\u4e2d\u200b\u521b\u5efa\u200b\u865a\u62df\u73af\u5883\u200b\uff1a</p> <pre><code>python -m venv .env\n</code></pre> <p>\u200b\u5728\u200b Linux \u200b\u548c\u200b MacOs \u200b\u7cfb\u7edf\u200b\u4e2d\u200b\u6fc0\u6d3b\u200b\u865a\u62df\u73af\u5883\u200b\uff1a</p> <p><pre><code>source .env/bin/activate\n</code></pre> \u200b\u5728\u200b Windows \u200b\u7cfb\u7edf\u200b\u4e2d\u200b\u6fc0\u6d3b\u200b\u865a\u62df\u73af\u5883\u200b\uff1a</p> <pre><code>.env/Scripts/activate\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u5b89\u88c5\u200b \ud83e\udd17 Transformers\uff1a</p> <pre><code>pip install transformers\n</code></pre> <p>\u200b\u82e5\u4ec5\u200b\u9700\u200b CPU \u200b\u652f\u6301\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u5355\u884c\u200b\u547d\u4ee4\u200b\u65b9\u4fbf\u200b\u5730\u200b\u5b89\u88c5\u200b \ud83e\udd17 Transformers \u200b\u548c\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u5e93\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u5b89\u88c5\u200b \ud83e\udd17 Transformers \u200b\u548c\u200b PyTorch\uff1a</p> <pre><code>pip install 'transformers[torch]'\n</code></pre> <p>\ud83e\udd17 Transformers \u200b\u548c\u200b TensorFlow 2.0\uff1a</p> <pre><code>pip install 'transformers[tf-cpu]'\n</code></pre> <p> <p>M1 / ARM\u200b\u7528\u6237\u200b</p> <p>\u200b\u5728\u200b\u5b89\u88c5\u200b TensorFlow 2.0 \u200b\u524d\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u5b89\u88c5\u200b\u4ee5\u4e0b\u200b\u5e93\u200b\uff1a <pre><code>brew install cmake\nbrew install pkg-config\n</code></pre></p> <p></p> <p>\ud83e\udd17 Transformers \u200b\u548c\u200b Flax:</p> <pre><code>pip install 'transformers[flax]'\n</code></pre> <p>\u200b\u6700\u540e\u200b\uff0c\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u4ee5\u200b\u68c0\u67e5\u200b \ud83e\udd17 Transformers \u200b\u662f\u5426\u200b\u5df2\u200b\u88ab\u200b\u6b63\u786e\u200b\u5b89\u88c5\u200b\u3002\u200b\u8be5\u200b\u547d\u4ee4\u200b\u5c06\u200b\u4e0b\u8f7d\u200b\u4e00\u4e2a\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\"\n</code></pre> <p>\u200b\u7136\u540e\u200b\u6253\u5370\u200b\u6807\u7b7e\u200b\u4ee5\u53ca\u200b\u5206\u6570\u200b\uff1a</p> <pre><code>[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n</code></pre>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/installation/#_2","title":"\u6e90\u7801\u200b\u5b89\u88c5","text":"<p>\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u4ece\u200b\u6e90\u7801\u200b\u5b89\u88c5\u200b \ud83e\udd17 Transformers\uff1a</p> <pre><code>pip install git+https://github.com/huggingface/transformers\n</code></pre> <p>\u200b\u6b64\u200b\u547d\u4ee4\u200b\u4e0b\u8f7d\u200b\u7684\u200b\u662f\u200b\u6700\u65b0\u200b\u7684\u200b\u524d\u6cbf\u200b <code>main</code> \u200b\u7248\u672c\u200b\u800c\u200b\u4e0d\u662f\u200b\u6700\u65b0\u200b\u7684\u200b <code>stable</code> \u200b\u7248\u672c\u200b\u3002<code>main</code> \u200b\u7248\u672c\u200b\u9002\u7528\u200b\u4e8e\u200b\u8ddf\u200b\u6700\u65b0\u200b\u5f00\u53d1\u200b\u4fdd\u6301\u4e00\u81f4\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4e0a\u6b21\u200b\u6b63\u5f0f\u7248\u200b\u53d1\u5e03\u200b\u5e26\u6765\u200b\u7684\u200b bug \u200b\u88ab\u200b\u4fee\u590d\u200b\u4e86\u200b\uff0c\u200b\u4f46\u200b\u65b0\u200b\u7248\u672c\u200b\u5c1a\u672a\u200b\u88ab\u200b\u63a8\u51fa\u200b\u3002\u200b\u4f46\u662f\u200b\uff0c\u200b\u8fd9\u200b\u4e5f\u200b\u8bf4\u660e\u200b <code>main</code> \u200b\u7248\u672c\u200b\u5e76\u4e0d\u4e00\u5b9a\u200b\u603b\u662f\u200b\u7a33\u5b9a\u200b\u7684\u200b\u3002\u200b\u6211\u4eec\u200b\u52aa\u529b\u200b\u4fdd\u6301\u200b <code>main</code> \u200b\u7248\u672c\u200b\u7684\u200b\u53ef\u64cd\u4f5c\u6027\u200b\uff0c\u200b\u5927\u591a\u6570\u200b\u95ee\u9898\u200b\u901a\u5e38\u200b\u5728\u200b\u51e0\u4e2a\u200b\u5c0f\u65f6\u200b\u6216\u200b\u4e00\u5929\u200b\u4ee5\u5185\u200b\u5c31\u200b\u80fd\u200b\u88ab\u200b\u89e3\u51b3\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u9047\u5230\u200b\u95ee\u9898\u200b\uff0c\u200b\u8bf7\u200b\u63d0\u4e2a\u200b Issue \u200b\u4ee5\u4fbf\u200b\u6211\u4eec\u200b\u80fd\u200b\u66f4\u200b\u5feb\u200b\u4fee\u590d\u200b\u3002</p> <p>\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u4ee5\u200b\u68c0\u67e5\u200b \ud83e\udd17 Transformers \u200b\u662f\u5426\u200b\u5df2\u200b\u88ab\u200b\u6b63\u786e\u200b\u5b89\u88c5\u200b\uff1a</p> <pre><code>python -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))\"\n</code></pre>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/installation/#_3","title":"\u53ef\u200b\u7f16\u8f91\u200b\u5b89\u88c5","text":"<p>\u200b\u5982\u679c\u200b\u4f60\u200b\u6709\u200b\u4e0b\u5217\u200b\u9700\u6c42\u200b\uff0c\u200b\u9700\u8981\u200b\u8fdb\u884c\u200b\u53ef\u200b\u7f16\u8f91\u200b\u5b89\u88c5\u200b\uff1a</p> <ul> <li>\u200b\u4f7f\u7528\u200b\u6e90\u7801\u200b\u7684\u200b <code>main</code> \u200b\u7248\u672c\u200b\u3002</li> <li>\u200b\u4e3a\u200b \ud83e\udd17 Transformers \u200b\u8d21\u732e\u200b\u4ee3\u7801\u200b\uff0c\u200b\u9700\u8981\u200b\u6d4b\u8bd5\u4ee3\u7801\u200b\u4e2d\u200b\u7684\u200b\u66f4\u6539\u200b\u3002</li> </ul> <p>\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u514b\u9686\u200b\u4ed3\u5e93\u200b\u5e76\u200b\u5b89\u88c5\u200b \ud83e\udd17 Transformers\uff1a</p> <pre><code>git clone https://github.com/huggingface/transformers.git\ncd transformers\npip install -e .\n</code></pre> <p>\u200b\u8fd9\u4e9b\u200b\u547d\u4ee4\u200b\u5c06\u4f1a\u200b\u94fe\u63a5\u200b\u4f60\u200b\u514b\u9686\u200b\u7684\u200b\u4ed3\u5e93\u200b\u4ee5\u53ca\u200b\u4f60\u200b\u7684\u200b Python \u200b\u5e93\u200b\u8def\u5f84\u200b\u3002\u200b\u73b0\u5728\u200b\uff0cPython \u200b\u4e0d\u4ec5\u200b\u4f1a\u200b\u5728\u200b\u6b63\u5e38\u200b\u7684\u200b\u5e93\u200b\u8def\u5f84\u200b\u4e2d\u200b\u641c\u7d22\u200b\u5e93\u200b\uff0c\u200b\u4e5f\u200b\u4f1a\u200b\u5728\u200b\u4f60\u200b\u514b\u9686\u200b\u5230\u200b\u7684\u200b\u6587\u4ef6\u5939\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u67e5\u627e\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u7684\u200b Python \u200b\u5305\u200b\u901a\u5e38\u200b\u672c\u5e94\u200b\u5b89\u88c5\u200b\u5728\u200b <code>~/anaconda3/envs/main/lib/python3.7/site-packages/</code> \u200b\u76ee\u5f55\u200b\u4e2d\u200b\uff0c\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b Python \u200b\u4e5f\u200b\u4f1a\u200b\u641c\u7d22\u200b\u4f60\u200b\u514b\u9686\u200b\u5230\u200b\u7684\u200b\u6587\u4ef6\u5939\u200b\uff1a<code>~/transformers/</code>\u3002</p> <p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u200b\u7ee7\u7eed\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200b\u5e93\u200b\uff0c\u200b\u5fc5\u987b\u200b\u4fdd\u7559\u200b <code>transformers</code> \u200b\u6587\u4ef6\u5939\u200b\u3002</p> <p></p> <p>\u200b\u73b0\u5728\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\uff0c\u200b\u5c06\u200b\u4f60\u200b\u514b\u9686\u200b\u7684\u200b \ud83e\udd17 Transformers \u200b\u5e93\u200b\u8f7b\u677e\u200b\u66f4\u65b0\u200b\u81f3\u200b\u6700\u65b0\u200b\u7248\u672c\u200b\uff1a</p> <pre><code>cd ~/transformers/\ngit pull\n</code></pre> <p>\u200b\u4f60\u200b\u7684\u200b Python \u200b\u73af\u5883\u200b\u5c06\u200b\u5728\u200b\u4e0b\u6b21\u200b\u8fd0\u884c\u200b\u65f6\u200b\u627e\u5230\u200b <code>main</code> \u200b\u7248\u672c\u200b\u7684\u200b \ud83e\udd17 Transformers\u3002</p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/installation/#conda","title":"\u4f7f\u7528\u200b conda \u200b\u5b89\u88c5","text":"<p>\u200b\u4ece\u200b conda \u200b\u7684\u200b <code>huggingface</code> \u200b\u9891\u9053\u200b\u5b89\u88c5\u200b\uff1a</p> <pre><code>conda install -c huggingface transformers\n</code></pre>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/installation/#_4","title":"\u7f13\u5b58\u200b\u8bbe\u7f6e","text":"<p>\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4f1a\u200b\u88ab\u200b\u4e0b\u8f7d\u200b\u5e76\u200b\u672c\u5730\u200b\u7f13\u5b58\u200b\u5230\u200b <code>~/.cache/huggingface/hub</code>\u3002\u200b\u8fd9\u200b\u662f\u200b\u7531\u200b\u73af\u5883\u53d8\u91cf\u200b <code>TRANSFORMERS_CACHE</code> \u200b\u6307\u5b9a\u200b\u7684\u200b\u9ed8\u8ba4\u200b\u76ee\u5f55\u200b\u3002\u200b\u5728\u200b Windows \u200b\u4e0a\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u76ee\u5f55\u200b\u4e3a\u200b <code>C:\\Users\\username\\.cache\\huggingface\\hub</code>\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u6309\u7167\u200b\u4e0d\u540c\u200b\u4f18\u5148\u7ea7\u200b\u6539\u53d8\u200b\u4e0b\u8ff0\u200b\u73af\u5883\u53d8\u91cf\u200b\uff0c\u200b\u4ee5\u200b\u6307\u5b9a\u200b\u4e0d\u540c\u200b\u7684\u200b\u7f13\u5b58\u200b\u76ee\u5f55\u200b\u3002</p> <ol> <li>\u200b\u73af\u5883\u53d8\u91cf\u200b\uff08\u200b\u9ed8\u8ba4\u200b\uff09: <code>HUGGINGFACE_HUB_CACHE</code> \u200b\u6216\u200b <code>TRANSFORMERS_CACHE</code>\u3002</li> <li>\u200b\u73af\u5883\u53d8\u91cf\u200b <code>HF_HOME</code>\u3002</li> <li>\u200b\u73af\u5883\u53d8\u91cf\u200b <code>XDG_CACHE_HOME</code> + <code>/huggingface</code>\u3002</li> </ol> <p> <p>\u200b\u9664\u975e\u200b\u4f60\u200b\u660e\u786e\u200b\u6307\u5b9a\u200b\u4e86\u200b\u73af\u5883\u53d8\u91cf\u200b <code>TRANSFORMERS_CACHE</code>\uff0c\ud83e\udd17 Transformers \u200b\u5c06\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u4f7f\u7528\u200b\u8f83\u200b\u65e9\u200b\u7248\u672c\u200b\u8bbe\u7f6e\u200b\u7684\u200b\u73af\u5883\u53d8\u91cf\u200b <code>PYTORCH_TRANSFORMERS_CACHE</code> \u200b\u6216\u200b <code>PYTORCH_PRETRAINED_BERT_CACHE</code>\u3002</p> <p></p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/installation/#_5","title":"\u79bb\u7ebf\u200b\u6a21\u5f0f","text":"<p>\ud83e\udd17 Transformers \u200b\u53ef\u4ee5\u200b\u4ec5\u200b\u4f7f\u7528\u200b\u672c\u5730\u200b\u6587\u4ef6\u200b\u5728\u200b\u9632\u706b\u5899\u200b\u6216\u200b\u79bb\u7ebf\u200b\u73af\u5883\u4e2d\u8fd0\u884c\u200b\u3002\u200b\u8bbe\u7f6e\u200b\u73af\u5883\u53d8\u91cf\u200b <code>TRANSFORMERS_OFFLINE=1</code> \u200b\u4ee5\u200b\u542f\u7528\u200b\u8be5\u200b\u884c\u4e3a\u200b\u3002</p> <p> <p>\u200b\u901a\u8fc7\u200b\u8bbe\u7f6e\u200b\u73af\u5883\u53d8\u91cf\u200b <code>HF_DATASETS_OFFLINE=1</code> \u200b\u5c06\u200b \ud83e\udd17 Datasets \u200b\u6dfb\u52a0\u200b\u81f3\u200b\u4f60\u200b\u7684\u200b\u79bb\u7ebf\u200b\u8bad\u7ec3\u200b\u5de5\u4f5c\u200b\u6d41\u7a0b\u200b\u4e2d\u200b\u3002</p> <p></p> <p>\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4f60\u200b\u901a\u5e38\u200b\u4f1a\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u5bf9\u5916\u90e8\u200b\u5b9e\u4f8b\u200b\u8fdb\u884c\u200b\u9632\u706b\u5899\u200b\u4fdd\u62a4\u200b\u7684\u200b\u7684\u200b\u666e\u901a\u200b\u7f51\u7edc\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u7a0b\u5e8f\u200b\uff1a</p> <pre><code>python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...\n</code></pre> <p>\u200b\u5728\u200b\u79bb\u7ebf\u200b\u73af\u5883\u4e2d\u8fd0\u884c\u200b\u76f8\u540c\u200b\u7684\u200b\u7a0b\u5e8f\u200b\uff1a</p> <pre><code>HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 \\\npython examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u811a\u672c\u200b\u53ef\u4ee5\u200b\u5e94\u8be5\u200b\u6b63\u5e38\u200b\u8fd0\u884c\u200b\uff0c\u200b\u800c\u200b\u65e0\u9700\u200b\u6302\u200b\u8d77\u200b\u6216\u200b\u7b49\u5f85\u200b\u8d85\u65f6\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u77e5\u9053\u200b\u53ea\u5e94\u200b\u67e5\u627e\u200b\u672c\u5730\u200b\u6587\u4ef6\u200b\u3002</p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/installation/#_6","title":"\u83b7\u53d6\u200b\u79bb\u7ebf\u200b\u65f6\u200b\u4f7f\u7528\u200b\u7684\u200b\u6a21\u578b\u200b\u548c\u200b\u5206\u8bcd\u5668","text":"<p>\u200b\u53e6\u200b\u4e00\u79cd\u200b\u79bb\u7ebf\u200b\u65f6\u200b\u4f7f\u7528\u200b \ud83e\udd17 Transformers \u200b\u7684\u200b\u65b9\u6cd5\u200b\u662f\u200b\u9884\u5148\u200b\u4e0b\u8f7d\u200b\u597d\u200b\u6587\u4ef6\u200b\uff0c\u200b\u7136\u540e\u200b\u5728\u200b\u9700\u8981\u200b\u79bb\u7ebf\u200b\u4f7f\u7528\u200b\u65f6\u200b\u6307\u5411\u200b\u5b83\u4eec\u200b\u7684\u200b\u79bb\u7ebf\u200b\u8def\u5f84\u200b\u3002\u200b\u6709\u200b\u4e09\u79cd\u200b\u5b9e\u73b0\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff1a</p> <ul> <li> <p>\u200b\u5355\u51fb\u200b Model Hub \u200b\u7528\u6237\u754c\u9762\u200b\u4e0a\u200b\u7684\u200b \u2193 \u200b\u56fe\u6807\u200b\u4e0b\u8f7d\u200b\u6587\u4ef6\u200b\u3002</p> <p></p> </li> <li> <p>\u200b\u4f7f\u7528\u200b [<code>PreTrainedModel.from_pretrained</code>] \u200b\u548c\u200b [<code>PreTrainedModel.save_pretrained</code>] \u200b\u5de5\u4f5c\u200b\u6d41\u7a0b\u200b\uff1a</p> <ol> <li>\u200b\u9884\u5148\u200b\u4f7f\u7528\u200b [<code>PreTrainedModel.from_pretrained</code>] \u200b\u4e0b\u8f7d\u200b\u6587\u4ef6\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n&gt;&gt;&gt; model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n</code></pre> <ol> <li>\u200b\u4f7f\u7528\u200b [<code>PreTrainedModel.save_pretrained</code>] \u200b\u5c06\u200b\u6587\u4ef6\u200b\u4fdd\u5b58\u200b\u81f3\u200b\u6307\u5b9a\u200b\u76ee\u5f55\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; tokenizer.save_pretrained(\"./your/path/bigscience_t0\")\n&gt;&gt;&gt; model.save_pretrained(\"./your/path/bigscience_t0\")\n</code></pre> <ol> <li>\u200b\u73b0\u5728\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200b\u79bb\u7ebf\u200b\u65f6\u200b\u4ece\u200b\u6307\u5b9a\u200b\u76ee\u5f55\u200b\u4f7f\u7528\u200b [<code>PreTrainedModel.from_pretrained</code>] \u200b\u91cd\u65b0\u200b\u52a0\u8f7d\u200b\u4f60\u200b\u7684\u200b\u6587\u4ef6\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"./your/path/bigscience_t0\")\n&gt;&gt;&gt; model = AutoModel.from_pretrained(\"./your/path/bigscience_t0\")\n</code></pre> </li> <li> <p>\u200b\u4f7f\u7528\u200b\u4ee3\u7801\u200b\u7528\u200b huggingface_hub \u200b\u5e93\u200b\u4e0b\u8f7d\u200b\u6587\u4ef6\u200b\uff1a</p> <ol> <li>\u200b\u5728\u200b\u4f60\u200b\u7684\u200b\u865a\u62df\u73af\u5883\u200b\u4e2d\u200b\u5b89\u88c5\u200b <code>huggingface_hub</code> \u200b\u5e93\u200b\uff1a</li> </ol> <pre><code>python -m pip install huggingface_hub\n</code></pre> <ol> <li>\u200b\u4f7f\u7528\u200b <code>hf_hub_download</code> \u200b\u51fd\u6570\u200b\u5c06\u200b\u6587\u4ef6\u200b\u4e0b\u8f7d\u200b\u5230\u200b\u6307\u5b9a\u200b\u8def\u5f84\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u5c06\u200b <code>config.json</code> \u200b\u6587\u4ef6\u200b\u4ece\u200b T0 \u200b\u6a21\u578b\u200b\u4e0b\u8f7d\u200b\u81f3\u200b\u4f60\u200b\u60f3\u8981\u200b\u7684\u200b\u8def\u5f84\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from huggingface_hub import hf_hub_download\n\n&gt;&gt;&gt; hf_hub_download(repo_id=\"bigscience/T0_3B\", filename=\"config.json\", cache_dir=\"./your/path/bigscience_t0\")\n</code></pre> </li> </ul> <p>\u200b\u4e0b\u8f7d\u200b\u5b8c\u200b\u6587\u4ef6\u200b\u5e76\u200b\u5728\u200b\u672c\u5730\u200b\u7f13\u5b58\u200b\u540e\u200b\uff0c\u200b\u6307\u5b9a\u200b\u5176\u200b\u672c\u5730\u200b\u8def\u5f84\u200b\u4ee5\u200b\u52a0\u8f7d\u200b\u548c\u200b\u4f7f\u7528\u200b\u8be5\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoConfig\n\n&gt;&gt;&gt; config = AutoConfig.from_pretrained(\"./your/path/bigscience_t0/config.json\")\n</code></pre> <p> <p>\u200b\u8bf7\u53c2\u9605\u200b \u200b\u5982\u4f55\u200b\u4ece\u200b Hub \u200b\u4e0b\u8f7d\u200b\u6587\u4ef6\u200b \u200b\u90e8\u5206\u200b\uff0c\u200b\u83b7\u53d6\u200b\u6709\u5173\u200b\u4e0b\u8f7d\u200b\u5b58\u50a8\u200b\u5728\u200b Hub \u200b\u4e0a\u200b\u6587\u4ef6\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\u3002</p> <p></p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/","title":"Quicktour","text":""},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#_1","title":"\u5feb\u901f\u200b\u4e0a\u200b\u624b","text":"<p>[[open-in-colab]]</p> <p>\u200b\u5feb\u200b\u6765\u200b\u4f7f\u7528\u200b \ud83e\udd17 Transformers \u200b\u5427\u200b\uff01\u200b\u65e0\u8bba\u200b\u4f60\u200b\u662f\u200b\u5f00\u53d1\u4eba\u5458\u200b\u8fd8\u662f\u200b\u65e5\u5e38\u200b\u7528\u6237\u200b\uff0c\u200b\u8fd9\u7bc7\u200b\u5feb\u901f\u200b\u4e0a\u200b\u624b\u200b\u6559\u7a0b\u200b\u90fd\u200b\u5c06\u200b\u5e2e\u52a9\u200b\u4f60\u200b\u5165\u95e8\u200b\u5e76\u4e14\u200b\u5411\u200b\u4f60\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b [<code>pipeline</code>] \u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\uff0c\u200b\u4f7f\u7528\u200b AutoClass \u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u548c\u200b\u9884\u200b\u5904\u7406\u5668\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u4f7f\u7528\u200b PyTorch \u200b\u6216\u200b TensorFlow \u200b\u5feb\u901f\u200b\u8bad\u7ec3\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u662f\u200b\u4e00\u4e2a\u200b\u521d\u5b66\u8005\u200b\uff0c\u200b\u6211\u4eec\u200b\u5efa\u8bae\u200b\u4f60\u200b\u63a5\u4e0b\u6765\u200b\u67e5\u770b\u200b\u6211\u4eec\u200b\u7684\u200b\u6559\u7a0b\u200b\u6216\u8005\u200b\u8bfe\u7a0b\u200b\uff0c\u200b\u6765\u200b\u66f4\u200b\u6df1\u5165\u200b\u5730\u200b\u4e86\u89e3\u200b\u5728\u200b\u8fd9\u91cc\u200b\u4ecb\u7ecd\u200b\u5230\u200b\u7684\u200b\u6982\u5ff5\u200b\u3002</p> <p>\u200b\u5728\u200b\u5f00\u59cb\u200b\u4e4b\u524d\u200b\uff0c\u200b\u786e\u4fdd\u200b\u4f60\u200b\u5df2\u7ecf\u200b\u5b89\u88c5\u200b\u4e86\u200b\u6240\u6709\u200b\u5fc5\u8981\u200b\u7684\u200b\u5e93\u200b\uff1a</p> <pre><code>!pip install transformers datasets\n</code></pre> <p>\u200b\u4f60\u200b\u8fd8\u200b\u9700\u8981\u200b\u5b89\u88c5\u200b\u559c\u6b22\u200b\u7684\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u6846\u67b6\u200b\uff1a</p> <p> <p><pre><code>pip install torch\n</code></pre> <p><pre><code>pip install tensorflow\n</code></pre> </p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#pipeline","title":"Pipeline","text":"<p>\u200b\u4f7f\u7528\u200b [<code>pipeline</code>] \u200b\u662f\u200b\u5229\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\u7684\u200b\u6700\u200b\u7b80\u5355\u200b\u7684\u200b\u65b9\u5f0f\u200b\u3002\u200b\u4f60\u200b\u80fd\u591f\u200b\u5c06\u200b [<code>pipeline</code>] \u200b\u5f00\u7bb1\u200b\u5373\u200b\u7528\u5730\u200b\u7528\u4e8e\u200b\u8de8\u200b\u4e0d\u540c\u200b\u6a21\u6001\u200b\u7684\u200b\u591a\u79cd\u200b\u4efb\u52a1\u200b\u3002\u200b\u6765\u200b\u770b\u770b\u200b\u5b83\u200b\u652f\u6301\u200b\u7684\u200b\u4efb\u52a1\u200b\u5217\u8868\u200b\uff1a</p> \u200b\u4efb\u52a1\u200b \u200b\u63cf\u8ff0\u200b \u200b\u6a21\u6001\u200b Pipeline \u200b\u6587\u672c\u200b\u5206\u7c7b\u200b \u200b\u4e3a\u200b\u7ed9\u5b9a\u200b\u7684\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u5206\u914d\u200b\u4e00\u4e2a\u200b\u6807\u7b7e\u200b NLP pipeline(task=\"sentiment-analysis\") \u200b\u6587\u672c\u200b\u751f\u6210\u200b \u200b\u6839\u636e\u200b\u7ed9\u5b9a\u200b\u7684\u200b\u63d0\u793a\u200b\u751f\u6210\u200b\u6587\u672c\u200b NLP pipeline(task=\"text-generation\") \u200b\u547d\u540d\u200b\u5b9e\u4f53\u200b\u8bc6\u522b\u200b \u200b\u4e3a\u200b\u5e8f\u5217\u200b\u91cc\u200b\u7684\u200b\u6bcf\u4e2a\u200b token \u200b\u5206\u914d\u200b\u4e00\u4e2a\u200b\u6807\u7b7e\u200b\uff08\u200b\u4eba\u200b, \u200b\u7ec4\u7ec7\u200b, \u200b\u5730\u5740\u200b\u7b49\u7b49\u200b\uff09 NLP pipeline(task=\"ner\") \u200b\u95ee\u7b54\u200b\u7cfb\u7edf\u200b \u200b\u901a\u8fc7\u200b\u7ed9\u5b9a\u200b\u7684\u200b\u4e0a\u4e0b\u6587\u200b\u548c\u200b\u95ee\u9898\u200b, \u200b\u5728\u200b\u6587\u672c\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u7b54\u6848\u200b NLP pipeline(task=\"question-answering\") \u200b\u63a9\u76d6\u200b\u586b\u5145\u200b \u200b\u9884\u6d4b\u51fa\u200b\u6b63\u786e\u200b\u7684\u200b\u5728\u200b\u5e8f\u5217\u200b\u4e2d\u200b\u88ab\u200b\u63a9\u76d6\u200b\u7684\u200btoken NLP pipeline(task=\"fill-mask\") \u200b\u6587\u672c\u200b\u6458\u8981\u200b \u200b\u4e3a\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u6216\u200b\u6587\u6863\u200b\u751f\u6210\u200b\u603b\u7ed3\u200b NLP pipeline(task=\"summarization\") \u200b\u6587\u672c\u200b\u7ffb\u8bd1\u200b \u200b\u5c06\u200b\u6587\u672c\u200b\u4ece\u200b\u4e00\u79cd\u200b\u8bed\u8a00\u200b\u7ffb\u8bd1\u200b\u4e3a\u200b\u53e6\u200b\u4e00\u79cd\u200b\u8bed\u8a00\u200b NLP pipeline(task=\"translation\") \u200b\u56fe\u50cf\u200b\u5206\u7c7b\u200b \u200b\u4e3a\u200b\u56fe\u50cf\u200b\u5206\u914d\u200b\u4e00\u4e2a\u200b\u6807\u7b7e\u200b Computer vision pipeline(task=\"image-classification\") \u200b\u56fe\u50cf\u200b\u5206\u5272\u200b \u200b\u4e3a\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u6bcf\u4e2a\u200b\u72ec\u7acb\u200b\u7684\u200b\u50cf\u7d20\u200b\u5206\u914d\u200b\u6807\u7b7e\u200b\uff08\u200b\u652f\u6301\u200b\u8bed\u4e49\u200b\u3001\u200b\u5168\u666f\u200b\u548c\u200b\u5b9e\u4f8b\u200b\u5206\u5272\u200b\uff09 Computer vision pipeline(task=\"image-segmentation\") \u200b\u76ee\u6807\u200b\u68c0\u6d4b\u200b \u200b\u9884\u6d4b\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u76ee\u6807\u200b\u5bf9\u8c61\u200b\u7684\u200b\u8fb9\u754c\u200b\u6846\u200b\u548c\u200b\u7c7b\u522b\u200b Computer vision pipeline(task=\"object-detection\") \u200b\u97f3\u9891\u200b\u5206\u7c7b\u200b \u200b\u7ed9\u200b\u97f3\u9891\u6587\u4ef6\u200b\u5206\u914d\u200b\u4e00\u4e2a\u200b\u6807\u7b7e\u200b Audio pipeline(task=\"audio-classification\") \u200b\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b \u200b\u5c06\u200b\u97f3\u9891\u6587\u4ef6\u200b\u4e2d\u200b\u7684\u200b\u8bed\u97f3\u200b\u63d0\u53d6\u200b\u4e3a\u200b\u6587\u672c\u200b Audio pipeline(task=\"automatic-speech-recognition\") \u200b\u89c6\u89c9\u200b\u95ee\u7b54\u200b \u200b\u7ed9\u5b9a\u200b\u4e00\u4e2a\u200b\u56fe\u50cf\u200b\u548c\u200b\u4e00\u4e2a\u200b\u95ee\u9898\u200b\uff0c\u200b\u6b63\u786e\u200b\u5730\u200b\u56de\u7b54\u200b\u6709\u5173\u200b\u56fe\u50cf\u200b\u7684\u200b\u95ee\u9898\u200b Multimodal pipeline(task=\"vqa\") <p>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b [<code>pipeline</code>] \u200b\u5b9e\u4f8b\u200b\u5e76\u4e14\u200b\u6307\u5b9a\u200b\u4f60\u200b\u60f3\u8981\u200b\u5c06\u200b\u5b83\u200b\u7528\u4e8e\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u5f00\u59cb\u200b\u4e86\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5c06\u200b [<code>pipeline</code>] \u200b\u7528\u4e8e\u200b\u4efb\u4f55\u200b\u4e00\u4e2a\u200b\u4e0a\u9762\u200b\u63d0\u5230\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u5982\u679c\u200b\u60f3\u200b\u77e5\u9053\u200b\u652f\u6301\u200b\u7684\u200b\u4efb\u52a1\u200b\u7684\u200b\u5b8c\u6574\u200b\u5217\u8868\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u67e5\u9605\u200b pipeline API \u200b\u53c2\u8003\u200b\u3002\u200b\u4e0d\u8fc7\u200b, \u200b\u5728\u200b\u8fd9\u7bc7\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u4f60\u200b\u5c06\u200b\u628a\u200b [<code>pipeline</code>] \u200b\u7528\u200b\u5728\u200b\u4e00\u4e2a\u200b\u60c5\u611f\u200b\u5206\u6790\u200b\u793a\u4f8b\u200b\u4e0a\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; classifier = pipeline(\"sentiment-analysis\")\n</code></pre> <p>[<code>pipeline</code>] \u200b\u4f1a\u200b\u4e0b\u8f7d\u200b\u5e76\u200b\u7f13\u5b58\u200b\u4e00\u4e2a\u200b\u7528\u4e8e\u200b\u60c5\u611f\u200b\u5206\u6790\u200b\u7684\u200b\u9ed8\u8ba4\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u548c\u200b\u5206\u8bcd\u5668\u200b\u3002\u200b\u73b0\u5728\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200b\u76ee\u6807\u200b\u6587\u672c\u200b\u4e0a\u200b\u4f7f\u7528\u200b <code>classifier</code> \u200b\u4e86\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; classifier(\"We are very happy to show you the \ud83e\udd17 Transformers library.\")\n[{'label': 'POSITIVE', 'score': 0.9998}]\n</code></pre> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u6709\u200b\u4e0d\u6b62\u200b\u4e00\u4e2a\u200b\u8f93\u5165\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u628a\u200b\u6240\u6709\u200b\u8f93\u5165\u200b\u653e\u5165\u200b\u4e00\u4e2a\u200b\u5217\u8868\u200b\u7136\u540e\u200b\u4f20\u7ed9\u200b[<code>pipeline</code>]\uff0c\u200b\u5b83\u200b\u5c06\u200b\u4f1a\u200b\u8fd4\u56de\u200b\u4e00\u4e2a\u200b\u5b57\u5178\u200b\u5217\u8868\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; results = classifier([\"We are very happy to show you the \ud83e\udd17 Transformers library.\", \"We hope you don't hate it.\"])\n&gt;&gt;&gt; for result in results:\n...     print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\nlabel: POSITIVE, with score: 0.9998\nlabel: NEGATIVE, with score: 0.5309\n</code></pre> <p>[<code>pipeline</code>] \u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u4e3a\u200b\u4efb\u4f55\u200b\u4f60\u200b\u559c\u6b22\u200b\u7684\u200b\u4efb\u52a1\u200b\u904d\u5386\u200b\u6574\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\u3002\u200b\u5728\u200b\u4e0b\u9762\u200b\u8fd9\u4e2a\u200b\u793a\u4f8b\u200b\u4e2d\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u9009\u62e9\u200b\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b\u4f5c\u4e3a\u200b\u6211\u4eec\u200b\u7684\u200b\u4efb\u52a1\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")\n</code></pre> <p>\u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200b\u4f60\u200b\u60f3\u200b\u904d\u5386\u200b\u7684\u200b\u97f3\u9891\u200b\u6570\u636e\u200b\u96c6\u200b\uff08\u200b\u67e5\u9605\u200b \ud83e\udd17 Datasets \u200b\u5feb\u901f\u200b\u5f00\u59cb\u200b \u200b\u83b7\u5f97\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff09\u3002\u200b\u6bd4\u5982\u200b\uff0c\u200b\u52a0\u8f7d\u200b MInDS-14 \u200b\u6570\u636e\u200b\u96c6\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from datasets import load_dataset, Audio\n\n&gt;&gt;&gt; dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")  # doctest: +IGNORE_RESULT\n</code></pre> <p>\u200b\u4f60\u200b\u9700\u8981\u200b\u786e\u4fdd\u200b\u6570\u636e\u200b\u96c6\u4e2d\u200b\u7684\u200b\u97f3\u9891\u200b\u7684\u200b\u91c7\u6837\u7387\u200b\u4e0e\u200b <code>facebook/wav2vec2-base-960h</code> \u200b\u8bad\u7ec3\u200b\u7528\u5230\u200b\u7684\u200b\u97f3\u9891\u200b\u7684\u200b\u91c7\u6837\u7387\u200b\u4e00\u81f4\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))\n</code></pre> <p>\u200b\u5f53\u200b\u8c03\u7528\u200b <code>\"audio\"</code> \u200b\u5217\u65f6\u200b, \u200b\u97f3\u9891\u6587\u4ef6\u200b\u5c06\u4f1a\u200b\u81ea\u52a8\u200b\u52a0\u8f7d\u200b\u5e76\u91cd\u200b\u91c7\u6837\u200b\u3002 \u200b\u4ece\u524d\u200b\u56db\u4e2a\u200b\u6837\u672c\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u539f\u59cb\u200b\u6ce2\u5f62\u200b\u6570\u7ec4\u200b\uff0c\u200b\u5c06\u200b\u5b83\u200b\u4f5c\u4e3a\u200b\u5217\u8868\u200b\u4f20\u7ed9\u200b pipeline\uff1a</p> <pre><code>&gt;&gt;&gt; result = speech_recognizer(dataset[:4][\"audio\"])\n&gt;&gt;&gt; print([d[\"text\"] for d in result])\n['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FODING HOW I'D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE AP SO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I THURN A JOIN A COUNT']\n</code></pre> <p>\u200b\u5bf9\u4e8e\u200b\u8f93\u5165\u200b\u975e\u5e38\u200b\u5e9e\u5927\u200b\u7684\u200b\u5927\u578b\u200b\u6570\u636e\u200b\u96c6\u200b\uff08\u200b\u6bd4\u5982\u200b\u8bed\u97f3\u200b\u6216\u200b\u89c6\u89c9\u200b\uff09\uff0c\u200b\u4f60\u200b\u4f1a\u200b\u60f3\u5230\u200b\u4f7f\u7528\u200b\u4e00\u4e2a\u200b\u751f\u6210\u5668\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u4e00\u4e2a\u200b\u5c06\u200b\u6240\u6709\u200b\u8f93\u5165\u200b\u90fd\u200b\u52a0\u8f7d\u200b\u8fdb\u200b\u5185\u5b58\u200b\u7684\u200b\u5217\u8868\u200b\u3002\u200b\u67e5\u9605\u200b pipeline API \u200b\u53c2\u8003\u200b \u200b\u6765\u200b\u83b7\u53d6\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#pipeline_1","title":"\u5728\u200b pipeline \u200b\u4e2d\u200b\u4f7f\u7528\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u548c\u200b\u5206\u8bcd\u5668","text":"<p>[<code>pipeline</code>] \u200b\u53ef\u4ee5\u200b\u5bb9\u7eb3\u200b Hub \u200b\u4e2d\u200b\u7684\u200b\u4efb\u4f55\u200b\u6a21\u578b\u200b\uff0c\u200b\u8fd9\u200b\u8ba9\u200b [<code>pipeline</code>] \u200b\u66f4\u200b\u5bb9\u6613\u200b\u9002\u7528\u200b\u4e8e\u200b\u5176\u4ed6\u200b\u7528\u4f8b\u200b\u3002\u200b\u6bd4\u5982\u200b\uff0c\u200b\u4f60\u200b\u60f3\u8981\u200b\u4e00\u4e2a\u200b\u80fd\u591f\u200b\u5904\u7406\u200b\u6cd5\u8bed\u200b\u6587\u672c\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b Hub \u200b\u4e0a\u200b\u7684\u200b\u6807\u8bb0\u200b\u6765\u200b\u7b5b\u9009\u200b\u51fa\u200b\u5408\u9002\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u9760\u200b\u524d\u200b\u7684\u200b\u7b5b\u9009\u200b\u7ed3\u679c\u200b\u4f1a\u200b\u8fd4\u56de\u200b\u4e00\u4e2a\u200b\u4e3a\u200b\u60c5\u611f\u200b\u5206\u6790\u200b\u5fae\u8c03\u200b\u7684\u200b\u591a\u200b\u8bed\u8a00\u200b\u7684\u200b BERT \u200b\u6a21\u578b\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u5b83\u200b\u7528\u4e8e\u200b\u6cd5\u8bed\u200b\u6587\u672c\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n</code></pre> <p>  \u200b\u4f7f\u7528\u200b [<code>AutoModelForSequenceClassification</code>] \u200b\u548c\u200b [<code>AutoTokenizer</code>] \u200b\u6765\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u548c\u200b\u5b83\u200b\u5173\u8054\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\uff08\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200b\u4e0b\u200b\u4e00\u8282\u200b\u7684\u200b <code>AutoClass</code>\uff09\uff1a <p><pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n&gt;&gt;&gt; model = AutoModelForSequenceClassification.from_pretrained(model_name)\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(model_name)\n</code></pre>  \u200b\u4f7f\u7528\u200b [<code>TFAutoModelForSequenceClassification</code>] \u200b\u548c\u200b [<code>AutoTokenizer</code>] \u200b\u6765\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u548c\u200b\u5b83\u200b\u5173\u8054\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\uff08\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\u53ef\u4ee5\u200b\u53c2\u8003\u200b\u4e0b\u200b\u4e00\u8282\u200b\u7684\u200b <code>TFAutoClass</code>\uff09\uff1a <p><pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n\n&gt;&gt;&gt; model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(model_name)\n</code></pre> </p> <p>\u200b\u5728\u200b [<code>pipeline</code>] \u200b\u4e2d\u200b\u6307\u5b9a\u200b\u6a21\u578b\u200b\u548c\u200b\u5206\u8bcd\u5668\u200b\uff0c\u200b\u73b0\u5728\u200b\u4f60\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u5728\u200b\u6cd5\u8bed\u200b\u6587\u672c\u200b\u4e0a\u200b\u4f7f\u7528\u200b <code>classifier</code> \u200b\u4e86\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n&gt;&gt;&gt; classifier(\"Nous sommes tr\u00e8s heureux de vous pr\u00e9senter la biblioth\u00e8que \ud83e\udd17 Transformers.\")\n[{'label': '5 stars', 'score': 0.7273}]\n</code></pre> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u6ca1\u6709\u200b\u627e\u5230\u200b\u9002\u5408\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u5c31\u200b\u9700\u8981\u200b\u5728\u200b\u4f60\u200b\u7684\u200b\u6570\u636e\u200b\u4e0a\u200b\u5fae\u8c03\u200b\u4e00\u4e2a\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4e86\u200b\u3002\u200b\u67e5\u770b\u200b \u200b\u5fae\u8c03\u200b\u6559\u7a0b\u200b \u200b\u6765\u200b\u5b66\u4e60\u200b\u600e\u6837\u200b\u8fdb\u884c\u200b\u5fae\u8c03\u200b\u3002\u200b\u6700\u540e\u200b\uff0c\u200b\u5fae\u8c03\u200b\u5b8c\u200b\u6a21\u578b\u200b\u540e\u200b\uff0c\u200b\u8003\u8651\u4e00\u4e0b\u200b\u5728\u200b Hub \u200b\u4e0a\u200b\u4e0e\u200b\u793e\u533a\u200b \u200b\u5206\u4eab\u200b \u200b\u8fd9\u4e2a\u200b\u6a21\u578b\u200b\uff0c\u200b\u628a\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u666e\u53ca\u200b\u5230\u200b\u6bcf\u200b\u4e00\u4e2a\u200b\u4eba\u200b! \ud83e\udd17</p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#autoclass","title":"AutoClass","text":"<p>\u200b\u5728\u200b\u5e55\u540e\u200b\uff0c\u200b\u662f\u200b\u7531\u200b [<code>AutoModelForSequenceClassification</code>] \u200b\u548c\u200b [<code>AutoTokenizer</code>] \u200b\u4e00\u8d77\u200b\u652f\u6301\u200b\u4f60\u200b\u5728\u200b\u4e0a\u9762\u200b\u7528\u5230\u200b\u7684\u200b [<code>pipeline</code>]\u3002AutoClass \u200b\u662f\u200b\u4e00\u4e2a\u200b\u80fd\u591f\u200b\u901a\u8fc7\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u540d\u79f0\u200b\u6216\u200b\u8def\u5f84\u200b\u81ea\u52a8\u200b\u67e5\u627e\u200b\u5176\u200b\u67b6\u6784\u200b\u7684\u200b\u5feb\u6377\u65b9\u5f0f\u200b\u3002\u200b\u4f60\u200b\u53ea\u200b\u9700\u8981\u200b\u4e3a\u200b\u4f60\u200b\u7684\u200b\u4efb\u52a1\u200b\u9009\u62e9\u200b\u5408\u9002\u200b\u7684\u200b <code>AutoClass</code> \u200b\u548c\u200b\u5b83\u200b\u5173\u8054\u200b\u7684\u200b\u9884\u5904\u7406\u200b\u7c7b\u200b\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u56de\u8fc7\u5934\u6765\u200b\u770b\u200b\u4e0a\u200b\u4e00\u8282\u200b\u7684\u200b\u793a\u4f8b\u200b\uff0c\u200b\u770b\u770b\u200b\u600e\u6837\u200b\u4f7f\u7528\u200b <code>AutoClass</code> \u200b\u6765\u200b\u91cd\u73b0\u200b\u4f7f\u7528\u200b [<code>pipeline</code>] \u200b\u7684\u200b\u7ed3\u679c\u200b\u3002</p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#autotokenizer","title":"AutoTokenizer","text":"<p>\u200b\u5206\u8bcd\u5668\u200b\u8d1f\u8d23\u200b\u9884\u5904\u7406\u200b\u6587\u672c\u200b\uff0c\u200b\u5c06\u200b\u6587\u672c\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u7528\u4e8e\u200b\u8f93\u5165\u200b\u6a21\u578b\u200b\u7684\u200b\u6570\u5b57\u200b\u6570\u7ec4\u200b\u3002\u200b\u6709\u200b\u591a\u4e2a\u200b\u7528\u6765\u200b\u7ba1\u7406\u200b\u5206\u8bcd\u200b\u8fc7\u7a0b\u200b\u7684\u200b\u89c4\u5219\u200b\uff0c\u200b\u5305\u62ec\u200b\u5982\u4f55\u200b\u62c6\u5206\u200b\u5355\u8bcd\u200b\u548c\u200b\u5728\u200b\u4ec0\u4e48\u6837\u200b\u7684\u200b\u7ea7\u522b\u200b\u4e0a\u200b\u62c6\u5206\u200b\u5355\u8bcd\u200b\uff08\u200b\u5728\u200b \u200b\u5206\u8bcd\u5668\u200b\u603b\u7ed3\u200b \u200b\u5b66\u4e60\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b\u5206\u8bcd\u200b\u7684\u200b\u4fe1\u606f\u200b\uff09\u3002\u200b\u8981\u200b\u8bb0\u4f4f\u200b\u6700\u200b\u91cd\u8981\u200b\u7684\u200b\u662f\u200b\u4f60\u200b\u9700\u8981\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\u8981\u200b\u4e0e\u200b\u6a21\u578b\u200b\u7684\u200b\u540d\u79f0\u200b\u76f8\u540c\u200b, \u200b\u6765\u200b\u786e\u4fdd\u200b\u548c\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u4f7f\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u5206\u8bcd\u200b\u89c4\u5219\u200b\u3002</p> <p>\u200b\u4f7f\u7528\u200b [<code>AutoTokenizer</code>] \u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200b\u5206\u8bcd\u5668\u200b:</p> <pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer\n\n&gt;&gt;&gt; model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(model_name)\n</code></pre> <p>\u200b\u5c06\u200b\u6587\u672c\u200b\u4f20\u5165\u200b\u5206\u8bcd\u5668\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; encoding = tokenizer(\"We are very happy to show you the \ud83e\udd17 Transformers library.\")\n&gt;&gt;&gt; print(encoding)\n{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n</code></pre> <p>\u200b\u5206\u8bcd\u5668\u200b\u8fd4\u56de\u200b\u4e86\u200b\u542b\u6709\u200b\u5982\u4e0b\u200b\u5185\u5bb9\u200b\u7684\u200b\u5b57\u5178\u200b:</p> <ul> <li>input_ids\uff1a\u200b\u7528\u200b\u6570\u5b57\u200b\u8868\u793a\u200b\u7684\u200b token\u3002</li> <li>attention_mask\uff1a\u200b\u5e94\u8be5\u200b\u5173\u6ce8\u200b\u54ea\u4e9b\u200b token \u200b\u7684\u200b\u6307\u793a\u200b\u3002</li> </ul> <p>\u200b\u5206\u8bcd\u5668\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u63a5\u53d7\u200b\u5217\u8868\u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\uff0c\u200b\u5e76\u200b\u586b\u5145\u200b\u548c\u200b\u622a\u65ad\u200b\u6587\u672c\u200b\uff0c\u200b\u8fd4\u56de\u200b\u5177\u6709\u200b\u7edf\u4e00\u200b\u957f\u5ea6\u200b\u7684\u200b\u6279\u6b21\u200b\uff1a</p> <p> <p><pre><code>&gt;&gt;&gt; pt_batch = tokenizer(\n...     [\"We are very happy to show you the \ud83e\udd17 Transformers library.\", \"We hope you don't hate it.\"],\n...     padding=True,\n...     truncation=True,\n...     max_length=512,\n...     return_tensors=\"pt\",\n... )\n</code></pre> <p><pre><code>&gt;&gt;&gt; tf_batch = tokenizer(\n...     [\"We are very happy to show you the \ud83e\udd17 Transformers library.\", \"We hope you don't hate it.\"],\n...     padding=True,\n...     truncation=True,\n...     max_length=512,\n...     return_tensors=\"tf\",\n... )\n</code></pre> </p> <p> <p>\u200b\u67e5\u9605\u200b\u9884\u5904\u7406\u200b\u6559\u7a0b\u200b\u6765\u200b\u83b7\u5f97\u200b\u6709\u5173\u200b\u5206\u8bcd\u200b\u7684\u200b\u66f4\u200b\u8be6\u7ec6\u200b\u7684\u200b\u4fe1\u606f\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b [<code>AutoFeatureExtractor</code>] \u200b\u548c\u200b [<code>AutoProcessor</code>] \u200b\u6765\u200b\u5904\u7406\u200b\u56fe\u50cf\u200b\uff0c\u200b\u97f3\u9891\u200b\uff0c\u200b\u8fd8\u6709\u200b\u591a\u200b\u6a21\u5f0f\u200b\u8f93\u5165\u200b\u3002</p> <p></p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#automodel","title":"AutoModel","text":"<p>  \ud83e\udd17 Transformers \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u79cd\u200b\u7b80\u5355\u200b\u7edf\u4e00\u200b\u7684\u200b\u65b9\u5f0f\u200b\u6765\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u5b9e\u4f8b\u200b. \u200b\u8fd9\u200b\u8868\u793a\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u50cf\u200b\u52a0\u8f7d\u200b [<code>AutoTokenizer</code>] \u200b\u4e00\u6837\u200b\u52a0\u8f7d\u200b [<code>AutoModel</code>]\u3002\u200b\u552f\u4e00\u200b\u4e0d\u540c\u200b\u7684\u200b\u5730\u65b9\u200b\u662f\u200b\u4e3a\u200b\u4f60\u200b\u7684\u200b\u4efb\u52a1\u200b\u9009\u62e9\u200b\u6b63\u786e\u200b\u7684\u200b[<code>AutoModel</code>]\u3002\u200b\u5bf9\u4e8e\u200b\u6587\u672c\u200b\uff08\u200b\u6216\u200b\u5e8f\u5217\u200b\uff09\u200b\u5206\u7c7b\u200b\uff0c\u200b\u4f60\u200b\u5e94\u8be5\u200b\u52a0\u8f7d\u200b[<code>AutoModelForSequenceClassification</code>]\uff1a <pre><code>&gt;&gt;&gt; from transformers import AutoModelForSequenceClassification\n\n&gt;&gt;&gt; model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n&gt;&gt;&gt; pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n</code></pre> <p> <p>\u200b\u901a\u8fc7\u200b \u200b\u4efb\u52a1\u200b\u6458\u8981\u200b \u200b\u67e5\u627e\u200b [<code>AutoModel</code>] \u200b\u652f\u6301\u200b\u7684\u200b\u4efb\u52a1\u200b.</p> <p></p> <p>\u200b\u73b0\u5728\u200b\u53ef\u4ee5\u200b\u628a\u200b\u9884\u5904\u7406\u200b\u597d\u200b\u7684\u200b\u8f93\u5165\u200b\u6279\u6b21\u200b\u76f4\u63a5\u200b\u9001\u200b\u8fdb\u200b\u6a21\u578b\u200b\u3002\u200b\u4f60\u200b\u53ea\u200b\u9700\u8981\u200b\u901a\u8fc7\u200b <code>**</code> \u200b\u6765\u200b\u89e3\u5305\u200b\u5b57\u5178\u200b:</p> <pre><code>&gt;&gt;&gt; pt_outputs = pt_model(**pt_batch)\n</code></pre> <p>\u200b\u6a21\u578b\u200b\u5728\u200b <code>logits</code> \u200b\u5c5e\u6027\u200b\u8f93\u51fa\u200b\u6700\u7ec8\u200b\u7684\u200b\u6fc0\u6d3b\u200b\u7ed3\u679c\u200b. \u200b\u5728\u200b <code>logits</code> \u200b\u4e0a\u200b\u5e94\u7528\u200b softmax \u200b\u51fd\u6570\u200b\u6765\u200b\u67e5\u8be2\u200b\u6982\u7387\u200b:</p> <p><pre><code>&gt;&gt;&gt; from torch import nn\n\n&gt;&gt;&gt; pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n&gt;&gt;&gt; print(pt_predictions)\ntensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=&lt;SoftmaxBackward0&gt;)\n</code></pre>  \ud83e\udd17 Transformers \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u79cd\u200b\u7b80\u5355\u200b\u7edf\u4e00\u200b\u7684\u200b\u65b9\u5f0f\u200b\u6765\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u5b9e\u4f8b\u200b\u3002\u200b\u8fd9\u200b\u8868\u793a\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u50cf\u200b\u52a0\u8f7d\u200b [<code>AutoTokenizer</code>] \u200b\u4e00\u6837\u200b\u52a0\u8f7d\u200b [<code>TFAutoModel</code>]\u3002\u200b\u552f\u4e00\u200b\u4e0d\u540c\u200b\u7684\u200b\u5730\u65b9\u200b\u662f\u200b\u4e3a\u200b\u4f60\u200b\u7684\u200b\u4efb\u52a1\u200b\u9009\u62e9\u200b\u6b63\u786e\u200b\u7684\u200b [<code>TFAutoModel</code>]\uff0c\u200b\u5bf9\u4e8e\u200b\u6587\u672c\u200b\uff08\u200b\u6216\u200b\u5e8f\u5217\u200b\uff09\u200b\u5206\u7c7b\u200b\uff0c\u200b\u4f60\u200b\u5e94\u8be5\u200b\u52a0\u8f7d\u200b [<code>TFAutoModelForSequenceClassification</code>]\uff1a <pre><code>&gt;&gt;&gt; from transformers import TFAutoModelForSequenceClassification\n\n&gt;&gt;&gt; model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n&gt;&gt;&gt; tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n</code></pre> <p> <p>\u200b\u901a\u8fc7\u200b \u200b\u4efb\u52a1\u200b\u6458\u8981\u200b \u200b\u67e5\u627e\u200b [<code>AutoModel</code>] \u200b\u652f\u6301\u200b\u7684\u200b\u4efb\u52a1\u200b.</p> <p></p> <p>\u200b\u73b0\u5728\u200b\u901a\u8fc7\u200b\u76f4\u63a5\u200b\u5c06\u200b\u5b57\u5178\u200b\u7684\u200b\u952e\u200b\u4f20\u7ed9\u200b\u5f20\u91cf\u200b\uff0c\u200b\u5c06\u200b\u9884\u5904\u7406\u200b\u7684\u200b\u8f93\u5165\u200b\u6279\u6b21\u200b\u4f20\u7ed9\u200b\u6a21\u578b\u200b\u3002</p> <pre><code>&gt;&gt;&gt; tf_outputs = tf_model(tf_batch)\n</code></pre> <p>\u200b\u6a21\u578b\u200b\u5728\u200b <code>logits</code> \u200b\u5c5e\u6027\u200b\u8f93\u51fa\u200b\u6700\u7ec8\u200b\u7684\u200b\u6fc0\u6d3b\u200b\u7ed3\u679c\u200b\u3002\u200b\u5728\u200b <code>logits</code> \u200b\u4e0a\u200b\u5e94\u7528\u200bsoftmax\u200b\u51fd\u6570\u200b\u6765\u200b\u67e5\u8be2\u200b\u6982\u7387\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; import tensorflow as tf\n\n&gt;&gt;&gt; tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)\n&gt;&gt;&gt; tf_predictions  # doctest: +IGNORE_RESULT\n</code></pre> </p> <p> <p>\u200b\u6240\u6709\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\uff08PyTorch \u200b\u6216\u200b TensorFlow\uff09\u200b\u5728\u200b\u6700\u7ec8\u200b\u7684\u200b\u6fc0\u6d3b\u200b\u51fd\u6570\u200b\uff08\u200b\u6bd4\u5982\u200b softmax\uff09\u200b\u4e4b\u524d\u200b \u200b\u8f93\u51fa\u200b\u5f20\u91cf\u200b\uff0c \u200b\u56e0\u4e3a\u200b\u6700\u7ec8\u200b\u7684\u200b\u6fc0\u6d3b\u200b\u51fd\u6570\u200b\u5e38\u5e38\u200b\u4e0e\u200b loss \u200b\u878d\u5408\u200b\u3002\u200b\u6a21\u578b\u200b\u7684\u200b\u8f93\u51fa\u200b\u662f\u200b\u7279\u6b8a\u200b\u7684\u200b\u6570\u636e\u200b\u7c7b\u200b\uff0c\u200b\u6240\u4ee5\u200b\u5b83\u4eec\u200b\u7684\u200b\u5c5e\u6027\u200b\u53ef\u4ee5\u200b\u5728\u200b IDE \u200b\u4e2d\u200b\u88ab\u200b\u81ea\u52a8\u200b\u8865\u5168\u200b\u3002\u200b\u6a21\u578b\u200b\u7684\u200b\u8f93\u51fa\u200b\u5c31\u200b\u50cf\u200b\u4e00\u4e2a\u200b\u5143\u7ec4\u200b\u6216\u200b\u5b57\u5178\u200b\uff08\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u6574\u6570\u200b\u3001\u200b\u5207\u7247\u200b\u6216\u200b\u5b57\u7b26\u4e32\u200b\u6765\u200b\u7d22\u5f15\u200b\u5b83\u200b\uff09\uff0c\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u4e3a\u200b None \u200b\u7684\u200b\u5c5e\u6027\u200b\u4f1a\u200b\u88ab\u200b\u5ffd\u7565\u200b\u3002</p> <p></p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#_2","title":"\u4fdd\u5b58\u200b\u6a21\u578b","text":"<p>  \u200b\u5f53\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u5fae\u8c03\u200b\u5b8c\u6210\u200b\uff0c\u200b\u4f60\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>PreTrainedModel.save_pretrained</code>] \u200b\u628a\u200b\u5b83\u200b\u548c\u200b\u5b83\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\u4fdd\u5b58\u200b\u4e0b\u6765\u200b\uff1a <pre><code>&gt;&gt;&gt; pt_save_directory = \"./pt_save_pretrained\"\n&gt;&gt;&gt; tokenizer.save_pretrained(pt_save_directory)  # doctest: +IGNORE_RESULT\n&gt;&gt;&gt; pt_model.save_pretrained(pt_save_directory)\n</code></pre> <p>\u200b\u5f53\u200b\u4f60\u200b\u51c6\u5907\u200b\u518d\u6b21\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>PreTrainedModel.from_pretrained</code>] \u200b\u52a0\u8f7d\u200b\u5b83\u200b\u4e86\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n</code></pre>  \u200b\u5f53\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u5fae\u8c03\u200b\u5b8c\u6210\u200b\uff0c\u200b\u4f60\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>TFPreTrainedModel.save_pretrained</code>] \u200b\u628a\u200b\u5b83\u200b\u548c\u200b\u5b83\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\u4fdd\u5b58\u200b\u4e0b\u6765\u200b\uff1a <pre><code>&gt;&gt;&gt; tf_save_directory = \"./tf_save_pretrained\"\n&gt;&gt;&gt; tokenizer.save_pretrained(tf_save_directory)  # doctest: +IGNORE_RESULT\n&gt;&gt;&gt; tf_model.save_pretrained(tf_save_directory)\n</code></pre> <p>\u200b\u5f53\u200b\u4f60\u200b\u51c6\u5907\u200b\u518d\u6b21\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>TFPreTrainedModel.from_pretrained</code>] \u200b\u52a0\u8f7d\u200b\u5b83\u200b\u4e86\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; tf_model = TFAutoModelForSequenceClassification.from_pretrained(\"./tf_save_pretrained\")\n</code></pre> </p> <p>\ud83e\udd17 Transformers \u200b\u6709\u200b\u4e00\u4e2a\u200b\u7279\u522b\u200b\u9177\u200b\u7684\u200b\u529f\u80fd\u200b\uff0c\u200b\u5b83\u200b\u80fd\u591f\u200b\u4fdd\u5b58\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\uff0c\u200b\u5e76\u4e14\u200b\u5c06\u200b\u5b83\u200b\u52a0\u8f7d\u200b\u4e3a\u200b PyTorch \u200b\u6216\u200b TensorFlow \u200b\u6a21\u578b\u200b\u3002<code>from_pt</code> \u200b\u6216\u200b <code>from_tf</code> \u200b\u53c2\u6570\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u6a21\u578b\u200b\u4ece\u200b\u4e00\u4e2a\u200b\u6846\u67b6\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u6846\u67b6\u200b\uff1a</p> <p> <p><pre><code>&gt;&gt;&gt; from transformers import AutoModel\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)\n&gt;&gt;&gt; pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)\n</code></pre> <p><pre><code>&gt;&gt;&gt; from transformers import TFAutoModel\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n&gt;&gt;&gt; tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n</code></pre> </p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#_3","title":"\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u6784\u5efa","text":"<p>\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4fee\u6539\u200b\u6a21\u578b\u200b\u7684\u200b\u914d\u7f6e\u200b\u7c7b\u6765\u200b\u6539\u53d8\u200b\u6a21\u578b\u200b\u7684\u200b\u6784\u5efa\u200b\u65b9\u5f0f\u200b\u3002\u200b\u914d\u7f6e\u200b\u6307\u660e\u200b\u4e86\u200b\u6a21\u578b\u200b\u7684\u200b\u5c5e\u6027\u200b\uff0c\u200b\u6bd4\u5982\u200b\u9690\u85cf\u200b\u5c42\u200b\u6216\u8005\u200b\u6ce8\u610f\u529b\u200b\u5934\u200b\u7684\u200b\u6570\u91cf\u200b\u3002\u200b\u5f53\u200b\u4f60\u200b\u4ece\u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200b\u914d\u7f6e\u200b\u7c7b\u200b\u521d\u59cb\u5316\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u4f60\u200b\u5c31\u200b\u5f00\u59cb\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u6784\u5efa\u200b\u4e86\u200b\u3002\u200b\u6a21\u578b\u200b\u5c5e\u6027\u200b\u662f\u200b\u968f\u673a\u200b\u521d\u59cb\u5316\u200b\u7684\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u5148\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff0c\u200b\u7136\u540e\u200b\u624d\u80fd\u200b\u5f97\u5230\u200b\u6709\u200b\u610f\u4e49\u200b\u7684\u200b\u7ed3\u679c\u200b\u3002</p> <p>\u200b\u901a\u8fc7\u200b\u5bfc\u5165\u200b [<code>AutoConfig</code>] \u200b\u6765\u200b\u5f00\u59cb\u200b\uff0c\u200b\u4e4b\u540e\u200b\u52a0\u8f7d\u200b\u4f60\u200b\u60f3\u200b\u4fee\u6539\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002\u200b\u5728\u200b [<code>AutoConfig.from_pretrained</code>] \u200b\u4e2d\u200b\uff0c\u200b\u4f60\u200b\u80fd\u591f\u200b\u6307\u5b9a\u200b\u60f3\u8981\u200b\u4fee\u6539\u200b\u7684\u200b\u5c5e\u6027\u200b\uff0c\u200b\u6bd4\u5982\u200b\u6ce8\u610f\u529b\u200b\u5934\u200b\u7684\u200b\u6570\u91cf\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoConfig\n\n&gt;&gt;&gt; my_config = AutoConfig.from_pretrained(\"distilbert-base-uncased\", n_heads=12)\n</code></pre> <p>  \u200b\u4f7f\u7528\u200b [<code>AutoModel.from_config</code>] \u200b\u6839\u636e\u200b\u4f60\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\uff1a <p><pre><code>&gt;&gt;&gt; from transformers import AutoModel\n\n&gt;&gt;&gt; my_model = AutoModel.from_config(my_config)\n</code></pre>  \u200b\u4f7f\u7528\u200b [<code>TFAutoModel.from_config</code>] \u200b\u6839\u636e\u200b\u4f60\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\uff1a <p><pre><code>&gt;&gt;&gt; from transformers import TFAutoModel\n\n&gt;&gt;&gt; my_model = TFAutoModel.from_config(my_config)\n</code></pre> </p> <p>\u200b\u67e5\u9605\u200b \u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u81ea\u5b9a\u4e49\u200b\u7ed3\u6784\u200b \u200b\u6307\u5357\u200b\u83b7\u53d6\u200b\u66f4\u200b\u591a\u200b\u5173\u4e8e\u200b\u6784\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u200b\u7684\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#trainer-pytorch","title":"Trainer - PyTorch \u200b\u4f18\u5316\u200b\u8bad\u7ec3\u200b\u5faa\u73af","text":"<p>\u200b\u6240\u6709\u200b\u7684\u200b\u6a21\u578b\u200b\u90fd\u200b\u662f\u200b\u6807\u51c6\u200b\u7684\u200b <code>torch.nn.Module</code>\uff0c\u200b\u6240\u4ee5\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200b\u4efb\u4f55\u200b\u5178\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u5b83\u4eec\u200b\u3002\u200b\u5f53\u200b\u4f60\u200b\u7f16\u5199\u200b\u81ea\u5df1\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u65f6\u200b\uff0c\ud83e\udd17 Transformers \u200b\u4e3a\u200b PyTorch \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b [<code>Trainer</code>] \u200b\u7c7b\u200b\uff0c\u200b\u5b83\u200b\u5305\u542b\u200b\u4e86\u200b\u57fa\u7840\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u5e76\u4e14\u200b\u4e3a\u200b\u8bf8\u5982\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u7b49\u200b\u7279\u6027\u200b\u589e\u52a0\u200b\u4e86\u200b\u989d\u5916\u200b\u7684\u200b\u529f\u80fd\u200b\u3002</p> <p>\u200b\u53d6\u51b3\u4e8e\u200b\u4f60\u200b\u7684\u200b\u4efb\u52a1\u200b, \u200b\u4f60\u200b\u901a\u5e38\u200b\u53ef\u4ee5\u200b\u4f20\u9012\u200b\u4ee5\u4e0b\u200b\u7684\u200b\u53c2\u6570\u200b\u7ed9\u200b [<code>Trainer</code>]\uff1a</p> <ol> <li>[<code>PreTrainedModel</code>] \u200b\u6216\u8005\u200b <code>torch.nn.Module</code>\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from transformers import AutoModelForSequenceClassification\n\n&gt;&gt;&gt; model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <ol> <li>[<code>TrainingArguments</code>] \u200b\u542b\u6709\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4fee\u6539\u200b\u7684\u200b\u6a21\u578b\u200b\u8d85\u200b\u53c2\u6570\u200b\uff0c\u200b\u6bd4\u5982\u200b\u5b66\u4e60\u200b\u7387\u200b\uff0c\u200b\u6279\u6b21\u200b\u5927\u5c0f\u200b\u548c\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u7684\u200b\u8fed\u4ee3\u200b\u6b21\u6570\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u6ca1\u6709\u200b\u6307\u5b9a\u200b\u8bad\u7ec3\u200b\u53c2\u6570\u200b\uff0c\u200b\u90a3\u4e48\u200b\u5b83\u4f1a\u200b\u4f7f\u7528\u200b\u9ed8\u8ba4\u503c\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from transformers import TrainingArguments\n\n&gt;&gt;&gt; training_args = TrainingArguments(\n...     output_dir=\"path/to/save/folder/\",\n...     learning_rate=2e-5,\n...     per_device_train_batch_size=8,\n...     per_device_eval_batch_size=8,\n...     num_train_epochs=2,\n... )\n</code></pre> <ol> <li>\u200b\u4e00\u4e2a\u200b\u9884\u5904\u7406\u200b\u7c7b\u200b\uff0c\u200b\u6bd4\u5982\u200b\u5206\u8bcd\u5668\u200b\uff0c\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\u6216\u8005\u200b\u5904\u7406\u5668\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <ol> <li>\u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from datasets import load_dataset\n\n&gt;&gt;&gt; dataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT\n</code></pre> <ol> <li>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u7ed9\u200b\u6570\u636e\u200b\u96c6\u200b\u5206\u8bcd\u200b\u7684\u200b\u51fd\u6570\u200b\uff0c\u200b\u5e76\u4e14\u200b\u4f7f\u7528\u200b [<code>~datasets.Dataset.map</code>] \u200b\u5e94\u7528\u200b\u5230\u200b\u6574\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; def tokenize_dataset(dataset):\n...     return tokenizer(dataset[\"text\"])\n\n&gt;&gt;&gt; dataset = dataset.map(tokenize_dataset, batched=True)\n</code></pre> <ol> <li>\u200b\u7528\u6765\u200b\u4ece\u200b\u6570\u636e\u200b\u96c6\u4e2d\u200b\u521b\u5efa\u200b\u6279\u6b21\u200b\u7684\u200b [<code>DataCollatorWithPadding</code>]\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from transformers import DataCollatorWithPadding\n\n&gt;&gt;&gt; data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u628a\u200b\u6240\u6709\u200b\u7684\u200b\u7c7b\u200b\u4f20\u7ed9\u200b [<code>Trainer</code>]\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import Trainer\n\n&gt;&gt;&gt; trainer = Trainer(\n...     model=model,\n...     args=training_args,\n...     train_dataset=dataset[\"train\"],\n...     eval_dataset=dataset[\"test\"],\n...     tokenizer=tokenizer,\n...     data_collator=data_collator,\n... )  # doctest: +SKIP\n</code></pre> <p>\u200b\u4e00\u5207\u200b\u51c6\u5907\u5c31\u7eea\u200b\u540e\u200b\uff0c\u200b\u8c03\u7528\u200b [<code>~Trainer.train</code>] \u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; trainer.train()  # doctest: +SKIP\n</code></pre> <p> <p>\u200b\u5bf9\u4e8e\u200b\u50cf\u200b\u7ffb\u8bd1\u200b\u6216\u200b\u6458\u8981\u200b\u8fd9\u4e9b\u200b\u4f7f\u7528\u200b\u5e8f\u5217\u200b\u5230\u200b\u5e8f\u5217\u200b\u6a21\u578b\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u7528\u200b [<code>Seq2SeqTrainer</code>] \u200b\u548c\u200b [<code>Seq2SeqTrainingArguments</code>] \u200b\u6765\u200b\u66ff\u4ee3\u200b\u3002</p> <p></p> <p>\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5b50\u200b\u7c7b\u5316\u200b [<code>Trainer</code>] \u200b\u4e2d\u200b\u7684\u200b\u65b9\u6cd5\u200b\u6765\u81ea\u200b\u5b9a\u4e49\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u3002\u200b\u8fd9\u6837\u200b\u4f60\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u81ea\u5b9a\u4e49\u200b\u50cf\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\uff0c\u200b\u4f18\u5316\u200b\u5668\u200b\u548c\u200b\u8c03\u5ea6\u200b\u5668\u200b\u8fd9\u6837\u200b\u7684\u200b\u7279\u6027\u200b\u3002\u200b\u67e5\u9605\u200b [<code>Trainer</code>] \u200b\u53c2\u8003\u624b\u518c\u200b\u4e86\u89e3\u200b\u54ea\u4e9b\u200b\u65b9\u6cd5\u200b\u80fd\u591f\u200b\u88ab\u5b50\u200b\u7c7b\u5316\u200b\u3002</p> <p>\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u81ea\u5b9a\u4e49\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u7684\u200b\u65b9\u5f0f\u200b\u662f\u200b\u901a\u8fc7\u200b\u56de\u8c03\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u56de\u8c03\u200b\u6765\u200b\u4e0e\u200b\u5176\u4ed6\u200b\u5e93\u200b\u96c6\u6210\u200b\uff0c\u200b\u67e5\u770b\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u6765\u200b\u62a5\u544a\u200b\u8fdb\u5ea6\u200b\u6216\u200b\u63d0\u524d\u7ed3\u675f\u200b\u8bad\u7ec3\u200b\u3002\u200b\u56de\u8c03\u200b\u4e0d\u4f1a\u200b\u4fee\u6539\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u3002\u200b\u5982\u679c\u200b\u60f3\u200b\u81ea\u5b9a\u4e49\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u7b49\u200b\uff0c\u200b\u5c31\u200b\u9700\u8981\u200b\u5b50\u200b\u7c7b\u5316\u200b [<code>Trainer</code>] \u200b\u4e86\u200b\u3002</p>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#tensorflow","title":"\u4f7f\u7528\u200b Tensorflow \u200b\u8bad\u7ec3","text":"<p>\u200b\u6240\u6709\u200b\u6a21\u578b\u200b\u90fd\u200b\u662f\u200b\u6807\u51c6\u200b\u7684\u200b <code>tf.keras.Model</code>\uff0c\u200b\u6240\u4ee5\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b Keras API \u200b\u5b9e\u73b0\u200b\u5728\u200b Tensorflow \u200b\u4e2d\u200b\u8bad\u7ec3\u200b\u3002\ud83e\udd17 Transformers \u200b\u63d0\u4f9b\u200b\u4e86\u200b [<code>~TFPreTrainedModel.prepare_tf_dataset</code>] \u200b\u65b9\u6cd5\u200b\u6765\u200b\u8f7b\u677e\u200b\u5730\u200b\u5c06\u200b\u6570\u636e\u200b\u96c6\u200b\u52a0\u8f7d\u200b\u4e3a\u200b <code>tf.data.Dataset</code>\uff0c\u200b\u8fd9\u6837\u200b\u4f60\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b Keras \u200b\u7684\u200b <code>compile</code> \u200b\u548c\u200b <code>fit</code> \u200b\u65b9\u6cd5\u200b\u9a6c\u4e0a\u200b\u5f00\u59cb\u200b\u8bad\u7ec3\u200b\u3002</p> <ol> <li>\u200b\u4f7f\u7528\u200b [<code>TFPreTrainedModel</code>] \u200b\u6216\u8005\u200b <code>tf.keras.Model</code> \u200b\u6765\u200b\u5f00\u59cb\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from transformers import TFAutoModelForSequenceClassification\n\n&gt;&gt;&gt; model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <ol> <li>\u200b\u4e00\u4e2a\u200b\u9884\u5904\u7406\u200b\u7c7b\u200b\uff0c\u200b\u6bd4\u5982\u200b\u5206\u8bcd\u5668\u200b\uff0c\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\u6216\u8005\u200b\u5904\u7406\u5668\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <ol> <li>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u7ed9\u200b\u6570\u636e\u200b\u96c6\u200b\u5206\u8bcd\u200b\u7684\u200b\u51fd\u6570\u200b</li> </ol> <pre><code>&gt;&gt;&gt; def tokenize_dataset(dataset):\n...     return tokenizer(dataset[\"text\"])  # doctest: +SKIP\n</code></pre> <ol> <li>\u200b\u4f7f\u7528\u200b [<code>~datasets.Dataset.map</code>] \u200b\u5c06\u200b\u5206\u8bcd\u5668\u200b\u5e94\u7528\u200b\u5230\u200b\u6574\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u4e4b\u540e\u200b\u5c06\u200b\u6570\u636e\u200b\u96c6\u200b\u548c\u200b\u5206\u8bcd\u5668\u200b\u4f20\u7ed9\u200b [<code>~TFPreTrainedModel.prepare_tf_dataset</code>]\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u9700\u8981\u7684\u8bdd\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u5728\u200b\u8fd9\u91cc\u200b\u6539\u53d8\u200b\u6279\u6b21\u200b\u5927\u5c0f\u200b\u548c\u200b\u662f\u5426\u200b\u6253\u4e71\u200b\u6570\u636e\u200b\u96c6\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; dataset = dataset.map(tokenize_dataset)  # doctest: +SKIP\n&gt;&gt;&gt; tf_dataset = model.prepare_tf_dataset(\n...     dataset, batch_size=16, shuffle=True, tokenizer=tokenizer\n... )  # doctest: +SKIP\n</code></pre> <ol> <li>\u200b\u4e00\u5207\u200b\u51c6\u5907\u5c31\u7eea\u200b\u540e\u200b\uff0c\u200b\u8c03\u7528\u200b <code>compile</code> \u200b\u548c\u200b <code>fit</code> \u200b\u5f00\u59cb\u200b\u8bad\u7ec3\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from tensorflow.keras.optimizers import Adam\n\n&gt;&gt;&gt; model.compile(optimizer=Adam(3e-5))\n&gt;&gt;&gt; model.fit(dataset)  # doctest: +SKIP\n</code></pre>"},{"location":"1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/quicktour/#_4","title":"\u63a5\u4e0b\u6765\u200b\u505a\u200b\u4ec0\u4e48\u200b?","text":"<p>\u200b\u73b0\u5728\u200b\u4f60\u200b\u5df2\u7ecf\u200b\u5b8c\u6210\u200b\u4e86\u200b \ud83e\udd17 Transformers \u200b\u7684\u200b\u5feb\u901f\u200b\u4e0a\u200b\u624b\u200b\u6559\u7a0b\u200b\uff0c\u200b\u6765\u200b\u770b\u770b\u200b\u6211\u4eec\u200b\u7684\u200b\u6307\u5357\u200b\u5e76\u4e14\u200b\u5b66\u4e60\u200b\u5982\u4f55\u200b\u505a\u200b\u4e00\u4e9b\u200b\u66f4\u200b\u5177\u4f53\u200b\u7684\u200b\u4e8b\u60c5\u200b\uff0c\u200b\u6bd4\u5982\u200b\u5199\u200b\u4e00\u4e2a\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\uff0c\u200b\u4e3a\u200b\u67d0\u4e2a\u200b\u4efb\u52a1\u200b\u5fae\u8c03\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u4ee5\u53ca\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u811a\u672c\u200b\u6765\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u6709\u200b\u5174\u8da3\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b \ud83e\udd17 Transformers \u200b\u7684\u200b\u6838\u5fc3\u200b\u7ae0\u8282\u200b\uff0c\u200b\u90a3\u200b\u5c31\u200b\u559d\u676f\u200b\u5496\u5561\u200b\u7136\u540e\u200b\u6765\u200b\u770b\u770b\u200b\u6211\u4eec\u200b\u7684\u200b\u6982\u5ff5\u200b\u6307\u5357\u200b\u5427\u200b\uff01</p>"},{"location":"2-%E6%95%99%E7%A8%8B/accelerate/","title":"Accelerate","text":""},{"location":"2-%E6%95%99%E7%A8%8B/accelerate/#_1","title":"\ud83e\udd17 \u200b\u52a0\u901f\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3","text":"<p>\u200b\u968f\u7740\u200b\u6a21\u578b\u200b\u53d8\u5f97\u200b\u8d8a\u6765\u8d8a\u200b\u5927\u200b\uff0c\u200b\u5e76\u884c\u6027\u200b\u5df2\u7ecf\u200b\u6210\u4e3a\u200b\u5728\u200b\u6709\u9650\u200b\u786c\u4ef6\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u66f4\u5927\u200b\u6a21\u578b\u200b\u548c\u200b\u52a0\u901f\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\u7684\u200b\u7b56\u7565\u200b\uff0c\u200b\u589e\u52a0\u200b\u4e86\u200b\u6570\u4e2a\u200b\u6570\u91cf\u7ea7\u200b\u3002\u200b\u5728\u200bHugging Face\uff0c\u200b\u6211\u4eec\u200b\u521b\u5efa\u200b\u4e86\u200b\ud83e\udd17 \u200b\u52a0\u901f\u200b\u5e93\u200b\uff0c\u200b\u4ee5\u200b\u5e2e\u52a9\u200b\u7528\u6237\u200b\u5728\u200b\u4efb\u4f55\u200b\u7c7b\u578b\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u8bbe\u7f6e\u200b\u4e0a\u200b\u8f7b\u677e\u200b\u8bad\u7ec3\u200b\ud83e\udd17 Transformers\u200b\u6a21\u578b\u200b\uff0c\u200b\u65e0\u8bba\u662f\u200b\u5728\u200b\u4e00\u53f0\u200b\u673a\u5668\u200b\u4e0a\u200b\u7684\u200b\u591a\u4e2a\u200bGPU\u200b\u8fd8\u662f\u200b\u5728\u200b\u591a\u4e2a\u200b\u673a\u5668\u200b\u4e0a\u200b\u7684\u200b\u591a\u4e2a\u200bGPU\u3002\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u81ea\u5b9a\u4e49\u200b\u60a8\u200b\u7684\u200b\u539f\u751f\u200bPyTorch\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\uff0c\u200b\u4ee5\u200b\u542f\u7528\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\u4e2d\u200b\u7684\u200b\u8bad\u7ec3\u200b\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/accelerate/#_2","title":"\u8bbe\u7f6e","text":"<p>\u200b\u901a\u8fc7\u200b\u5b89\u88c5\u200b\ud83e\udd17 \u200b\u52a0\u901f\u200b\u5f00\u59cb\u200b:</p> <pre><code>pip install accelerate\n</code></pre> <p>\u200b\u7136\u540e\u200b\u5bfc\u5165\u200b\u5e76\u200b\u521b\u5efa\u200b[<code>~accelerate.Accelerator</code>]\u200b\u5bf9\u8c61\u200b\u3002[<code>~accelerate.Accelerator</code>]\u200b\u5c06\u200b\u81ea\u52a8\u68c0\u6d4b\u200b\u60a8\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u8bbe\u7f6e\u200b\u7c7b\u578b\u200b\uff0c\u200b\u5e76\u200b\u521d\u59cb\u5316\u200b\u6240\u6709\u200b\u5fc5\u8981\u200b\u7684\u200b\u8bad\u7ec3\u200b\u7ec4\u4ef6\u200b\u3002\u200b\u60a8\u200b\u4e0d\u200b\u9700\u8981\u200b\u663e\u5f0f\u200b\u5730\u200b\u5c06\u200b\u6a21\u578b\u200b\u653e\u5728\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from accelerate import Accelerator\n\n&gt;&gt;&gt; accelerator = Accelerator()\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/accelerate/#_3","title":"\u51c6\u5907\u200b\u52a0\u901f","text":"<p>\u200b\u4e0b\u200b\u4e00\u6b65\u200b\u662f\u200b\u5c06\u200b\u6240\u6709\u200b\u76f8\u5173\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5bf9\u8c61\u200b\u4f20\u9012\u200b\u7ed9\u200b[<code>~accelerate.Accelerator.prepare</code>]\u200b\u65b9\u6cd5\u200b\u3002\u200b\u8fd9\u200b\u5305\u62ec\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u548c\u200b\u8bc4\u4f30\u200bDataLoader\u3001\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u548c\u200b\u4e00\u4e2a\u200b\u4f18\u5316\u200b\u5668\u200b:</p> <pre><code>&gt;&gt;&gt; train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n...     train_dataloader, eval_dataloader, model, optimizer\n... )\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/accelerate/#_4","title":"\u53cd\u5411\u200b\u4f20\u64ad","text":"<p>\u200b\u6700\u540e\u200b\u4e00\u6b65\u200b\u662f\u200b\u7528\u200b\ud83e\udd17 \u200b\u52a0\u901f\u200b\u7684\u200b[<code>~accelerate.Accelerator.backward</code>]\u200b\u65b9\u6cd5\u200b\u66ff\u6362\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u4e2d\u200b\u7684\u200b\u5178\u578b\u200b<code>loss.backward()</code>:</p> <pre><code>&gt;&gt;&gt; for epoch in range(num_epochs):\n...     for batch in train_dataloader:\n...         outputs = model(**batch)\n...         loss = outputs.loss\n...         accelerator.backward(loss)\n\n...         optimizer.step()\n...         lr_scheduler.step()\n...         optimizer.zero_grad()\n...         progress_bar.update(1)\n</code></pre> <p>\u200b\u5982\u200b\u60a8\u200b\u5728\u200b\u4e0b\u9762\u200b\u7684\u200b\u4ee3\u7801\u200b\u4e2d\u6240\u89c1\u200b\uff0c\u200b\u60a8\u200b\u53ea\u200b\u9700\u8981\u200b\u6dfb\u52a0\u200b\u56db\u884c\u200b\u989d\u5916\u200b\u7684\u200b\u4ee3\u7801\u200b\u5230\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u4e2d\u200b\u5373\u53ef\u200b\u542f\u7528\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\uff01</p> <pre><code>+ from accelerate import Accelerator\n  from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler\n\n+ accelerator = Accelerator()\n\n  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n  optimizer = AdamW(model.parameters(), lr=3e-5)\n\n- device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n- model.to(device)\n\n+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n+     train_dataloader, eval_dataloader, model, optimizer\n+ )\n\n  num_epochs = 3\n  num_training_steps = num_epochs * len(train_dataloader)\n  lr_scheduler = get_scheduler(\n      \"linear\",\n      optimizer=optimizer,\n      num_warmup_steps=0,\n      num_training_steps=num_training_steps\n  )\n\n  progress_bar = tqdm(range(num_training_steps))\n\n  model.train()\n  for epoch in range(num_epochs):\n      for batch in train_dataloader:\n-         batch = {k: v.to(device) for k, v in batch.items()}\n          outputs = model(**batch)\n          loss = outputs.loss\n-         loss.backward()\n+         accelerator.backward(loss)\n\n          optimizer.step()\n          lr_scheduler.step()\n          optimizer.zero_grad()\n          progress_bar.update(1)\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/accelerate/#_5","title":"\u8bad\u7ec3","text":"<p>\u200b\u5728\u200b\u6dfb\u52a0\u200b\u4e86\u200b\u76f8\u5173\u200b\u4ee3\u7801\u200b\u884c\u540e\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5728\u200b\u811a\u672c\u200b\u6216\u200b\u7b14\u8bb0\u672c\u200b\uff08\u200b\u5982\u200bColaboratory\uff09\u200b\u4e2d\u200b\u542f\u52a8\u200b\u8bad\u7ec3\u200b\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/accelerate/#_6","title":"\u7528\u200b\u811a\u672c\u200b\u8bad\u7ec3","text":"<p>\u200b\u5982\u679c\u200b\u60a8\u200b\u4ece\u200b\u811a\u672c\u200b\u4e2d\u200b\u8fd0\u884c\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u8bf7\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u4ee5\u200b\u521b\u5efa\u200b\u548c\u200b\u4fdd\u5b58\u200b\u914d\u7f6e\u6587\u4ef6\u200b:</p> <pre><code>accelerate config\n</code></pre> <p>\u200b\u7136\u540e\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u542f\u52a8\u200b\u8bad\u7ec3\u200b:</p> <pre><code>accelerate launch train.py\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/accelerate/#_7","title":"\u7528\u200b\u7b14\u8bb0\u672c\u200b\u8bad\u7ec3","text":"<p>\ud83e\udd17 \u200b\u52a0\u901f\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u7b14\u8bb0\u672c\u200b\u4e2d\u200b\u8fd0\u884c\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u8ba1\u5212\u200b\u4f7f\u7528\u200bColaboratory\u200b\u7684\u200bTPU\uff0c\u200b\u5219\u200b\u53ef\u200b\u5728\u200b\u5176\u4e2d\u200b\u8fd0\u884c\u200b\u3002\u200b\u5c06\u200b\u8d1f\u8d23\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6240\u6709\u200b\u4ee3\u7801\u200b\u5305\u88c5\u200b\u5728\u200b\u4e00\u4e2a\u200b\u51fd\u6570\u200b\u4e2d\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u4f20\u9012\u200b\u7ed9\u200b[<code>~accelerate.notebook_launcher</code>]:</p> <pre><code>&gt;&gt;&gt; from accelerate import notebook_launcher\n\n&gt;&gt;&gt; notebook_launcher(training_function)\n</code></pre> <p>\u200b\u6709\u5173\u200b\ud83e\udd17 \u200b\u52a0\u901f\u200b\u53ca\u5176\u200b\u4e30\u5bcc\u200b\u529f\u80fd\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u6587\u6863\u200b\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/","title":"Pipeline tutorial","text":""},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#pipeline","title":"\u63a8\u7406\u200bpipeline","text":"<p>[<code>pipeline</code>] \u200b\u8ba9\u200b\u4f7f\u7528\u200bHub\u200b\u4e0a\u200b\u7684\u200b\u4efb\u4f55\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u4efb\u4f55\u200b\u8bed\u8a00\u200b\u3001\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u3001\u200b\u8bed\u97f3\u200b\u4ee5\u53ca\u200b\u591a\u200b\u6a21\u6001\u200b\u4efb\u52a1\u200b\u7684\u200b\u63a8\u7406\u200b\u53d8\u5f97\u200b\u975e\u5e38\u7b80\u5355\u200b\u3002\u200b\u5373\u4f7f\u200b\u60a8\u200b\u5bf9\u200b\u7279\u5b9a\u200b\u7684\u200b\u6a21\u6001\u200b\u6ca1\u6709\u200b\u7ecf\u9a8c\u200b\uff0c\u200b\u6216\u8005\u200b\u4e0d\u200b\u719f\u6089\u200b\u6a21\u578b\u200b\u7684\u200b\u6e90\u7801\u200b\uff0c\u200b\u60a8\u200b\u4ecd\u7136\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b[<code>pipeline</code>]\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\uff01\u200b\u672c\u200b\u6559\u7a0b\u200b\u5c06\u200b\u6559\u200b\u60a8\u200b\uff1a</p> <ul> <li>\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b[<code>pipeline</code>] \u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\u3002</li> <li>\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u7279\u5b9a\u200b\u7684\u200b<code>tokenizer</code>(\u200b\u5206\u8bcd\u5668\u200b)\u200b\u6216\u200b\u6a21\u578b\u200b\u3002</li> <li>\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b[<code>pipeline</code>] \u200b\u8fdb\u884c\u200b\u97f3\u9891\u200b\u3001\u200b\u89c6\u89c9\u200b\u548c\u200b\u591a\u200b\u6a21\u6001\u200b\u4efb\u52a1\u200b\u7684\u200b\u63a8\u7406\u200b\u3002</li> </ul> <p> <p>\u200b\u8bf7\u200b\u67e5\u770b\u200b[<code>pipeline</code>]\u200b\u6587\u6863\u200b\u4ee5\u200b\u83b7\u53d6\u200b\u5df2\u200b\u652f\u6301\u200b\u7684\u200b\u4efb\u52a1\u200b\u548c\u200b\u53ef\u7528\u200b\u53c2\u6570\u200b\u7684\u200b\u5b8c\u6574\u200b\u5217\u8868\u200b\u3002</p> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#pipeline_1","title":"Pipeline\u200b\u4f7f\u7528","text":"<p>\u200b\u867d\u7136\u200b\u6bcf\u4e2a\u200b\u4efb\u52a1\u200b\u90fd\u200b\u6709\u200b\u4e00\u4e2a\u200b\u5173\u8054\u200b\u7684\u200b[<code>pipeline</code>]\uff0c\u200b\u4f46\u200b\u4f7f\u7528\u200b\u901a\u7528\u200b\u7684\u200b\u62bd\u8c61\u200b\u7684\u200b[<code>pipeline</code>]\u200b\u66f4\u52a0\u200b\u7b80\u5355\u200b\uff0c\u200b\u5176\u4e2d\u200b\u5305\u542b\u200b\u6240\u6709\u200b\u7279\u5b9a\u200b\u4efb\u52a1\u200b\u7684\u200b<code>pipelines</code>\u3002[<code>pipeline</code>]\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200b\u9ed8\u8ba4\u200b\u6a21\u578b\u200b\u548c\u200b\u4e00\u4e2a\u200b\u80fd\u591f\u200b\u8fdb\u884c\u200b\u4efb\u52a1\u200b\u63a8\u7406\u200b\u7684\u200b\u9884\u5904\u7406\u200b\u7c7b\u200b\u3002\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4ee5\u200b\u4f7f\u7528\u200b[<code>pipeline</code>]\u200b\u8fdb\u884c\u200b\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b\uff08ASR\uff09\u200b\u6216\u200b\u8bed\u97f3\u200b\u8f6c\u200b\u6587\u672c\u200b\u4e3a\u4f8b\u200b\u3002</p> <ol> <li>\u200b\u9996\u5148\u200b\uff0c\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b[<code>pipeline</code>]\u200b\u5e76\u200b\u6307\u5b9a\u200b\u63a8\u7406\u200b\u4efb\u52a1\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; transcriber = pipeline(task=\"automatic-speech-recognition\")\n</code></pre> <ol> <li>\u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u8f93\u5165\u200b\u4f20\u9012\u200b\u7ed9\u200b[<code>pipeline</code>]\u3002\u200b\u5bf9\u4e8e\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b\uff0c\u200b\u8fd9\u200b\u901a\u5e38\u200b\u662f\u200b\u4e00\u4e2a\u200b\u97f3\u9891\u200b\u8f93\u5165\u200b\u6587\u4ef6\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}\n</code></pre> <p>\u200b\u60a8\u200b\u6ca1\u6709\u200b\u5f97\u5230\u200b\u60a8\u200b\u671f\u671b\u200b\u7684\u200b\u7ed3\u679c\u200b\uff1f\u200b\u53ef\u4ee5\u200b\u5728\u200bHub\u200b\u4e0a\u200b\u67e5\u770b\u200b\u4e00\u4e9b\u200b\u6700\u200b\u53d7\u6b22\u8fce\u200b\u7684\u200b\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b\u6a21\u578b\u200b  \uff0c\u200b\u770b\u770b\u200b\u662f\u5426\u200b\u53ef\u4ee5\u200b\u83b7\u5f97\u200b\u66f4\u597d\u200b\u7684\u200b\u8f6c\u5f55\u200b\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5c1d\u8bd5\u200b\u6765\u81ea\u200b OpenAI \u200b\u7684\u200bWhisper large-v2 \u200b\u6a21\u578b\u200b\u3002Whisperb\u200b\u6bd4\u200bWav2Vec2\u200b\u665a\u200b2\u200b\u5e74\u200b\u53d1\u5e03\u200b\uff0c\u200b\u4f7f\u7528\u200b\u63a5\u8fd1\u200b10\u200b\u500d\u200b\u7684\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u4e86\u200b\u8bad\u7ec3\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5b83\u200b\u5728\u200b\u5927\u591a\u6570\u200b\u4e0b\u6e38\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b\u4e0a\u200b\u51fb\u8d25\u200b\u4e86\u200bWav2Vec2\u3002 \u200b\u5b83\u200b\u8fd8\u200b\u5177\u6709\u200b\u9884\u6d4b\u200b\u6807\u70b9\u200b\u548c\u200b\u5927\u5c0f\u5199\u200b\u7684\u200b\u9644\u52a0\u200b\u4f18\u52bf\u200b\uff0c\u200b\u800c\u200bWav2Vec2\u200b\u5219\u200b\u65e0\u6cd5\u200b\u5b9e\u73b0\u200b\u8fd9\u4e9b\u200b\u529f\u80fd\u200b\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5728\u200b\u8fd9\u91cc\u200b\u5c1d\u8bd5\u200b\u4e00\u4e0b\u200b\uff0c\u200b\u770b\u770b\u200b\u5b83\u200b\u7684\u200b\u8868\u73b0\u200b\u5982\u4f55\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; transcriber = pipeline(model=\"openai/whisper-large-v2\")\n&gt;&gt;&gt; transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u8fd9\u4e2a\u200b\u7ed3\u679c\u200b\u770b\u8d77\u6765\u200b\u66f4\u200b\u51c6\u786e\u200b\u4e86\u200b\uff01\u200b\u8981\u200b\u8fdb\u884c\u200b\u6df1\u5165\u200b\u7684\u200bWav2Vec2\u200b\u4e0e\u200bWhisper\u200b\u6bd4\u8f83\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u97f3\u9891\u200b\u53d8\u6362\u5668\u200b\u8bfe\u7a0b\u200b\u3002 \u200b\u6211\u4eec\u200b\u9f13\u52b1\u200b\u60a8\u200b\u5728\u200b Hub \u200b\u4e0a\u200b\u67e5\u770b\u200b\u4e0d\u540c\u200b\u8bed\u8a00\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u4e13\u4e1a\u200b\u9886\u57df\u200b\u7684\u200b\u6a21\u578b\u200b\u7b49\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200bHub\u200b\u4e0a\u200b\u76f4\u63a5\u200b\u67e5\u770b\u200b\u5e76\u200b\u6bd4\u8f83\u200b\u6a21\u578b\u200b\u7684\u200b\u7ed3\u679c\u200b\uff0c\u200b\u4ee5\u200b\u786e\u5b9a\u200b\u662f\u5426\u200b\u9002\u5408\u200b\u6216\u200b\u5904\u7406\u200b\u8fb9\u7f18\u200b\u60c5\u51b5\u200b\u662f\u5426\u200b\u6bd4\u200b\u5176\u4ed6\u200b\u6a21\u578b\u200b\u66f4\u597d\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u6ca1\u6709\u200b\u627e\u5230\u200b\u9002\u7528\u200b\u4e8e\u200b\u60a8\u200b\u7684\u200b\u7528\u4f8b\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u60a8\u200b\u59cb\u7ec8\u200b\u53ef\u4ee5\u200b\u8bad\u7ec3\u200b\u81ea\u5df1\u200b\u7684\u200b\u6a21\u578b\u200b\uff01</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200b\u591a\u4e2a\u200b\u8f93\u5165\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u8f93\u5165\u200b\u4f5c\u4e3a\u200b\u5217\u8868\u200b\u4f20\u9012\u200b\uff1a</p> <pre><code>transcriber(\n    [\n        \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\",\n        \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\",\n    ]\n)\n</code></pre> <p><code>Pipelines</code>\u200b\u975e\u5e38\u9002\u5408\u200b\u7528\u4e8e\u200b\u6d4b\u8bd5\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u4ece\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u5207\u6362\u200b\u5230\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u975e\u5e38\u200b\u7410\u788e\u200b\uff1b\u200b\u4f46\u662f\u200b\uff0c\u200b\u8fd8\u6709\u200b\u4e00\u4e9b\u200b\u65b9\u6cd5\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u5b83\u4eec\u200b\u4f18\u5316\u200b\u540e\u200b\u7528\u4e8e\u200b\u5927\u578b\u200b\u5de5\u4f5c\u200b\u8d1f\u8f7d\u200b\u800c\u200b\u4e0d\u4ec5\u4ec5\u200b\u662f\u200b\u6d4b\u8bd5\u200b\u3002\u200b\u8bf7\u200b\u67e5\u770b\u200b\u4ee5\u4e0b\u200b\u6307\u5357\u200b\uff0c\u200b\u6df1\u5165\u63a2\u8ba8\u200b\u5982\u4f55\u200b\u8fed\u4ee3\u200b\u6574\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\u6216\u200b\u5728\u200bWeb\u200b\u670d\u52a1\u5668\u200b\u4e2d\u200b\u4f7f\u7528\u200b<code>Pipelines</code>\uff1a * \u200b\u5728\u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u4f7f\u7528\u200b\u6d41\u6c34\u7ebf\u200b * \u200b\u5728\u200bWeb\u200b\u670d\u52a1\u5668\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u6d41\u6c34\u7ebf\u200b</p>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#_1","title":"\u53c2\u6570","text":"<p>[<code>pipeline</code>] \u200b\u652f\u6301\u200b\u8bb8\u591a\u200b\u53c2\u6570\u200b\uff1b\u200b\u6709\u4e9b\u200b\u662f\u200b\u9002\u7528\u200b\u4e8e\u200b\u7279\u5b9a\u200b\u4efb\u52a1\u200b\u7684\u200b\uff0c\u200b\u800c\u200b\u6709\u4e9b\u200b\u9002\u7528\u200b\u4e8e\u200b\u6240\u6709\u200b<code>pipeline</code>\u3002\u200b\u901a\u5e38\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u4efb\u4f55\u200b\u5730\u65b9\u200b\u6307\u5b9a\u200b\u5bf9\u5e94\u200b\u53c2\u6570\u200b\uff1a</p> <pre><code>transcriber = pipeline(model=\"openai/whisper-large-v2\", my_parameter=1)\n\nout = transcriber(...)  # This will use `my_parameter=1`.\nout = transcriber(..., my_parameter=2)  # This will override and use `my_parameter=2`.\nout = transcriber(...)  # This will go back to using `my_parameter=1`.\n</code></pre> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u67e5\u770b\u200b\u5176\u4e2d\u200b\u7684\u200b\u4e09\u4e2a\u200b\u91cd\u8981\u200b\u53c2\u6570\u200b\uff1a</p>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#_2","title":"\u8bbe\u5907","text":"<p>\u200b\u5982\u679c\u200b\u60a8\u200b\u4f7f\u7528\u200b <code>device=n</code>\uff0c<code>pipeline</code>\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u5c06\u200b\u6a21\u578b\u200b\u653e\u5728\u200b\u6307\u5b9a\u200b\u7684\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u3002\u200b\u65e0\u8bba\u200b\u60a8\u200b\u4f7f\u7528\u200bPyTorch\u200b\u8fd8\u662f\u200bTensorflow\uff0c\u200b\u8fd9\u200b\u90fd\u200b\u53ef\u4ee5\u200b\u5de5\u4f5c\u200b\u3002</p> <pre><code>transcriber = pipeline(model=\"openai/whisper-large-v2\", device=0)\n</code></pre> <p>\u200b\u5982\u679c\u200b\u6a21\u578b\u200b\u5bf9\u4e8e\u200b\u5355\u4e2a\u200bGPU\u200b\u6765\u8bf4\u200b\u8fc7\u4e8e\u200b\u5e9e\u5927\u200b\uff0c\u200b\u5e76\u4e14\u200b\u60a8\u200b\u6b63\u5728\u200b\u4f7f\u7528\u200bPyTorch\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8bbe\u7f6e\u200b <code>device_map=\"auto\"</code> \u200b\u4ee5\u200b\u81ea\u52a8\u200b\u786e\u5b9a\u200b\u5982\u4f55\u200b\u52a0\u8f7d\u200b\u548c\u200b\u5b58\u50a8\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u3002\u200b\u4f7f\u7528\u200b <code>device_map</code> \u200b\u53c2\u6570\u200b\u9700\u8981\u200b\u5b89\u88c5\u200b\ud83e\udd17 Accelerate \u200b\u8f6f\u4ef6\u5305\u200b\uff1a</p> <pre><code>pip install --upgrade accelerate\n</code></pre> <p>\u200b\u4ee5\u4e0b\u200b\u4ee3\u7801\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u5728\u200b\u5404\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u52a0\u8f7d\u200b\u548c\u200b\u5b58\u50a8\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\uff1a</p> <pre><code>transcriber = pipeline(model=\"openai/whisper-large-v2\", device_map=\"auto\")\n</code></pre> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u5982\u679c\u200b\u4f20\u9012\u200b\u4e86\u200b <code>device_map=\"auto\"</code>\uff0c\u200b\u5728\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u60a8\u200b\u7684\u200b <code>pipeline</code> \u200b\u65f6\u200b\u4e0d\u200b\u9700\u8981\u200b\u6dfb\u52a0\u200b <code>device=device</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u5426\u5219\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u9047\u5230\u200b\u4e00\u4e9b\u200b\u610f\u5916\u200b\u7684\u200b\u72b6\u51b5\u200b\uff01</p>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#_3","title":"\u6279\u91cf\u200b\u5927\u5c0f","text":"<p>\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c<code>pipelines</code>\u200b\u4e0d\u4f1a\u200b\u8fdb\u884c\u200b\u6279\u91cf\u200b\u63a8\u7406\u200b\uff0c\u200b\u539f\u56e0\u200b\u5728\u200b\u8fd9\u91cc\u200b\u8be6\u7ec6\u200b\u89e3\u91ca\u200b\u3002\u200b\u56e0\u4e3a\u200b\u6279\u5904\u7406\u200b\u4e0d\u200b\u4e00\u5b9a\u200b\u66f4\u200b\u5feb\u200b\uff0c\u200b\u5b9e\u9645\u4e0a\u200b\u5728\u200b\u67d0\u4e9b\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u66f4\u6162\u200b\u3002</p> <p>\u200b\u4f46\u200b\u5982\u679c\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u7528\u4f8b\u200b\u4e2d\u8d77\u200b\u4f5c\u7528\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\uff1a</p> <pre><code>transcriber = pipeline(model=\"openai/whisper-large-v2\", device=0, batch_size=2)\naudio_filenames = [f\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/{i}.flac\" for i in range(1, 5)]\ntexts = transcriber(audio_filenames)\n</code></pre> <p>\u200b\u4ee5\u4e0a\u200b\u4ee3\u7801\u200b\u4f1a\u200b\u5728\u200b\u63d0\u4f9b\u200b\u7684\u200b4\u200b\u4e2a\u200b\u97f3\u9891\u6587\u4ef6\u200b\u4e0a\u200b\u8fd0\u884c\u200b<code>pipeline</code>\uff0c\u200b\u5b83\u4f1a\u200b\u5c06\u200b\u5b83\u4eec\u200b\u4ee5\u200b2\u200b\u4e2a\u200b\u4e00\u7ec4\u200b\u7684\u200b\u6279\u6b21\u200b\u4f20\u9012\u200b\u7ed9\u200b\u6a21\u578b\u200b\uff08\u200b\u6a21\u578b\u200b\u5728\u200bGPU\u200b\u4e0a\u200b\uff0c\u200b\u6b64\u65f6\u200b\u6279\u5904\u7406\u200b\u66f4\u200b\u6709\u200b\u53ef\u80fd\u200b\u6709\u6240\u200b\u5e2e\u52a9\u200b\uff09\uff0c\u200b\u800c\u200b\u60a8\u200b\u65e0\u9700\u200b\u7f16\u5199\u200b\u989d\u5916\u200b\u7684\u200b\u4ee3\u7801\u200b\u3002\u200b\u8f93\u51fa\u200b\u5e94\u200b\u59cb\u7ec8\u200b\u4e0e\u200b\u6ca1\u6709\u200b\u6279\u5904\u7406\u200b\u65f6\u200b\u6536\u5230\u200b\u7684\u200b\u7ed3\u679c\u200b\u76f8\u4e00\u81f4\u200b\u3002\u200b\u5b83\u200b\u53ea\u662f\u200b\u4e00\u79cd\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u66f4\u200b\u5feb\u200b\u5730\u200b\u4f7f\u7528\u200b<code>pipeline</code>\u200b\u7684\u200b\u65b9\u5f0f\u200b\u3002</p> <p><code>pipeline</code>\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u51cf\u8f7b\u200b\u4e00\u4e9b\u200b\u6279\u5904\u7406\u200b\u7684\u200b\u590d\u6742\u6027\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5bf9\u4e8e\u200b\u67d0\u4e9b\u200b<code>pipeline</code>\uff0c\u200b\u9700\u8981\u200b\u5c06\u200b\u5355\u4e2a\u200b\u9879\u76ee\u200b\uff08\u200b\u5982\u957f\u200b\u97f3\u9891\u6587\u4ef6\u200b\uff09\u200b\u5206\u6210\u200b\u591a\u4e2a\u200b\u90e8\u5206\u200b\u4ee5\u4f9b\u200b\u6a21\u578b\u200b\u5904\u7406\u200b\u3002<code>pipeline</code>\u200b\u4e3a\u200b\u60a8\u200b\u6267\u884c\u200b\u8fd9\u79cd\u200bchunk batching\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#_4","title":"\u4efb\u52a1\u200b\u7279\u5b9a\u200b\u53c2\u6570","text":"<p>\u200b\u6240\u6709\u200b\u4efb\u52a1\u200b\u90fd\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u7279\u5b9a\u200b\u4e8e\u200b\u4efb\u52a1\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u53c2\u6570\u200b\u63d0\u4f9b\u200b\u989d\u5916\u200b\u7684\u200b\u7075\u6d3b\u6027\u200b\u548c\u200b\u9009\u62e9\u200b\uff0c\u200b\u4ee5\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u5b8c\u6210\u200b\u5de5\u4f5c\u200b\u3002 \u200b\u4f8b\u5982\u200b\uff0c[<code>transformers.AutomaticSpeechRecognitionPipeline.__call__</code>] \u200b\u65b9\u6cd5\u200b\u5177\u6709\u200b\u4e00\u4e2a\u200b <code>return_timestamps</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u5b57\u5e55\u200b\u89c6\u9891\u200b\u4f3c\u4e4e\u200b\u5f88\u200b\u6709\u200b\u5e2e\u52a9\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; transcriber = pipeline(model=\"openai/whisper-large-v2\", return_timestamps=True)\n&gt;&gt;&gt; transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.', 'chunks': [{'timestamp': (0.0, 11.88), 'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its'}, {'timestamp': (11.88, 12.38), 'text': ' creed.'}]}\n</code></pre> <p>\u200b\u6b63\u5982\u200b\u60a8\u200b\u6240\u200b\u770b\u5230\u200b\u7684\u200b\uff0c\u200b\u6a21\u578b\u200b\u63a8\u65ad\u51fa\u200b\u4e86\u200b\u6587\u672c\u200b\uff0c\u200b\u8fd8\u200b\u8f93\u51fa\u200b\u4e86\u200b\u5404\u4e2a\u200b\u53e5\u5b50\u200b\u53d1\u97f3\u200b\u7684\u200b\u65f6\u95f4\u200b\u3002</p> <p>\u200b\u6bcf\u4e2a\u200b\u4efb\u52a1\u200b\u90fd\u200b\u6709\u200b\u8bb8\u591a\u200b\u53ef\u7528\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u56e0\u6b64\u200b\u8bf7\u200b\u67e5\u770b\u200b\u6bcf\u4e2a\u200b\u4efb\u52a1\u200b\u7684\u200bAPI\u200b\u53c2\u8003\u200b\uff0c\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8fdb\u884c\u200b\u54ea\u4e9b\u200b\u8c03\u6574\u200b\uff01\u200b\u4f8b\u5982\u200b\uff0c[<code>~transformers.AutomaticSpeechRecognitionPipeline</code>] \u200b\u5177\u6709\u200b <code>chunk_length_s</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u5904\u7406\u200b\u975e\u5e38\u200b\u957f\u200b\u7684\u200b\u97f3\u9891\u6587\u4ef6\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4e3a\u200b\u6574\u90e8\u200b\u7535\u5f71\u200b\u6216\u957f\u200b\u8fbe\u200b\u4e00\u200b\u5c0f\u65f6\u200b\u7684\u200b\u89c6\u9891\u200b\u914d\u200b\u5b57\u5e55\u200b\uff09\u200b\u975e\u5e38\u200b\u6709\u200b\u5e2e\u52a9\u200b\uff0c\u200b\u8fd9\u200b\u901a\u5e38\u200b\u662f\u200b\u6a21\u578b\u200b\u65e0\u6cd5\u200b\u5355\u72ec\u200b\u5904\u7406\u200b\u7684\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; transcriber = pipeline(model=\"openai/whisper-large-v2\", chunk_length_s=30, return_timestamps=True)\n&gt;&gt;&gt; transcriber(\"https://huggingface.co/datasets/sanchit-gandhi/librispeech_long/resolve/main/audio.wav\")\n{'text': \" Chapter 16. I might have told you of the beginning of this liaison in a few lines, but I wanted you to see every step by which we came.  I, too, agree to whatever Marguerite wished, Marguerite to be unable to live apart from me. It was the day after the evening...\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u627e\u200b\u4e0d\u5230\u200b\u4e00\u4e2a\u200b\u771f\u6b63\u200b\u6709\u200b\u5e2e\u52a9\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u6b22\u8fce\u200b\u63d0\u51fa\u200b\u8bf7\u6c42\u200b\uff01</p>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#pipelines","title":"\u5728\u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u4f7f\u7528\u200bpipelines","text":"<p><code>pipelines</code>\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u5bf9\u200b\u5927\u578b\u200b\u6570\u636e\u200b\u96c6\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\u3002\u200b\u6211\u4eec\u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200b\u8fed\u4ee3\u200b\u5668\u6765\u200b\u5b8c\u6210\u200b\u8fd9\u4e00\u200b\u4efb\u52a1\u200b\uff0c\u200b\u8fd9\u200b\u662f\u200b\u6700\u200b\u7b80\u5355\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff1a</p> <pre><code>def data():\n    for i in range(1000):\n        yield f\"My example {i}\"\n\n\npipe = pipeline(model=\"gpt2\", device=0)\ngenerated_characters = 0\nfor out in pipe(data()):\n    generated_characters += len(out[0][\"generated_text\"])\n</code></pre> <p>\u200b\u8fed\u4ee3\u200b\u5668\u200b <code>data()</code> \u200b\u4f1a\u200b\u4ea7\u751f\u200b\u6bcf\u4e2a\u200b\u7ed3\u679c\u200b\uff0c<code>pipelines</code>\u200b\u4f1a\u200b\u81ea\u52a8\u8bc6\u522b\u200b\u8f93\u5165\u200b\u4e3a\u200b\u53ef\u200b\u8fed\u4ee3\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u5e76\u200b\u5728\u200bGPU\u200b\u4e0a\u200b\u5904\u7406\u200b\u6570\u636e\u200b\u7684\u200b\u540c\u65f6\u200b\u5f00\u59cb\u200b\u83b7\u53d6\u6570\u636e\u200b\uff08\u200b\u5728\u200b\u5e95\u5c42\u200b\u4f7f\u7528\u200bDataLoader\uff09\u3002\u200b\u8fd9\u200b\u4e00\u70b9\u200b\u975e\u5e38\u200b\u91cd\u8981\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u60a8\u200b\u4e0d\u5fc5\u200b\u4e3a\u200b\u6574\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\u5206\u914d\u5185\u5b58\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5c3d\u53ef\u80fd\u200b\u5feb\u5730\u200b\u5c06\u200b\u6570\u636e\u200b\u4f20\u9001\u200b\u5230\u200bGPU\u3002</p> <p>\u200b\u7531\u4e8e\u200b\u6279\u5904\u7406\u200b\u53ef\u4ee5\u200b\u52a0\u901f\u200b\u5904\u7406\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5728\u200b\u8fd9\u91cc\u200b\u5c1d\u8bd5\u200b\u8c03\u6574\u200b <code>batch_size</code> \u200b\u53c2\u6570\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5f88\u200b\u6709\u7528\u200b\u3002</p> <p>\u200b\u8fed\u4ee3\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u6700\u200b\u7b80\u5355\u200b\u65b9\u6cd5\u200b\u5c31\u200b\u662f\u4ece\u200b\ud83e\udd17 Datasets \u200b\u4e2d\u200b\u52a0\u8f7d\u200b\u6570\u636e\u200b\u96c6\u200b\uff1a</p> <pre><code># KeyDataset is a util that will just output the item we're interested in.\nfrom transformers.pipelines.pt_utils import KeyDataset\nfrom datasets import load_dataset\n\npipe = pipeline(model=\"hf-internal-testing/tiny-random-wav2vec2\", device=0)\ndataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation[:10]\")\n\nfor out in pipe(KeyDataset(dataset, \"audio\")):\n    print(out)\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#webpipelines","title":"\u5728\u200bWeb\u200b\u670d\u52a1\u5668\u200b\u4e0a\u200b\u4f7f\u7528\u200bpipelines","text":"<p> \u200b\u521b\u5efa\u200b\u63a8\u7406\u200b\u5f15\u64ce\u200b\u662f\u200b\u4e00\u4e2a\u200b\u590d\u6742\u200b\u7684\u200b\u4e3b\u9898\u200b\uff0c\u200b\u503c\u5f97\u200b\u6709\u200b\u81ea\u5df1\u200b\u7684\u200b\u9875\u9762\u200b\u3002 </p> <p>\u200b\u94fe\u63a5\u200b</p>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#_5","title":"\u89c6\u89c9\u200b\u6d41\u6c34\u7ebf","text":"<p>\u200b\u5bf9\u4e8e\u200b\u89c6\u89c9\u200b\u4efb\u52a1\u200b\uff0c\u200b\u4f7f\u7528\u200b[<code>pipeline</code>] \u200b\u51e0\u4e4e\u200b\u662f\u200b\u76f8\u540c\u200b\u7684\u200b\u3002</p> <p>\u200b\u6307\u5b9a\u200b\u60a8\u200b\u7684\u200b\u4efb\u52a1\u200b\u5e76\u200b\u5c06\u200b\u56fe\u50cf\u200b\u4f20\u9012\u200b\u7ed9\u200b\u5206\u7c7b\u5668\u200b\u3002\u200b\u56fe\u50cf\u200b\u53ef\u4ee5\u200b\u662f\u200b\u94fe\u63a5\u200b\u3001\u200b\u672c\u5730\u200b\u8def\u5f84\u200b\u6216\u200bbase64\u200b\u7f16\u7801\u200b\u7684\u200b\u56fe\u50cf\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4e0b\u9762\u200b\u663e\u793a\u200b\u7684\u200b\u662f\u200b\u54ea\u79cd\u200b\u54c1\u79cd\u200b\u7684\u200b\u732b\u200b\uff1f</p> <p> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; vision_classifier = pipeline(model=\"google/vit-base-patch16-224\")\n&gt;&gt;&gt; preds = vision_classifier(\n...     images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n... )\n&gt;&gt;&gt; preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n&gt;&gt;&gt; preds\n[{'score': 0.4335, 'label': 'lynx, catamount'}, {'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}, {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}, {'score': 0.0239, 'label': 'Egyptian cat'}, {'score': 0.0229, 'label': 'tiger cat'}]\n</code></pre></p>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#_6","title":"\u6587\u672c\u200b\u6d41\u6c34\u7ebf","text":"<p>\u200b\u5bf9\u4e8e\u200bNLP\u200b\u4efb\u52a1\u200b\uff0c\u200b\u4f7f\u7528\u200b[<code>pipeline</code>] \u200b\u51e0\u4e4e\u200b\u662f\u200b\u76f8\u540c\u200b\u7684\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; # This model is a `zero-shot-classification` model.\n&gt;&gt;&gt; # It will classify text, except you are free to choose any label you might imagine\n&gt;&gt;&gt; classifier = pipeline(model=\"facebook/bart-large-mnli\")\n&gt;&gt;&gt; classifier(\n...     \"I have a problem with my iphone that needs to be resolved asap!!\",\n...     candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n... )\n{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#_7","title":"\u591a\u200b\u6a21\u6001\u200b\u6d41\u6c34\u7ebf","text":"<p>[<code>pipeline</code>] \u200b\u652f\u6301\u200b\u591a\u4e2a\u200b\u6a21\u6001\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u89c6\u89c9\u200b\u95ee\u9898\u200b\u56de\u7b54\u200b\uff08VQA\uff09\u200b\u4efb\u52a1\u200b\u7ed3\u5408\u200b\u4e86\u200b\u6587\u672c\u200b\u548c\u200b\u56fe\u50cf\u200b\u3002\u200b\u8bf7\u200b\u968f\u610f\u200b\u4f7f\u7528\u200b\u60a8\u200b\u559c\u6b22\u200b\u7684\u200b\u4efb\u4f55\u200b\u56fe\u50cf\u200b\u94fe\u63a5\u200b\u548c\u200b\u60a8\u200b\u60f3\u8981\u200b\u95ee\u200b\u5173\u4e8e\u200b\u8be5\u200b\u56fe\u50cf\u200b\u7684\u200b\u95ee\u9898\u200b\u3002\u200b\u56fe\u50cf\u200b\u53ef\u4ee5\u200b\u662f\u200bURL\u200b\u6216\u200b\u56fe\u50cf\u200b\u7684\u200b\u672c\u5730\u200b\u8def\u5f84\u200b\u3002</p> <p>\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200binvoice image\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; vqa = pipeline(model=\"impira/layoutlm-document-qa\")\n&gt;&gt;&gt; vqa(\n...     image=\"https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png\",\n...     question=\"What is the invoice number?\",\n... )\n[{'score': 0.42515, 'answer': 'us-001', 'start': 16, 'end': 16}]\n</code></pre> <p> <p>\u200b\u8981\u200b\u8fd0\u884c\u200b\u4e0a\u9762\u200b\u7684\u200b\u793a\u4f8b\u200b\uff0c\u200b\u9664\u4e86\u200b\ud83e\udd17 Transformers\u200b\u4e4b\u5916\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5b89\u88c5\u200b<code>pytesseract</code>\u3002</p> <pre><code>sudo apt install -y tesseract-ocr\npip install pytesseract\n</code></pre> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/pipeline_tutorial/#acceleratepipeline","title":"\u5728\u200b\u5927\u200b\u6a21\u578b\u200b\u4e0a\u200b\u4f7f\u7528\u200b\ud83e\udd17 <code>accelerate</code>\u200b\u548c\u200b<code>pipeline</code>\uff1a","text":"<p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u5730\u200b\u4f7f\u7528\u200b\ud83e\udd17 <code>accelerate</code>\u200b\u5728\u200b\u5927\u200b\u6a21\u578b\u200b\u4e0a\u200b\u8fd0\u884c\u200b <code>pipeline</code>\uff01\u200b\u9996\u5148\u200b\u786e\u4fdd\u60a8\u200b\u5df2\u7ecf\u200b\u4f7f\u7528\u200b <code>pip install accelerate</code> \u200b\u5b89\u88c5\u200b\u4e86\u200b <code>accelerate</code>\u3002</p> <p>\u200b\u9996\u5148\u200b\u4f7f\u7528\u200b <code>device_map=\"auto\"</code> \u200b\u52a0\u8f7d\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\uff01\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b\u793a\u4f8b\u200b\u4e2d\u200b\u4f7f\u7528\u200b <code>facebook/opt-1.3b</code>\u3002</p> <pre><code># pip install accelerate\nimport torch\nfrom transformers import pipeline\n\npipe = pipeline(model=\"facebook/opt-1.3b\", torch_dtype=torch.bfloat16, device_map=\"auto\")\noutput = pipe(\"This is a cool example!\", do_sample=True, top_p=0.95)\n</code></pre> <p>\u200b\u5982\u679c\u200b\u5b89\u88c5\u200b <code>bitsandbytes</code> \u200b\u5e76\u200b\u6dfb\u52a0\u200b\u53c2\u6570\u200b <code>load_in_8bit=True</code>\uff0c\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u4f20\u9012\u200b8\u200b\u4f4d\u200b\u52a0\u8f7d\u200b\u7684\u200b\u6a21\u578b\u200b\u3002</p> <pre><code># pip install accelerate bitsandbytes\nimport torch\nfrom transformers import pipeline\n\npipe = pipeline(model=\"facebook/opt-1.3b\", device_map=\"auto\", model_kwargs={\"load_in_8bit\": True})\noutput = pipe(\"This is a cool example!\", do_sample=True, top_p=0.95)\n</code></pre> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c06\u200b<code>checkpoint</code>\u200b\u66ff\u6362\u200b\u4e3a\u200b\u4efb\u4f55\u200b\u652f\u6301\u200b\u5927\u200b\u6a21\u578b\u200b\u52a0\u8f7d\u200b\u7684\u200bHugging Face\u200b\u6a21\u578b\u200b\uff0c\u200b\u6bd4\u5982\u200bBLOOM\uff01</p>"},{"location":"2-%E6%95%99%E7%A8%8B/preprocessing/","title":"Preprocessing","text":""},{"location":"2-%E6%95%99%E7%A8%8B/preprocessing/#_1","title":"\u9884\u5904\u7406","text":"<p>[[open-in-colab]]</p> <p>\u200b\u5728\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4e4b\u524d\u200b\uff0c\u200b\u6570\u636e\u200b\u9700\u8981\u200b\u88ab\u200b\u9884\u5904\u7406\u200b\u4e3a\u200b\u671f\u671b\u200b\u7684\u200b\u6a21\u578b\u200b\u8f93\u5165\u200b\u683c\u5f0f\u200b\u3002\u200b\u65e0\u8bba\u200b\u60a8\u200b\u7684\u200b\u6570\u636e\u200b\u662f\u200b\u6587\u672c\u200b\u3001\u200b\u56fe\u50cf\u200b\u8fd8\u662f\u200b\u97f3\u9891\u200b\uff0c\u200b\u5b83\u4eec\u200b\u90fd\u200b\u9700\u8981\u200b\u88ab\u200b\u8f6c\u6362\u200b\u5e76\u200b\u7ec4\u5408\u6210\u200b\u6279\u91cf\u200b\u7684\u200b\u5f20\u91cf\u200b\u3002\ud83e\udd17 Transformers \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u7ec4\u200b\u9884\u5904\u7406\u200b\u7c7b\u6765\u200b\u5e2e\u52a9\u200b\u51c6\u5907\u200b\u6570\u636e\u200b\u4ee5\u4f9b\u200b\u6a21\u578b\u200b\u4f7f\u7528\u200b\u3002\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u4e86\u89e3\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a</p> <ul> <li>\u200b\u5bf9\u4e8e\u200b\u6587\u672c\u200b\uff0c\u200b\u4f7f\u7528\u200b\u5206\u8bcd\u5668\u200b(<code>Tokenizer</code>)\u200b\u5c06\u200b\u6587\u672c\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u4e00\u7cfb\u5217\u200b\u6807\u8bb0\u200b(<code>tokens</code>)\uff0c\u200b\u5e76\u200b\u521b\u5efa\u200b<code>tokens</code>\u200b\u7684\u200b\u6570\u5b57\u200b\u8868\u793a\u200b\uff0c\u200b\u5c06\u200b\u5b83\u4eec\u200b\u7ec4\u5408\u6210\u200b\u5f20\u91cf\u200b\u3002</li> <li>\u200b\u5bf9\u4e8e\u200b\u8bed\u97f3\u200b\u548c\u200b\u97f3\u9891\u200b\uff0c\u200b\u4f7f\u7528\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b(<code>Feature extractor</code>)\u200b\u4ece\u200b\u97f3\u9891\u200b\u6ce2\u5f62\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u987a\u5e8f\u200b\u7279\u5f81\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u5f20\u91cf\u200b\u3002</li> <li>\u200b\u56fe\u50cf\u200b\u8f93\u5165\u200b\u4f7f\u7528\u200b\u56fe\u50cf\u200b\u5904\u7406\u5668\u200b(<code>ImageProcessor</code>)\u200b\u5c06\u200b\u56fe\u50cf\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u5f20\u91cf\u200b\u3002</li> <li>\u200b\u591a\u200b\u6a21\u6001\u200b\u8f93\u5165\u200b\uff0c\u200b\u4f7f\u7528\u200b\u5904\u7406\u5668\u200b(<code>Processor</code>)\u200b\u7ed3\u5408\u200b\u4e86\u200b<code>Tokenizer</code>\u200b\u548c\u200b<code>ImageProcessor</code>\u200b\u6216\u200b<code>Processor</code>\u3002</li> </ul> <p> <p><code>AutoProcessor</code> \u200b\u59cb\u7ec8\u200b\u6709\u6548\u200b\u7684\u200b\u81ea\u52a8\u200b\u9009\u62e9\u200b\u9002\u7528\u200b\u4e8e\u200b\u60a8\u200b\u4f7f\u7528\u200b\u7684\u200b\u6a21\u578b\u200b\u7684\u200b\u6b63\u786e\u200b<code>class</code>\uff0c\u200b\u65e0\u8bba\u200b\u60a8\u200b\u4f7f\u7528\u200b\u7684\u200b\u662f\u200b<code>Tokenizer</code>\u3001<code>ImageProcessor</code>\u3001<code>Feature extractor</code>\u200b\u8fd8\u662f\u200b<code>Processor</code>\u3002</p> <p></p> <p>\u200b\u5728\u200b\u5f00\u59cb\u200b\u4e4b\u524d\u200b\uff0c\u200b\u8bf7\u200b\u5b89\u88c5\u200b\ud83e\udd17 Datasets\uff0c\u200b\u4ee5\u4fbf\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u52a0\u8f7d\u200b\u4e00\u4e9b\u200b\u6570\u636e\u200b\u96c6\u6765\u200b\u8fdb\u884c\u200b\u5b9e\u9a8c\u200b\uff1a</p> <pre><code>pip install datasets\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/preprocessing/#_2","title":"\u81ea\u7136\u8bed\u8a00\u200b\u5904\u7406","text":"<p>\u200b\u5904\u7406\u200b\u6587\u672c\u200b\u6570\u636e\u200b\u7684\u200b\u4e3b\u8981\u200b\u5de5\u5177\u200b\u662f\u200bTokenizer\u3002<code>Tokenizer</code>\u200b\u6839\u636e\u200b\u4e00\u7ec4\u200b\u89c4\u5219\u200b\u5c06\u200b\u6587\u672c\u200b\u62c6\u200b\u5206\u4e3a\u200b<code>tokens</code>\u3002\u200b\u7136\u540e\u200b\u5c06\u200b\u8fd9\u4e9b\u200b<code>tokens</code>\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6570\u5b57\u200b\uff0c\u200b\u7136\u540e\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u5f20\u91cf\u200b\uff0c\u200b\u6210\u4e3a\u200b\u6a21\u578b\u200b\u7684\u200b\u8f93\u5165\u200b\u3002\u200b\u6a21\u578b\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u4efb\u4f55\u200b\u9644\u52a0\u200b\u8f93\u5165\u200b\u90fd\u200b\u7531\u200b<code>Tokenizer</code>\u200b\u6dfb\u52a0\u200b\u3002</p> <p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u8ba1\u5212\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff0c\u200b\u91cd\u8981\u200b\u7684\u200b\u662f\u200b\u4f7f\u7528\u200b\u4e0e\u200b\u4e4b\u200b\u5173\u8054\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b<code>Tokenizer</code>\u3002\u200b\u8fd9\u200b\u786e\u4fdd\u200b\u6587\u672c\u200b\u7684\u200b\u62c6\u5206\u200b\u65b9\u5f0f\u200b\u4e0e\u200b\u9884\u200b\u8bad\u7ec3\u200b\u8bed\u6599\u5e93\u200b\u76f8\u540c\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u9884\u200b\u8bad\u7ec3\u200b\u671f\u95f4\u200b\u4f7f\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u6807\u8bb0\u200b-\u200b\u7d22\u5f15\u200b\u7684\u200b\u5bf9\u5e94\u200b\u5173\u7cfb\u200b\uff08\u200b\u901a\u5e38\u200b\u79f0\u4e3a\u200b\u8bcd\u6c47\u8868\u200b-<code>vocab</code>\uff09\u3002</p> <p></p> <p>\u200b\u5f00\u59cb\u200b\u4f7f\u7528\u200b[<code>AutoTokenizer.from_pretrained</code>]\u200b\u65b9\u6cd5\u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200b\u9884\u200b\u8bad\u7ec3\u200b<code>tokenizer</code>\u3002\u200b\u8fd9\u200b\u5c06\u200b\u4e0b\u8f7d\u200b\u6a21\u578b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b<code>vocab</code>\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n</code></pre> <p>\u200b\u7136\u540e\u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u6587\u672c\u200b\u4f20\u9012\u200b\u7ed9\u200b<code>tokenizer</code>\uff1a</p> <pre><code>&gt;&gt;&gt; encoded_input = tokenizer(\"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\")\n&gt;&gt;&gt; print(encoded_input)\n{'input_ids': [101, 2079, 2025, 19960, 10362, 1999, 1996, 3821, 1997, 16657, 1010, 2005, 2027, 2024, 11259, 1998, 4248, 2000, 4963, 1012, 102],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n</code></pre> <p><code>tokenizer</code>\u200b\u8fd4\u56de\u200b\u4e00\u4e2a\u200b\u5305\u542b\u200b\u4e09\u4e2a\u200b\u91cd\u8981\u200b\u5bf9\u8c61\u200b\u7684\u200b\u5b57\u5178\u200b\uff1a</p> <ul> <li>input_ids \u200b\u662f\u200b\u4e0e\u200b\u53e5\u5b50\u200b\u4e2d\u200b\u6bcf\u4e2a\u200b<code>token</code>\u200b\u5bf9\u5e94\u200b\u7684\u200b\u7d22\u5f15\u200b\u3002</li> <li>attention_mask \u200b\u6307\u793a\u200b\u662f\u5426\u200b\u5e94\u8be5\u200b\u5173\u6ce8\u200b\u4e00\u4e2a\u200b<code>toekn</code>\u3002</li> <li>token_type_ids \u200b\u5728\u200b\u5b58\u5728\u200b\u591a\u4e2a\u200b\u5e8f\u5217\u200b\u65f6\u200b\u6807\u8bc6\u200b\u4e00\u4e2a\u200b<code>token</code>\u200b\u5c5e\u4e8e\u200b\u54ea\u4e2a\u200b\u5e8f\u5217\u200b\u3002</li> </ul> <p>\u200b\u901a\u8fc7\u200b\u89e3\u7801\u200b <code>input_ids</code> \u200b\u6765\u200b\u8fd4\u56de\u200b\u60a8\u200b\u7684\u200b\u8f93\u5165\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; tokenizer.decode(encoded_input[\"input_ids\"])\n'[CLS] Do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]'\n</code></pre> <p>\u200b\u5982\u200b\u60a8\u200b\u6240\u89c1\u200b\uff0c<code>tokenizer</code>\u200b\u5411\u200b\u53e5\u5b50\u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u4e86\u200b\u4e24\u4e2a\u200b\u7279\u6b8a\u200b<code>token</code> - <code>CLS</code> \u200b\u548c\u200b <code>SEP</code>\uff08\u200b\u5206\u7c7b\u5668\u200b\u548c\u200b\u5206\u9694\u7b26\u200b\uff09\u3002\u200b\u5e76\u975e\u200b\u6240\u6709\u200b\u6a21\u578b\u200b\u90fd\u200b\u9700\u8981\u200b\u7279\u6b8a\u200b<code>token</code>\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u9700\u8981\u200b\uff0c<code>tokenizer</code>\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u4e3a\u200b\u60a8\u200b\u6dfb\u52a0\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u6709\u200b\u591a\u4e2a\u200b\u53e5\u5b50\u200b\u9700\u8981\u200b\u9884\u5904\u7406\u200b\uff0c\u200b\u5c06\u200b\u5b83\u4eec\u200b\u4f5c\u4e3a\u200b\u5217\u8868\u200b\u4f20\u9012\u200b\u7ed9\u200b<code>tokenizer</code>\uff1a</p> <pre><code>&gt;&gt;&gt; batch_sentences = [\n...     \"But what about second breakfast?\",\n...     \"Don't think he knows about second breakfast, Pip.\",\n...     \"What about elevensies?\",\n... ]\n&gt;&gt;&gt; encoded_inputs = tokenizer(batch_sentences)\n&gt;&gt;&gt; print(encoded_inputs)\n{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102],\n               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n               [101, 1327, 1164, 5450, 23434, 136, 102]],\n 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1],\n                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n                    [1, 1, 1, 1, 1, 1, 1]]}\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/preprocessing/#_3","title":"\u586b\u5145","text":"<p>\u200b\u53e5\u5b50\u200b\u7684\u200b\u957f\u5ea6\u200b\u5e76\u200b\u4e0d\u200b\u603b\u662f\u200b\u76f8\u540c\u200b\uff0c\u200b\u8fd9\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u6210\u4e3a\u200b\u4e00\u4e2a\u200b\u95ee\u9898\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6a21\u578b\u200b\u8f93\u5165\u200b\u7684\u200b\u5f20\u91cf\u200b\u9700\u8981\u200b\u5177\u6709\u200b\u7edf\u4e00\u200b\u7684\u200b\u5f62\u72b6\u200b\u3002\u200b\u586b\u5145\u200b\u662f\u200b\u4e00\u79cd\u200b\u7b56\u7565\u200b\uff0c\u200b\u901a\u8fc7\u200b\u5728\u200b\u8f83\u200b\u77ed\u200b\u7684\u200b\u53e5\u5b50\u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u7279\u6b8a\u200b\u7684\u200b<code>padding token</code>\uff0c\u200b\u4ee5\u200b\u786e\u4fdd\u200b\u5f20\u91cf\u200b\u662f\u200b\u77e9\u5f62\u200b\u7684\u200b\u3002</p> <p>\u200b\u5c06\u200b <code>padding</code> \u200b\u53c2\u6570\u8bbe\u7f6e\u200b\u4e3a\u200b <code>True</code>\uff0c\u200b\u4ee5\u200b\u4f7f\u200b\u6279\u6b21\u200b\u4e2d\u8f83\u200b\u77ed\u200b\u7684\u200b\u5e8f\u5217\u200b\u586b\u5145\u200b\u5230\u200b\u4e0e\u200b\u6700\u957f\u200b\u5e8f\u5217\u200b\u76f8\u5339\u914d\u200b\u7684\u200b\u957f\u5ea6\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; batch_sentences = [\n...     \"But what about second breakfast?\",\n...     \"Don't think he knows about second breakfast, Pip.\",\n...     \"What about elevensies?\",\n... ]\n&gt;&gt;&gt; encoded_input = tokenizer(batch_sentences, padding=True)\n&gt;&gt;&gt; print(encoded_input)\n{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],\n 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n                    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}\n</code></pre> <p>\u200b\u7b2c\u4e00\u53e5\u200b\u548c\u200b\u7b2c\u4e09\u53e5\u200b\u56e0\u4e3a\u200b\u8f83\u200b\u77ed\u200b\uff0c\u200b\u901a\u8fc7\u200b<code>0</code>\u200b\u8fdb\u884c\u200b\u586b\u5145\u200b\uff0c\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/preprocessing/#_4","title":"\u622a\u65ad","text":"<p>\u200b\u53e6\u4e00\u65b9\u9762\u200b\uff0c\u200b\u6709\u65f6\u5019\u200b\u4e00\u4e2a\u200b\u5e8f\u5217\u200b\u53ef\u80fd\u200b\u5bf9\u6a21\u578b\u200b\u6765\u8bf4\u200b\u592a\u957f\u200b\u4e86\u200b\u3002\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5c06\u200b\u5e8f\u5217\u200b\u622a\u65ad\u200b\u4e3a\u200b\u66f4\u200b\u77ed\u200b\u7684\u200b\u957f\u5ea6\u200b\u3002</p> <p>\u200b\u5c06\u200b <code>truncation</code> \u200b\u53c2\u6570\u8bbe\u7f6e\u200b\u4e3a\u200b <code>True</code>\uff0c\u200b\u4ee5\u200b\u5c06\u200b\u5e8f\u5217\u200b\u622a\u65ad\u200b\u4e3a\u200b\u6a21\u578b\u200b\u63a5\u53d7\u200b\u7684\u200b\u6700\u5927\u200b\u957f\u5ea6\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; batch_sentences = [\n...     \"But what about second breakfast?\",\n...     \"Don't think he knows about second breakfast, Pip.\",\n...     \"What about elevensies?\",\n... ]\n&gt;&gt;&gt; encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)\n&gt;&gt;&gt; print(encoded_input)\n{'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n               [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n               [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],\n 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n                    [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]}\n</code></pre> <p> <p>\u200b\u67e5\u770b\u200b\u586b\u5145\u200b\u548c\u200b\u622a\u65ad\u200b\u6982\u5ff5\u200b\u6307\u5357\u200b\uff0c\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u6709\u5173\u200b\u586b\u5145\u200b\u548c\u200b\u622a\u65ad\u200b\u53c2\u6570\u200b\u7684\u200b\u4fe1\u606f\u200b\u3002</p> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/preprocessing/#_5","title":"\u6784\u5efa\u200b\u5f20\u91cf","text":"<p>\u200b\u6700\u540e\u200b\uff0c<code>tokenizer</code>\u200b\u53ef\u4ee5\u200b\u8fd4\u56de\u200b\u5b9e\u9645\u200b\u8f93\u5165\u200b\u5230\u200b\u6a21\u578b\u200b\u7684\u200b\u5f20\u91cf\u200b\u3002</p> <p>\u200b\u5c06\u200b <code>return_tensors</code> \u200b\u53c2\u6570\u8bbe\u7f6e\u200b\u4e3a\u200b <code>pt</code>\uff08\u200b\u5bf9\u4e8e\u200bPyTorch\uff09\u200b\u6216\u200b <code>tf</code>\uff08\u200b\u5bf9\u4e8e\u200bTensorFlow\uff09\uff1a</p> <p> <p><pre><code>&gt;&gt;&gt; batch_sentences = [\n...     \"But what about second breakfast?\",\n...     \"Don't think he knows about second breakfast, Pip.\",\n...     \"What about elevensies?\",\n... ]\n&gt;&gt;&gt; encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n&gt;&gt;&gt; print(encoded_input)\n{'input_ids': tensor([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n                      [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n                      [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]]),\n 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n                           [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n                           [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n</code></pre> <p><pre><code>&gt;&gt;&gt; batch_sentences = [\n...     \"But what about second breakfast?\",\n...     \"Don't think he knows about second breakfast, Pip.\",\n...     \"What about elevensies?\",\n... ]\n&gt;&gt;&gt; encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"tf\")\n&gt;&gt;&gt; print(encoded_input)\n{'input_ids': &lt;tf.Tensor: shape=(2, 9), dtype=int32, numpy=\narray([[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0],\n       [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102],\n       [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]],\n      dtype=int32)&gt;,\n 'token_type_ids': &lt;tf.Tensor: shape=(2, 9), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)&gt;,\n 'attention_mask': &lt;tf.Tensor: shape=(2, 9), dtype=int32, numpy=\narray([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n       [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)&gt;}\n</code></pre> </p>"},{"location":"2-%E6%95%99%E7%A8%8B/preprocessing/#_6","title":"\u97f3\u9891","text":"<p>\u200b\u5bf9\u4e8e\u200b\u97f3\u9891\u200b\u4efb\u52a1\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200bfeature extractor\u200b\u6765\u200b\u51c6\u5907\u200b\u60a8\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u4ee5\u200b\u4f9b\u200b\u6a21\u578b\u200b\u4f7f\u7528\u200b\u3002<code>feature extractor</code>\u200b\u65e8\u5728\u200b\u4ece\u200b\u539f\u59cb\u200b\u97f3\u9891\u200b\u6570\u636e\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u7279\u5f81\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200b\u5b83\u4eec\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u5f20\u91cf\u200b\u3002</p> <p>\u200b\u52a0\u8f7d\u200bMInDS-14\u200b\u6570\u636e\u200b\u96c6\u200b\uff08\u200b\u6709\u5173\u200b\u5982\u4f55\u200b\u52a0\u8f7d\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\ud83e\udd17 Datasets\u200b\u6559\u7a0b\u200b\uff09\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u5728\u200b\u97f3\u9891\u200b\u6570\u636e\u200b\u96c6\u4e2d\u200b\u4f7f\u7528\u200b<code>feature extractor</code>\uff1a</p> <pre><code>&gt;&gt;&gt; from datasets import load_dataset, Audio\n\n&gt;&gt;&gt; dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n</code></pre> <p>\u200b\u8bbf\u95ee\u200b <code>audio</code> \u200b\u5217\u200b\u7684\u200b\u7b2c\u4e00\u4e2a\u200b\u5143\u7d20\u200b\u4ee5\u200b\u67e5\u770b\u200b\u8f93\u5165\u200b\u3002\u200b\u8c03\u7528\u200b <code>audio</code> \u200b\u5217\u4f1a\u200b\u81ea\u52a8\u200b\u52a0\u8f7d\u200b\u548c\u200b\u91cd\u65b0\u200b\u91c7\u6837\u200b\u97f3\u9891\u6587\u4ef6\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; dataset[0][\"audio\"]\n{'array': array([ 0.        ,  0.00024414, -0.00024414, ..., -0.00024414,\n         0.        ,  0.        ], dtype=float32),\n 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',\n 'sampling_rate': 8000}\n</code></pre> <p>\u200b\u8fd9\u4f1a\u200b\u8fd4\u56de\u200b\u4e09\u4e2a\u200b\u5bf9\u8c61\u200b\uff1a</p> <ul> <li><code>array</code> \u200b\u662f\u200b\u52a0\u8f7d\u200b\u7684\u200b\u8bed\u97f3\u200b\u4fe1\u53f7\u200b - \u200b\u5e76\u200b\u5728\u200b\u5fc5\u8981\u200b\u65f6\u200b\u91cd\u65b0\u200b\u91c7\u200b\u4e3a\u200b<code>1D array</code>\u3002</li> <li><code>path</code> \u200b\u6307\u5411\u200b\u97f3\u9891\u6587\u4ef6\u200b\u7684\u200b\u4f4d\u7f6e\u200b\u3002</li> <li><code>sampling_rate</code> \u200b\u662f\u200b\u6bcf\u79d2\u200b\u6d4b\u91cf\u200b\u7684\u200b\u8bed\u97f3\u200b\u4fe1\u53f7\u200b\u6570\u636e\u200b\u70b9\u200b\u6570\u91cf\u200b\u3002</li> </ul> <p>\u200b\u5bf9\u4e8e\u200b\u672c\u200b\u6559\u7a0b\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u4f7f\u7528\u200bWav2Vec2\u200b\u6a21\u578b\u200b\u3002\u200b\u67e5\u770b\u200b\u6a21\u578b\u200b\u5361\u7247\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u4e86\u89e3\u200b\u5230\u200bWav2Vec2\u200b\u662f\u200b\u5728\u200b16kHz\u200b\u91c7\u6837\u200b\u7684\u200b\u8bed\u97f3\u200b\u97f3\u9891\u200b\u6570\u636e\u200b\u4e0a\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u3002\u200b\u91cd\u8981\u200b\u7684\u200b\u662f\u200b\uff0c\u200b\u60a8\u200b\u7684\u200b\u97f3\u9891\u200b\u6570\u636e\u200b\u7684\u200b\u91c7\u6837\u7387\u200b\u8981\u200b\u4e0e\u200b\u7528\u4e8e\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u91c7\u6837\u7387\u200b\u5339\u914d\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u6570\u636e\u200b\u7684\u200b\u91c7\u6837\u7387\u200b\u4e0d\u540c\u200b\uff0c\u200b\u90a3\u4e48\u200b\u60a8\u200b\u9700\u8981\u200b\u5bf9\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u91cd\u65b0\u200b\u91c7\u6837\u200b\u3002</p> <ol> <li>\u200b\u4f7f\u7528\u200b\ud83e\udd17 Datasets\u200b\u7684\u200b[<code>~datasets.Dataset.cast_column</code>]\u200b\u65b9\u6cd5\u200b\u5c06\u200b\u91c7\u6837\u7387\u200b\u63d0\u5347\u200b\u5230\u200b16kHz\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16_000))\n</code></pre> <ol> <li>\u200b\u518d\u6b21\u200b\u8c03\u7528\u200b <code>audio</code> \u200b\u5217\u4ee5\u200b\u91cd\u65b0\u200b\u91c7\u6837\u200b\u97f3\u9891\u6587\u4ef6\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; dataset[0][\"audio\"]\n{'array': array([ 2.3443763e-05,  2.1729663e-04,  2.2145823e-04, ...,\n         3.8356509e-05, -7.3497440e-06, -2.1754686e-05], dtype=float32),\n 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav',\n 'sampling_rate': 16000}\n</code></pre> <p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200b<code>feature extractor</code>\u200b\u4ee5\u200b\u5bf9\u200b\u8f93\u5165\u200b\u8fdb\u884c\u200b\u6807\u51c6\u5316\u200b\u548c\u200b\u586b\u5145\u200b\u3002\u200b\u5f53\u200b\u586b\u5145\u200b\u6587\u672c\u200b\u6570\u636e\u200b\u65f6\u200b\uff0c\u200b\u4f1a\u4e3a\u200b\u8f83\u200b\u77ed\u200b\u7684\u200b\u5e8f\u5217\u200b\u6dfb\u52a0\u200b <code>0</code>\u3002\u200b\u76f8\u540c\u200b\u7684\u200b\u7406\u5ff5\u200b\u9002\u7528\u200b\u4e8e\u200b\u97f3\u9891\u200b\u6570\u636e\u200b\u3002<code>feature extractor</code>\u200b\u6dfb\u52a0\u200b <code>0</code> - \u200b\u88ab\u200b\u89e3\u91ca\u200b\u4e3a\u200b\u9759\u97f3\u200b - \u200b\u5230\u200b<code>array</code> \u3002</p> <p>\u200b\u4f7f\u7528\u200b [<code>AutoFeatureExtractor.from_pretrained</code>] \u200b\u52a0\u8f7d\u200b<code>feature extractor</code>\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoFeatureExtractor\n\n&gt;&gt;&gt; feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n</code></pre> <p>\u200b\u5c06\u200b\u97f3\u9891\u200b <code>array</code> \u200b\u4f20\u9012\u200b\u7ed9\u200b<code>feature extractor</code>\u3002\u200b\u6211\u4eec\u200b\u8fd8\u200b\u5efa\u8bae\u200b\u5728\u200b<code>feature extractor</code>\u200b\u4e2d\u200b\u6dfb\u52a0\u200b <code>sampling_rate</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u4ee5\u200b\u66f4\u597d\u200b\u5730\u200b\u8c03\u8bd5\u200b\u53ef\u80fd\u200b\u53d1\u751f\u200b\u7684\u200b\u9759\u97f3\u200b\u9519\u8bef\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; audio_input = [dataset[0][\"audio\"][\"array\"]]\n&gt;&gt;&gt; feature_extractor(audio_input, sampling_rate=16000)\n{'input_values': [array([ 3.8106556e-04,  2.7506407e-03,  2.8015103e-03, ...,\n        5.6335266e-04,  4.6588284e-06, -1.7142107e-04], dtype=float32)]}\n</code></pre> <p>\u200b\u5c31\u200b\u50cf\u200b<code>tokenizer</code>\u200b\u4e00\u6837\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5e94\u7528\u200b\u586b\u5145\u200b\u6216\u200b\u622a\u65ad\u200b\u6765\u200b\u5904\u7406\u200b\u6279\u6b21\u200b\u4e2d\u200b\u7684\u200b\u53ef\u53d8\u200b\u5e8f\u5217\u200b\u3002\u200b\u8bf7\u200b\u67e5\u770b\u200b\u8fd9\u200b\u4e24\u4e2a\u200b\u97f3\u9891\u200b\u6837\u672c\u200b\u7684\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; dataset[0][\"audio\"][\"array\"].shape\n(173398,)\n\n&gt;&gt;&gt; dataset[1][\"audio\"][\"array\"].shape\n(106496,)\n</code></pre> <p>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u51fd\u6570\u200b\u6765\u200b\u9884\u5904\u7406\u200b\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u4ee5\u200b\u4f7f\u200b\u97f3\u9891\u200b\u6837\u672c\u200b\u5177\u6709\u200b\u76f8\u540c\u200b\u7684\u200b\u957f\u5ea6\u200b\u3002\u200b\u901a\u8fc7\u200b\u6307\u5b9a\u200b\u6700\u5927\u200b\u6837\u672c\u200b\u957f\u5ea6\u200b\uff0c<code>feature extractor</code>\u200b\u5c06\u200b\u586b\u5145\u200b\u6216\u200b\u622a\u65ad\u200b\u5e8f\u5217\u200b\u4ee5\u4f7f\u200b\u5176\u200b\u5339\u914d\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; def preprocess_function(examples):\n...     audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n...     inputs = feature_extractor(\n...         audio_arrays,\n...         sampling_rate=16000,\n...         padding=True,\n...         max_length=100000,\n...         truncation=True,\n...     )\n...     return inputs\n</code></pre> <p>\u200b\u5c06\u200b<code>preprocess_function</code>\u200b\u5e94\u7528\u200b\u4e8e\u200b\u6570\u636e\u200b\u96c6\u4e2d\u200b\u7684\u200b\u524d\u200b\u51e0\u4e2a\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; processed_dataset = preprocess_function(dataset[:5])\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u6837\u672c\u200b\u957f\u5ea6\u200b\u662f\u200b\u76f8\u540c\u200b\u7684\u200b\uff0c\u200b\u5e76\u4e14\u200b\u4e0e\u200b\u6307\u5b9a\u200b\u7684\u200b\u6700\u5927\u200b\u957f\u5ea6\u200b\u5339\u914d\u200b\u3002\u200b\u60a8\u200b\u73b0\u5728\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u7ecf\u8fc7\u200b\u5904\u7406\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u4f20\u9012\u200b\u7ed9\u200b\u6a21\u578b\u200b\u4e86\u200b\uff01</p> <pre><code>&gt;&gt;&gt; processed_dataset[\"input_values\"][0].shape\n(100000,)\n\n&gt;&gt;&gt; processed_dataset[\"input_values\"][1].shape\n(100000,)\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/preprocessing/#_7","title":"\u8ba1\u7b97\u673a\u200b\u89c6\u89c9","text":"<p>\u200b\u5bf9\u4e8e\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u4efb\u52a1\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b image processor\u200b\u6765\u200b\u51c6\u5907\u200b\u6570\u636e\u200b\u96c6\u4ee5\u200b\u4f9b\u200b\u6a21\u578b\u200b\u4f7f\u7528\u200b\u3002\u200b\u56fe\u50cf\u200b\u9884\u5904\u7406\u200b\u5305\u62ec\u200b\u591a\u4e2a\u200b\u6b65\u9aa4\u200b\u5c06\u200b\u56fe\u50cf\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6a21\u578b\u200b\u671f\u671b\u200b\u8f93\u5165\u200b\u7684\u200b\u683c\u5f0f\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u6b65\u9aa4\u200b\u5305\u62ec\u200b\u4f46\u200b\u4e0d\u200b\u9650\u4e8e\u200b\u8c03\u6574\u200b\u5927\u5c0f\u200b\u3001\u200b\u6807\u51c6\u5316\u200b\u3001\u200b\u989c\u8272\u200b\u901a\u9053\u200b\u6821\u6b63\u200b\u4ee5\u53ca\u200b\u5c06\u200b\u56fe\u50cf\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u5f20\u91cf\u200b\u3002</p> <p> <p>\u200b\u56fe\u50cf\u200b\u9884\u5904\u7406\u200b\u901a\u5e38\u200b\u9075\u5faa\u200b\u67d0\u79cd\u200b\u5f62\u5f0f\u200b\u7684\u200b\u56fe\u50cf\u589e\u5f3a\u200b\u3002\u200b\u56fe\u50cf\u200b\u9884\u5904\u7406\u200b\u548c\u200b\u56fe\u50cf\u589e\u5f3a\u200b\u90fd\u200b\u4f1a\u200b\u6539\u53d8\u200b\u56fe\u50cf\u200b\u6570\u636e\u200b\uff0c\u200b\u4f46\u200b\u5b83\u4eec\u200b\u6709\u200b\u4e0d\u540c\u200b\u7684\u200b\u76ee\u7684\u200b\uff1a</p> <ul> <li>\u200b\u56fe\u50cf\u589e\u5f3a\u200b\u53ef\u4ee5\u200b\u5e2e\u52a9\u200b\u9632\u6b62\u200b\u8fc7\u62df\u200b\u5408\u5e76\u200b\u589e\u52a0\u200b\u6a21\u578b\u200b\u7684\u200b\u9c81\u68d2\u6027\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u6570\u636e\u200b\u589e\u5f3a\u200b\u65b9\u9762\u200b\u5145\u5206\u53d1\u6325\u200b\u521b\u9020\u6027\u200b - \u200b\u8c03\u6574\u200b\u4eae\u5ea6\u200b\u548c\u200b\u989c\u8272\u200b\u3001\u200b\u88c1\u526a\u200b\u3001\u200b\u65cb\u8f6c\u200b\u3001\u200b\u8c03\u6574\u200b\u5927\u5c0f\u200b\u3001\u200b\u7f29\u653e\u200b\u7b49\u200b\u3002\u200b\u4f46\u200b\u8981\u200b\u6ce8\u610f\u200b\u4e0d\u8981\u200b\u6539\u53d8\u200b\u56fe\u50cf\u200b\u7684\u200b\u542b\u4e49\u200b\u3002</li> <li>\u200b\u56fe\u50cf\u200b\u9884\u5904\u7406\u200b\u786e\u4fdd\u200b\u56fe\u50cf\u200b\u4e0e\u200b\u6a21\u578b\u200b\u9884\u671f\u200b\u7684\u200b\u8f93\u5165\u200b\u683c\u5f0f\u200b\u5339\u914d\u200b\u3002\u200b\u5728\u200b\u5fae\u8c03\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u5fc5\u987b\u200b\u5bf9\u200b\u56fe\u50cf\u200b\u8fdb\u884c\u200b\u4e0e\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u76f8\u540c\u200b\u7684\u200b\u9884\u5904\u7406\u200b\u3002</li> </ul> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4efb\u4f55\u200b\u60a8\u200b\u559c\u6b22\u200b\u7684\u200b\u56fe\u50cf\u589e\u5f3a\u200b\u5e93\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u56fe\u50cf\u200b\u9884\u5904\u7406\u200b\uff0c\u200b\u8bf7\u200b\u4f7f\u7528\u200b\u4e0e\u200b\u6a21\u578b\u200b\u76f8\u5173\u8054\u200b\u7684\u200b<code>ImageProcessor</code>\u3002</p> <p></p> <p>\u200b\u52a0\u8f7d\u200bfood101\u200b\u6570\u636e\u200b\u96c6\u200b\uff08\u200b\u6709\u5173\u200b\u5982\u4f55\u200b\u52a0\u8f7d\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\ud83e\udd17 Datasets\u200b\u6559\u7a0b\u200b\uff09\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u5728\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u6570\u636e\u200b\u96c6\u4e2d\u200b\u4f7f\u7528\u200b\u56fe\u50cf\u200b\u5904\u7406\u5668\u200b\uff1a</p> <p> <p>\u200b\u56e0\u4e3a\u200b\u6570\u636e\u200b\u96c6\u200b\u76f8\u5f53\u200b\u5927\u200b\uff0c\u200b\u8bf7\u200b\u4f7f\u7528\u200b\ud83e\udd17 Datasets\u200b\u7684\u200b<code>split</code>\u200b\u53c2\u6570\u200b\u52a0\u8f7d\u200b\u8bad\u7ec3\u200b\u96c6\u4e2d\u200b\u7684\u200b\u5c11\u91cf\u200b\u6837\u672c\u200b\uff01</p> <p></p> <pre><code>&gt;&gt;&gt; from datasets import load_dataset\n\n&gt;&gt;&gt; dataset = load_dataset(\"food101\", split=\"train[:100]\")\n</code></pre> <p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u4f7f\u7528\u200b\ud83e\udd17 Datasets\u200b\u7684\u200b<code>Image</code>\u200b\u529f\u80fd\u200b\u67e5\u770b\u200b\u56fe\u50cf\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; dataset[0][\"image\"]\n</code></pre> <p>\u200b\u4f7f\u7528\u200b [<code>AutoImageProcessor.from_pretrained</code>] \u200b\u52a0\u8f7d\u200b<code>image processor</code>\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoImageProcessor\n\n&gt;&gt;&gt; image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n</code></pre> <p>\u200b\u9996\u5148\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u8fdb\u884c\u200b\u56fe\u50cf\u589e\u5f3a\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4efb\u4f55\u200b\u60a8\u200b\u559c\u6b22\u200b\u7684\u200b\u5e93\u200b\uff0c\u200b\u4f46\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4f7f\u7528\u200btorchvision\u200b\u7684\u200b<code>transforms</code>\u200b\u6a21\u5757\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200b\u5174\u8da3\u200b\u4f7f\u7528\u200b\u5176\u4ed6\u200b\u6570\u636e\u200b\u589e\u5f3a\u200b\u5e93\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200bAlbumentations\u200b\u6216\u200bKornia notebooks\u200b\u4e2d\u200b\u7684\u200b\u793a\u4f8b\u200b\u3002</p> <ol> <li>\u200b\u5728\u200b\u8fd9\u91cc\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b<code>Compose</code>\u200b\u5c06\u200b<code>RandomResizedCrop</code>\u200b\u548c\u200b <code>ColorJitter</code>\u200b\u53d8\u6362\u200b\u8fde\u63a5\u200b\u5728\u200b\u4e00\u8d77\u200b\u3002\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u8c03\u6574\u200b\u5927\u5c0f\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u4ece\u200b<code>image_processor</code>\u200b\u4e2d\u200b\u83b7\u53d6\u200b\u56fe\u50cf\u200b\u5c3a\u5bf8\u200b\u8981\u6c42\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u4e00\u4e9b\u200b\u6a21\u578b\u200b\uff0c\u200b\u7cbe\u786e\u200b\u7684\u200b\u9ad8\u5ea6\u200b\u548c\u200b\u5bbd\u5ea6\u200b\u9700\u8981\u200b\u88ab\u200b\u5b9a\u4e49\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u5176\u4ed6\u200b\u6a21\u578b\u200b\u53ea\u200b\u9700\u200b\u5b9a\u4e49\u200b<code>shortest_edge</code>\u3002</li> </ol> <pre><code>&gt;&gt;&gt; from torchvision.transforms import RandomResizedCrop, ColorJitter, Compose\n\n&gt;&gt;&gt; size = (\n...     image_processor.size[\"shortest_edge\"]\n...     if \"shortest_edge\" in image_processor.size\n...     else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n... )\n\n&gt;&gt;&gt; _transforms = Compose([RandomResizedCrop(size), ColorJitter(brightness=0.5, hue=0.5)])\n</code></pre> <ol> <li>\u200b\u6a21\u578b\u200b\u63a5\u53d7\u200b <code>pixel_values</code> \u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\u3002<code>ImageProcessor</code> \u200b\u53ef\u4ee5\u200b\u8fdb\u884c\u200b\u56fe\u50cf\u200b\u7684\u200b\u6807\u51c6\u5316\u200b\uff0c\u200b\u5e76\u200b\u751f\u6210\u200b\u9002\u5f53\u200b\u7684\u200b\u5f20\u91cf\u200b\u3002\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u51fd\u6570\u200b\uff0c\u200b\u5c06\u200b\u56fe\u50cf\u589e\u5f3a\u200b\u548c\u200b\u56fe\u50cf\u200b\u9884\u5904\u7406\u200b\u6b65\u9aa4\u200b\u7ec4\u5408\u200b\u8d77\u6765\u200b\u5904\u7406\u200b\u6279\u91cf\u200b\u56fe\u50cf\u200b\uff0c\u200b\u5e76\u200b\u751f\u6210\u200b <code>pixel_values</code>\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; def transforms(examples):\n...     images = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n...     examples[\"pixel_values\"] = image_processor(images, do_resize=False, return_tensors=\"pt\")[\"pixel_values\"]\n...     return examples\n</code></pre> <p> <p>\u200b\u5728\u200b\u4e0a\u9762\u200b\u7684\u200b\u793a\u4f8b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u8bbe\u7f6e\u200b<code>do_resize=False</code>\uff0c\u200b\u56e0\u4e3a\u200b\u6211\u4eec\u200b\u5df2\u7ecf\u200b\u5728\u200b\u56fe\u50cf\u589e\u5f3a\u200b\u8f6c\u6362\u200b\u4e2d\u200b\u8c03\u6574\u200b\u4e86\u200b\u56fe\u50cf\u200b\u7684\u200b\u5927\u5c0f\u200b\uff0c\u200b\u5e76\u200b\u5229\u7528\u200b\u4e86\u200b\u9002\u5f53\u200b\u7684\u200b<code>image_processor</code>\u200b\u7684\u200b<code>size</code>\u200b\u5c5e\u6027\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u5728\u200b\u56fe\u50cf\u589e\u5f3a\u200b\u671f\u95f4\u200b\u4e0d\u200b\u8c03\u6574\u200b\u56fe\u50cf\u200b\u7684\u200b\u5927\u5c0f\u200b\uff0c\u200b\u8bf7\u200b\u5c06\u200b\u6b64\u53c2\u6570\u200b\u6392\u9664\u200b\u5728\u5916\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b<code>ImageProcessor</code>\u200b\u5c06\u200b\u5904\u7406\u200b\u8c03\u6574\u200b\u5927\u5c0f\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u5e0c\u671b\u200b\u5c06\u200b\u56fe\u50cf\u200b\u6807\u51c6\u5316\u200b\u6b65\u9aa4\u200b\u4e3a\u200b\u56fe\u50cf\u589e\u5f3a\u200b\u7684\u200b\u4e00\u90e8\u5206\u200b\uff0c\u200b\u8bf7\u200b\u4f7f\u7528\u200b<code>image_processor.image_mean</code>\u200b\u548c\u200b<code>image_processor.image_std</code>\u3002</p> <p></p> <ol> <li>\u200b\u7136\u540e\u200b\u4f7f\u7528\u200b\ud83e\udd17 Datasets\u200b\u7684\u200b<code>set_transform</code>\u200b\u5728\u200b\u8fd0\u884c\u200b\u65f6\u200b\u5e94\u7528\u200b\u8fd9\u4e9b\u200b\u53d8\u6362\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; dataset.set_transform(transforms)\n</code></pre> <ol> <li>\u200b\u73b0\u5728\u200b\uff0c\u200b\u5f53\u200b\u60a8\u200b\u8bbf\u95ee\u200b\u56fe\u50cf\u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u6ce8\u610f\u200b\u5230\u200b<code>image processor</code>\u200b\u5df2\u200b\u6dfb\u52a0\u200b\u4e86\u200b <code>pixel_values</code>\u3002\u200b\u60a8\u200b\u73b0\u5728\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u7ecf\u8fc7\u200b\u5904\u7406\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u4f20\u9012\u200b\u7ed9\u200b\u6a21\u578b\u200b\u4e86\u200b\uff01</li> </ol> <pre><code>&gt;&gt;&gt; dataset[0].keys()\n</code></pre> <p>\u200b\u8fd9\u200b\u662f\u200b\u5728\u200b\u5e94\u7528\u200b\u53d8\u6362\u200b\u540e\u200b\u7684\u200b\u56fe\u50cf\u200b\u6837\u5b50\u200b\u3002\u200b\u56fe\u50cf\u200b\u5df2\u200b\u88ab\u200b\u968f\u673a\u200b\u88c1\u526a\u200b\uff0c\u200b\u5e76\u200b\u5176\u200b\u989c\u8272\u200b\u5c5e\u6027\u200b\u53d1\u751f\u200b\u4e86\u200b\u53d8\u5316\u200b\u3002</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import matplotlib.pyplot as plt\n\n&gt;&gt;&gt; img = dataset[0][\"pixel_values\"]\n&gt;&gt;&gt; plt.imshow(img.permute(1, 2, 0))\n</code></pre> <p> <p>\u200b\u5bf9\u4e8e\u200b\u8bf8\u5982\u200b\u76ee\u6807\u200b\u68c0\u6d4b\u200b\u3001\u200b\u8bed\u4e49\u200b\u5206\u5272\u200b\u3001\u200b\u5b9e\u4f8b\u200b\u5206\u5272\u200b\u548c\u200b\u5168\u666f\u200b\u5206\u5272\u200b\u7b49\u200b\u4efb\u52a1\u200b\uff0c<code>ImageProcessor</code>\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u8bad\u7ec3\u200b\u540e\u5904\u7406\u200b\u65b9\u6cd5\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u65b9\u6cd5\u200b\u5c06\u200b\u6a21\u578b\u200b\u7684\u200b\u539f\u59cb\u200b\u8f93\u51fa\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6709\u200b\u610f\u4e49\u200b\u7684\u200b\u9884\u6d4b\u200b\uff0c\u200b\u5982\u200b\u8fb9\u754c\u200b\u6846\u200b\u6216\u200b\u5206\u5272\u200b\u5730\u56fe\u200b\u3002</p> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/preprocessing/#_8","title":"\u586b\u5145","text":"<p>\u200b\u5728\u200b\u67d0\u4e9b\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5728\u200b\u5fae\u8c03\u200bDETR\u200b\u65f6\u200b\uff0c\u200b\u6a21\u578b\u200b\u5728\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u5e94\u7528\u200b\u4e86\u200b\u5c3a\u5ea6\u200b\u589e\u5f3a\u200b\u3002\u200b\u8fd9\u200b\u53ef\u80fd\u200b\u5bfc\u81f4\u200b\u6279\u5904\u7406\u200b\u4e2d\u200b\u7684\u200b\u56fe\u50cf\u200b\u5927\u5c0f\u200b\u4e0d\u540c\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b[<code>DetrImageProcessor.pad</code>]\u200b\u6765\u200b\u6307\u5b9a\u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200b<code>collate_fn</code>\u200b\u5c06\u200b\u56fe\u50cf\u200b\u6279\u5904\u7406\u200b\u5728\u200b\u4e00\u8d77\u200b\u3002</p> <pre><code>&gt;&gt;&gt; def collate_fn(batch):\n...     pixel_values = [item[\"pixel_values\"] for item in batch]\n...     encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n...     labels = [item[\"labels\"] for item in batch]\n...     batch = {}\n...     batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n...     batch[\"pixel_mask\"] = encoding[\"pixel_mask\"]\n...     batch[\"labels\"] = labels\n...     return batch\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/preprocessing/#_9","title":"\u591a\u200b\u6a21\u6001","text":"<p>\u200b\u5bf9\u4e8e\u200b\u6d89\u53ca\u200b\u591a\u200b\u6a21\u6001\u200b\u8f93\u5165\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200bprocessor\u200b\u6765\u200b\u4e3a\u200b\u6a21\u578b\u200b\u51c6\u5907\u200b\u6570\u636e\u200b\u96c6\u200b\u3002<code>processor</code>\u200b\u5c06\u200b\u4e24\u4e2a\u200b\u5904\u7406\u200b\u5bf9\u8c61\u200b-\u200b\u4f8b\u5982\u200b<code>tokenizer</code>\u200b\u548c\u200b<code>feature extractor</code>-\u200b\u7ec4\u5408\u200b\u5728\u200b\u4e00\u8d77\u200b\u3002</p> <p>\u200b\u52a0\u8f7d\u200bLJ Speech\u200b\u6570\u636e\u200b\u96c6\u200b\uff08\u200b\u6709\u5173\u200b\u5982\u4f55\u200b\u52a0\u8f7d\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\ud83e\udd17 Datasets \u200b\u6559\u7a0b\u200b\uff09\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b<code>processor</code>\u200b\u8fdb\u884c\u200b\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b\uff08ASR\uff09\uff1a</p> <pre><code>&gt;&gt;&gt; from datasets import load_dataset\n\n&gt;&gt;&gt; lj_speech = load_dataset(\"lj_speech\", split=\"train\")\n</code></pre> <p>\u200b\u5bf9\u4e8e\u200bASR\uff08\u200b\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b\uff09\uff0c\u200b\u4e3b\u8981\u200b\u5173\u6ce8\u200b<code>audio</code>\u200b\u548c\u200b<code>text</code>\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u4ee5\u200b\u5220\u9664\u200b\u5176\u4ed6\u200b\u5217\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; lj_speech = lj_speech.map(remove_columns=[\"file\", \"id\", \"normalized_text\"])\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u67e5\u770b\u200b<code>audio</code>\u200b\u548c\u200b<code>text</code>\u200b\u5217\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; lj_speech[0][\"audio\"]\n{'array': array([-7.3242188e-04, -7.6293945e-04, -6.4086914e-04, ...,\n         7.3242188e-04,  2.1362305e-04,  6.1035156e-05], dtype=float32),\n 'path': '/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav',\n 'sampling_rate': 22050}\n\n&gt;&gt;&gt; lj_speech[0][\"text\"]\n'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'\n</code></pre> <p>\u200b\u8bf7\u200b\u8bb0\u4f4f\u200b\uff0c\u200b\u60a8\u200b\u5e94\u200b\u59cb\u7ec8\u200b\u91cd\u65b0\u200b\u91c7\u6837\u200b\u97f3\u9891\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u91c7\u6837\u7387\u200b\uff0c\u200b\u4ee5\u200b\u5339\u914d\u200b\u7528\u4e8e\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u91c7\u6837\u7387\u200b\uff01</p> <pre><code>&gt;&gt;&gt; lj_speech = lj_speech.cast_column(\"audio\", Audio(sampling_rate=16_000))\n</code></pre> <p>\u200b\u4f7f\u7528\u200b[<code>AutoProcessor.from_pretrained</code>]\u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200b<code>processor</code>\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoProcessor\n\n&gt;&gt;&gt; processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n</code></pre> <ol> <li>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u51fd\u6570\u200b\uff0c\u200b\u7528\u4e8e\u200b\u5c06\u200b\u5305\u542b\u200b\u5728\u200b <code>array</code> \u200b\u4e2d\u200b\u7684\u200b\u97f3\u9891\u200b\u6570\u636e\u5904\u7406\u200b\u4e3a\u200b <code>input_values</code>\uff0c\u200b\u5e76\u200b\u5c06\u200b <code>text</code> \u200b\u6807\u8bb0\u200b\u4e3a\u200b <code>labels</code>\u3002\u200b\u8fd9\u4e9b\u200b\u5c06\u200b\u662f\u200b\u8f93\u5165\u200b\u6a21\u578b\u200b\u7684\u200b\u6570\u636e\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; def prepare_dataset(example):\n...     audio = example[\"audio\"]\n\n...     example.update(processor(audio=audio[\"array\"], text=example[\"text\"], sampling_rate=16000))\n\n...     return example\n</code></pre> <ol> <li>\u200b\u5c06\u200b <code>prepare_dataset</code> \u200b\u51fd\u6570\u200b\u5e94\u7528\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u793a\u4f8b\u200b\uff1a</li> </ol> <pre><code>&gt;&gt;&gt; prepare_dataset(lj_speech[0])\n</code></pre> <p><code>processor</code>\u200b\u73b0\u5728\u200b\u5df2\u7ecf\u200b\u6dfb\u52a0\u200b\u4e86\u200b <code>input_values</code> \u200b\u548c\u200b <code>labels</code>\uff0c\u200b\u5e76\u4e14\u200b\u91c7\u6837\u7387\u200b\u4e5f\u200b\u6b63\u786e\u200b\u964d\u4f4e\u200b\u4e3a\u200b\u4e3a\u200b16kHz\u3002\u200b\u73b0\u5728\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u5904\u7406\u200b\u540e\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u4f20\u9012\u200b\u7ed9\u200b\u6a21\u578b\u200b\uff01</p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/","title":"Training","text":""},{"location":"2-%E6%95%99%E7%A8%8B/training/#_1","title":"\u5fae\u8c03\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b","text":"<p>[[open-in-colab]]</p> <p>\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u6709\u200b\u8bb8\u591a\u200b\u663e\u8457\u200b\u7684\u200b\u597d\u5904\u200b\u3002\u200b\u5b83\u200b\u964d\u4f4e\u200b\u4e86\u200b\u8ba1\u7b97\u6210\u672c\u200b\uff0c\u200b\u51cf\u5c11\u200b\u4e86\u200b\u78b3\u200b\u6392\u653e\u200b\uff0c\u200b\u540c\u65f6\u200b\u5141\u8bb8\u200b\u60a8\u200b\u4f7f\u7528\u200b\u6700\u200b\u5148\u8fdb\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u800c\u200b\u65e0\u9700\u200b\u4ece\u5934\u5f00\u59cb\u200b\u8bad\u7ec3\u200b\u4e00\u4e2a\u200b\u3002\ud83e\udd17 Transformers \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u6d89\u53ca\u200b\u5404\u79cd\u200b\u4efb\u52a1\u200b\u7684\u200b\u6210\u5343\u4e0a\u4e07\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002\u200b\u5f53\u200b\u60a8\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5728\u200b\u4e0e\u200b\u4efb\u52a1\u200b\u76f8\u5173\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u8bad\u7ec3\u200b\u8be5\u200b\u6a21\u578b\u200b\u3002\u200b\u8fd9\u79cd\u200b\u64cd\u4f5c\u200b\u88ab\u200b\u79f0\u4e3a\u200b\u5fae\u8c03\u200b\uff0c\u200b\u662f\u200b\u4e00\u79cd\u200b\u975e\u5e38\u200b\u5f3a\u5927\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6280\u672f\u200b\u3002\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u4f7f\u7528\u200b\u60a8\u200b\u9009\u62e9\u200b\u7684\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6846\u67b6\u200b\u6765\u200b\u5fae\u8c03\u200b\u4e00\u4e2a\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff1a</p> <ul> <li>\u200b\u4f7f\u7528\u200b \ud83e\udd17 Transformers \u200b\u7684\u200b [<code>Trainer</code>] \u200b\u6765\u200b\u5fae\u8c03\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002</li> <li>\u200b\u5728\u200b TensorFlow \u200b\u4e2d\u200b\u4f7f\u7528\u200b Keras \u200b\u6765\u200b\u5fae\u8c03\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002</li> <li>\u200b\u5728\u200b\u539f\u751f\u200b PyTorch \u200b\u4e2d\u200b\u5fae\u8c03\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002</li> </ul> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#_2","title":"\u51c6\u5907\u200b\u6570\u636e\u200b\u96c6","text":"<p>\u200b\u5728\u200b\u60a8\u200b\u8fdb\u884c\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u5fae\u8c03\u200b\u4e4b\u524d\u200b\uff0c\u200b\u9700\u8981\u200b\u4e0b\u8f7d\u200b\u4e00\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\u5e76\u200b\u4e3a\u200b\u8bad\u7ec3\u200b\u505a\u597d\u200b\u51c6\u5907\u200b\u3002\u200b\u4e4b\u524d\u200b\u7684\u200b\u6559\u7a0b\u200b\u5411\u200b\u60a8\u200b\u5c55\u793a\u200b\u4e86\u200b\u5982\u4f55\u200b\u5904\u7406\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\uff0c\u200b\u73b0\u5728\u200b\u60a8\u200b\u6709\u200b\u673a\u4f1a\u200b\u5c06\u200b\u8fd9\u4e9b\u200b\u6280\u80fd\u200b\u4ed8\u8bf8\u5b9e\u8df5\u200b\uff01</p> <p>\u200b\u9996\u5148\u200b\uff0c\u200b\u52a0\u8f7d\u200bYelp\u200b\u8bc4\u8bba\u200b\u6570\u636e\u200b\u96c6\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from datasets import load_dataset\n\n&gt;&gt;&gt; dataset = load_dataset(\"yelp_review_full\")\n&gt;&gt;&gt; dataset[\"train\"][100]\n{'label': 0,\n 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}\n</code></pre> <p>\u200b\u6b63\u5982\u200b\u60a8\u200b\u73b0\u5728\u200b\u6240\u77e5\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b<code>tokenizer</code>\u200b\u6765\u200b\u5904\u7406\u200b\u6587\u672c\u200b\uff0c\u200b\u5305\u62ec\u200b\u586b\u5145\u200b\u548c\u200b\u622a\u65ad\u200b\u64cd\u4f5c\u200b\u4ee5\u200b\u5904\u7406\u200b\u53ef\u53d8\u200b\u7684\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u3002\u200b\u5982\u679c\u200b\u8981\u200b\u4e00\u6b21\u6027\u200b\u5904\u7406\u200b\u60a8\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b \ud83e\udd17 Datasets \u200b\u7684\u200b <code>map</code> \u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5c06\u200b\u9884\u5904\u7406\u200b\u51fd\u6570\u200b\u5e94\u7528\u200b\u4e8e\u200b\u6574\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n\n\n&gt;&gt;&gt; def tokenize_function(examples):\n...     return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\n\n&gt;&gt;&gt; tokenized_datasets = dataset.map(tokenize_function, batched=True)\n</code></pre> \u200b\u5982\u679c\u200b\u613f\u610f\u200b\u7684\u8bdd\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u5b8c\u6574\u200b\u6570\u636e\u200b\u96c6\u200b\u63d0\u53d6\u200b\u4e00\u4e2a\u200b\u8f83\u200b\u5c0f\u5b50\u200b\u96c6\u6765\u200b\u8fdb\u884c\u200b\u5fae\u8c03\u200b\uff0c\u200b\u4ee5\u200b\u51cf\u5c11\u200b\u8bad\u7ec3\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u65f6\u95f4\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n&gt;&gt;&gt; small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n</code></pre> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#_3","title":"\u8bad\u7ec3","text":"<p>\u200b\u6b64\u65f6\u200b\uff0c\u200b\u60a8\u200b\u5e94\u8be5\u200b\u6839\u636e\u200b\u60a8\u200b\u8bad\u7ec3\u200b\u6240\u7528\u200b\u7684\u200b\u6846\u67b6\u200b\u6765\u200b\u9009\u62e9\u200b\u5bf9\u5e94\u200b\u7684\u200b\u6559\u7a0b\u200b\u7ae0\u8282\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u53f3\u4fa7\u200b\u7684\u200b\u94fe\u63a5\u200b\u8df3\u8f6c\u200b\u5230\u200b\u60a8\u200b\u60f3\u8981\u200b\u7684\u200b\u7ae0\u8282\u200b - \u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u9690\u85cf\u200b\u67d0\u4e2a\u200b\u6846\u67b6\u200b\u5bf9\u5e94\u200b\u7684\u200b\u6240\u6709\u200b\u6559\u7a0b\u200b\u5185\u5bb9\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u4f7f\u7528\u200b\u53f3\u4e0a\u89d2\u200b\u7684\u200b\u6309\u94ae\u200b\uff01</p> <p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#pytorch-trainer","title":"\u4f7f\u7528\u200b PyTorch Trainer \u200b\u8fdb\u884c\u200b\u8bad\u7ec3","text":"<p>\ud83e\udd17 Transformers \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u4e13\u200b\u4e3a\u200b\u8bad\u7ec3\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u800c\u200b\u4f18\u5316\u200b\u7684\u200b [<code>Trainer</code>] \u200b\u7c7b\u200b\uff0c\u200b\u4f7f\u200b\u60a8\u200b\u65e0\u9700\u200b\u624b\u52a8\u200b\u7f16\u5199\u200b\u81ea\u5df1\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u6b65\u9aa4\u200b\u800c\u200b\u66f4\u200b\u8f7b\u677e\u200b\u5730\u200b\u5f00\u59cb\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u3002[<code>Trainer</code>] API \u200b\u652f\u6301\u200b\u5404\u79cd\u200b\u8bad\u7ec3\u200b\u9009\u9879\u200b\u548c\u200b\u529f\u80fd\u200b\uff0c\u200b\u5982\u200b\u65e5\u5fd7\u200b\u8bb0\u5f55\u200b\u3001\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u548c\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u3002</p> <p>\u200b\u9996\u5148\u200b\u52a0\u8f7d\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u5e76\u200b\u6307\u5b9a\u200b\u671f\u671b\u200b\u7684\u200b\u6807\u7b7e\u200b\u6570\u91cf\u200b\u3002\u200b\u6839\u636e\u200b Yelp Review \u200b\u6570\u636e\u200b\u96c6\u200b\u5361\u7247\u200b\uff0c\u200b\u60a8\u200b\u77e5\u9053\u200b\u6709\u200b\u4e94\u4e2a\u200b\u6807\u7b7e\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoModelForSequenceClassification\n\n&gt;&gt;&gt; model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)\n</code></pre> <p> <p>\u200b\u60a8\u200b\u5c06\u200b\u4f1a\u200b\u770b\u5230\u200b\u4e00\u4e2a\u200b\u8b66\u544a\u200b\uff0c\u200b\u63d0\u5230\u200b\u4e00\u4e9b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\u672a\u200b\u88ab\u200b\u4f7f\u7528\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u4e00\u4e9b\u200b\u6743\u91cd\u200b\u88ab\u200b\u968f\u673a\u200b\u521d\u59cb\u5316\u200b\u3002\u200b\u4e0d\u7528\u200b\u62c5\u5fc3\u200b\uff0c\u200b\u8fd9\u662f\u200b\u5b8c\u5168\u200b\u6b63\u5e38\u200b\u7684\u200b\uff01BERT \u200b\u6a21\u578b\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b<code>head</code>\u200b\u88ab\u200b\u4e22\u5f03\u200b\uff0c\u200b\u5e76\u200b\u66ff\u6362\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u968f\u673a\u200b\u521d\u59cb\u5316\u200b\u7684\u200b\u5206\u7c7b\u200b<code>head</code>\u3002\u200b\u60a8\u200b\u5c06\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u5e8f\u5217\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b\u4e0a\u200b\u5fae\u8c03\u200b\u8fd9\u4e2a\u200b\u65b0\u200b\u6a21\u578b\u200b<code>head</code>\uff0c\u200b\u5c06\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u77e5\u8bc6\u200b\u8f6c\u79fb\u200b\u7ed9\u200b\u5b83\u200b\u3002</p> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#_4","title":"\u8bad\u7ec3\u200b\u8d85\u200b\u53c2\u6570","text":"<p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b [<code>TrainingArguments</code>] \u200b\u7c7b\u200b\uff0c\u200b\u5176\u4e2d\u200b\u5305\u542b\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8c03\u6574\u200b\u7684\u200b\u6240\u6709\u200b\u8d85\u200b\u53c2\u6570\u200b\u4ee5\u53ca\u200b\u7528\u4e8e\u200b\u6fc0\u6d3b\u200b\u4e0d\u540c\u200b\u8bad\u7ec3\u200b\u9009\u9879\u200b\u7684\u200b\u6807\u5fd7\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u672c\u200b\u6559\u7a0b\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u9ed8\u8ba4\u200b\u7684\u200b\u8bad\u7ec3\u200b\u8d85\u200b\u53c2\u6570\u200b\u5f00\u59cb\u200b\uff0c\u200b\u4f46\u200b\u968f\u65f6\u200b\u53ef\u4ee5\u200b\u5c1d\u8bd5\u200b\u4e0d\u540c\u200b\u7684\u200b\u8bbe\u7f6e\u200b\u4ee5\u200b\u627e\u5230\u200b\u6700\u4f73\u200b\u8bbe\u7f6e\u200b\u3002</p> <p>\u200b\u6307\u5b9a\u200b\u4fdd\u5b58\u200b\u8bad\u7ec3\u200b\u68c0\u67e5\u70b9\u200b\u7684\u200b\u4f4d\u7f6e\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import TrainingArguments\n\n&gt;&gt;&gt; training_args = TrainingArguments(output_dir=\"test_trainer\")\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#_5","title":"\u8bc4\u4f30","text":"<p>[<code>Trainer</code>] \u200b\u5728\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u4e0d\u4f1a\u200b\u81ea\u52a8\u200b\u8bc4\u4f30\u200b\u6a21\u578b\u200b\u6027\u80fd\u200b\u3002\u200b\u60a8\u200b\u9700\u8981\u200b\u5411\u200b [<code>Trainer</code>] \u200b\u4f20\u9012\u200b\u4e00\u4e2a\u200b\u51fd\u6570\u200b\u6765\u200b\u8ba1\u7b97\u200b\u548c\u200b\u5c55\u793a\u200b\u6307\u6807\u200b\u3002\ud83e\udd17 Evaluate \u200b\u5e93\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b <code>accuracy</code> \u200b\u51fd\u6570\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>evaluate.load</code>] \u200b\u51fd\u6570\u200b\u52a0\u8f7d\u200b\u5b83\u200b\uff08\u200b\u6709\u5173\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u6b64\u200b\u5feb\u901f\u200b\u5165\u95e8\u200b\uff09\uff1a</p> <p><pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import evaluate\n\n&gt;&gt;&gt; metric = evaluate.load(\"accuracy\")\n</code></pre> \u200b\u5728\u200b <code>metric</code> \u200b\u4e0a\u200b\u8c03\u7528\u200b [<code>~evaluate.compute</code>] \u200b\u6765\u200b\u8ba1\u7b97\u200b\u60a8\u200b\u7684\u200b\u9884\u6d4b\u200b\u7684\u200b\u51c6\u786e\u6027\u200b\u3002\u200b\u5728\u200b\u5c06\u200b\u9884\u6d4b\u200b\u4f20\u9012\u200b\u7ed9\u200b <code>compute</code> \u200b\u4e4b\u524d\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5c06\u200b\u9884\u6d4b\u200b\u8f6c\u6362\u200b\u4e3a\u200b<code>logits</code>\uff08\u200b\u8bf7\u200b\u8bb0\u4f4f\u200b\uff0c\u200b\u6240\u6709\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u90fd\u200b\u8fd4\u56de\u200b\u5bf9\u200b<code>logits</code>\uff09\uff1a</p> <pre><code>&gt;&gt;&gt; def compute_metrics(eval_pred):\n...     logits, labels = eval_pred\n...     predictions = np.argmax(logits, axis=-1)\n...     return metric.compute(predictions=predictions, references=labels)\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u5e0c\u671b\u200b\u5728\u200b\u5fae\u8c03\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u76d1\u89c6\u200b\u8bc4\u4f30\u200b\u6307\u6807\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u53c2\u6570\u200b\u4e2d\u200b\u6307\u5b9a\u200b <code>evaluation_strategy</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u4ee5\u200b\u5728\u200b\u6bcf\u4e2a\u200b<code>epoch</code>\u200b\u7ed3\u675f\u200b\u65f6\u200b\u5c55\u793a\u200b\u8bc4\u4f30\u200b\u6307\u6807\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import TrainingArguments, Trainer\n\n&gt;&gt;&gt; training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#_6","title":"\u8bad\u7ec3\u5668","text":"<p>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u5305\u542b\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u3001\u200b\u8bad\u7ec3\u200b\u53c2\u6570\u200b\u3001\u200b\u8bad\u7ec3\u200b\u548c\u200b\u6d4b\u8bd5\u6570\u636e\u200b\u96c6\u200b\u4ee5\u53ca\u200b\u8bc4\u4f30\u200b\u51fd\u6570\u200b\u7684\u200b [<code>Trainer</code>] \u200b\u5bf9\u8c61\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; trainer = Trainer(\n...     model=model,\n...     args=training_args,\n...     train_dataset=small_train_dataset,\n...     eval_dataset=small_eval_dataset,\n...     compute_metrics=compute_metrics,\n... )\n</code></pre> \u200b\u7136\u540e\u200b\u8c03\u7528\u200b[<code>~transformers.Trainer.train</code>]\u200b\u4ee5\u200b\u5fae\u8c03\u200b\u6a21\u578b\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; trainer.train()\n</code></pre> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#kerastensorflow","title":"\u4f7f\u7528\u200bkeras\u200b\u8bad\u7ec3\u200bTensorFlow\u200b\u6a21\u578b","text":"<p>\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b Keras API \u200b\u5728\u200b TensorFlow \u200b\u4e2d\u200b\u8bad\u7ec3\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\uff01</p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#keras","title":"\u52a0\u8f7d\u200b\u7528\u4e8e\u200b Keras \u200b\u7684\u200b\u6570\u636e","text":"<p>\u200b\u5f53\u200b\u60a8\u200b\u5e0c\u671b\u200b\u4f7f\u7528\u200b Keras API \u200b\u8bad\u7ec3\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u8f6c\u6362\u200b\u4e3a\u200b Keras \u200b\u53ef\u200b\u7406\u89e3\u200b\u7684\u200b\u683c\u5f0f\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u5f88\u5c0f\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u6574\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\u8f6c\u6362\u200b\u4e3a\u200bNumPy\u200b\u6570\u7ec4\u200b\u5e76\u200b\u4f20\u9012\u200b\u7ed9\u200b Keras\u3002\u200b\u5728\u200b\u8fdb\u884c\u200b\u66f4\u200b\u590d\u6742\u200b\u7684\u200b\u64cd\u4f5c\u200b\u4e4b\u524d\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5148\u200b\u5c1d\u8bd5\u200b\u8fd9\u79cd\u200b\u65b9\u6cd5\u200b\u3002</p> <p>\u200b\u9996\u5148\u200b\uff0c\u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\u3002\u200b\u6211\u4eec\u200b\u5c06\u200b\u4f7f\u7528\u200b GLUE benchmark \u200b\u4e2d\u200b\u7684\u200b CoLA \u200b\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u662f\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u4e8c\u5143\u200b\u6587\u672c\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b\u3002\u200b\u73b0\u5728\u200b\u53ea\u200b\u4f7f\u7528\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u96c6\u200b\u3002</p> <p><pre><code>from datasets import load_dataset\n\ndataset = load_dataset(\"glue\", \"cola\")\ndataset = dataset[\"train\"]  # Just take the training split for now\n</code></pre> \u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u52a0\u8f7d\u200b\u4e00\u4e2a\u200b<code>tokenizer</code>\u200b\u5e76\u200b\u5c06\u200b\u6570\u636e\u200b\u6807\u8bb0\u200b\u4e3a\u200b NumPy \u200b\u6570\u7ec4\u200b\u3002\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u6807\u7b7e\u200b\u5df2\u7ecf\u200b\u662f\u200b\u7531\u200b 0 \u200b\u548c\u200b 1 \u200b\u7ec4\u6210\u200b\u7684\u200b<code>list</code>\uff0c\u200b\u56e0\u6b64\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u5c06\u200b\u5176\u200b\u8f6c\u6362\u200b\u4e3a\u200b NumPy \u200b\u6570\u7ec4\u200b\u800c\u200b\u65e0\u9700\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\u5904\u7406\u200b\uff01</p> <p><pre><code>from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\ntokenized_data = tokenizer(dataset[\"sentence\"], return_tensors=\"np\", padding=True)\n# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\ntokenized_data = dict(tokenized_data)\n\nlabels = np.array(dataset[\"label\"])  # Label is already an array of 0 and 1\n</code></pre> \u200b\u6700\u540e\u200b\uff0c\u200b\u52a0\u8f7d\u200b\u3001<code>compile</code> \u200b\u548c\u200b <code>fit</code> \u200b\u6a21\u578b\u200b\u3002\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0cTransformers \u200b\u6a21\u578b\u200b\u90fd\u200b\u6709\u200b\u4e00\u4e2a\u200b\u9ed8\u8ba4\u200b\u7684\u200b\u4e0e\u200b\u4efb\u52a1\u200b\u76f8\u5173\u200b\u7684\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9664\u975e\u200b\u60a8\u200b\u5e0c\u671b\u200b\u81ea\u5b9a\u4e49\u200b\uff0c\u200b\u5426\u5219\u200b\u65e0\u9700\u200b\u6307\u5b9a\u200b\u4e00\u4e2a\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\uff1a</p> <pre><code>from transformers import TFAutoModelForSequenceClassification\nfrom tensorflow.keras.optimizers import Adam\n\n# Load and compile our model\nmodel = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n# Lower learning rates are often better for fine-tuning transformers\nmodel.compile(optimizer=Adam(3e-5))  # No loss argument!\n\nmodel.fit(tokenized_data, labels)\n</code></pre> <p> <p>\u200b\u5f53\u200b\u60a8\u200b\u4f7f\u7528\u200b <code>compile()</code> \u200b\u7f16\u8bd1\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u65e0\u9700\u200b\u4f20\u9012\u200b\u635f\u5931\u200b\u53c2\u6570\u200b\uff01\u200b\u5982\u679c\u200b\u4e0d\u200b\u6307\u5b9a\u200b\u635f\u5931\u200b\u53c2\u6570\u200b\uff0cHugging Face \u200b\u6a21\u578b\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u9009\u62e9\u200b\u9002\u5408\u200b\u5176\u200b\u4efb\u52a1\u200b\u548c\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\u7684\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u3002\u200b\u5982\u679c\u200b\u9700\u8981\u200b\uff0c\u200b\u60a8\u200b\u59cb\u7ec8\u200b\u53ef\u4ee5\u200b\u81ea\u5df1\u200b\u6307\u5b9a\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u4ee5\u200b\u8986\u76d6\u200b\u9ed8\u8ba4\u200b\u914d\u7f6e\u200b\u3002</p> <p></p> <p>\u200b\u8fd9\u79cd\u200b\u65b9\u6cd5\u200b\u5bf9\u4e8e\u200b\u8f83\u200b\u5c0f\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u6548\u679c\u200b\u5f88\u200b\u597d\u200b\uff0c\u200b\u4f46\u200b\u5bf9\u4e8e\u200b\u8f83\u5927\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u53d1\u73b0\u200b\u5b83\u200b\u5f00\u59cb\u200b\u53d8\u5f97\u200b\u6709\u200b\u95ee\u9898\u200b\u3002\u200b\u4e3a\u4ec0\u4e48\u200b\u5462\u200b\uff1f\u200b\u56e0\u4e3a\u200b\u5206\u8bcd\u200b\u540e\u200b\u7684\u200b\u6570\u7ec4\u200b\u548c\u200b\u6807\u7b7e\u200b\u5fc5\u987b\u200b\u5b8c\u5168\u200b\u52a0\u8f7d\u200b\u5230\u200b\u5185\u5b58\u200b\u4e2d\u200b\uff0c\u200b\u800c\u4e14\u200b\u7531\u4e8e\u200b NumPy \u200b\u65e0\u6cd5\u200b\u5904\u7406\u200b\u201c\u200b\u4e0d\u89c4\u5219\u200b\u201d\u200b\u6570\u7ec4\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6bcf\u4e2a\u200b\u5206\u8bcd\u200b\u540e\u200b\u7684\u200b\u6837\u672c\u200b\u957f\u5ea6\u200b\u90fd\u200b\u5fc5\u987b\u200b\u88ab\u200b\u586b\u5145\u200b\u5230\u200b\u6570\u636e\u200b\u96c6\u4e2d\u200b\u6700\u957f\u200b\u6837\u672c\u200b\u7684\u200b\u957f\u5ea6\u200b\u3002\u200b\u8fd9\u200b\u5c06\u200b\u4f7f\u200b\u60a8\u200b\u7684\u200b\u6570\u7ec4\u200b\u53d8\u5f97\u200b\u66f4\u5927\u200b\uff0c\u200b\u800c\u200b\u6240\u6709\u200b\u8fd9\u4e9b\u200b<code>padding tokens</code>\u200b\u4e5f\u200b\u4f1a\u200b\u51cf\u6162\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\uff01</p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#tfdatadataset","title":"\u5c06\u200b\u6570\u636e\u200b\u52a0\u8f7d\u200b\u4e3a\u200b tf.data.Dataset","text":"<p>\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u907f\u514d\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\u51cf\u6162\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u6570\u636e\u200b\u52a0\u8f7d\u200b\u4e3a\u200b <code>tf.data.Dataset</code>\u3002\u200b\u867d\u7136\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u81ea\u5df1\u200b\u7f16\u5199\u200b\u81ea\u5df1\u200b\u7684\u200b <code>tf.data</code> \u200b\u6d41\u6c34\u7ebf\u200b\uff0c\u200b\u4f46\u200b\u6211\u4eec\u200b\u6709\u200b\u4e24\u79cd\u200b\u65b9\u4fbf\u200b\u7684\u200b\u65b9\u6cd5\u200b\u6765\u200b\u5b9e\u73b0\u200b\u8fd9\u200b\u4e00\u70b9\u200b\uff1a</p> <ul> <li>[<code>~TFPreTrainedModel.prepare_tf_dataset</code>]\uff1a\u200b\u8fd9\u662f\u200b\u6211\u4eec\u200b\u5728\u200b\u5927\u591a\u6570\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u63a8\u8350\u200b\u7684\u200b\u65b9\u6cd5\u200b\u3002\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u662f\u200b\u6a21\u578b\u200b\u4e0a\u200b\u7684\u200b\u4e00\u4e2a\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5b83\u200b\u53ef\u4ee5\u200b\u68c0\u67e5\u200b\u6a21\u578b\u200b\u4ee5\u200b\u81ea\u52a8\u200b\u786e\u5b9a\u200b\u54ea\u4e9b\u200b\u5217\u53ef\u200b\u7528\u4f5c\u200b\u6a21\u578b\u200b\u8f93\u5165\u200b\uff0c\u200b\u5e76\u200b\u4e22\u5f03\u200b\u5176\u4ed6\u200b\u5217\u4ee5\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u66f4\u200b\u7b80\u5355\u200b\u3001\u200b\u6027\u80fd\u200b\u66f4\u597d\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u3002</li> <li>[<code>~datasets.Dataset.to_tf_dataset</code>]\uff1a\u200b\u8fd9\u4e2a\u200b\u65b9\u6cd5\u200b\u66f4\u200b\u4f4e\u7ea7\u200b\uff0c\u200b\u4f46\u200b\u5f53\u200b\u60a8\u200b\u5e0c\u671b\u200b\u5b8c\u5168\u200b\u63a7\u5236\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u521b\u5efa\u200b\u65b9\u5f0f\u200b\u65f6\u200b\u975e\u5e38\u200b\u6709\u7528\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u6307\u5b9a\u200b\u8981\u200b\u5305\u62ec\u200b\u7684\u200b\u786e\u5207\u200b <code>columns</code> \u200b\u548c\u200b <code>label_cols</code> \u200b\u6765\u200b\u5b9e\u73b0\u200b\u3002</li> </ul> <p>\u200b\u5728\u200b\u4f7f\u7528\u200b [<code>~TFPreTrainedModel.prepare_tf_dataset</code>] \u200b\u4e4b\u524d\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5c06\u200b<code>tokenizer</code>\u200b\u7684\u200b\u8f93\u51fa\u200b\u6dfb\u52a0\u200b\u5230\u200b\u6570\u636e\u200b\u96c6\u200b\u4f5c\u4e3a\u200b\u5217\u200b\uff0c\u200b\u5982\u200b\u4e0b\u9762\u200b\u7684\u200b\u4ee3\u7801\u200b\u793a\u4f8b\u200b\u6240\u793a\u200b\uff1a</p> <p><pre><code>def tokenize_dataset(data):\n    # Keys of the returned dictionary will be added to the dataset as columns\n    return tokenizer(data[\"text\"])\n\n\ndataset = dataset.map(tokenize_dataset)\n</code></pre> \u200b\u8bf7\u200b\u8bb0\u4f4f\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0cHugging Face \u200b\u6570\u636e\u200b\u96c6\u200b\u5b58\u50a8\u200b\u5728\u200b\u786c\u76d8\u200b\u4e0a\u200b\uff0c\u200b\u56e0\u6b64\u200b\u8fd9\u200b\u4e0d\u4f1a\u200b\u589e\u52a0\u200b\u60a8\u200b\u7684\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\uff01\u200b\u4e00\u65e6\u200b\u5217\u200b\u5df2\u7ecf\u200b\u6dfb\u52a0\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u6570\u636e\u200b\u96c6\u4e2d\u200b\u6d41\u5f0f\u200b\u7684\u200b\u4f20\u8f93\u200b\u6279\u6b21\u200b\u6570\u636e\u200b\uff0c\u200b\u5e76\u200b\u4e3a\u200b\u6bcf\u4e2a\u200b\u6279\u6b21\u200b\u6dfb\u52a0\u200b<code>padding tokens</code>\uff0c\u200b\u8fd9\u200b\u4e0e\u200b\u4e3a\u200b\u6574\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\u6dfb\u52a0\u200b<code>padding tokens</code>\u200b\u76f8\u6bd4\u200b\uff0c\u200b\u5927\u5927\u51cf\u5c11\u200b\u4e86\u200b<code>padding tokens</code>\u200b\u7684\u200b\u6570\u91cf\u200b\u3002</p> <p><pre><code>&gt;&gt;&gt; tf_dataset = model.prepare_tf_dataset(dataset[\"train\"], batch_size=16, shuffle=True, tokenizer=tokenizer)\n</code></pre> \u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u5728\u200b\u4e0a\u9762\u200b\u7684\u200b\u4ee3\u7801\u200b\u793a\u4f8b\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5c06\u200b<code>tokenizer</code>\u200b\u4f20\u9012\u200b\u7ed9\u200b<code>prepare_tf_dataset</code>\uff0c\u200b\u4ee5\u4fbf\u200b\u5b83\u200b\u53ef\u4ee5\u200b\u5728\u200b\u52a0\u8f7d\u200b\u6279\u6b21\u200b\u65f6\u200b\u6b63\u786e\u200b\u586b\u5145\u200b\u5b83\u4eec\u200b\u3002\u200b\u5982\u679c\u200b\u6570\u636e\u200b\u96c6\u4e2d\u200b\u7684\u200b\u6240\u6709\u200b\u6837\u672c\u200b\u90fd\u200b\u5177\u6709\u200b\u76f8\u540c\u200b\u7684\u200b\u957f\u5ea6\u200b\u800c\u4e14\u200b\u4e0d\u200b\u9700\u8981\u200b\u586b\u5145\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8df3\u8fc7\u200b\u6b64\u53c2\u6570\u200b\u3002\u200b\u5982\u679c\u200b\u9700\u8981\u200b\u6267\u884c\u200b\u6bd4\u200b\u586b\u5145\u200b\u6837\u672c\u200b\u66f4\u200b\u590d\u6742\u200b\u7684\u200b\u64cd\u4f5c\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u7528\u4e8e\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u7684\u200b<code>tokens</code> \u200b\u66ff\u6362\u200b\uff09\uff0c\u200b\u5219\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>collate_fn</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u4f20\u9012\u200b\u4e00\u4e2a\u200b\u51fd\u6570\u200b\u6765\u200b\u5c06\u200b\u6837\u672c\u200b\u5217\u8868\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6279\u6b21\u200b\u5e76\u200b\u5e94\u7528\u200b\u4efb\u4f55\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u9884\u5904\u7406\u200b\u3002\u200b\u8bf7\u200b\u67e5\u770b\u200b\u6211\u4eec\u200b\u7684\u200b\u793a\u4f8b\u200b\u6216\u200b\u7b14\u8bb0\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u6b64\u200b\u65b9\u6cd5\u200b\u7684\u200b\u5b9e\u9645\u64cd\u4f5c\u200b\u3002</p> <p>\u200b\u4e00\u65e6\u200b\u521b\u5efa\u200b\u4e86\u200b <code>tf.data.Dataset</code>\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u50cf\u200b\u4ee5\u524d\u200b\u4e00\u6837\u200b\u7f16\u8bd1\u200b\u548c\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>model.compile(optimizer=Adam(3e-5))  # No loss argument!\n\nmodel.fit(tf_dataset)\n</code></pre> <p> </p> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#pytorch","title":"\u5728\u200b\u539f\u751f\u200b PyTorch \u200b\u4e2d\u200b\u8bad\u7ec3","text":"<p> <p>[<code>Trainer</code>] \u200b\u8d1f\u8d23\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\uff0c\u200b\u5141\u8bb8\u200b\u60a8\u200b\u5728\u200b\u4e00\u884c\u200b\u4ee3\u7801\u200b\u4e2d\u200b\u5fae\u8c03\u200b\u6a21\u578b\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u559c\u6b22\u200b\u7f16\u5199\u200b\u81ea\u5df1\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u7684\u200b\u7528\u6237\u200b\uff0c\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u5728\u200b\u539f\u751f\u200b PyTorch \u200b\u4e2d\u200b\u5fae\u8c03\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u3002</p> <p>\u200b\u73b0\u5728\u200b\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u91cd\u65b0\u542f\u52a8\u200b\u60a8\u200b\u7684\u200b<code>notebook</code>\uff0c\u200b\u6216\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u4ee3\u7801\u200b\u4ee5\u200b\u91ca\u653e\u200b\u4e00\u4e9b\u200b\u5185\u5b58\u200b\uff1a</p> <pre><code>del model\ndel trainer\ntorch.cuda.empty_cache()\n</code></pre> <p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u624b\u52a8\u200b\u5904\u7406\u200b <code>tokenized_dataset</code> \u200b\u4ee5\u200b\u51c6\u5907\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u3002</p> <ol> <li> <p>\u200b\u79fb\u9664\u200b text \u200b\u5217\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6a21\u578b\u200b\u4e0d\u200b\u63a5\u53d7\u200b\u539f\u59cb\u200b\u6587\u672c\u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n</code></pre> </li> <li> <p>\u200b\u5c06\u200b label \u200b\u5217\u200b\u91cd\u547d\u540d\u200b\u4e3a\u200b labels\uff0c\u200b\u56e0\u4e3a\u200b\u6a21\u578b\u200b\u671f\u671b\u200b\u53c2\u6570\u200b\u7684\u200b\u540d\u79f0\u200b\u4e3a\u200b labels\uff1a</p> <pre><code>&gt;&gt;&gt; tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n</code></pre> </li> <li> <p>\u200b\u8bbe\u7f6e\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u683c\u5f0f\u200b\u4ee5\u200b\u8fd4\u56de\u200b PyTorch \u200b\u5f20\u91cf\u200b\u800c\u200b\u4e0d\u662f\u200b<code>lists</code>\uff1a</p> <pre><code>&gt;&gt;&gt; tokenized_datasets.set_format(\"torch\")\n</code></pre> </li> </ol> <p>\u200b\u63a5\u7740\u200b\uff0c\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u5148\u524d\u200b\u5c55\u793a\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u8f83\u200b\u5c0f\u5b50\u200b\u96c6\u200b\uff0c\u200b\u4ee5\u200b\u52a0\u901f\u200b\u5fae\u8c03\u200b\u8fc7\u7a0b\u200b</p> <pre><code>&gt;&gt;&gt; small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n&gt;&gt;&gt; small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#dataloader","title":"DataLoader","text":"<p>\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u548c\u200b\u6d4b\u8bd5\u6570\u636e\u200b\u96c6\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b<code>DataLoader</code>\u200b\u7c7b\u200b\uff0c\u200b\u4ee5\u4fbf\u200b\u53ef\u4ee5\u200b\u8fed\u4ee3\u200b\u5904\u7406\u200b\u6570\u636e\u200b\u6279\u6b21\u200b</p> <pre><code>&gt;&gt;&gt; from torch.utils.data import DataLoader\n\n&gt;&gt;&gt; train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)\n&gt;&gt;&gt; eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)\n</code></pre> <p>\u200b\u52a0\u8f7d\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u5e76\u200b\u6307\u5b9a\u200b\u671f\u671b\u200b\u7684\u200b\u6807\u7b7e\u200b\u6570\u91cf\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoModelForSequenceClassification\n\n&gt;&gt;&gt; model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#optimizer-and-learning-rate-scheduler","title":"Optimizer and learning rate scheduler","text":"<p>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b<code>optimizer</code>\u200b\u548c\u200b<code>learning rate scheduler</code>\u200b\u4ee5\u200b\u8fdb\u884c\u200b\u6a21\u578b\u200b\u5fae\u8c03\u200b\u3002\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b PyTorch \u200b\u4e2d\u200b\u7684\u200b AdamW \u200b\u4f18\u5316\u200b\u5668\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from torch.optim import AdamW\n\n&gt;&gt;&gt; optimizer = AdamW(model.parameters(), lr=5e-5)\n</code></pre> <p>\u200b\u521b\u5efa\u200b\u6765\u81ea\u200b [<code>Trainer</code>] \u200b\u7684\u200b\u9ed8\u8ba4\u200b<code>learning rate scheduler</code>\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import get_scheduler\n\n&gt;&gt;&gt; num_epochs = 3\n&gt;&gt;&gt; num_training_steps = num_epochs * len(train_dataloader)\n&gt;&gt;&gt; lr_scheduler = get_scheduler(\n...     name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n... )\n</code></pre> <p>\u200b\u6700\u540e\u200b\uff0c\u200b\u6307\u5b9a\u200b <code>device</code> \u200b\u4ee5\u200b\u4f7f\u7528\u200b GPU\uff08\u200b\u5982\u679c\u200b\u6709\u200b\u7684\u8bdd\u200b\uff09\u3002\u200b\u5426\u5219\u200b\uff0c\u200b\u4f7f\u7528\u200b CPU \u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u51e0\u4e2a\u200b\u5c0f\u65f6\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u51e0\u5206\u949f\u200b\u3002</p> <pre><code>&gt;&gt;&gt; import torch\n\n&gt;&gt;&gt; device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n&gt;&gt;&gt; model.to(device)\n</code></pre> <p> <p>\u200b\u5982\u679c\u200b\u6ca1\u6709\u200b GPU\uff0c\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200bnotebook\u200b\u5e73\u53f0\u200b\u5982\u200b Colaboratory \u200b\u6216\u200b SageMaker StudioLab \u200b\u6765\u200b\u514d\u8d39\u200b\u83b7\u5f97\u200b\u4e91\u7aef\u200bGPU\u200b\u4f7f\u7528\u200b\u3002</p> <p></p> <p>\u200b\u73b0\u5728\u200b\u60a8\u200b\u5df2\u7ecf\u200b\u51c6\u5907\u200b\u597d\u200b\u8bad\u7ec3\u200b\u4e86\u200b\uff01\ud83e\udd73</p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#_7","title":"\u8bad\u7ec3\u200b\u5faa\u73af","text":"<p>\u200b\u4e3a\u4e86\u200b\u8ddf\u8e2a\u200b\u8bad\u7ec3\u200b\u8fdb\u5ea6\u200b\uff0c\u200b\u4f7f\u7528\u200b tqdm \u200b\u5e93\u6765\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u8fdb\u5ea6\u6761\u200b\uff0c\u200b\u663e\u793a\u200b\u8bad\u7ec3\u200b\u6b65\u6570\u200b\u7684\u200b\u8fdb\u5c55\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from tqdm.auto import tqdm\n\n&gt;&gt;&gt; progress_bar = tqdm(range(num_training_steps))\n\n&gt;&gt;&gt; model.train()\n&gt;&gt;&gt; for epoch in range(num_epochs):\n...     for batch in train_dataloader:\n...         batch = {k: v.to(device) for k, v in batch.items()}\n...         outputs = model(**batch)\n...         loss = outputs.loss\n...         loss.backward()\n\n...         optimizer.step()\n...         lr_scheduler.step()\n...         optimizer.zero_grad()\n...         progress_bar.update(1)\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#_8","title":"\u8bc4\u4f30","text":"<p>\u200b\u5c31\u200b\u50cf\u200b\u60a8\u200b\u5728\u200b [<code>Trainer</code>] \u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u8bc4\u4f30\u200b\u51fd\u6570\u200b\u4e00\u6837\u200b\uff0c\u200b\u5f53\u200b\u60a8\u200b\u7f16\u5199\u200b\u81ea\u5df1\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u505a\u200b\u540c\u6837\u200b\u7684\u200b\u4e8b\u60c5\u200b\u3002\u200b\u4f46\u200b\u4e0e\u200b\u5728\u200b\u6bcf\u4e2a\u200b<code>epoch</code>\u200b\u7ed3\u675f\u200b\u65f6\u200b\u8ba1\u7b97\u200b\u548c\u200b\u5c55\u793a\u200b\u6307\u6807\u200b\u4e0d\u540c\u200b\uff0c\u200b\u8fd9\u200b\u4e00\u6b21\u200b\u60a8\u200b\u5c06\u200b\u4f7f\u7528\u200b [<code>~evaluate.add_batch</code>] \u200b\u7d2f\u79ef\u200b\u6240\u6709\u200b\u6279\u6b21\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u6700\u540e\u200b\u8ba1\u7b97\u200b\u6307\u6807\u200b\u3002</p> <p><pre><code>&gt;&gt;&gt; import evaluate\n\n&gt;&gt;&gt; metric = evaluate.load(\"accuracy\")\n&gt;&gt;&gt; model.eval()\n&gt;&gt;&gt; for batch in eval_dataloader:\n...     batch = {k: v.to(device) for k, v in batch.items()}\n...     with torch.no_grad():\n...         outputs = model(**batch)\n\n...     logits = outputs.logits\n...     predictions = torch.argmax(logits, dim=-1)\n...     metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\n&gt;&gt;&gt; metric.compute()\n</code></pre> </p> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/training/#_9","title":"\u9644\u52a0\u200b\u8d44\u6e90","text":"<p>\u200b\u66f4\u200b\u591a\u200b\u5fae\u8c03\u200b\u4f8b\u5b50\u200b\u53ef\u200b\u53c2\u8003\u200b\u5982\u4e0b\u200b\u94fe\u63a5\u200b\uff1a</p> <ul> <li> <p>\ud83e\udd17 Transformers \u200b\u793a\u4f8b\u200b \u200b\u5305\u542b\u200b\u7528\u4e8e\u200b\u5728\u200b PyTorch \u200b\u548c\u200b TensorFlow \u200b\u4e2d\u200b\u8bad\u7ec3\u200b\u5e38\u89c1\u200b\u81ea\u7136\u8bed\u8a00\u200b\u5904\u7406\u200b\u4efb\u52a1\u200b\u7684\u200b\u811a\u672c\u200b\u3002</p> </li> <li> <p>\ud83e\udd17 Transformers \u200b\u7b14\u8bb0\u200b \u200b\u5305\u542b\u200b\u9488\u5bf9\u200b\u7279\u5b9a\u200b\u4efb\u52a1\u200b\u5728\u200b PyTorch \u200b\u548c\u200b TensorFlow \u200b\u4e2d\u200b\u5fae\u8c03\u200b\u6a21\u578b\u200b\u7684\u200b\u5404\u79cd\u200b<code>notebook</code>\u3002</p> </li> </ul>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/","title":"Transformers agents","text":""},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#transformers-agents","title":"Transformers Agents","text":"<p> <p><code>Transformers Agents</code>\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5b9e\u9a8c\u6027\u200b\u7684\u200b\u968f\u65f6\u200b\u53ef\u80fd\u200b\u53d1\u751f\u53d8\u5316\u200b\u7684\u200bAPI\u3002\u200b\u7531\u4e8e\u200bAPI\u200b\u6216\u200b\u5e95\u5c42\u200b\u6a21\u578b\u200b\u53ef\u80fd\u200b\u53d1\u751f\u53d8\u5316\u200b\uff0c<code>agents</code>\u200b\u8fd4\u56de\u200b\u7684\u200b\u7ed3\u679c\u200b\u4e5f\u200b\u4f1a\u200b\u6709\u6240\u4e0d\u540c\u200b\u3002</p> <p></p> <p>Transformers\u200b\u7248\u672c\u200b<code>v4.29.0</code>\u200b\u57fa\u4e8e\u200b<code>tools</code>\u200b\u548c\u200b<code>agents</code>\u200b\u6982\u5ff5\u200b\u6784\u5efa\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u6b64\u200bColab\u200b\u94fe\u63a5\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u6d4b\u8bd5\u200b\u3002</p> <p>\u200b\u7b80\u800c\u8a00\u4e4b\u200b\uff0c\u200b\u5b83\u200b\u5728\u200b<code>Transformers</code>\u200b\u4e4b\u4e0a\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u81ea\u7136\u8bed\u8a00\u200bAPI\uff1a\u200b\u6211\u4eec\u200b\u5b9a\u4e49\u200b\u4e86\u200b\u4e00\u7ec4\u200b\u7ecf\u8fc7\u200b\u7b5b\u9009\u200b\u7684\u200b<code>tools</code>\uff0c\u200b\u5e76\u200b\u8bbe\u8ba1\u200b\u4e86\u200b\u4e00\u4e2a\u200b<code>agents</code>\u200b\u6765\u200b\u89e3\u8bfb\u200b\u81ea\u7136\u8bed\u8a00\u200b\u5e76\u200b\u4f7f\u7528\u200b\u8fd9\u4e9b\u200b\u5de5\u5177\u200b\u3002\u200b\u5b83\u200b\u5177\u6709\u200b\u5f88\u5f3a\u200b\u7684\u200b\u53ef\u6269\u5c55\u6027\u200b\uff1b\u200b\u6211\u4eec\u200b\u7b5b\u9009\u200b\u4e86\u200b\u4e00\u4e9b\u200b\u76f8\u5173\u200b\u7684\u200b<code>tools</code>\uff0c\u200b\u4f46\u200b\u6211\u4eec\u200b\u5c06\u200b\u5411\u200b\u60a8\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\u901a\u8fc7\u200b\u793e\u533a\u200b\u5f00\u53d1\u200b\u7684\u200b<code>tool</code>\u200b\u8f7b\u677e\u200b\u5730\u200b\u6269\u5c55\u200b\u7cfb\u7edf\u200b\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4ece\u200b\u4e00\u4e9b\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u8fd9\u4e2a\u200b\u65b0\u200bAPI\u200b\u5b9e\u73b0\u200b\u7684\u200b\u793a\u4f8b\u200b\u5f00\u59cb\u200b\u3002\u200b\u5728\u200b\u5904\u7406\u200b\u591a\u200b\u6a21\u6001\u200b\u4efb\u52a1\u200b\u65f6\u200b\u5b83\u200b\u5c24\u5176\u200b\u5f3a\u5927\u200b\uff0c\u200b\u56e0\u6b64\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5feb\u901f\u200b\u8bd5\u7740\u200b\u751f\u6210\u200b\u56fe\u50cf\u200b\u5e76\u200b\u5927\u58f0\u200b\u6717\u8bfb\u200b\u6587\u672c\u200b\u3002</p> <pre><code>agent.run(\"Caption the following image\", image=image)\n</code></pre> \u200b\u8f93\u5165\u200b \u200b\u8f93\u51fa\u200b A beaver is swimming in the water <p><pre><code>agent.run(\"Read the following text out loud\", text=text)\n</code></pre> | \u200b\u8f93\u5165\u200b                            | \u200b\u8f93\u51fa\u200b                                                                                                                                                                                                               | |-----------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | A beaver is swimming in the water |  your browser does not support the audio element.  </p> <p><pre><code>agent.run(\n    \"In the following `document`, where will the TRRF Scientific Advisory Council Meeting take place?\",\n    document=document,\n)\n</code></pre> | \u200b\u8f93\u5165\u200b                                                                                                                   | \u200b\u8f93\u51fa\u200b     | |-----------------------------------------------------------------------------------------------------------------------------|----------------| |  | ballroom foyer |</p>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#_1","title":"\u5feb\u901f\u200b\u5165\u95e8","text":"<p>\u200b\u8981\u200b\u4f7f\u7528\u200b <code>agent.run</code>\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u4e00\u4e2a\u200b<code>agent</code>\uff0c\u200b\u5b83\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5927\u578b\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff08LLM\uff09\u3002\u200b\u6211\u4eec\u200b\u652f\u6301\u200bOpenAI\u200b\u6a21\u578b\u200b\u4ee5\u53ca\u200b\u6765\u81ea\u200bBigCode\u200b\u548c\u200bOpenAssistant\u200b\u7684\u200b\u5f00\u6e90\u200b\u66ff\u4ee3\u200b\u65b9\u6848\u200b\u3002OpenAI\u200b\u6a21\u578b\u200b\u6027\u80fd\u200b\u66f4\u597d\u200b\uff08\u200b\u4f46\u200b\u9700\u8981\u200b\u60a8\u200b\u62e5\u6709\u200bOpenAI API\u200b\u5bc6\u94a5\u200b\uff0c\u200b\u56e0\u6b64\u200b\u65e0\u6cd5\u200b\u514d\u8d39\u200b\u4f7f\u7528\u200b\uff09\uff0cHugging Face\u200b\u4e3a\u200bBigCode\u200b\u548c\u200bOpenAssistant\u200b\u6a21\u578b\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u514d\u8d39\u200b\u8bbf\u95ee\u200b\u7aef\u70b9\u200b\u3002</p> <p>\u200b\u4e00\u200b\u5f00\u59cb\u200b\u8bf7\u200b\u5b89\u88c5\u200b<code>agents</code>\u200b\u9644\u52a0\u200b\u6a21\u5757\u200b\uff0c\u200b\u4ee5\u200b\u5b89\u88c5\u200b\u6240\u6709\u200b\u9ed8\u8ba4\u200b\u4f9d\u8d56\u200b\u9879\u200b\u3002</p> <pre><code>pip install transformers[agents]\n</code></pre> <p>\u200b\u8981\u200b\u4f7f\u7528\u200bOpenAI\u200b\u6a21\u578b\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5b89\u88c5\u200b<code>openai</code>\u200b\u4f9d\u8d56\u200b\u9879\u540e\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u4e00\u4e2a\u200b<code>OpenAiAgent</code>\uff1a</p> <pre><code>pip install openai\n</code></pre> <pre><code>from transformers import OpenAiAgent\n\nagent = OpenAiAgent(model=\"text-davinci-003\", api_key=\"&lt;your_api_key&gt;\")\n</code></pre> <p>\u200b\u8981\u200b\u4f7f\u7528\u200bBigCode\u200b\u6216\u200bOpenAssistant\uff0c\u200b\u8bf7\u200b\u9996\u5148\u200b\u767b\u5f55\u200b\u4ee5\u200b\u8bbf\u95ee\u200bInference API\uff1a</p> <pre><code>from huggingface_hub import login\n\nlogin(\"&lt;YOUR_TOKEN&gt;\")\n</code></pre> <p>\u200b\u7136\u540e\u200b\uff0c\u200b\u5b9e\u4f8b\u200b\u5316\u200b<code>agent</code>\uff1a</p> <pre><code>from transformers import HfAgent\n\n# Starcoder\nagent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\")\n# StarcoderBase\n# agent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoderbase\")\n# OpenAssistant\n# agent = HfAgent(url_endpoint=\"https://api-inference.huggingface.co/models/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\")\n</code></pre> <p>\u200b\u6b64\u200b\u793a\u4f8b\u200b\u4f7f\u7528\u200b\u4e86\u200b\u76ee\u524d\u200bHugging Face\u200b\u514d\u8d39\u200b\u63d0\u4f9b\u200b\u7684\u200b\u63a8\u7406\u200bAPI\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u6709\u200b\u81ea\u5df1\u200b\u7684\u200b\u63a8\u7406\u200b\u7aef\u70b9\u200b\u7528\u4e8e\u200b\u6b64\u200b\u6a21\u578b\u200b\uff08\u200b\u6216\u200b\u5176\u4ed6\u200b\u6a21\u578b\u200b\uff09\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u7528\u200b\u4f60\u200b\u7684\u200bURL\u200b\u66ff\u6362\u200b\u4e0a\u9762\u200b\u7684\u200bURL\u3002</p> <p> <p>StarCoder\u200b\u548c\u200bOpenAssistant\u200b\u53ef\u4ee5\u200b\u514d\u8d39\u200b\u4f7f\u7528\u200b\uff0c\u200b\u5e76\u4e14\u200b\u5728\u200b\u7b80\u5355\u200b\u4efb\u52a1\u200b\u4e0a\u200b\u8868\u73b0\u51fa\u8272\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u5f53\u200b\u5904\u7406\u200b\u66f4\u200b\u590d\u6742\u200b\u7684\u200b\u63d0\u793a\u200b\u65f6\u200b\u5c31\u200b\u4e0d\u518d\u200b\u6709\u6548\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u9047\u5230\u200b\u8fd9\u6837\u200b\u7684\u200b\u95ee\u9898\u200b\uff0c\u200b\u6211\u4eec\u200b\u5efa\u8bae\u200b\u5c1d\u8bd5\u200b\u4f7f\u7528\u200bOpenAI\u200b\u6a21\u578b\u200b\uff0c\u200b\u5c3d\u7ba1\u200b\u9057\u61be\u200b\u7684\u200b\u662f\u200b\u5b83\u200b\u4e0d\u662f\u200b\u5f00\u6e90\u200b\u7684\u200b\uff0c\u200b\u4f46\u200b\u5b83\u200b\u5728\u200b\u76ee\u524d\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u8868\u73b0\u200b\u66f4\u597d\u200b\u3002</p> <p></p> <p>\u200b\u73b0\u5728\u200b\uff0c\u200b\u60a8\u200b\u5df2\u7ecf\u200b\u53ef\u4ee5\u200b\u5f00\u59cb\u200b\u4f7f\u7528\u200b\u4e86\u200b\uff01\u200b\u8ba9\u200b\u6211\u4eec\u200b\u6df1\u5165\u200b\u4e86\u89e3\u200b\u60a8\u200b\u73b0\u5728\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u7684\u200b\u4e24\u4e2a\u200bAPI\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#run","title":"\u5355\u6b21\u200b\u6267\u884c\u200b(run)","text":"<p>\u200b\u5355\u6b21\u200b\u6267\u884c\u200b\u65b9\u6cd5\u200b\u662f\u200b\u4f7f\u7528\u200b<code>agent</code>\u200b\u7684\u200b <code>~Agent.run</code>\uff1a</p> <pre><code>agent.run(\"Draw me a picture of rivers and lakes.\")\n</code></pre> <p></p> <p>\u200b\u5b83\u4f1a\u200b\u81ea\u52a8\u200b\u9009\u62e9\u200b\u9002\u5408\u200b\u60a8\u200b\u8981\u200b\u6267\u884c\u200b\u7684\u200b\u4efb\u52a1\u200b\u7684\u200b<code>tool</code>\uff08\u200b\u6216\u200b<code>tools</code>\uff09\uff0c\u200b\u5e76\u200b\u4ee5\u200b\u9002\u5f53\u200b\u7684\u200b\u65b9\u5f0f\u200b\u8fd0\u884c\u200b\u5b83\u4eec\u200b\u3002\u200b\u5b83\u200b\u53ef\u4ee5\u200b\u5728\u200b\u540c\u4e00\u200b\u6307\u4ee4\u200b\u4e2d\u200b\u6267\u884c\u200b\u4e00\u4e2a\u200b\u6216\u200b\u591a\u4e2a\u200b\u4efb\u52a1\u200b\uff08\u200b\u5c3d\u7ba1\u200b\u60a8\u200b\u7684\u200b\u6307\u4ee4\u200b\u8d8a\u200b\u590d\u6742\u200b\uff0c<code>agent</code>\u200b\u5931\u8d25\u200b\u7684\u200b\u53ef\u80fd\u6027\u200b\u5c31\u200b\u8d8a\u200b\u5927\u200b\uff09\u3002</p> <pre><code>agent.run(\"Draw me a picture of the sea then transform the picture to add an island\")\n</code></pre> <p></p> <p></p> <p>\u200b\u6bcf\u4e2a\u200b [<code>~Agent.run</code>] \u200b\u64cd\u4f5c\u200b\u90fd\u200b\u662f\u200b\u72ec\u7acb\u200b\u7684\u200b\uff0c\u200b\u56e0\u6b64\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u591a\u6b21\u200b\u8fde\u7eed\u200b\u8fd0\u884c\u200b [<code>~Agent.run</code>]\u200b\u5e76\u200b\u6267\u884c\u200b\u4e0d\u540c\u200b\u7684\u200b\u4efb\u52a1\u200b\u3002</p> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u60a8\u200b\u7684\u200b <code>agent</code> \u200b\u53ea\u662f\u200b\u4e00\u4e2a\u200b\u5927\u578b\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u56e0\u6b64\u200b\u60a8\u200b\u7565\u6709\u200b\u53d8\u5316\u200b\u7684\u200b\u63d0\u793a\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u4ea7\u751f\u200b\u5b8c\u5168\u200b\u4e0d\u540c\u200b\u7684\u200b\u7ed3\u679c\u200b\u3002\u200b\u91cd\u8981\u200b\u7684\u200b\u662f\u200b\u5c3d\u53ef\u80fd\u200b\u6e05\u6670\u200b\u5730\u200b\u89e3\u91ca\u200b\u60a8\u200b\u8981\u200b\u6267\u884c\u200b\u7684\u200b\u4efb\u52a1\u200b\u3002\u200b\u6211\u4eec\u200b\u5728\u200b\u8fd9\u91cc\u200b\u66f4\u200b\u6df1\u5165\u200b\u5730\u200b\u8ba8\u8bba\u200b\u4e86\u200b\u5982\u4f55\u200b\u7f16\u5199\u200b\u826f\u597d\u200b\u7684\u200b\u63d0\u793a\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u5728\u200b\u591a\u6b21\u200b\u6267\u884c\u200b\u4e4b\u95f4\u200b\u4fdd\u6301\u200b\u540c\u4e00\u200b\u72b6\u6001\u200b\u6216\u200b\u5411\u200b<code>agent</code>\u200b\u4f20\u9012\u200b\u975e\u200b\u6587\u672c\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u6307\u5b9a\u200b<code>agent</code>\u200b\u8981\u200b\u4f7f\u7528\u200b\u7684\u200b\u53d8\u91cf\u200b\u6765\u200b\u5b9e\u73b0\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u751f\u6210\u200b\u6709\u5173\u200b\u6cb3\u6d41\u200b\u548c\u200b\u6e56\u6cca\u200b\u7684\u200b\u7b2c\u4e00\u5e45\u200b\u56fe\u50cf\u200b\uff0c\u200b\u5e76\u200b\u8981\u6c42\u200b\u6a21\u578b\u200b\u901a\u8fc7\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\u5411\u200b\u8be5\u200b\u56fe\u7247\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u5c9b\u5c7f\u200b\uff1a</p> <pre><code>picture = agent.run(\"Generate a picture of rivers and lakes.\")\nupdated_picture = agent.run(\"Transform the image in `picture` to add an island to it.\", picture=picture)\n</code></pre> <p> <p>\u200b\u5f53\u200b\u6a21\u578b\u200b\u65e0\u6cd5\u200b\u7406\u89e3\u200b\u60a8\u200b\u7684\u200b\u8bf7\u6c42\u200b\u548c\u200b\u5e93\u200b\u4e2d\u200b\u7684\u200b\u5de5\u5177\u200b\u65f6\u200b\uff0c\u200b\u8fd9\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u6709\u6240\u200b\u5e2e\u52a9\u200b\u3002\u200b\u4f8b\u5982\u200b\uff1a</p> <pre><code>agent.run(\"Draw me the picture of a capybara swimming in the sea\")\n</code></pre> <p>\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u6a21\u578b\u200b\u53ef\u4ee5\u200b\u4ee5\u200b\u4e24\u79cd\u200b\u65b9\u5f0f\u200b\u7406\u89e3\u200b\u60a8\u200b\u7684\u200b\u8bf7\u6c42\u200b\uff1a - \u200b\u4f7f\u7528\u200b<code>text-to-image</code> \u200b\u751f\u6210\u200b\u5728\u200b\u5927\u6d77\u200b\u4e2d\u200b\u6e38\u6cf3\u200b\u7684\u200b\u5927\u200b\u6c34\u736d\u200b - \u200b\u6216\u8005\u200b\uff0c\u200b\u4f7f\u7528\u200b<code>text-to-image</code>\u200b\u751f\u6210\u200b\u5927\u200b\u6c34\u736d\u200b\uff0c\u200b\u7136\u540e\u200b\u4f7f\u7528\u200b<code>image-transformation</code>\u200b\u5de5\u5177\u200b\u4f7f\u200b\u5176\u200b\u5728\u200b\u5927\u6d77\u200b\u4e2d\u200b\u6e38\u6cf3\u200b</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u5f3a\u5236\u200b\u4f7f\u7528\u200b\u7b2c\u4e00\u79cd\u200b\u60c5\u666f\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5c06\u200b\u63d0\u793a\u200b\u4f5c\u4e3a\u200b\u53c2\u6570\u4f20\u9012\u200b\u7ed9\u200b\u5b83\u200b\u6765\u200b\u5b9e\u73b0\u200b\uff1a</p> <pre><code>agent.run(\"Draw me a picture of the `prompt`\", prompt=\"a capybara swimming in the sea\")\n</code></pre> <p></p>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#chat","title":"\u57fa\u4e8e\u200b\u4ea4\u6d41\u200b\u7684\u200b\u6267\u884c\u200b (chat)","text":"<p>\u200b\u57fa\u4e8e\u200b\u4ea4\u6d41\u200b\u7684\u200b\u6267\u884c\u200b\uff08chat\uff09\u200b\u65b9\u5f0f\u200b\u662f\u200b\u4f7f\u7528\u200b [<code>~Agent.chat</code>]\uff1a</p> <pre><code>agent.chat(\"Generate a picture of rivers and lakes\")\n</code></pre> <p> </p> <pre><code>agent.chat(\"Transform the picture so that there is a rock in there\")\n</code></pre> <p></p> <p></p> <p>\u200b\u5f53\u200b\u60a8\u200b\u5e0c\u671b\u200b\u5728\u200b\u4e0d\u540c\u200b\u6307\u4ee4\u200b\u4e4b\u95f4\u200b\u4fdd\u6301\u200b\u540c\u4e00\u200b\u72b6\u6001\u200b\u65f6\u200b\uff0c\u200b\u8fd9\u4f1a\u200b\u662f\u200b\u4e00\u4e2a\u200b\u6709\u8da3\u200b\u7684\u200b\u65b9\u6cd5\u200b\u3002\u200b\u5b83\u200b\u66f4\u200b\u9002\u5408\u200b\u7528\u4e8e\u200b\u5355\u4e2a\u200b\u6307\u4ee4\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u590d\u6742\u200b\u7684\u200b\u591a\u6b65\u200b\u6307\u4ee4\u200b\uff08<code>~Agent.run</code> \u200b\u65b9\u6cd5\u200b\u66f4\u200b\u9002\u5408\u200b\u5904\u7406\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\uff09\u3002</p> <p>\u200b\u8fd9\u79cd\u200b\u65b9\u6cd5\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u63a5\u53d7\u200b\u53c2\u6570\u200b\uff0c\u200b\u4ee5\u4fbf\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f20\u9012\u200b\u975e\u200b\u6587\u672c\u200b\u7c7b\u578b\u200b\u6216\u200b\u7279\u5b9a\u200b\u63d0\u793a\u200b\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#_2","title":"\u26a0\ufe0f \u200b\u8fdc\u7a0b\u200b\u6267\u884c","text":"<p>\u200b\u51fa\u4e8e\u200b\u6f14\u793a\u200b\u76ee\u7684\u200b\u4ee5\u4fbf\u200b\u9002\u7528\u200b\u4e8e\u200b\u6240\u6709\u200b\u8bbe\u7f6e\u200b\uff0c\u200b\u6211\u4eec\u200b\u4e3a\u200b\u53d1\u5e03\u200b\u7248\u672c\u200b\u7684\u200b\u5c11\u6570\u200b\u9ed8\u8ba4\u200b\u5de5\u5177\u200b\u521b\u5efa\u200b\u4e86\u200b\u8fdc\u7a0b\u200b\u6267\u884c\u5668\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u5de5\u5177\u200b\u662f\u200b\u4f7f\u7528\u200b\u63a8\u7406\u200b\u7ec8\u7aef\u200b\uff08inference endpoints\uff09\u200b\u521b\u5efa\u200b\u7684\u200b\u3002</p> <p>\u200b\u76ee\u524d\u200b\u6211\u4eec\u200b\u5df2\u200b\u5c06\u200b\u5176\u200b\u5173\u95ed\u200b\uff0c\u200b\u4f46\u200b\u4e3a\u4e86\u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u81ea\u884c\u200b\u8bbe\u7f6e\u200b\u8fdc\u7a0b\u200b\u6267\u884c\u5668\u200b\u5de5\u5177\u200b\uff0c\u200b\u6211\u4eec\u200b\u5efa\u8bae\u200b\u9605\u8bfb\u200b\u81ea\u5b9a\u4e49\u200b\u5de5\u5177\u200b\u6307\u5357\u200b\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#toolsagents","title":"\u8fd9\u91cc\u200b\u53d1\u751f\u200b\u4e86\u200b\u4ec0\u4e48\u200b\uff1f\u200b\u4ec0\u4e48\u200b\u662f\u200b<code>tools</code>\uff0c\u200b\u4ec0\u4e48\u200b\u662f\u200b<code>agents</code>\uff1f","text":""},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#agents","title":"Agents","text":"<p>\u200b\u8fd9\u91cc\u200b\u7684\u200b<code>Agents</code>\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5927\u578b\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u6211\u4eec\u200b\u901a\u8fc7\u200b\u63d0\u793a\u200b\u5b83\u200b\u4ee5\u200b\u8bbf\u95ee\u200b\u7279\u5b9a\u200b\u7684\u200b\u5de5\u5177\u96c6\u200b\u3002</p> <p>\u200b\u5927\u578b\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u5728\u200b\u751f\u6210\u200b\u5c0f\u200b\u4ee3\u7801\u200b\u793a\u4f8b\u200b\u65b9\u9762\u200b\u8868\u73b0\u51fa\u8272\u200b\uff0c\u200b\u56e0\u6b64\u200b\u8fd9\u4e2a\u200bAPI\u200b\u5229\u7528\u200b\u8fd9\u4e00\u200b\u7279\u70b9\u200b\uff0c\u200b\u901a\u8fc7\u200b\u63d0\u793a\u200bLLM\u200b\u751f\u6210\u200b\u4e00\u4e2a\u200b\u4f7f\u7528\u200b<code>tools</code>\u200b\u96c6\u5408\u200b\u7684\u200b\u5c0f\u200b\u4ee3\u7801\u200b\u793a\u4f8b\u200b\u3002\u200b\u7136\u540e\u200b\uff0c\u200b\u6839\u636e\u200b\u60a8\u200b\u7ed9\u200b<code>Agents</code>\u200b\u7684\u200b\u4efb\u52a1\u200b\u548c\u200b<code>tools</code>\u200b\u7684\u200b\u63cf\u8ff0\u200b\u6765\u200b\u5b8c\u6210\u200b\u6b64\u200b\u63d0\u793a\u200b\u3002\u200b\u8fd9\u79cd\u200b\u65b9\u5f0f\u200b\u8ba9\u200b\u5b83\u200b\u80fd\u591f\u200b\u8bbf\u95ee\u200b\u5de5\u5177\u200b\u7684\u200b\u6587\u6863\u200b\uff0c\u200b\u7279\u522b\u200b\u662f\u200b\u5b83\u4eec\u200b\u7684\u200b\u671f\u671b\u200b\u8f93\u5165\u200b\u548c\u200b\u8f93\u51fa\u200b\uff0c\u200b\u4ee5\u200b\u751f\u6210\u200b\u76f8\u5173\u200b\u7684\u200b\u4ee3\u7801\u200b\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#tools","title":"Tools","text":"<p><code>Tools</code>\u200b\u975e\u5e38\u7b80\u5355\u200b\uff1a\u200b\u5b83\u4eec\u200b\u662f\u200b\u6709\u200b\u540d\u79f0\u200b\u548c\u200b\u63cf\u8ff0\u200b\u7684\u200b\u5355\u4e2a\u200b\u51fd\u6570\u200b\u3002\u200b\u7136\u540e\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b\u8fd9\u4e9b\u200b<code>tools</code>\u200b\u7684\u200b\u63cf\u8ff0\u200b\u6765\u200b\u63d0\u793a\u200b\u4ee3\u7406\u200b\u3002\u200b\u901a\u8fc7\u200b\u63d0\u793a\u200b\uff0c\u200b\u6211\u4eec\u200b\u5411\u200b<code>agent</code>\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b<code>tool</code>\u200b\u6765\u200b\u6267\u884c\u200b\u67e5\u8be2\u8bed\u8a00\u200b\u4e2d\u200b\u8bf7\u6c42\u200b\u7684\u200b\u64cd\u4f5c\u200b\u3002</p> <p>\u200b\u8fd9\u662f\u200b\u4f7f\u7528\u200b\u5168\u65b0\u200b<code>tools</code>\u200b\u800c\u200b\u4e0d\u662f\u200b<code>pipelines</code>\uff0c\u200b\u56e0\u4e3a\u200b<code>agent</code>\u200b\u7f16\u5199\u200b\u7684\u200b\u4ee3\u7801\u200b\u66f4\u597d\u200b\uff0c\u200b\u5177\u6709\u200b\u975e\u5e38\u200b\u539f\u5b50\u5316\u200b\u7684\u200b<code>tools</code>\u3002<code>pipelines</code>\u200b\u7ecf\u5e38\u200b\u88ab\u200b\u91cd\u6784\u200b\uff0c\u200b\u5e76\u4e14\u200b\u901a\u5e38\u200b\u5c06\u200b\u591a\u4e2a\u200b\u4efb\u52a1\u200b\u5408\u5e76\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u3002<code>tools</code>\u200b\u65e8\u5728\u200b\u4e13\u6ce8\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u975e\u5e38\u7b80\u5355\u200b\u7684\u200b\u4efb\u52a1\u200b\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#_3","title":"\u4ee3\u7801\u6267\u884c\u200b\uff1f","text":"<p>\u200b\u7136\u540e\u200b\uff0c\u200b\u8fd9\u200b\u6bb5\u200b\u4ee3\u7801\u200b\u57fa\u4e8e\u200b<code>tools</code>\u200b\u7684\u200b\u8f93\u5165\u200b\u88ab\u200b\u6211\u4eec\u200b\u7684\u200b\u5c0f\u578b\u200bPython\u200b\u89e3\u91ca\u5668\u200b\u6267\u884c\u200b\u3002\u200b\u6211\u4eec\u200b\u542c\u5230\u200b\u4f60\u200b\u5728\u200b\u540e\u9762\u200b\u5927\u58f0\u200b\u547c\u558a\u200b\u201c\u200b\u4efb\u610f\u200b\u4ee3\u7801\u6267\u884c\u200b\uff01\u201d\uff0c\u200b\u4f46\u200b\u8ba9\u200b\u6211\u4eec\u200b\u89e3\u91ca\u200b\u4e3a\u4ec0\u4e48\u200b\u60c5\u51b5\u200b\u5e76\u975e\u5982\u6b64\u200b\u3002</p> <p>\u200b\u53ea\u80fd\u200b\u60a8\u200b\u63d0\u4f9b\u200b\u7684\u200b<code>tools</code>\u200b\u548c\u200b\u6253\u5370\u51fd\u6570\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u6267\u884c\u200b\uff0c\u200b\u56e0\u6b64\u200b\u60a8\u200b\u5df2\u7ecf\u200b\u53d7\u5230\u200b\u4e86\u200b\u6267\u884c\u200b\u7684\u200b\u9650\u5236\u200b\u3002\u200b\u5982\u679c\u200b\u4ec5\u9650\u4e8e\u200b Hugging Face \u200b\u5de5\u5177\u200b\uff0c\u200b\u90a3\u4e48\u200b\u60a8\u200b\u5e94\u8be5\u200b\u662f\u200b\u5b89\u5168\u200b\u7684\u200b\u3002</p> <p>\u200b\u7136\u540e\u200b\uff0c\u200b\u6211\u4eec\u200b\u4e0d\u200b\u5141\u8bb8\u200b\u4efb\u4f55\u200b\u5c5e\u6027\u200b\u67e5\u627e\u200b\u6216\u200b\u5bfc\u5165\u200b\uff08\u200b\u65e0\u8bba\u5982\u4f55\u200b\u90fd\u200b\u4e0d\u200b\u9700\u8981\u200b\u5c06\u200b\u8f93\u5165\u200b/\u200b\u8f93\u51fa\u200b\u4f20\u9012\u200b\u7ed9\u200b\u4e00\u200b\u5c0f\u7ec4\u200b\u51fd\u6570\u200b\uff09\uff0c\u200b\u56e0\u6b64\u200b\u6240\u6709\u200b\u6700\u200b\u660e\u663e\u200b\u7684\u200b\u653b\u51fb\u200b\uff08\u200b\u5e76\u4e14\u200b\u60a8\u200b\u9700\u8981\u200b\u63d0\u793a\u200bLLM\u200b\u65e0\u8bba\u5982\u4f55\u200b\u8f93\u51fa\u200b\u5b83\u4eec\u200b\uff09\u200b\u4e0d\u200b\u5e94\u8be5\u200b\u662f\u200b\u4e00\u4e2a\u200b\u95ee\u9898\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u200b\u8d85\u7ea7\u200b\u5b89\u5168\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u9644\u52a0\u200b\u53c2\u6570\u200b return_code=True \u200b\u6267\u884c\u200b run() \u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c<code>agent</code>\u200b\u5c06\u200b\u53ea\u200b\u8fd4\u56de\u200b\u8981\u200b\u6267\u884c\u200b\u7684\u200b\u4ee3\u7801\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u51b3\u5b9a\u200b\u662f\u5426\u200b\u6267\u884c\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b<code>agent</code>\u200b\u751f\u6210\u200b\u7684\u200b\u4ee3\u7801\u200b\u5b58\u5728\u200b\u4efb\u4f55\u200b\u5c1d\u8bd5\u200b\u6267\u884c\u200b\u975e\u6cd5\u64cd\u4f5c\u200b\u7684\u200b\u884c\u4e3a\u200b\uff0c\u200b\u6216\u8005\u200b\u4ee3\u7801\u200b\u4e2d\u200b\u51fa\u73b0\u200b\u4e86\u200b\u5e38\u89c4\u200bPython\u200b\u9519\u8bef\u200b\uff0c\u200b\u6267\u884c\u200b\u5c06\u200b\u505c\u6b62\u200b\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#tools_1","title":"\u4e00\u7ec4\u200b\u7ecf\u8fc7\u200b\u7cbe\u5fc3\u200b\u7b5b\u9009\u200b\u7684\u200b<code>tools</code>","text":"<p>\u200b\u6211\u4eec\u200b\u786e\u5b9a\u200b\u4e86\u200b\u4e00\u7ec4\u200b\u53ef\u4ee5\u200b\u8d4b\u4e88\u200b\u8fd9\u4e9b\u200b<code>agent</code>\u200b\u5f3a\u5927\u200b\u80fd\u529b\u200b\u7684\u200b<code>tools</code>\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u6211\u4eec\u200b\u5728\u200b<code>transformers</code>\u200b\u4e2d\u200b\u96c6\u6210\u200b\u7684\u200b<code>tools</code>\u200b\u7684\u200b\u66f4\u65b0\u200b\u5217\u8868\u200b\uff1a</p> <ul> <li>\u200b\u6587\u6863\u200b\u95ee\u7b54\u200b\uff1a\u200b\u7ed9\u5b9a\u200b\u4e00\u4e2a\u200b\u56fe\u50cf\u683c\u5f0f\u200b\u7684\u200b\u6587\u6863\u200b\uff08\u200b\u4f8b\u5982\u200bPDF\uff09\uff0c\u200b\u56de\u7b54\u200b\u8be5\u200b\u6587\u6863\u200b\u4e0a\u200b\u7684\u200b\u95ee\u9898\u200b\uff08Donut\uff09</li> <li>\u200b\u6587\u672c\u200b\u95ee\u7b54\u200b\uff1a\u200b\u7ed9\u5b9a\u200b\u4e00\u6bb5\u200b\u957f\u200b\u6587\u672c\u200b\u548c\u200b\u4e00\u4e2a\u200b\u95ee\u9898\u200b\uff0c\u200b\u56de\u7b54\u200b\u6587\u672c\u200b\u4e2d\u200b\u7684\u200b\u95ee\u9898\u200b\uff08Flan-T5\uff09</li> <li>\u200b\u65e0\u6761\u4ef6\u200b\u56fe\u50cf\u200b\u5b57\u5e55\u200b\uff1a\u200b\u4e3a\u200b\u56fe\u50cf\u200b\u6dfb\u52a0\u200b\u5b57\u5e55\u200b\uff01\uff08BLIP\uff09</li> <li>\u200b\u56fe\u50cf\u200b\u95ee\u7b54\u200b\uff1a\u200b\u7ed9\u5b9a\u200b\u4e00\u5f20\u200b\u56fe\u50cf\u200b\uff0c\u200b\u56de\u7b54\u200b\u8be5\u200b\u56fe\u50cf\u200b\u4e0a\u200b\u7684\u200b\u95ee\u9898\u200b\uff08VILT\uff09</li> <li>\u200b\u56fe\u50cf\u200b\u5206\u5272\u200b\uff1a\u200b\u7ed9\u5b9a\u200b\u4e00\u5f20\u200b\u56fe\u50cf\u200b\u548c\u200b\u4e00\u4e2a\u200b\u63d0\u793a\u200b\uff0c\u200b\u8f93\u51fa\u200b\u8be5\u200b\u63d0\u793a\u200b\u7684\u200b\u5206\u5272\u200b\u63a9\u6a21\u200b\uff08CLIPSeg\uff09</li> <li>\u200b\u8bed\u97f3\u200b\u8f6c\u200b\u6587\u672c\u200b\uff1a\u200b\u7ed9\u5b9a\u200b\u4e00\u4e2a\u200b\u4eba\u200b\u8bf4\u8bdd\u200b\u7684\u200b\u97f3\u9891\u200b\u5f55\u97f3\u200b\uff0c\u200b\u5c06\u200b\u6f14\u8bb2\u200b\u5185\u5bb9\u200b\u8f6c\u5f55\u200b\u4e3a\u200b\u6587\u672c\u200b\uff08Whisper\uff09</li> <li>\u200b\u6587\u672c\u200b\u8f6c\u200b\u8bed\u97f3\u200b\uff1a\u200b\u5c06\u200b\u6587\u672c\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u8bed\u97f3\u200b\uff08SpeechT5\uff09</li> <li>Zero-Shot\u200b\u6587\u672c\u200b\u5206\u7c7b\u200b\uff1a\u200b\u7ed9\u5b9a\u200b\u4e00\u4e2a\u200b\u6587\u672c\u200b\u548c\u200b\u4e00\u4e2a\u200b\u6807\u7b7e\u200b\u5217\u8868\u200b\uff0c\u200b\u786e\u5b9a\u200b\u6587\u672c\u200b\u6700\u200b\u7b26\u5408\u200b\u54ea\u4e2a\u200b\u6807\u7b7e\u200b\uff08BART\uff09</li> <li>\u200b\u6587\u672c\u200b\u6458\u8981\u200b\uff1a\u200b\u603b\u7ed3\u200b\u957f\u200b\u6587\u672c\u200b\u4e3a\u200b\u4e00\u4e24\u53e5\u8bdd\u200b\uff08BART\uff09</li> <li>\u200b\u7ffb\u8bd1\u200b\uff1a\u200b\u5c06\u200b\u6587\u672c\u200b\u7ffb\u8bd1\u200b\u4e3a\u200b\u6307\u5b9a\u200b\u8bed\u8a00\u200b\uff08NLLB\uff09</li> </ul> <p>\u200b\u8fd9\u4e9b\u200b<code>tools</code>\u200b\u5df2\u200b\u5728\u200btransformers\u200b\u4e2d\u200b\u96c6\u6210\u200b\uff0c\u200b\u5e76\u4e14\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u624b\u52a8\u200b\u4f7f\u7528\u200b\uff0c\u200b\u4f8b\u5982\u200b\uff1a</p> <pre><code>from transformers import load_tool\n\ntool = load_tool(\"text-to-speech\")\naudio = tool(\"This is a text to speech tool\")\n</code></pre>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#_4","title":"\u81ea\u5b9a\u4e49\u200b\u5de5\u5177","text":"<p>\u200b\u5c3d\u7ba1\u200b\u6211\u4eec\u200b\u786e\u5b9a\u200b\u4e86\u200b\u4e00\u7ec4\u200b\u7ecf\u8fc7\u200b\u7b5b\u9009\u200b\u7684\u200b<code>tools</code>\uff0c\u200b\u4f46\u200b\u6211\u4eec\u200b\u575a\u4fe1\u200b\uff0c\u200b\u6b64\u200b\u5b9e\u73b0\u200b\u63d0\u4f9b\u200b\u7684\u200b\u4e3b\u8981\u200b\u4ef7\u503c\u200b\u5728\u4e8e\u200b\u80fd\u591f\u200b\u5feb\u901f\u200b\u521b\u5efa\u200b\u548c\u200b\u5171\u4eab\u200b\u81ea\u5b9a\u4e49\u200b<code>tool</code>\u3002</p> <p>\u200b\u901a\u8fc7\u200b\u5c06\u200b\u5de5\u5177\u200b\u7684\u200b\u4ee3\u7801\u200b\u4e0a\u200b\u4f20\u5230\u200bHugging Face\u200b\u7a7a\u95f4\u200b\u6216\u200b\u6a21\u578b\u200brepository\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u901a\u8fc7\u200b<code>agent</code>\u200b\u4f7f\u7528\u200b<code>tools</code>\u3002\u200b\u6211\u4eec\u200b\u5df2\u7ecf\u200b\u6dfb\u52a0\u200b\u4e86\u200b\u4e00\u4e9b\u200b\u4e0e\u200btransformers\u200b\u65e0\u5173\u200b\u7684\u200b<code>tools</code>\u200b\u5230\u200b<code>huggingface-tools</code>\u200b\u7ec4\u7ec7\u200b\u4e2d\u200b\uff1a</p> <ul> <li>\u200b\u6587\u672c\u200b\u4e0b\u8f7d\u200b\u5668\u200b\uff1a\u200b\u4ece\u200bWeb URL\u200b\u4e0b\u8f7d\u200b\u6587\u672c\u200b</li> <li>\u200b\u6587\u672c\u200b\u5230\u200b\u56fe\u50cf\u200b\uff1a\u200b\u6839\u636e\u200b\u63d0\u793a\u200b\u751f\u6210\u200b\u56fe\u50cf\u200b\uff0c\u200b\u5229\u7528\u200b<code>stable diffusion</code></li> <li>\u200b\u56fe\u50cf\u200b\u8f6c\u6362\u200b\uff1a\u200b\u6839\u636e\u200b\u521d\u59cb\u200b\u56fe\u50cf\u200b\u548c\u200b\u63d0\u793a\u200b\u4fee\u6539\u200b\u56fe\u50cf\u200b\uff0c\u200b\u5229\u7528\u200b<code>instruct pix2pix stable diffusion</code></li> <li>\u200b\u6587\u672c\u200b\u5230\u200b\u89c6\u9891\u200b\uff1a\u200b\u6839\u636e\u200b\u63d0\u793a\u200b\u751f\u6210\u200b\u5c0f\u89c6\u9891\u200b\uff0c\u200b\u5229\u7528\u200b<code>damo-vilab</code></li> </ul> <p>\u200b\u4ece\u200b\u4e00\u200b\u5f00\u59cb\u200b\u5c31\u200b\u4e00\u76f4\u200b\u5728\u200b\u4f7f\u7528\u200b\u7684\u200b\u6587\u672c\u200b\u5230\u200b\u56fe\u50cf\u200b<code>tool</code>\u200b\u662f\u200b\u4e00\u4e2a\u200b\u8fdc\u7a0b\u200b<code>tool</code>\uff0c\u200b\u4f4d\u4e8e\u200bhuggingface-tools/text-to-image\uff01\u200b\u6211\u4eec\u200b\u5c06\u200b\u7ee7\u7eed\u200b\u5728\u200b\u6b64\u200b\u7ec4\u7ec7\u200b\u548c\u200b\u5176\u4ed6\u200b\u7ec4\u7ec7\u200b\u4e0a\u200b\u53d1\u5e03\u200b\u6b64\u7c7b\u200b<code>tool</code>\uff0c\u200b\u4ee5\u200b\u8fdb\u4e00\u6b65\u200b\u589e\u5f3a\u200b\u6b64\u200b\u5b9e\u73b0\u200b\u3002</p> <p><code>agents</code>\u200b\u9ed8\u8ba4\u200b\u53ef\u4ee5\u200b\u8bbf\u95ee\u200b\u5b58\u50a8\u200b\u5728\u200b<code>huggingface-tools</code>\u200b\u4e0a\u200b\u7684\u200b<code>tools</code>\u3002\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b\u540e\u7eed\u200b\u6307\u5357\u200b\u4e2d\u200b\u89e3\u91ca\u200b\u5982\u4f55\u200b\u7f16\u5199\u200b\u548c\u200b\u5171\u4eab\u200b\u81ea\u5b9a\u4e49\u200b<code>tools</code>\uff0c\u200b\u4ee5\u53ca\u200b\u5982\u4f55\u200b\u5229\u7528\u200bHub\u200b\u4e0a\u200b\u5b58\u5728\u200b\u7684\u200b\u4efb\u4f55\u200b\u81ea\u5b9a\u4e49\u200b<code>tools</code>\u3002</p>"},{"location":"2-%E6%95%99%E7%A8%8B/transformers_agents/#_5","title":"\u4ee3\u7801\u751f\u6210","text":"<p>\u200b\u5230\u200b\u76ee\u524d\u4e3a\u6b62\u200b\uff0c\u200b\u6211\u4eec\u200b\u5df2\u7ecf\u200b\u5c55\u793a\u200b\u4e86\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b<code>agents</code>\u200b\u6765\u200b\u4e3a\u200b\u60a8\u200b\u6267\u884c\u200b\u64cd\u4f5c\u200b\u3002\u200b\u4f46\u662f\u200b\uff0c<code>agents</code>\u200b\u4ec5\u200b\u4f7f\u7528\u200b\u975e\u5e38\u200b\u53d7\u9650\u200bPython\u200b\u89e3\u91ca\u5668\u200b\u6267\u884c\u200b\u7684\u200b\u4ee3\u7801\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u5e0c\u671b\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200b\u73af\u5883\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u751f\u6210\u200b\u7684\u200b\u4ee3\u7801\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u63d0\u793a\u200b<code>agents</code>\u200b\u8fd4\u56de\u200b\u4ee3\u7801\u200b\uff0c\u200b\u4ee5\u53ca\u200b<code>tools</code>\u200b\u7684\u200b\u5b9a\u4e49\u200b\u548c\u200b\u51c6\u786e\u200b\u7684\u200b\u5bfc\u5165\u200b\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4ee5\u4e0b\u200b\u6307\u4ee4\u200b</p> <pre><code>agent.run(\"Draw me a picture of rivers and lakes\", return_code=True)\n</code></pre> <p>\u200b\u8fd4\u56de\u200b\u4ee5\u4e0b\u200b\u4ee3\u7801\u200b</p> <pre><code>from transformers import load_tool\n\nimage_generator = load_tool(\"huggingface-tools/text-to-image\")\n\nimage = image_generator(prompt=\"rivers and lakes\")\n</code></pre> <p>\u200b\u7136\u540e\u200b\u4f60\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u8c03\u6574\u200b\u5e76\u200b\u6267\u884c\u200b\u4ee3\u7801\u200b</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/","title":"Create a model","text":""},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/#_1","title":"\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u67b6\u6784","text":"<p><code>AutoClass</code> \u200b\u81ea\u52a8\u200b\u63a8\u65ad\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\u5e76\u200b\u4e0b\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u914d\u7f6e\u200b\u548c\u200b\u6743\u91cd\u200b\u3002\u200b\u4e00\u822c\u6765\u8bf4\u200b\uff0c\u200b\u6211\u4eec\u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200b <code>AutoClass</code> \u200b\u751f\u6210\u200b\u4e0e\u200b\u68c0\u67e5\u70b9\u200b\uff08checkpoint\uff09\u200b\u65e0\u5173\u200b\u7684\u200b\u4ee3\u7801\u200b\u3002\u200b\u5e0c\u671b\u200b\u5bf9\u200b\u7279\u5b9a\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u6709\u200b\u66f4\u200b\u591a\u200b\u63a7\u5236\u200b\u7684\u200b\u7528\u6237\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4ec5\u200b\u4ece\u200b\u51e0\u4e2a\u200b\u57fa\u7c7b\u200b\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u3002\u200b\u8fd9\u200b\u5bf9\u4e8e\u200b\u4efb\u4f55\u200b\u6709\u200b\u5174\u8da3\u200b\u5b66\u4e60\u200b\u3001\u200b\u8bad\u7ec3\u200b\u6216\u200b\u8bd5\u9a8c\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u7684\u200b\u4eba\u200b\u53ef\u80fd\u200b\u7279\u522b\u200b\u6709\u7528\u200b\u3002\u200b\u901a\u8fc7\u200b\u672c\u200b\u6307\u5357\u200b\uff0c\u200b\u6df1\u5165\u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u4e0d\u200b\u901a\u8fc7\u200b <code>AutoClass</code> \u200b\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u3002\u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\uff1a</p> <ul> <li>\u200b\u52a0\u8f7d\u200b\u5e76\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u914d\u7f6e\u200b\u3002</li> <li>\u200b\u521b\u5efa\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\u3002</li> <li>\u200b\u4e3a\u200b\u6587\u672c\u200b\u521b\u5efa\u200b\u6162\u901f\u200b\u548c\u200b\u5feb\u901f\u200b\u5206\u8bcd\u5668\u200b\u3002</li> <li>\u200b\u4e3a\u200b\u89c6\u89c9\u200b\u4efb\u52a1\u200b\u521b\u5efa\u200b\u56fe\u50cf\u200b\u5904\u7406\u5668\u200b\u3002</li> <li>\u200b\u4e3a\u200b\u97f3\u9891\u200b\u4efb\u52a1\u200b\u521b\u5efa\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\u3002</li> <li>\u200b\u4e3a\u200b\u591a\u200b\u6a21\u6001\u200b\u4efb\u52a1\u200b\u521b\u5efa\u200b\u5904\u7406\u5668\u200b\u3002</li> </ul>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/#_2","title":"\u914d\u7f6e","text":"<p>\u200b\u914d\u7f6e\u200b \u200b\u6d89\u53ca\u200b\u5230\u200b\u6a21\u578b\u200b\u7684\u200b\u5177\u4f53\u200b\u5c5e\u6027\u200b\u3002\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u914d\u7f6e\u200b\u90fd\u200b\u6709\u200b\u4e0d\u540c\u200b\u7684\u200b\u5c5e\u6027\u200b\uff1b\u200b\u4f8b\u5982\u200b\uff0c\u200b\u6240\u6709\u200b NLP \u200b\u6a21\u578b\u200b\u90fd\u200b\u5171\u4eab\u200b <code>hidden_size</code>\u3001<code>num_attention_heads</code>\u3001 <code>num_hidden_layers</code> \u200b\u548c\u200b <code>vocab_size</code> \u200b\u5c5e\u6027\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u5c5e\u6027\u200b\u7528\u4e8e\u200b\u6307\u5b9a\u200b\u6784\u5efa\u200b\u6a21\u578b\u200b\u65f6\u200b\u7684\u200b\u6ce8\u610f\u529b\u200b\u5934\u200b\u6570\u91cf\u200b\u6216\u200b\u9690\u85cf\u200b\u5c42\u5c42\u200b\u6570\u200b\u3002</p> <p>\u200b\u8bbf\u95ee\u200b [<code>DistilBertConfig</code>] \u200b\u4ee5\u200b\u66f4\u200b\u8fd1\u200b\u4e00\u6b65\u200b\u4e86\u89e3\u200b DistilBERT\uff0c\u200b\u68c0\u67e5\u200b\u5b83\u200b\u7684\u200b\u5c5e\u6027\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import DistilBertConfig\n\n&gt;&gt;&gt; config = DistilBertConfig()\n&gt;&gt;&gt; print(config)\nDistilBertConfig {\n  \"activation\": \"gelu\",\n  \"attention_dropout\": 0.1,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"initializer_range\": 0.02,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"transformers_version\": \"4.16.2\",\n  \"vocab_size\": 30522\n}\n</code></pre> <p>[<code>DistilBertConfig</code>] \u200b\u663e\u793a\u200b\u4e86\u200b\u6784\u5efa\u200b\u57fa\u7840\u200b [<code>DistilBertModel</code>] \u200b\u6240\u200b\u4f7f\u7528\u200b\u7684\u200b\u6240\u6709\u200b\u9ed8\u8ba4\u200b\u5c5e\u6027\u200b\u3002\u200b\u6240\u6709\u200b\u5c5e\u6027\u200b\u90fd\u200b\u53ef\u4ee5\u200b\u8fdb\u884c\u200b\u81ea\u5b9a\u4e49\u200b\uff0c\u200b\u4e3a\u200b\u5b9e\u9a8c\u200b\u521b\u9020\u200b\u4e86\u200b\u7a7a\u95f4\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u9ed8\u8ba4\u200b\u6a21\u578b\u200b\u81ea\u5b9a\u4e49\u200b\u4e3a\u200b\uff1a</p> <ul> <li>\u200b\u4f7f\u7528\u200b <code>activation</code> \u200b\u53c2\u6570\u200b\u5c1d\u8bd5\u200b\u4e0d\u540c\u200b\u7684\u200b\u6fc0\u6d3b\u200b\u51fd\u6570\u200b\u3002</li> <li>\u200b\u4f7f\u7528\u200b <code>attention_dropout</code> \u200b\u53c2\u6570\u200b\u4e3a\u200b attention probabilities \u200b\u4f7f\u7528\u200b\u66f4\u200b\u9ad8\u200b\u7684\u200b dropout ratio\u3002</li> </ul> <pre><code>&gt;&gt;&gt; my_config = DistilBertConfig(activation=\"relu\", attention_dropout=0.4)\n&gt;&gt;&gt; print(my_config)\nDistilBertConfig {\n  \"activation\": \"relu\",\n  \"attention_dropout\": 0.4,\n  \"dim\": 768,\n  \"dropout\": 0.1,\n  \"hidden_dim\": 3072,\n  \"initializer_range\": 0.02,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"distilbert\",\n  \"n_heads\": 12,\n  \"n_layers\": 6,\n  \"pad_token_id\": 0,\n  \"qa_dropout\": 0.1,\n  \"seq_classif_dropout\": 0.2,\n  \"sinusoidal_pos_embds\": false,\n  \"transformers_version\": \"4.16.2\",\n  \"vocab_size\": 30522\n}\n</code></pre> <p>\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u5c5e\u6027\u200b\u53ef\u4ee5\u200b\u5728\u200b [<code>~PretrainedConfig.from_pretrained</code>] \u200b\u51fd\u6570\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u4fee\u6539\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; my_config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\", activation=\"relu\", attention_dropout=0.4)\n</code></pre> <p>\u200b\u5f53\u200b\u4f60\u200b\u5bf9\u6a21\u578b\u200b\u914d\u7f6e\u200b\u6ee1\u610f\u200b\u65f6\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>~PretrainedConfig.save_pretrained</code>] \u200b\u6765\u200b\u4fdd\u5b58\u200b\u914d\u7f6e\u200b\u3002\u200b\u4f60\u200b\u7684\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u5c06\u200b\u4ee5\u200b JSON \u200b\u6587\u4ef6\u200b\u7684\u200b\u5f62\u5f0f\u200b\u5b58\u50a8\u200b\u5728\u200b\u6307\u5b9a\u200b\u7684\u200b\u4fdd\u5b58\u200b\u76ee\u5f55\u200b\u4e2d\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; my_config.save_pretrained(save_directory=\"./your_model_save_path\")\n</code></pre> <p>\u200b\u8981\u200b\u91cd\u7528\u200b\u914d\u7f6e\u6587\u4ef6\u200b\uff0c\u200b\u8bf7\u200b\u4f7f\u7528\u200b [<code>~PretrainedConfig.from_pretrained</code>] \u200b\u8fdb\u884c\u200b\u52a0\u8f7d\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; my_config = DistilBertConfig.from_pretrained(\"./your_model_save_path/config.json\")\n</code></pre> <p> <p>\u200b\u4f60\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4fdd\u5b58\u200b\u4e3a\u200b\u5b57\u5178\u200b\uff0c\u200b\u751a\u81f3\u200b\u53ea\u200b\u4fdd\u5b58\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u200b\u5c5e\u6027\u200b\u4e0e\u200b\u9ed8\u8ba4\u200b\u914d\u7f6e\u200b\u5c5e\u6027\u200b\u4e4b\u95f4\u200b\u7684\u200b\u5dee\u5f02\u200b\uff01\u200b\u6709\u5173\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b \u200b\u914d\u7f6e\u200b \u200b\u6587\u6863\u200b\u3002</p> <p></p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/#_3","title":"\u6a21\u578b","text":"<p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u3002\u200b\u6a21\u578b\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u200b\u6cdb\u6307\u200b\u67b6\u6784\u200b\uff0c\u200b\u5b9a\u4e49\u200b\u4e86\u200b\u6bcf\u200b\u4e00\u5c42\u200b\u7f51\u7edc\u200b\u7684\u200b\u884c\u4e3a\u200b\u4ee5\u53ca\u200b\u8fdb\u884c\u200b\u7684\u200b\u64cd\u4f5c\u200b\u3002\u200b\u914d\u7f6e\u200b\u4e2d\u200b\u7684\u200b <code>num_hidden_layers</code> \u200b\u7b49\u200b\u5c5e\u6027\u200b\u7528\u4e8e\u200b\u5b9a\u4e49\u200b\u67b6\u6784\u200b\u3002\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u90fd\u200b\u5171\u4eab\u200b\u57fa\u7c7b\u200b [<code>PreTrainedModel</code>] \u200b\u548c\u200b\u4e00\u4e9b\u200b\u5e38\u7528\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u4f8b\u5982\u200b\u8c03\u6574\u200b\u8f93\u5165\u200b\u5d4c\u5165\u200b\u7684\u200b\u5927\u5c0f\u200b\u548c\u200b\u4fee\u526a\u200b\u81ea\u200b\u6ce8\u610f\u529b\u200b\u5934\u200b\u3002\u200b\u6b64\u5916\u200b\uff0c\u200b\u6240\u6709\u200b\u6a21\u578b\u200b\u90fd\u200b\u662f\u200b <code>torch.nn.Module</code>\u3001<code>tf.keras.Model</code> \u200b\u6216\u200b <code>flax.linen.Module</code> \u200b\u7684\u200b\u5b50\u7c7b\u200b\u3002\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u6a21\u578b\u200b\u4e0e\u200b\u5404\u81ea\u200b\u6846\u67b6\u200b\u7684\u200b\u7528\u6cd5\u200b\u517c\u5bb9\u200b\u3002</p> <p>  \u200b\u5c06\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u200b\u5c5e\u6027\u200b\u52a0\u8f7d\u200b\u5230\u200b\u6a21\u578b\u200b\u4e2d\u200b\uff1a <pre><code>&gt;&gt;&gt; from transformers import DistilBertModel\n\n&gt;&gt;&gt; my_config = DistilBertConfig.from_pretrained(\"./your_model_save_path/config.json\")\n&gt;&gt;&gt; model = DistilBertModel(my_config)\n</code></pre> <p>\u200b\u8fd9\u200b\u6bb5\u200b\u4ee3\u7801\u200b\u521b\u5efa\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u5177\u6709\u200b\u968f\u673a\u200b\u53c2\u6570\u200b\u800c\u200b\u4e0d\u662f\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u5728\u200b\u8bad\u7ec3\u200b\u8be5\u200b\u6a21\u578b\u200b\u4e4b\u524d\u200b\uff0c\u200b\u60a8\u200b\u8fd8\u200b\u65e0\u6cd5\u200b\u5c06\u200b\u8be5\u200b\u6a21\u578b\u200b\u7528\u4e8e\u200b\u4efb\u4f55\u200b\u7528\u9014\u200b\u3002\u200b\u8bad\u7ec3\u200b\u662f\u200b\u4e00\u9879\u200b\u6602\u8d35\u200b\u4e14\u200b\u8017\u65f6\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u3002\u200b\u901a\u5e38\u200b\u6765\u8bf4\u200b\uff0c\u200b\u6700\u597d\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u6765\u200b\u66f4\u200b\u5feb\u200b\u5730\u200b\u83b7\u5f97\u200b\u66f4\u597d\u200b\u7684\u200b\u7ed3\u679c\u200b\uff0c\u200b\u540c\u65f6\u200b\u4ec5\u200b\u4f7f\u7528\u200b\u8bad\u7ec3\u200b\u6240\u200b\u9700\u200b\u8d44\u6e90\u200b\u7684\u200b\u4e00\u5c0f\u90e8\u5206\u200b\u3002</p> <p>\u200b\u4f7f\u7528\u200b [<code>~PreTrainedModel.from_pretrained</code>] \u200b\u521b\u5efa\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <p>\u200b\u5f53\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\u65f6\u200b\uff0c\u200b\u5982\u679c\u200b\u6a21\u578b\u200b\u662f\u200b\u7531\u200b \ud83e\udd17 Transformers \u200b\u63d0\u4f9b\u200b\u7684\u200b\uff0c\u200b\u5c06\u200b\u81ea\u52a8\u200b\u52a0\u8f7d\u200b\u9ed8\u8ba4\u200b\u6a21\u578b\u200b\u914d\u7f6e\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u613f\u610f\u200b\uff0c\u200b\u4ecd\u7136\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u9ed8\u8ba4\u200b\u6a21\u578b\u200b\u914d\u7f6e\u200b\u7684\u200b\u67d0\u4e9b\u200b\u6216\u8005\u200b\u6240\u6709\u200b\u5c5e\u6027\u200b\u66ff\u6362\u6210\u200b\u4f60\u200b\u81ea\u5df1\u200b\u7684\u200b\u914d\u7f6e\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\", config=my_config)\n</code></pre>  \u200b\u5c06\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u200b\u5c5e\u6027\u200b\u52a0\u8f7d\u200b\u5230\u200b\u6a21\u578b\u200b\u4e2d\u200b\uff1a <pre><code>&gt;&gt;&gt; from transformers import TFDistilBertModel\n\n&gt;&gt;&gt; my_config = DistilBertConfig.from_pretrained(\"./your_model_save_path/my_config.json\")\n&gt;&gt;&gt; tf_model = TFDistilBertModel(my_config)\n</code></pre> <p>\u200b\u8fd9\u200b\u6bb5\u200b\u4ee3\u7801\u200b\u521b\u5efa\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u5177\u6709\u200b\u968f\u673a\u200b\u53c2\u6570\u200b\u800c\u200b\u4e0d\u662f\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u5728\u200b\u8bad\u7ec3\u200b\u8be5\u200b\u6a21\u578b\u200b\u4e4b\u524d\u200b\uff0c\u200b\u60a8\u200b\u8fd8\u200b\u65e0\u6cd5\u200b\u5c06\u200b\u8be5\u200b\u6a21\u578b\u200b\u7528\u4e8e\u200b\u4efb\u4f55\u200b\u7528\u9014\u200b\u3002\u200b\u8bad\u7ec3\u200b\u662f\u200b\u4e00\u9879\u200b\u6602\u8d35\u200b\u4e14\u200b\u8017\u65f6\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u3002\u200b\u901a\u5e38\u200b\u6765\u8bf4\u200b\uff0c\u200b\u6700\u597d\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u6765\u200b\u66f4\u200b\u5feb\u200b\u5730\u200b\u83b7\u5f97\u200b\u66f4\u597d\u200b\u7684\u200b\u7ed3\u679c\u200b\uff0c\u200b\u540c\u65f6\u200b\u4ec5\u200b\u4f7f\u7528\u200b\u8bad\u7ec3\u200b\u6240\u200b\u9700\u200b\u8d44\u6e90\u200b\u7684\u200b\u4e00\u5c0f\u90e8\u5206\u200b\u3002</p> <p>\u200b\u4f7f\u7528\u200b [<code>~TFPreTrainedModel.from_pretrained</code>] \u200b\u521b\u5efa\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; tf_model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <p>\u200b\u5f53\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\u65f6\u200b\uff0c\u200b\u5982\u679c\u200b\u6a21\u578b\u200b\u662f\u200b\u7531\u200b \ud83e\udd17 Transformers \u200b\u63d0\u4f9b\u200b\u7684\u200b\uff0c\u200b\u5c06\u200b\u81ea\u52a8\u200b\u52a0\u8f7d\u200b\u9ed8\u8ba4\u200b\u6a21\u578b\u200b\u914d\u7f6e\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u613f\u610f\u200b\uff0c\u200b\u4ecd\u7136\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u9ed8\u8ba4\u200b\u6a21\u578b\u200b\u914d\u7f6e\u200b\u7684\u200b\u67d0\u4e9b\u200b\u6216\u8005\u200b\u6240\u6709\u200b\u5c5e\u6027\u200b\u66ff\u6362\u6210\u200b\u81ea\u5df1\u200b\u7684\u200b\u914d\u7f6e\u200b\uff1a</p> <p><pre><code>&gt;&gt;&gt; tf_model = TFDistilBertModel.from_pretrained(\"distilbert-base-uncased\", config=my_config)\n</code></pre> </p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/#model-heads","title":"\u6a21\u578b\u200b\u5934\u200b\uff08Model heads\uff09","text":"<p>\u200b\u6b64\u65f6\u200b\uff0c\u200b\u4f60\u200b\u5df2\u7ecf\u200b\u6709\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u8f93\u51fa\u200b\u9690\u85cf\u200b\u72b6\u6001\u200b\u7684\u200b\u57fa\u7840\u200b DistilBERT \u200b\u6a21\u578b\u200b\u3002\u200b\u9690\u85cf\u200b\u72b6\u6001\u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\u4f20\u9012\u200b\u5230\u200b\u6a21\u578b\u200b\u5934\u4ee5\u200b\u751f\u6210\u200b\u6700\u7ec8\u200b\u8f93\u51fa\u200b\u3002\ud83e\udd17 Transformers \u200b\u4e3a\u200b\u6bcf\u4e2a\u200b\u4efb\u52a1\u200b\u63d0\u4f9b\u200b\u4e0d\u540c\u200b\u7684\u200b\u6a21\u578b\u200b\u5934\u200b\uff0c\u200b\u53ea\u8981\u200b\u6a21\u578b\u200b\u652f\u6301\u200b\u8be5\u200b\u4efb\u52a1\u200b\uff08\u200b\u5373\u200b\uff0c\u200b\u60a8\u200b\u4e0d\u80fd\u200b\u4f7f\u7528\u200b DistilBERT \u200b\u6765\u200b\u6267\u884c\u200b\u50cf\u200b\u7ffb\u8bd1\u200b\u8fd9\u6837\u200b\u7684\u200b\u5e8f\u5217\u200b\u5230\u200b\u5e8f\u5217\u200b\u4efb\u52a1\u200b\uff09\u3002</p> <p>  \u200b\u4f8b\u5982\u200b\uff0c[<code>DistilBertForSequenceClassification</code>] \u200b\u662f\u200b\u4e00\u4e2a\u200b\u5e26\u6709\u200b\u5e8f\u5217\u200b\u5206\u7c7b\u200b\u5934\u200b\uff08sequence classification head\uff09\u200b\u7684\u200b\u57fa\u7840\u200b DistilBERT \u200b\u6a21\u578b\u200b\u3002\u200b\u5e8f\u5217\u200b\u5206\u7c7b\u200b\u5934\u200b\u662f\u200b\u6c60\u5316\u200b\u8f93\u51fa\u200b\u4e4b\u4e0a\u200b\u7684\u200b\u7ebf\u6027\u200b\u5c42\u200b\u3002 <pre><code>&gt;&gt;&gt; from transformers import DistilBertForSequenceClassification\n\n&gt;&gt;&gt; model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <p>\u200b\u901a\u8fc7\u200b\u5207\u6362\u200b\u5230\u200b\u4e0d\u540c\u200b\u7684\u200b\u6a21\u578b\u200b\u5934\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u5730\u200b\u5c06\u200b\u6b64\u200b\u68c0\u67e5\u70b9\u200b\u91cd\u590d\u200b\u7528\u4e8e\u200b\u5176\u4ed6\u200b\u4efb\u52a1\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u95ee\u7b54\u200b\u4efb\u52a1\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>DistilBertForQuestionAnswering</code>] \u200b\u6a21\u578b\u200b\u5934\u200b\u3002\u200b\u95ee\u7b54\u200b\u5934\u200b\uff08question answering head\uff09\u200b\u4e0e\u200b\u5e8f\u5217\u200b\u5206\u7c7b\u200b\u5934\u200b\u7c7b\u4f3c\u200b\uff0c\u200b\u4e0d\u540c\u70b9\u200b\u5728\u4e8e\u200b\u5b83\u200b\u662f\u200b\u9690\u85cf\u200b\u72b6\u6001\u200b\u8f93\u51fa\u200b\u4e4b\u4e0a\u200b\u7684\u200b\u7ebf\u6027\u200b\u5c42\u200b\u3002</p> <p><pre><code>&gt;&gt;&gt; from transformers import DistilBertForQuestionAnswering\n\n&gt;&gt;&gt; model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n</code></pre>  \u200b\u4f8b\u5982\u200b\uff0c[<code>TFDistilBertForSequenceClassification</code>] \u200b\u662f\u200b\u4e00\u4e2a\u200b\u5e26\u6709\u200b\u5e8f\u5217\u200b\u5206\u7c7b\u200b\u5934\u200b\uff08sequence classification head\uff09\u200b\u7684\u200b\u57fa\u7840\u200b DistilBERT \u200b\u6a21\u578b\u200b\u3002\u200b\u5e8f\u5217\u200b\u5206\u7c7b\u200b\u5934\u200b\u662f\u200b\u6c60\u5316\u200b\u8f93\u51fa\u200b\u4e4b\u4e0a\u200b\u7684\u200b\u7ebf\u6027\u200b\u5c42\u200b\u3002 <pre><code>&gt;&gt;&gt; from transformers import TFDistilBertForSequenceClassification\n\n&gt;&gt;&gt; tf_model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <p>\u200b\u901a\u8fc7\u200b\u5207\u6362\u200b\u5230\u200b\u4e0d\u540c\u200b\u7684\u200b\u6a21\u578b\u200b\u5934\u200b,\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u5730\u200b\u5c06\u200b\u6b64\u200b\u68c0\u67e5\u70b9\u200b\u91cd\u590d\u200b\u7528\u4e8e\u200b\u5176\u4ed6\u200b\u4efb\u52a1\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u95ee\u7b54\u200b\u4efb\u52a1\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>TFDistilBertForQuestionAnswering</code>] \u200b\u6a21\u578b\u200b\u5934\u200b\u3002\u200b\u95ee\u7b54\u200b\u5934\u200b\uff08question answering head\uff09\u200b\u4e0e\u200b\u5e8f\u5217\u200b\u5206\u7c7b\u200b\u5934\u200b\u7c7b\u4f3c\u200b\uff0c\u200b\u4e0d\u540c\u70b9\u200b\u5728\u4e8e\u200b\u5b83\u200b\u662f\u200b\u9690\u85cf\u200b\u72b6\u6001\u200b\u8f93\u51fa\u200b\u4e4b\u4e0a\u200b\u7684\u200b\u7ebf\u6027\u200b\u5c42\u200b\u3002</p> <p><pre><code>&gt;&gt;&gt; from transformers import TFDistilBertForQuestionAnswering\n\n&gt;&gt;&gt; tf_model = TFDistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> </p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/#_4","title":"\u5206\u8bcd\u5668","text":"<p>\u200b\u5728\u200b\u5c06\u200b\u6a21\u578b\u200b\u7528\u4e8e\u200b\u6587\u672c\u200b\u6570\u636e\u200b\u4e4b\u524d\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u7684\u200b\u6700\u540e\u200b\u4e00\u4e2a\u200b\u57fa\u7c7b\u200b\u662f\u200b tokenizer\uff0c\u200b\u5b83\u200b\u7528\u4e8e\u200b\u5c06\u200b\u539f\u59cb\u200b\u6587\u672c\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u5f20\u91cf\u200b\u3002\ud83e\udd17 Transformers \u200b\u652f\u6301\u200b\u4e24\u79cd\u200b\u7c7b\u578b\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\uff1a</p> <ul> <li>[<code>PreTrainedTokenizer</code>]\uff1a\u200b\u5206\u8bcd\u5668\u200b\u7684\u200bPython\u200b\u5b9e\u73b0\u200b</li> <li>[<code>PreTrainedTokenizerFast</code>]\uff1a\u200b\u6765\u81ea\u200b\u6211\u4eec\u200b\u57fa\u4e8e\u200b Rust \u200b\u7684\u200b \ud83e\udd17 Tokenizer \u200b\u5e93\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\u3002\u200b\u56e0\u4e3a\u200b\u5176\u200b\u4f7f\u7528\u200b\u4e86\u200b Rust \u200b\u5b9e\u73b0\u200b\uff0c\u200b\u8fd9\u79cd\u200b\u5206\u8bcd\u5668\u200b\u7c7b\u578b\u200b\u7684\u200b\u901f\u5ea6\u200b\u8981\u200b\u5feb\u5f97\u591a\u200b\uff0c\u200b\u5c24\u5176\u200b\u662f\u200b\u5728\u200b\u6279\u91cf\u200b\u5206\u8bcd\u200b\uff08batch tokenization\uff09\u200b\u7684\u200b\u65f6\u5019\u200b\u3002\u200b\u5feb\u901f\u200b\u5206\u8bcd\u5668\u200b\u8fd8\u200b\u63d0\u4f9b\u200b\u5176\u4ed6\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u4f8b\u5982\u200b\u504f\u79fb\u200b\u6620\u5c04\u200b\uff08offset mapping\uff09\uff0c\u200b\u5b83\u200b\u5c06\u200b\u6807\u8bb0\u200b\uff08token\uff09\u200b\u6620\u5c04\u200b\u5230\u200b\u5176\u200b\u539f\u59cb\u200b\u5355\u8bcd\u200b\u6216\u200b\u5b57\u7b26\u200b\u3002</li> </ul> <p>\u200b\u8fd9\u200b\u4e24\u79cd\u200b\u5206\u8bcd\u5668\u200b\u90fd\u200b\u652f\u6301\u200b\u5e38\u7528\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5982\u200b\u7f16\u7801\u200b\u548c\u200b\u89e3\u7801\u200b\u3001\u200b\u6dfb\u52a0\u200b\u65b0\u200b\u6807\u8bb0\u200b\u4ee5\u53ca\u200b\u7ba1\u7406\u200b\u7279\u6b8a\u200b\u6807\u8bb0\u200b\u3002</p> <p> <p>\u200b\u5e76\u975e\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u90fd\u200b\u652f\u6301\u200b\u5feb\u901f\u200b\u5206\u8bcd\u5668\u200b\u3002\u200b\u53c2\u7167\u200b\u8fd9\u5f20\u200b \u200b\u8868\u683c\u200b \u200b\u67e5\u770b\u200b\u6a21\u578b\u200b\u662f\u5426\u200b\u652f\u6301\u200b\u5feb\u901f\u200b\u5206\u8bcd\u5668\u200b\u3002</p> <p></p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u8bad\u7ec3\u200b\u4e86\u200b\u81ea\u5df1\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\uff0c\u200b\u5219\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u8bcd\u8868\u200b\u6587\u4ef6\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u5206\u8bcd\u5668\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import DistilBertTokenizer\n\n&gt;&gt;&gt; my_tokenizer = DistilBertTokenizer(vocab_file=\"my_vocab_file.txt\", do_lower_case=False, padding_side=\"left\")\n</code></pre> <p>\u200b\u8bf7\u200b\u52a1\u5fc5\u200b\u8bb0\u4f4f\u200b\uff0c\u200b\u81ea\u5b9a\u4e49\u200b\u5206\u8bcd\u5668\u200b\u751f\u6210\u200b\u7684\u200b\u8bcd\u8868\u200b\u4e0e\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u5206\u8bcd\u5668\u200b\u751f\u6210\u200b\u7684\u200b\u8bcd\u8868\u200b\u662f\u200b\u4e0d\u540c\u200b\u7684\u200b\u3002\u200b\u5982\u679c\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff0c\u200b\u5219\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u8bcd\u8868\u200b\uff0c\u200b\u5426\u5219\u200b\u8f93\u5165\u200b\u5c06\u200b\u6ca1\u6709\u200b\u610f\u4e49\u200b\u3002 \u200b\u4f7f\u7528\u200b [<code>DistilBertTokenizer</code>] \u200b\u7c7b\u200b\u521b\u5efa\u200b\u5177\u6709\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u8bcd\u8868\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import DistilBertTokenizer\n\n&gt;&gt;&gt; slow_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <p>\u200b\u4f7f\u7528\u200b [<code>DistilBertTokenizerFast</code>] \u200b\u7c7b\u200b\u521b\u5efa\u200b\u5feb\u901f\u200b\u5206\u8bcd\u5668\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import DistilBertTokenizerFast\n\n&gt;&gt;&gt; fast_tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n</code></pre> <p> <p>\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c[<code>AutoTokenizer</code>] \u200b\u5c06\u200b\u5c1d\u8bd5\u200b\u52a0\u8f7d\u200b\u5feb\u901f\u200b\u6807\u8bb0\u200b\u751f\u6210\u5668\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5728\u200b <code>from_pretrained</code> \u200b\u4e2d\u200b\u8bbe\u7f6e\u200b <code>use_fast=False</code> \u200b\u4ee5\u200b\u7981\u7528\u200b\u6b64\u200b\u884c\u4e3a\u200b\u3002</p> <p></p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/#_5","title":"\u56fe\u50cf\u200b\u5904\u7406\u5668","text":"<p>\u200b\u56fe\u50cf\u200b\u5904\u7406\u5668\u200b\u7528\u4e8e\u200b\u5904\u7406\u200b\u89c6\u89c9\u200b\u8f93\u5165\u200b\u3002\u200b\u5b83\u200b\u7ee7\u627f\u200b\u81ea\u200b [<code>~image_processing_utils.ImageProcessingMixin</code>] \u200b\u57fa\u7c7b\u200b\u3002</p> <p>\u200b\u8981\u200b\u4f7f\u7528\u200b\u5b83\u200b\uff0c\u200b\u9700\u8981\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u4e0e\u200b\u4f60\u200b\u4f7f\u7528\u200b\u7684\u200b\u6a21\u578b\u200b\u5173\u8054\u200b\u7684\u200b\u56fe\u50cf\u200b\u5904\u7406\u5668\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u4f7f\u7528\u200b ViT \u200b\u8fdb\u884c\u200b\u56fe\u50cf\u200b\u5206\u7c7b\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u9ed8\u8ba4\u200b\u7684\u200b [<code>ViTImageProcessor</code>]\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import ViTImageProcessor\n\n&gt;&gt;&gt; vit_extractor = ViTImageProcessor()\n&gt;&gt;&gt; print(vit_extractor)\nViTImageProcessor {\n  \"do_normalize\": true,\n  \"do_resize\": true,\n  \"image_processor_type\": \"ViTImageProcessor\",\n  \"image_mean\": [\n    0.5,\n    0.5,\n    0.5\n  ],\n  \"image_std\": [\n    0.5,\n    0.5,\n    0.5\n  ],\n  \"resample\": 2,\n  \"size\": 224\n}\n</code></pre> <p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u4e0d\u200b\u9700\u8981\u200b\u8fdb\u884c\u200b\u4efb\u4f55\u200b\u81ea\u5b9a\u4e49\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u4f7f\u7528\u200b <code>from_pretrained</code> \u200b\u65b9\u6cd5\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\u7684\u200b\u9ed8\u8ba4\u200b\u56fe\u50cf\u200b\u5904\u7406\u5668\u200b\u53c2\u6570\u200b\u3002</p> <p></p> <p>\u200b\u4fee\u6539\u200b\u4efb\u4f55\u200b [<code>ViTImageProcessor</code>] \u200b\u53c2\u6570\u200b\u4ee5\u200b\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u56fe\u50cf\u200b\u5904\u7406\u5668\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import ViTImageProcessor\n\n&gt;&gt;&gt; my_vit_extractor = ViTImageProcessor(resample=\"PIL.Image.BOX\", do_normalize=False, image_mean=[0.3, 0.3, 0.3])\n&gt;&gt;&gt; print(my_vit_extractor)\nViTImageProcessor {\n  \"do_normalize\": false,\n  \"do_resize\": true,\n  \"image_processor_type\": \"ViTImageProcessor\",\n  \"image_mean\": [\n    0.3,\n    0.3,\n    0.3\n  ],\n  \"image_std\": [\n    0.5,\n    0.5,\n    0.5\n  ],\n  \"resample\": \"PIL.Image.BOX\",\n  \"size\": 224\n}\n</code></pre>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/#_6","title":"\u7279\u5f81\u63d0\u53d6\u200b\u5668","text":"<p>\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\u7528\u4e8e\u200b\u5904\u7406\u200b\u97f3\u9891\u200b\u8f93\u5165\u200b\u3002\u200b\u5b83\u200b\u7ee7\u627f\u200b\u81ea\u200b [<code>~feature_extraction_utils.FeatureExtractionMixin</code>] \u200b\u57fa\u7c7b\u200b\uff0c\u200b\u4ea6\u53ef\u200b\u7ee7\u627f\u200b [<code>SequenceFeatureExtractor</code>] \u200b\u7c7b\u6765\u200b\u5904\u7406\u200b\u97f3\u9891\u200b\u8f93\u5165\u200b\u3002</p> <p>\u200b\u8981\u200b\u4f7f\u7528\u200b\u5b83\u200b\uff0c\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u4e0e\u200b\u4f60\u200b\u4f7f\u7528\u200b\u7684\u200b\u6a21\u578b\u200b\u5173\u8054\u200b\u7684\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u4f7f\u7528\u200b Wav2Vec2 \u200b\u8fdb\u884c\u200b\u97f3\u9891\u200b\u5206\u7c7b\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u9ed8\u8ba4\u200b\u7684\u200b [<code>Wav2Vec2FeatureExtractor</code>]\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import Wav2Vec2FeatureExtractor\n\n&gt;&gt;&gt; w2v2_extractor = Wav2Vec2FeatureExtractor()\n&gt;&gt;&gt; print(w2v2_extractor)\nWav2Vec2FeatureExtractor {\n  \"do_normalize\": true,\n  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n  \"feature_size\": 1,\n  \"padding_side\": \"right\",\n  \"padding_value\": 0.0,\n  \"return_attention_mask\": false,\n  \"sampling_rate\": 16000\n}\n</code></pre> <p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u4e0d\u200b\u9700\u8981\u200b\u8fdb\u884c\u200b\u4efb\u4f55\u200b\u81ea\u5b9a\u4e49\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u4f7f\u7528\u200b <code>from_pretrained</code> \u200b\u65b9\u6cd5\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\u7684\u200b\u9ed8\u8ba4\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\u53c2\u6570\u200b\u3002</p> <p></p> <p>\u200b\u4fee\u6539\u200b\u4efb\u4f55\u200b [<code>Wav2Vec2FeatureExtractor</code>] \u200b\u53c2\u6570\u200b\u4ee5\u200b\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import Wav2Vec2FeatureExtractor\n\n&gt;&gt;&gt; w2v2_extractor = Wav2Vec2FeatureExtractor(sampling_rate=8000, do_normalize=False)\n&gt;&gt;&gt; print(w2v2_extractor)\nWav2Vec2FeatureExtractor {\n  \"do_normalize\": false,\n  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n  \"feature_size\": 1,\n  \"padding_side\": \"right\",\n  \"padding_value\": 0.0,\n  \"return_attention_mask\": false,\n  \"sampling_rate\": 8000\n}\n</code></pre>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/#_7","title":"\u5904\u7406\u5668","text":"<p>\u200b\u5bf9\u4e8e\u200b\u652f\u6301\u200b\u591a\u200b\u6a21\u5f0f\u200b\u4efb\u52a1\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\ud83e\udd17 Transformers \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u5904\u7406\u5668\u200b\u7c7b\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u65b9\u4fbf\u200b\u5730\u200b\u5c06\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\u548c\u200b\u5206\u8bcd\u5668\u200b\u7b49\u200b\u5904\u7406\u200b\u7c7b\u200b\u5305\u88c5\u200b\u5230\u200b\u5355\u4e2a\u200b\u5bf9\u8c61\u200b\u4e2d\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b [<code>Wav2Vec2Processor</code>] \u200b\u6765\u200b\u6267\u884c\u200b\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b\u4efb\u52a1\u200b (ASR)\u3002 ASR \u200b\u5c06\u200b\u97f3\u9891\u200b\u8f6c\u5f55\u200b\u4e3a\u200b\u6587\u672c\u200b\uff0c\u200b\u56e0\u6b64\u200b\u60a8\u200b\u5c06\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\u548c\u200b\u4e00\u4e2a\u200b\u5206\u8bcd\u5668\u200b\u3002</p> <p>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u6765\u200b\u5904\u7406\u200b\u97f3\u9891\u200b\u8f93\u5165\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import Wav2Vec2FeatureExtractor\n\n&gt;&gt;&gt; feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)\n</code></pre> <p>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u5206\u8bcd\u5668\u200b\u6765\u200b\u5904\u7406\u200b\u6587\u672c\u200b\u8f93\u5165\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import Wav2Vec2CTCTokenizer\n\n&gt;&gt;&gt; tokenizer = Wav2Vec2CTCTokenizer(vocab_file=\"my_vocab_file.txt\")\n</code></pre> <p>\u200b\u5c06\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\u548c\u200b\u5206\u8bcd\u5668\u200b\u5408\u5e76\u200b\u5230\u200b [<code>Wav2Vec2Processor</code>] \u200b\u4e2d\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import Wav2Vec2Processor\n\n&gt;&gt;&gt; processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n</code></pre> <p>\u200b\u901a\u8fc7\u200b\u4e24\u4e2a\u200b\u57fa\u7c7b\u200b - \u200b\u914d\u7f6e\u200b\u7c7b\u200b\u548c\u200b\u6a21\u578b\u200b\u7c7b\u200b - \u200b\u4ee5\u53ca\u200b\u4e00\u4e2a\u200b\u9644\u52a0\u200b\u7684\u200b\u9884\u5904\u7406\u200b\u7c7b\u200b\uff08\u200b\u5206\u8bcd\u5668\u200b\u3001\u200b\u56fe\u50cf\u200b\u5904\u7406\u5668\u200b\u3001\u200b\u7279\u5f81\u63d0\u53d6\u200b\u5668\u200b\u6216\u200b\u5904\u7406\u5668\u200b\uff09\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u521b\u5efa\u200b \ud83e\udd17 Transformers \u200b\u652f\u6301\u200b\u7684\u200b\u4efb\u4f55\u200b\u6a21\u578b\u200b\u3002 \u200b\u6bcf\u4e2a\u200b\u57fa\u7c7b\u200b\u90fd\u200b\u662f\u200b\u53ef\u200b\u914d\u7f6e\u200b\u7684\u200b\uff0c\u200b\u5141\u8bb8\u200b\u4f60\u200b\u4f7f\u7528\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u7279\u5b9a\u200b\u5c5e\u6027\u200b\u3002 \u200b\u4f60\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u8bbe\u7f6e\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u6216\u200b\u4fee\u6539\u200b\u73b0\u6709\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u5fae\u8c03\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/custom_models/","title":"Custom models","text":""},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/custom_models/#_1","title":"\u5171\u4eab\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b","text":"<p>\ud83e\udd17 Transformers \u200b\u5e93\u200b\u8bbe\u8ba1\u200b\u5f97\u200b\u6613\u4e8e\u200b\u6269\u5c55\u200b\u3002\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u7684\u200b\u4ee3\u7801\u200b\u90fd\u200b\u5728\u200b\u4ed3\u5e93\u200b\u7ed9\u5b9a\u200b\u7684\u200b\u5b50\u200b\u6587\u4ef6\u5939\u200b\u4e2d\u200b\uff0c\u200b\u6ca1\u6709\u200b\u8fdb\u884c\u200b\u62bd\u8c61\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u590d\u5236\u200b\u6a21\u578b\u200b\u4ee3\u7801\u200b\u6587\u4ef6\u200b\u5e76\u200b\u6839\u636e\u200b\u9700\u8981\u200b\u8fdb\u884c\u200b\u8c03\u6574\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u8981\u200b\u7f16\u5199\u200b\u5168\u65b0\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u4ece\u5934\u5f00\u59cb\u200b\u53ef\u80fd\u200b\u66f4\u200b\u5bb9\u6613\u200b\u3002\u200b\u5728\u200b\u672c\u200b\u6559\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u5411\u200b\u4f60\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\u7f16\u5199\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u53ca\u5176\u200b\u914d\u7f6e\u200b\uff0c\u200b\u4ee5\u4fbf\u200b\u53ef\u4ee5\u200b\u5728\u200b Transformers \u200b\u4e2d\u200b\u4f7f\u7528\u200b\u5b83\u200b\uff1b\u200b\u4ee5\u53ca\u200b\u5982\u4f55\u200b\u4e0e\u200b\u793e\u533a\u200b\u5171\u4eab\u200b\u5b83\u200b\uff08\u200b\u53ca\u5176\u200b\u4f9d\u8d56\u200b\u7684\u200b\u4ee3\u7801\u200b\uff09\uff0c\u200b\u4ee5\u4fbf\u200b\u4efb\u4f55\u4eba\u200b\u90fd\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\uff0c\u200b\u5373\u4f7f\u200b\u5b83\u200b\u4e0d\u200b\u5728\u200b \ud83e\udd17 Transformers \u200b\u5e93\u4e2d\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u5c06\u200b\u4ee5\u200b ResNet \u200b\u6a21\u578b\u200b\u4e3a\u4f8b\u200b\uff0c\u200b\u901a\u8fc7\u200b\u5c06\u200b timm \u200b\u5e93\u200b \u200b\u7684\u200b ResNet \u200b\u7c7b\u200b\u5c01\u88c5\u200b\u5230\u200b [<code>PreTrainedModel</code>] \u200b\u4e2d\u6765\u200b\u8fdb\u884c\u200b\u8bf4\u660e\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/custom_models/#_2","title":"\u7f16\u5199\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e","text":"<p>\u200b\u5728\u200b\u6df1\u5165\u7814\u7a76\u200b\u6a21\u578b\u200b\u4e4b\u524d\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u9996\u5148\u200b\u7f16\u5199\u200b\u5176\u200b\u914d\u7f6e\u200b\u3002\u200b\u6a21\u578b\u200b\u7684\u200b\u914d\u7f6e\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u5176\u4e2d\u200b\u5305\u542b\u200b\u6784\u5efa\u200b\u6a21\u578b\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u6240\u6709\u200b\u4fe1\u606f\u200b\u3002\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b\u4e0b\u200b\u4e00\u8282\u200b\u4e2d\u200b\u770b\u5230\u200b\uff0c\u200b\u6a21\u578b\u200b\u53ea\u80fd\u200b\u63a5\u53d7\u200b\u4e00\u4e2a\u200b <code>config</code> \u200b\u6765\u200b\u8fdb\u884c\u200b\u521d\u59cb\u5316\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6211\u4eec\u200b\u5f88\u200b\u9700\u8981\u200b\u4f7f\u8be5\u200b\u5bf9\u8c61\u200b\u5c3d\u53ef\u80fd\u200b\u5b8c\u6574\u200b\u3002</p> <p>\u200b\u6211\u4eec\u200b\u5c06\u200b\u91c7\u7528\u200b\u4e00\u4e9b\u200b\u6211\u4eec\u200b\u53ef\u80fd\u200b\u60f3\u8981\u200b\u8c03\u6574\u200b\u7684\u200b ResNet \u200b\u7c7b\u200b\u7684\u200b\u53c2\u6570\u200b\u4e3e\u4f8b\u200b\u3002\u200b\u4e0d\u540c\u200b\u7684\u200b\u914d\u7f6e\u200b\u5c06\u200b\u4e3a\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e0d\u540c\u200b\u7c7b\u578b\u200b\u53ef\u80fd\u200b\u7684\u200b ResNet \u200b\u6a21\u578b\u200b\u3002\u200b\u5728\u200b\u786e\u8ba4\u200b\u5176\u4e2d\u200b\u4e00\u4e9b\u200b\u53c2\u6570\u200b\u7684\u200b\u6709\u6548\u6027\u200b\u540e\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ea\u200b\u9700\u200b\u5b58\u50a8\u200b\u8fd9\u4e9b\u200b\u53c2\u6570\u200b\u3002</p> <pre><code>from transformers import PretrainedConfig\nfrom typing import List\n\n\nclass ResnetConfig(PretrainedConfig):\n    model_type = \"resnet\"\n\n    def __init__(\n        self,\n        block_type=\"bottleneck\",\n        layers: List[int] = [3, 4, 6, 3],\n        num_classes: int = 1000,\n        input_channels: int = 3,\n        cardinality: int = 1,\n        base_width: int = 64,\n        stem_width: int = 64,\n        stem_type: str = \"\",\n        avg_down: bool = False,\n        **kwargs,\n    ):\n        if block_type not in [\"basic\", \"bottleneck\"]:\n            raise ValueError(f\"`block_type` must be 'basic' or bottleneck', got {block_type}.\")\n        if stem_type not in [\"\", \"deep\", \"deep-tiered\"]:\n            raise ValueError(f\"`stem_type` must be '', 'deep' or 'deep-tiered', got {stem_type}.\")\n\n        self.block_type = block_type\n        self.layers = layers\n        self.num_classes = num_classes\n        self.input_channels = input_channels\n        self.cardinality = cardinality\n        self.base_width = base_width\n        self.stem_width = stem_width\n        self.stem_type = stem_type\n        self.avg_down = avg_down\n        super().__init__(**kwargs)\n</code></pre> <p>\u200b\u7f16\u5199\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u200b\u65f6\u200b\u9700\u8981\u200b\u8bb0\u4f4f\u200b\u7684\u200b\u4e09\u4e2a\u200b\u91cd\u8981\u200b\u4e8b\u9879\u200b\u5982\u4e0b\u200b\uff1a - \u200b\u5fc5\u987b\u200b\u7ee7\u627f\u200b\u81ea\u200b <code>PretrainedConfig</code>\uff0c - <code>PretrainedConfig</code> \u200b\u7684\u200b <code>__init__</code> \u200b\u65b9\u6cd5\u200b\u5fc5\u987b\u200b\u63a5\u53d7\u200b\u4efb\u4f55\u200b kwargs\uff0c - \u200b\u8fd9\u4e9b\u200b <code>kwargs</code> \u200b\u9700\u8981\u200b\u4f20\u9012\u200b\u7ed9\u200b\u8d85\u7c7b\u200b\u7684\u200b <code>__init__</code> \u200b\u65b9\u6cd5\u200b\u3002</p> <p>\u200b\u7ee7\u627f\u200b\u662f\u200b\u4e3a\u4e86\u200b\u786e\u4fdd\u200b\u4f60\u200b\u83b7\u5f97\u200b\u6765\u81ea\u200b \ud83e\udd17 Transformers \u200b\u5e93\u200b\u7684\u200b\u6240\u6709\u200b\u529f\u80fd\u200b\uff0c\u200b\u800c\u200b\u53e6\u5916\u200b\u4e24\u4e2a\u200b\u7ea6\u675f\u200b\u6e90\u4e8e\u200b <code>PretrainedConfig</code> \u200b\u7684\u200b\u5b57\u200b\u6bb5\u200b\u6bd4\u200b\u4f60\u200b\u8bbe\u7f6e\u200b\u7684\u200b\u5b57\u200b\u6bb5\u200b\u591a\u200b\u3002\u200b\u5728\u200b\u4f7f\u7528\u200b <code>from_pretrained</code> \u200b\u65b9\u6cd5\u200b\u91cd\u65b0\u200b\u52a0\u8f7d\u200b\u914d\u7f6e\u200b\u65f6\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u5b57\u200b\u6bb5\u200b\u9700\u8981\u200b\u88ab\u200b\u4f60\u200b\u7684\u200b\u914d\u7f6e\u200b\u63a5\u53d7\u200b\uff0c\u200b\u7136\u540e\u200b\u4f20\u9012\u200b\u7ed9\u200b\u8d85\u7c7b\u200b\u3002</p> <p>\u200b\u4e3a\u200b\u4f60\u200b\u7684\u200b\u914d\u7f6e\u200b\u5b9a\u4e49\u200b <code>model_type</code>\uff08\u200b\u6b64\u5904\u200b\u4e3a\u200b <code>model_type=\"resnet\"</code>\uff09\u200b\u4e0d\u662f\u200b\u5fc5\u987b\u200b\u7684\u200b\uff0c\u200b\u9664\u975e\u200b\u4f60\u200b\u60f3\u200b\u4f7f\u7528\u200b\u81ea\u52a8\u200b\u7c7b\u200b\u6ce8\u518c\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\uff08\u200b\u8bf7\u53c2\u9605\u200b\u6700\u540e\u200b\u4e00\u8282\u200b\uff09\u3002</p> <p>\u200b\u505a\u200b\u5b8c\u200b\u8fd9\u4e9b\u200b\u4ee5\u540e\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u50cf\u200b\u4f7f\u7528\u200b\u5e93\u91cc\u200b\u4efb\u4f55\u200b\u5176\u4ed6\u200b\u6a21\u578b\u200b\u914d\u7f6e\u200b\u4e00\u6837\u200b\uff0c\u200b\u8f7b\u677e\u200b\u5730\u200b\u521b\u5efa\u200b\u548c\u200b\u4fdd\u5b58\u200b\u914d\u7f6e\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u4ee3\u7801\u200b\u5c55\u793a\u200b\u4e86\u200b\u5982\u4f55\u200b\u521b\u5efa\u200b\u5e76\u200b\u4fdd\u5b58\u200b resnet50d \u200b\u914d\u7f6e\u200b\uff1a</p> <pre><code>resnet50d_config = ResnetConfig(block_type=\"bottleneck\", stem_width=32, stem_type=\"deep\", avg_down=True)\nresnet50d_config.save_pretrained(\"custom-resnet\")\n</code></pre> <p>\u200b\u8fd9\u200b\u884c\u200b\u4ee3\u7801\u200b\u5c06\u200b\u5728\u200b <code>custom-resnet</code> \u200b\u6587\u4ef6\u5939\u200b\u5185\u200b\u4fdd\u5b58\u200b\u4e00\u4e2a\u200b\u540d\u4e3a\u200b <code>config.json</code> \u200b\u7684\u200b\u6587\u4ef6\u200b\u3002\u200b\u7136\u540e\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>from_pretrained</code> \u200b\u65b9\u6cd5\u200b\u91cd\u65b0\u200b\u52a0\u8f7d\u200b\u914d\u7f6e\u200b\uff1a</p> <pre><code>resnet50d_config = ResnetConfig.from_pretrained(\"custom-resnet\")\n</code></pre> <p>\u200b\u4f60\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>PretrainedConfig</code>] \u200b\u7c7b\u200b\u7684\u200b\u4efb\u4f55\u200b\u5176\u4ed6\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u4f8b\u5982\u200b [<code>~PretrainedConfig.push_to_hub</code>]\uff0c\u200b\u76f4\u63a5\u200b\u5c06\u200b\u914d\u7f6e\u200b\u4e0a\u200b\u4f20\u5230\u200b Hub\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/custom_models/#_3","title":"\u7f16\u5199\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b","text":"<p>\u200b\u6709\u200b\u4e86\u200b ResNet \u200b\u914d\u7f6e\u200b\u540e\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u7ee7\u7eed\u200b\u7f16\u5199\u200b\u6a21\u578b\u200b\u4e86\u200b\u3002\u200b\u5b9e\u9645\u4e0a\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u7f16\u5199\u200b\u4e24\u4e2a\u200b\u6a21\u578b\u200b\uff1a\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u7528\u4e8e\u200b\u4ece\u200b\u4e00\u6279\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u9690\u85cf\u200b\u7279\u5f81\u200b\uff08\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b [<code>BertModel</code>]\uff09\uff0c\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u9002\u7528\u200b\u4e8e\u200b\u56fe\u50cf\u200b\u5206\u7c7b\u200b\uff08\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b [<code>BertForSequenceClassification</code>]\uff09\u3002</p> <p>\u200b\u6b63\u5982\u200b\u4e4b\u524d\u200b\u63d0\u5230\u200b\u7684\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ea\u4f1a\u200b\u7f16\u5199\u200b\u4e00\u4e2a\u200b\u677e\u6563\u200b\u7684\u200b\u6a21\u578b\u200b\u5305\u88c5\u200b\uff0c\u200b\u4ee5\u200b\u4f7f\u200b\u793a\u4f8b\u200b\u4fdd\u6301\u200b\u7b80\u6d01\u200b\u3002\u200b\u5728\u200b\u7f16\u5199\u200b\u6b64\u7c7b\u200b\u4e4b\u524d\u200b\uff0c\u200b\u53ea\u200b\u9700\u8981\u200b\u5efa\u7acb\u200b\u8d77\u5757\u200b\u7c7b\u578b\u200b\uff08block types\uff09\u200b\u4e0e\u200b\u5b9e\u9645\u200b\u5757\u200b\u7c7b\u200b\uff08block classes\uff09\u200b\u4e4b\u95f4\u200b\u7684\u200b\u6620\u5c04\u200b\u3002\u200b\u7136\u540e\u200b\uff0c\u200b\u901a\u8fc7\u200b\u5c06\u200b\u6240\u6709\u200b\u5185\u5bb9\u200b\u4f20\u9012\u200b\u7ed9\u200bResNet\u200b\u7c7b\u200b\uff0c\u200b\u4ece\u200b\u914d\u7f6e\u200b\u4e2d\u200b\u5b9a\u4e49\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>from transformers import PreTrainedModel\nfrom timm.models.resnet import BasicBlock, Bottleneck, ResNet\nfrom .configuration_resnet import ResnetConfig\n\n\nBLOCK_MAPPING = {\"basic\": BasicBlock, \"bottleneck\": Bottleneck}\n\n\nclass ResnetModel(PreTrainedModel):\n    config_class = ResnetConfig\n\n    def __init__(self, config):\n        super().__init__(config)\n        block_layer = BLOCK_MAPPING[config.block_type]\n        self.model = ResNet(\n            block_layer,\n            config.layers,\n            num_classes=config.num_classes,\n            in_chans=config.input_channels,\n            cardinality=config.cardinality,\n            base_width=config.base_width,\n            stem_width=config.stem_width,\n            stem_type=config.stem_type,\n            avg_down=config.avg_down,\n        )\n\n    def forward(self, tensor):\n        return self.model.forward_features(tensor)\n</code></pre> <p>\u200b\u5bf9\u200b\u7528\u4e8e\u200b\u8fdb\u884c\u200b\u56fe\u50cf\u200b\u5206\u7c7b\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ea\u200b\u9700\u200b\u66f4\u6539\u200b\u524d\u5411\u200b\u65b9\u6cd5\u200b\uff1a</p> <pre><code>import torch\n\n\nclass ResnetModelForImageClassification(PreTrainedModel):\n    config_class = ResnetConfig\n\n    def __init__(self, config):\n        super().__init__(config)\n        block_layer = BLOCK_MAPPING[config.block_type]\n        self.model = ResNet(\n            block_layer,\n            config.layers,\n            num_classes=config.num_classes,\n            in_chans=config.input_channels,\n            cardinality=config.cardinality,\n            base_width=config.base_width,\n            stem_width=config.stem_width,\n            stem_type=config.stem_type,\n            avg_down=config.avg_down,\n        )\n\n    def forward(self, tensor, labels=None):\n        logits = self.model(tensor)\n        if labels is not None:\n            loss = torch.nn.cross_entropy(logits, labels)\n            return {\"loss\": loss, \"logits\": logits}\n        return {\"logits\": logits}\n</code></pre> <p>\u200b\u5728\u200b\u8fd9\u200b\u4e24\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u8bf7\u200b\u6ce8\u610f\u200b\u6211\u4eec\u200b\u5982\u4f55\u200b\u7ee7\u627f\u200b <code>PreTrainedModel</code> \u200b\u5e76\u200b\u4f7f\u7528\u200b <code>config</code> \u200b\u8c03\u7528\u200b\u4e86\u200b\u8d85\u7c7b\u200b\u7684\u200b\u521d\u59cb\u5316\u200b\uff08\u200b\u6709\u70b9\u50cf\u200b\u7f16\u5199\u200b\u5e38\u89c4\u200b\u7684\u200btorch.nn.Module\uff09\u3002\u200b\u8bbe\u7f6e\u200b <code>config_class</code> \u200b\u7684\u200b\u90a3\u884c\u200b\u4ee3\u7801\u200b\u4e0d\u662f\u200b\u5fc5\u987b\u200b\u7684\u200b\uff0c\u200b\u9664\u975e\u200b\u4f60\u200b\u60f3\u200b\u4f7f\u7528\u200b\u81ea\u52a8\u200b\u7c7b\u200b\u6ce8\u518c\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\uff08\u200b\u8bf7\u53c2\u9605\u200b\u6700\u540e\u200b\u4e00\u8282\u200b\uff09\u3002</p> <p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u4e0e\u200b\u5e93\u200b\u4e2d\u200b\u7684\u200b\u67d0\u4e2a\u200b\u6a21\u578b\u200b\u975e\u5e38\u200b\u76f8\u4f3c\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u91cd\u7528\u200b\u4e0e\u200b\u8be5\u200b\u6a21\u578b\u200b\u76f8\u540c\u200b\u7684\u200b\u914d\u7f6e\u200b\u3002</p> <p></p> <p>\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u8ba9\u200b\u6a21\u578b\u200b\u8fd4\u56de\u200b\u4efb\u4f55\u200b\u4f60\u200b\u60f3\u8981\u200b\u7684\u200b\u5185\u5bb9\u200b\uff0c\u200b\u4f46\u662f\u200b\u50cf\u200b\u6211\u4eec\u200b\u4e3a\u200b <code>ResnetModelForImageClassification</code> \u200b\u505a\u200b\u7684\u200b\u90a3\u6837\u200b\u8fd4\u56de\u200b\u4e00\u4e2a\u200b\u5b57\u5178\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u4f20\u9012\u200b\u6807\u7b7e\u200b\u65f6\u200b\u5305\u542b\u200bloss\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u80fd\u591f\u200b\u5728\u200b [<code>Trainer</code>] \u200b\u7c7b\u4e2d\u200b\u76f4\u63a5\u200b\u4f7f\u7528\u200b\u3002\u200b\u53ea\u8981\u200b\u4f60\u200b\u8ba1\u5212\u200b\u4f7f\u7528\u200b\u81ea\u5df1\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u6216\u200b\u5176\u4ed6\u200b\u5e93\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u5176\u4ed6\u200b\u8f93\u51fa\u200b\u683c\u5f0f\u200b\u3002</p> <p>\u200b\u73b0\u5728\u200b\u6211\u4eec\u200b\u5df2\u7ecf\u200b\u6709\u200b\u4e86\u200b\u6a21\u578b\u200b\u7c7b\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\uff1a</p> <pre><code>resnet50d = ResnetModelForImageClassification(resnet50d_config)\n</code></pre> <p>\u200b\u540c\u6837\u200b\u7684\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>PreTrainedModel</code>] \u200b\u7684\u200b\u4efb\u4f55\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u6bd4\u5982\u200b [<code>~PreTrainedModel.save_pretrained</code>] \u200b\u6216\u8005\u200b [<code>~PreTrainedModel.push_to_hub</code>]\u3002\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b\u4e0b\u200b\u4e00\u8282\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u7b2c\u4e8c\u79cd\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5e76\u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u6211\u4eec\u200b\u7684\u200b\u6a21\u578b\u200b\u7684\u200b\u4ee3\u7801\u200b\u63a8\u9001\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u3002\u200b\u4f46\u200b\u9996\u5148\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5728\u200b\u6a21\u578b\u200b\u5185\u200b\u52a0\u8f7d\u200b\u4e00\u4e9b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\u3002</p> <p>\u200b\u5728\u200b\u4f60\u200b\u81ea\u5df1\u200b\u7684\u200b\u7528\u4f8b\u200b\u4e2d\u200b\uff0c\u200b\u4f60\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5728\u200b\u81ea\u5df1\u200b\u7684\u200b\u6570\u636e\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u3002\u200b\u4e3a\u4e86\u200b\u5feb\u901f\u200b\u5b8c\u6210\u200b\u672c\u200b\u6559\u7a0b\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4f7f\u7528\u200b resnet50d \u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7248\u672c\u200b\u3002\u200b\u7531\u4e8e\u200b\u6211\u4eec\u200b\u7684\u200b\u6a21\u578b\u200b\u53ea\u662f\u200b\u5b83\u200b\u7684\u200b\u5305\u88c5\u200b\uff0c\u200b\u8f6c\u79fb\u200b\u8fd9\u4e9b\u200b\u6743\u91cd\u200b\u5c06\u4f1a\u200b\u5f88\u200b\u5bb9\u6613\u200b\uff1a</p> <pre><code>import timm\n\npretrained_model = timm.create_model(\"resnet50d\", pretrained=True)\nresnet50d.model.load_state_dict(pretrained_model.state_dict())\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u8ba9\u200b\u6211\u4eec\u200b\u770b\u770b\u200b\uff0c\u200b\u5982\u4f55\u200b\u786e\u4fdd\u200b\u5728\u200b\u6267\u884c\u200b [<code>~PreTrainedModel.save_pretrained</code>] \u200b\u6216\u200b [<code>~PreTrainedModel.push_to_hub</code>] \u200b\u65f6\u200b\uff0c\u200b\u6a21\u578b\u200b\u7684\u200b\u4ee3\u7801\u200b\u88ab\u200b\u4fdd\u5b58\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/custom_models/#hub","title":"\u5c06\u200b\u4ee3\u7801\u200b\u53d1\u9001\u5230\u200b Hub","text":"<p> <p>\u200b\u6b64\u200b API \u200b\u662f\u200b\u5b9e\u9a8c\u6027\u200b\u7684\u200b\uff0c\u200b\u672a\u6765\u200b\u7684\u200b\u53d1\u5e03\u200b\u4e2d\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u6709\u200b\u4e00\u4e9b\u200b\u8f7b\u5fae\u200b\u7684\u200b\u4e0d\u200b\u517c\u5bb9\u200b\u66f4\u6539\u200b\u3002</p> <p></p> <p>\u200b\u9996\u5148\u200b\uff0c\u200b\u786e\u4fdd\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u5728\u200b\u4e00\u4e2a\u200b <code>.py</code> \u200b\u6587\u4ef6\u200b\u4e2d\u200b\u5b8c\u5168\u200b\u5b9a\u4e49\u200b\u3002\u200b\u53ea\u8981\u200b\u6240\u6709\u200b\u6587\u4ef6\u200b\u90fd\u200b\u4f4d\u4e8e\u200b\u540c\u4e00\u200b\u76ee\u5f55\u200b\u4e2d\u200b\uff0c\u200b\u5b83\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f9d\u8d56\u4e8e\u200b\u67d0\u4e9b\u200b\u5176\u4ed6\u200b\u6587\u4ef6\u200b\u7684\u200b\u76f8\u5bf9\u200b\u5bfc\u5165\u200b\uff08\u200b\u76ee\u524d\u200b\u6211\u4eec\u200b\u8fd8\u200b\u4e0d\u200b\u4e3a\u5b50\u200b\u6a21\u5757\u200b\u652f\u6301\u200b\u6b64\u200b\u529f\u80fd\u200b\uff09\u3002\u200b\u5bf9\u4e8e\u200b\u6211\u4eec\u200b\u7684\u200b\u793a\u4f8b\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b\u5f53\u524d\u5de5\u4f5c\u200b\u76ee\u5f55\u200b\u4e2d\u200b\u540d\u4e3a\u200b <code>resnet_model</code> \u200b\u7684\u200b\u6587\u4ef6\u5939\u200b\u4e2d\u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200b <code>modeling_resnet.py</code> \u200b\u6587\u4ef6\u200b\u548c\u200b\u4e00\u4e2a\u200b <code>configuration_resnet.py</code> \u200b\u6587\u4ef6\u200b\u3002 \u200b\u914d\u7f6e\u6587\u4ef6\u200b\u5305\u542b\u200b <code>ResnetConfig</code> \u200b\u7684\u200b\u4ee3\u7801\u200b\uff0c\u200b\u6a21\u578b\u200b\u6587\u4ef6\u200b\u5305\u542b\u200b <code>ResnetModel</code> \u200b\u548c\u200b <code>ResnetModelForImageClassification</code> \u200b\u7684\u200b\u4ee3\u7801\u200b\u3002</p> <pre><code>.\n\u2514\u2500\u2500 resnet_model\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 configuration_resnet.py\n    \u2514\u2500\u2500 modeling_resnet.py\n</code></pre> <p><code>__init__.py</code> \u200b\u53ef\u4ee5\u200b\u4e3a\u7a7a\u200b\uff0c\u200b\u5b83\u200b\u7684\u200b\u5b58\u5728\u200b\u53ea\u662f\u200b\u4e3a\u4e86\u200b\u8ba9\u200b Python \u200b\u68c0\u6d4b\u200b\u5230\u200b <code>resnet_model</code> \u200b\u53ef\u4ee5\u200b\u7528\u4f5c\u200b\u6a21\u5757\u200b\u3002</p> <p> <p>\u200b\u5982\u679c\u200b\u4ece\u5e93\u200b\u4e2d\u200b\u590d\u5236\u200b\u6a21\u578b\u200b\u6587\u4ef6\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u5c06\u200b\u6587\u4ef6\u200b\u9876\u90e8\u200b\u7684\u200b\u6240\u6709\u200b\u76f8\u5bf9\u200b\u5bfc\u5165\u200b\u66ff\u6362\u200b\u4e3a\u200b\u4ece\u200b <code>transformers</code> \u200b\u5305\u4e2d\u200b\u7684\u200b\u5bfc\u5165\u200b\u3002</p> <p></p> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u91cd\u7528\u200b\uff08\u200b\u6216\u5b50\u200b\u7c7b\u5316\u200b\uff09\u200b\u73b0\u6709\u200b\u7684\u200b\u914d\u7f6e\u200b/\u200b\u6a21\u578b\u200b\u3002</p> <p>\u200b\u8981\u200b\u4e0e\u200b\u793e\u533a\u200b\u5171\u4eab\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u7167\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\uff1a\u200b\u9996\u5148\u200b\u4ece\u200b\u65b0\u521b\u5efa\u200b\u7684\u200b\u6587\u4ef6\u200b\u4e2d\u200b\u5bfc\u5165\u200bResNet\u200b\u6a21\u578b\u200b\u548c\u200b\u914d\u7f6e\u200b\uff1a</p> <pre><code>from resnet_model.configuration_resnet import ResnetConfig\nfrom resnet_model.modeling_resnet import ResnetModel, ResnetModelForImageClassification\n</code></pre> <p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u544a\u8bc9\u200b\u5e93\u200b\uff0c\u200b\u5f53\u200b\u4f7f\u7528\u200b <code>save_pretrained</code> \u200b\u65b9\u6cd5\u200b\u65f6\u200b\uff0c\u200b\u4f60\u200b\u5e0c\u671b\u200b\u590d\u5236\u200b\u8fd9\u4e9b\u200b\u5bf9\u8c61\u200b\u7684\u200b\u4ee3\u7801\u200b\u6587\u4ef6\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200b\u5b83\u4eec\u200b\u6b63\u786e\u200b\u6ce8\u518c\u200b\u5230\u200b\u7ed9\u5b9a\u200b\u7684\u200b Auto \u200b\u7c7b\u200b\uff08\u200b\u7279\u522b\u200b\u662f\u200b\u5bf9\u4e8e\u200b\u6a21\u578b\u200b\uff09\uff0c\u200b\u53ea\u200b\u9700\u8981\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u4ee3\u7801\u200b\uff1a</p> <pre><code>ResnetConfig.register_for_auto_class()\nResnetModel.register_for_auto_class(\"AutoModel\")\nResnetModelForImageClassification.register_for_auto_class(\"AutoModelForImageClassification\")\n</code></pre> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u914d\u7f6e\u200b\uff08\u200b\u53ea\u6709\u200b\u4e00\u4e2a\u200b\u81ea\u52a8\u200b\u7c7b\u200b [<code>AutoConfig</code>]\uff09\uff0c\u200b\u4e0d\u200b\u9700\u8981\u200b\u6307\u5b9a\u200b\u81ea\u52a8\u200b\u7c7b\u200b\uff0c\u200b\u4f46\u200b\u5bf9\u4e8e\u200b\u6a21\u578b\u200b\u6765\u8bf4\u200b\u60c5\u51b5\u200b\u4e0d\u540c\u200b\u3002 \u200b\u4f60\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u53ef\u80fd\u200b\u9002\u7528\u200b\u4e8e\u200b\u8bb8\u591a\u200b\u4e0d\u540c\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4f60\u200b\u5fc5\u987b\u200b\u6307\u5b9a\u200b\u54ea\u200b\u4e00\u4e2a\u200b\u81ea\u52a8\u200b\u7c7b\u200b\u9002\u5408\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u3002</p> <p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u50cf\u200b\u4e4b\u524d\u200b\u4e00\u6837\u200b\u521b\u5efa\u200b\u914d\u7f6e\u200b\u548c\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>resnet50d_config = ResnetConfig(block_type=\"bottleneck\", stem_width=32, stem_type=\"deep\", avg_down=True)\nresnet50d = ResnetModelForImageClassification(resnet50d_config)\n\npretrained_model = timm.create_model(\"resnet50d\", pretrained=True)\nresnet50d.model.load_state_dict(pretrained_model.state_dict())\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u8981\u200b\u5c06\u200b\u6a21\u578b\u200b\u63a8\u9001\u200b\u5230\u200b\u96c6\u7ebf\u5668\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200b\u4f60\u200b\u5df2\u200b\u767b\u5f55\u200b\u3002\u200b\u4f60\u200b\u770b\u200b\u53ef\u4ee5\u200b\u5728\u200b\u7ec8\u7aef\u200b\u4e2d\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\uff1a</p> <pre><code>huggingface-cli login\n</code></pre> <p>\u200b\u6216\u8005\u200b\u5728\u200b\u7b14\u8bb0\u672c\u200b\u4e2d\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u4ee3\u7801\u200b\uff1a</p> <pre><code>from huggingface_hub import notebook_login\n\nnotebook_login()\n</code></pre> <p>\u200b\u7136\u540e\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u8fd9\u6837\u200b\u5c06\u200b\u6a21\u578b\u200b\u63a8\u9001\u200b\u5230\u200b\u81ea\u5df1\u200b\u7684\u200b\u547d\u540d\u200b\u7a7a\u95f4\u200b\uff08\u200b\u6216\u200b\u4f60\u200b\u6240\u5c5e\u200b\u7684\u200b\u7ec4\u7ec7\u200b\uff09\uff1a</p> <pre><code>resnet50d.push_to_hub(\"custom-resnet50d\")\n</code></pre> <p>\u200b\u9664\u4e86\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u548c\u200b JSON \u200b\u683c\u5f0f\u200b\u7684\u200b\u914d\u7f6e\u200b\u5916\u200b\uff0c\u200b\u8fd9\u200b\u884c\u200b\u4ee3\u7801\u200b\u4e5f\u200b\u4f1a\u200b\u590d\u5236\u200b <code>custom-resnet50d</code> \u200b\u6587\u4ef6\u5939\u200b\u5185\u200b\u7684\u200b\u6a21\u578b\u200b\u4ee5\u53ca\u200b\u914d\u7f6e\u200b\u7684\u200b <code>.py</code> \u200b\u6587\u4ef6\u200b\u5e76\u200b\u5c06\u200b\u7ed3\u679c\u200b\u4e0a\u4f20\u200b\u81f3\u200b Hub\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200b\u6b64\u200b\u6a21\u578b\u200b\u4ed3\u5e93\u200b\u4e2d\u200b\u67e5\u770b\u200b\u7ed3\u679c\u200b\u3002</p> <p>\u200b\u6709\u5173\u200b\u63a8\u200b\u63a8\u9001\u200b\u81f3\u200b Hub \u200b\u65b9\u6cd5\u200b\u7684\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u5171\u4eab\u200b\u6559\u7a0b\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/custom_models/#_4","title":"\u4f7f\u7528\u200b\u5e26\u6709\u200b\u81ea\u5b9a\u4e49\u200b\u4ee3\u7801\u200b\u7684\u200b\u6a21\u578b","text":"<p>\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u81ea\u52a8\u200b\u7c7b\u200b\uff08auto-classes\uff09\u200b\u548c\u200b <code>from_pretrained</code> \u200b\u65b9\u6cd5\u200b\uff0c\u200b\u4f7f\u7528\u200b\u6a21\u578b\u200b\u4ed3\u5e93\u200b\u91cc\u200b\u5e26\u6709\u200b\u81ea\u5b9a\u4e49\u200b\u4ee3\u7801\u200b\u7684\u200b\u914d\u7f6e\u200b\u3001\u200b\u6a21\u578b\u200b\u6216\u200b\u5206\u8bcd\u5668\u200b\u6587\u4ef6\u200b\u3002\u200b\u6240\u6709\u200b\u4e0a\u200b\u4f20\u5230\u200b Hub \u200b\u7684\u200b\u6587\u4ef6\u200b\u548c\u200b\u4ee3\u7801\u200b\u90fd\u200b\u4f1a\u200b\u8fdb\u884c\u200b\u6076\u610f\u8f6f\u4ef6\u200b\u626b\u63cf\u200b\uff08\u200b\u6709\u5173\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b Hub \u200b\u5b89\u5168\u200b \u200b\u6587\u6863\u200b\uff09, \u200b\u4f46\u200b\u4f60\u200b\u4ecd\u200b\u5e94\u200b\u67e5\u770b\u200b\u6a21\u578b\u200b\u4ee3\u7801\u200b\u548c\u200b\u4f5c\u8005\u200b\uff0c\u200b\u4ee5\u200b\u907f\u514d\u200b\u5728\u200b\u4f60\u200b\u7684\u200b\u8ba1\u7b97\u673a\u200b\u4e0a\u200b\u6267\u884c\u200b\u6076\u610f\u4ee3\u7801\u200b\u3002 \u200b\u8bbe\u7f6e\u200b <code>trust_remote_code=True</code> \u200b\u4ee5\u200b\u4f7f\u7528\u200b\u5e26\u6709\u200b\u81ea\u5b9a\u4e49\u200b\u4ee3\u7801\u200b\u7684\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>from transformers import AutoModelForImageClassification\n\nmodel = AutoModelForImageClassification.from_pretrained(\"sgugger/custom-resnet50d\", trust_remote_code=True)\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u5f3a\u70c8\u5efa\u8bae\u200b\u4e3a\u200b <code>revision</code> \u200b\u53c2\u6570\u4f20\u9012\u200b\u63d0\u4ea4\u200b\u54c8\u5e0c\u200b\uff08commit hash\uff09\uff0c\u200b\u4ee5\u200b\u786e\u4fdd\u200b\u6a21\u578b\u200b\u7684\u200b\u4f5c\u8005\u200b\u6ca1\u6709\u200b\u4f7f\u7528\u200b\u4e00\u4e9b\u200b\u6076\u610f\u200b\u7684\u200b\u4ee3\u7801\u200b\u884c\u200b\u66f4\u65b0\u200b\u4e86\u200b\u4ee3\u7801\u200b\uff08\u200b\u9664\u975e\u200b\u60a8\u200b\u5b8c\u5168\u200b\u4fe1\u4efb\u200b\u6a21\u578b\u200b\u7684\u200b\u4f5c\u8005\u200b\uff09\u3002</p> <pre><code>commit_hash = \"ed94a7c6247d8aedce4647f00f20de6875b5b292\"\nmodel = AutoModelForImageClassification.from_pretrained(\n    \"sgugger/custom-resnet50d\", trust_remote_code=True, revision=commit_hash\n)\n</code></pre> <p>\u200b\u5728\u200b Hub \u200b\u4e0a\u200b\u6d4f\u89c8\u200b\u6a21\u578b\u200b\u4ed3\u5e93\u200b\u7684\u200b\u63d0\u4ea4\u200b\u5386\u53f2\u200b\u65f6\u200b\uff0c\u200b\u6709\u200b\u4e00\u4e2a\u200b\u6309\u94ae\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u590d\u5236\u200b\u4efb\u4f55\u200b\u63d0\u4ea4\u200b\u7684\u200b\u63d0\u4ea4\u200b\u54c8\u5e0c\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/custom_models/#_5","title":"\u5c06\u200b\u81ea\u5b9a\u4e49\u200b\u4ee3\u7801\u200b\u7684\u200b\u6a21\u578b\u200b\u6ce8\u518c\u200b\u5230\u200b\u81ea\u52a8\u200b\u7c7b","text":"<p>\u200b\u5982\u679c\u200b\u4f60\u200b\u5728\u200b\u7f16\u5199\u200b\u4e00\u4e2a\u200b\u6269\u5c55\u200b \ud83e\udd17 Transformers \u200b\u7684\u200b\u5e93\u200b\uff0c\u200b\u4f60\u200b\u53ef\u80fd\u200b\u60f3\u8981\u200b\u6269\u5c55\u200b\u81ea\u52a8\u200b\u7c7b\u4ee5\u200b\u5305\u542b\u200b\u60a8\u200b\u81ea\u5df1\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u8fd9\u200b\u4e0e\u200b\u5c06\u200b\u4ee3\u7801\u200b\u63a8\u9001\u200b\u5230\u200b Hub \u200b\u4e0d\u540c\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u7528\u6237\u200b\u9700\u8981\u200b\u5bfc\u5165\u200b\u4f60\u200b\u7684\u200b\u5e93\u200b\u624d\u80fd\u200b\u83b7\u53d6\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\uff08\u200b\u4e0e\u200b\u4ece\u200b Hub \u200b\u81ea\u52a8\u200b\u4e0b\u8f7d\u200b\u6a21\u578b\u200b\u4ee3\u7801\u200b\u76f8\u53cd\u200b\uff09\u3002</p> <p>\u200b\u53ea\u8981\u200b\u4f60\u200b\u7684\u200b\u914d\u7f6e\u200b <code>model_type</code> \u200b\u5c5e\u6027\u200b\u4e0e\u200b\u73b0\u6709\u200b\u6a21\u578b\u200b\u7c7b\u578b\u200b\u4e0d\u540c\u200b\uff0c\u200b\u5e76\u4e14\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u7c7b\u6709\u200b\u6b63\u786e\u200b\u7684\u200b <code>config_class</code> \u200b\u5c5e\u6027\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u50cf\u200b\u8fd9\u6837\u200b\u5c06\u200b\u5b83\u4eec\u200b\u6dfb\u52a0\u200b\u5230\u200b\u81ea\u52a8\u200b\u7c7b\u4e2d\u200b\uff1a</p> <pre><code>from transformers import AutoConfig, AutoModel, AutoModelForImageClassification\n\nAutoConfig.register(\"resnet\", ResnetConfig)\nAutoModel.register(ResnetConfig, ResnetModel)\nAutoModelForImageClassification.register(ResnetConfig, ResnetModelForImageClassification)\n</code></pre> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u5c06\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u200b\u6ce8\u518c\u200b\u5230\u200b [<code>AutoConfig</code>] \u200b\u65f6\u200b\uff0c\u200b\u4f7f\u7528\u200b\u7684\u200b\u7b2c\u4e00\u4e2a\u200b\u53c2\u6570\u200b\u9700\u8981\u200b\u4e0e\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u200b\u7684\u200b <code>model_type</code> \u200b\u5339\u914d\u200b\uff1b\u200b\u800c\u200b\u5c06\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u6ce8\u518c\u200b\u5230\u200b\u4efb\u4f55\u200b\u81ea\u52a8\u200b\u6a21\u578b\u200b\u7c7b\u65f6\u200b\uff0c\u200b\u4f7f\u7528\u200b\u7684\u200b\u7b2c\u4e00\u4e2a\u200b\u53c2\u6570\u200b\u9700\u8981\u200b\u4e0e\u200b <code>config_class</code> \u200b\u5339\u914d\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/fast_tokenizers/","title":"Fast tokenizers","text":""},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/fast_tokenizers/#tokenizers","title":"\u4f7f\u7528\u200b \ud83e\udd17 Tokenizers \u200b\u4e2d\u200b\u7684\u200b\u5206\u8bcd\u5668","text":"<p>[<code>PreTrainedTokenizerFast</code>] \u200b\u4f9d\u8d56\u4e8e\u200b \ud83e\udd17 Tokenizers \u200b\u5e93\u200b\u3002\u200b\u4ece\u200b \ud83e\udd17 Tokenizers \u200b\u5e93\u200b\u83b7\u5f97\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u8f7b\u677e\u200b\u5730\u200b\u52a0\u8f7d\u200b\u5230\u200b \ud83e\udd17 Transformers \u200b\u4e2d\u200b\u3002</p> <p>\u200b\u5728\u200b\u4e86\u89e3\u200b\u5177\u4f53\u5185\u5bb9\u200b\u4e4b\u524d\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5148\u200b\u7528\u200b\u51e0\u884c\u200b\u4ee3\u7801\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u865a\u62df\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from tokenizers import Tokenizer\n&gt;&gt;&gt; from tokenizers.models import BPE\n&gt;&gt;&gt; from tokenizers.trainers import BpeTrainer\n&gt;&gt;&gt; from tokenizers.pre_tokenizers import Whitespace\n\n&gt;&gt;&gt; tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n&gt;&gt;&gt; trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n\n&gt;&gt;&gt; tokenizer.pre_tokenizer = Whitespace()\n&gt;&gt;&gt; files = [...]\n&gt;&gt;&gt; tokenizer.train(files, trainer)\n</code></pre> <p>\u200b\u73b0\u5728\u200b\uff0c\u200b\u6211\u4eec\u200b\u62e5\u6709\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u9488\u5bf9\u200b\u6211\u4eec\u200b\u5b9a\u4e49\u200b\u7684\u200b\u6587\u4ef6\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\u3002\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5f53\u524d\u200b\u8fd0\u884c\u200b\u65f6\u4e2d\u200b\u7ee7\u7eed\u200b\u4f7f\u7528\u200b\u5b83\u200b\uff0c\u200b\u6216\u8005\u200b\u5c06\u200b\u5176\u200b\u4fdd\u5b58\u200b\u5230\u200b\u4e00\u4e2a\u200b JSON \u200b\u6587\u4ef6\u200b\u4ee5\u4f9b\u200b\u5c06\u6765\u200b\u91cd\u590d\u4f7f\u7528\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/fast_tokenizers/#_1","title":"\u76f4\u63a5\u200b\u4ece\u200b\u5206\u8bcd\u5668\u200b\u5bf9\u8c61\u200b\u52a0\u8f7d","text":"<p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u770b\u770b\u200b\u5982\u4f55\u200b\u5229\u7528\u200b \ud83e\udd17 Transformers \u200b\u5e93\u4e2d\u200b\u7684\u200b\u8fd9\u4e2a\u200b\u5206\u8bcd\u5668\u200b\u5bf9\u8c61\u200b\u3002[<code>PreTrainedTokenizerFast</code>] \u200b\u7c7b\u200b\u5141\u8bb8\u200b\u901a\u8fc7\u200b\u63a5\u53d7\u200b\u5df2\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u7684\u200b tokenizer \u200b\u5bf9\u8c61\u200b\u4f5c\u4e3a\u200b\u53c2\u6570\u200b\uff0c\u200b\u8fdb\u884c\u200b\u8f7b\u677e\u200b\u5b9e\u4f8b\u200b\u5316\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import PreTrainedTokenizerFast\n\n&gt;&gt;&gt; fast_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u4f7f\u7528\u200b \ud83e\udd17 Transformers \u200b\u5206\u8bcd\u5668\u200b\u5171\u4eab\u200b\u7684\u200b\u6240\u6709\u200b\u65b9\u6cd5\u200b\uff01\u200b\u524d\u5f80\u200b\u5206\u8bcd\u5668\u200b\u9875\u9762\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/fast_tokenizers/#json","title":"\u4ece\u200b JSON \u200b\u6587\u4ef6\u200b\u52a0\u8f7d","text":"<p>\u200b\u4e3a\u4e86\u200b\u4ece\u200b JSON \u200b\u6587\u4ef6\u200b\u4e2d\u200b\u52a0\u8f7d\u200b\u5206\u8bcd\u5668\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5148\u200b\u4fdd\u5b58\u200b\u6211\u4eec\u200b\u7684\u200b\u5206\u8bcd\u5668\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; tokenizer.save(\"tokenizer.json\")\n</code></pre> <p>\u200b\u6211\u4eec\u200b\u4fdd\u5b58\u200b\u6b64\u200b\u6587\u4ef6\u200b\u7684\u200b\u8def\u5f84\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b <code>tokenizer_file</code> \u200b\u53c2\u6570\u4f20\u9012\u200b\u7ed9\u200b [<code>PreTrainedTokenizerFast</code>] \u200b\u521d\u59cb\u5316\u200b\u65b9\u6cd5\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import PreTrainedTokenizerFast\n\n&gt;&gt;&gt; fast_tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"tokenizer.json\")\n</code></pre> <p>\u200b\u73b0\u5728\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u4f7f\u7528\u200b \ud83e\udd17 Transformers \u200b\u5206\u8bcd\u5668\u200b\u5171\u4eab\u200b\u7684\u200b\u6240\u6709\u200b\u65b9\u6cd5\u200b\uff01\u200b\u524d\u5f80\u200b\u5206\u8bcd\u5668\u200b\u9875\u9762\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/multilingual/","title":"Multilingual","text":""},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/multilingual/#_1","title":"\u7528\u4e8e\u200b\u63a8\u7406\u200b\u7684\u200b\u591a\u200b\u8bed\u8a00\u200b\u6a21\u578b","text":"<p>[[open-in-colab]]</p> <p>\ud83e\udd17 Transformers \u200b\u4e2d\u6709\u200b\u591a\u79cd\u200b\u591a\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u5b83\u4eec\u200b\u7684\u200b\u63a8\u7406\u200b\u7528\u6cd5\u200b\u4e0e\u200b\u5355\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u4e0d\u540c\u200b\u3002\u200b\u4f46\u662f\u200b\uff0c\u200b\u5e76\u975e\u200b\u6240\u6709\u200b\u7684\u200b\u591a\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u7528\u6cd5\u200b\u90fd\u200b\u4e0d\u540c\u200b\u3002\u200b\u4e00\u4e9b\u200b\u6a21\u578b\u200b\uff0c\u200b\u4f8b\u5982\u200b bert-base-multilingual-uncased \u200b\u5c31\u200b\u53ef\u4ee5\u200b\u50cf\u200b\u5355\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u4e00\u6837\u200b\u4f7f\u7528\u200b\u3002\u200b\u672c\u200b\u6307\u5357\u200b\u5c06\u200b\u5411\u200b\u60a8\u200b\u5c55\u793a\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u4e0d\u540c\u200b\u7528\u9014\u200b\u7684\u200b\u591a\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/multilingual/#xlm","title":"XLM","text":"<p>XLM \u200b\u6709\u200b\u5341\u4e2a\u200b\u4e0d\u540c\u200b\u7684\u200b\u68c0\u67e5\u70b9\u200b\uff0c\u200b\u5176\u4e2d\u200b\u53ea\u6709\u200b\u4e00\u4e2a\u200b\u662f\u200b\u5355\u200b\u8bed\u8a00\u200b\u7684\u200b\u3002\u200b\u5269\u4e0b\u200b\u7684\u200b\u4e5d\u4e2a\u200b\u68c0\u67e5\u70b9\u200b\u53ef\u4ee5\u200b\u5f52\u4e3a\u200b\u4e24\u7c7b\u200b\uff1a\u200b\u4f7f\u7528\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u7684\u200b\u68c0\u67e5\u70b9\u200b\u548c\u200b\u4e0d\u200b\u4f7f\u7528\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u7684\u200b\u68c0\u67e5\u70b9\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/multilingual/#xlm_1","title":"\u5e26\u6709\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u7684\u200b XLM","text":"<p>\u200b\u4ee5\u4e0b\u200b XLM \u200b\u6a21\u578b\u200b\u4f7f\u7528\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u6765\u200b\u6307\u5b9a\u200b\u63a8\u7406\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u7684\u200b\u8bed\u8a00\u200b\uff1a</p> <ul> <li><code>xlm-mlm-ende-1024</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0c\u200b\u82f1\u8bed\u200b-\u200b\u5fb7\u8bed\u200b\uff09</li> <li><code>xlm-mlm-enfr-1024</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0c\u200b\u82f1\u8bed\u200b-\u200b\u6cd5\u8bed\u200b\uff09</li> <li><code>xlm-mlm-enro-1024</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0c\u200b\u82f1\u8bed\u200b-\u200b\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u200b\uff09</li> <li><code>xlm-mlm-xnli15-1024</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0cXNLI \u200b\u6570\u636e\u200b\u96c6\u200b\u8bed\u8a00\u200b\uff09</li> <li><code>xlm-mlm-tlm-xnli15-1024</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b+\u200b\u7ffb\u8bd1\u200b\uff0cXNLI \u200b\u6570\u636e\u200b\u96c6\u200b\u8bed\u8a00\u200b\uff09</li> <li><code>xlm-clm-enfr-1024</code> \uff08\u200b\u56e0\u679c\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0c\u200b\u82f1\u8bed\u200b-\u200b\u6cd5\u8bed\u200b\uff09</li> <li><code>xlm-clm-ende-1024</code> \uff08\u200b\u56e0\u679c\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0c\u200b\u82f1\u8bed\u200b-\u200b\u5fb7\u8bed\u200b\uff09</li> </ul> <p>\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u88ab\u200b\u8868\u793a\u200b\u4e00\u4e2a\u200b\u5f20\u91cf\u200b\uff0c\u200b\u5176\u200b\u5f62\u72b6\u200b\u4e0e\u200b\u4f20\u9012\u200b\u7ed9\u200b\u6a21\u578b\u200b\u7684\u200b <code>input_ids</code> \u200b\u76f8\u540c\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u5f20\u91cf\u200b\u4e2d\u200b\u7684\u200b\u503c\u200b\u53d6\u51b3\u4e8e\u200b\u6240\u200b\u4f7f\u7528\u200b\u7684\u200b\u8bed\u8a00\u200b\uff0c\u200b\u5e76\u200b\u7531\u200b\u5206\u8bcd\u5668\u200b\u7684\u200b <code>lang2id</code> \u200b\u548c\u200b <code>id2lang</code>  \u200b\u5c5e\u6027\u200b\u8bc6\u522b\u200b\u3002</p> <p>\u200b\u5728\u200b\u6b64\u200b\u793a\u4f8b\u200b\u4e2d\u200b\uff0c\u200b\u52a0\u8f7d\u200b <code>xlm-clm-enfr-1024</code> \u200b\u68c0\u67e5\u70b9\u200b\uff08\u200b\u56e0\u679c\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0c\u200b\u82f1\u8bed\u200b-\u200b\u6cd5\u8bed\u200b\uff09\uff1a</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from transformers import XLMTokenizer, XLMWithLMHeadModel\n\n&gt;&gt;&gt; tokenizer = XLMTokenizer.from_pretrained(\"xlm-clm-enfr-1024\")\n&gt;&gt;&gt; model = XLMWithLMHeadModel.from_pretrained(\"xlm-clm-enfr-1024\")\n</code></pre> <p>\u200b\u5206\u8bcd\u5668\u200b\u7684\u200b <code>lang2id</code> \u200b\u5c5e\u6027\u200b\u663e\u793a\u200b\u4e86\u200b\u8be5\u200b\u6a21\u578b\u200b\u7684\u200b\u8bed\u8a00\u200b\u53ca\u5176\u200b\u5bf9\u5e94\u200b\u7684\u200bid\uff1a</p> <pre><code>&gt;&gt;&gt; print(tokenizer.lang2id)\n{'en': 0, 'fr': 1}\n</code></pre> <p>\u200b\u63a5\u4e0b\u6765\u200b\uff0c\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u793a\u4f8b\u200b\u8f93\u5165\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; input_ids = torch.tensor([tokenizer.encode(\"Wikipedia was used to\")])  # batch size \u200b\u4e3a\u200b 1\n</code></pre> <p>\u200b\u5c06\u200b\u8bed\u8a00\u200b id \u200b\u8bbe\u7f6e\u200b\u4e3a\u200b <code>\"en\"</code> \u200b\u5e76\u7528\u200b\u5176\u200b\u5b9a\u4e49\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u3002\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u662f\u200b\u4e00\u4e2a\u200b\u7528\u200b <code>0</code> \u200b\u586b\u5145\u200b\u7684\u200b\u5f20\u91cf\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u5f20\u91cf\u200b\u5e94\u8be5\u200b\u4e0e\u200b <code>input_ids</code> \u200b\u5927\u5c0f\u200b\u76f8\u540c\u200b\u3002</p> <pre><code>&gt;&gt;&gt; language_id = tokenizer.lang2id[\"en\"]  # 0\n&gt;&gt;&gt; langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])\n\n&gt;&gt;&gt; # \u200b\u6211\u4eec\u200b\u5c06\u200b\u5176\u200b reshape \u200b\u4e3a\u200b (batch_size, sequence_length) \u200b\u5927\u5c0f\u200b\n&gt;&gt;&gt; langs = langs.view(1, -1)  # \u200b\u73b0\u5728\u200b\u7684\u200b\u5f62\u72b6\u200b\u662f\u200b [1, sequence_length] (\u200b\u6211\u4eec\u200b\u7684\u200b batch size \u200b\u4e3a\u200b 1)\n</code></pre> <p>\u200b\u73b0\u5728\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5c06\u200b <code>input_ids</code> \u200b\u548c\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u4f20\u9012\u200b\u7ed9\u200b\u6a21\u578b\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; outputs = model(input_ids, langs=langs)\n</code></pre> <p>run_generation.py \u200b\u811a\u672c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>xlm-clm</code> \u200b\u68c0\u67e5\u70b9\u200b\u751f\u6210\u200b\u5e26\u6709\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u7684\u200b\u6587\u672c\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/multilingual/#xlm_2","title":"\u4e0d\u5e26\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u7684\u200b XLM","text":"<p>\u200b\u4ee5\u4e0b\u200b XLM \u200b\u6a21\u578b\u200b\u5728\u200b\u63a8\u7406\u200b\u65f6\u200b\u4e0d\u200b\u9700\u8981\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\uff1a</p> <ul> <li><code>xlm-mlm-17-1280</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0c\u200b\u652f\u6301\u200b 17 \u200b\u79cd\u200b\u8bed\u8a00\u200b\uff09</li> <li><code>xlm-mlm-100-1280</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0c\u200b\u652f\u6301\u200b 100 \u200b\u79cd\u200b\u8bed\u8a00\u200b\uff09</li> </ul> <p>\u200b\u4e0e\u200b\u4e4b\u524d\u200b\u7684\u200b XLM \u200b\u68c0\u67e5\u70b9\u200b\u4e0d\u540c\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u6a21\u578b\u200b\u7528\u4e8e\u200b\u901a\u7528\u200b\u53e5\u5b50\u200b\u8868\u793a\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/multilingual/#bert","title":"BERT","text":"<p>\u200b\u4ee5\u4e0b\u200b BERT \u200b\u6a21\u578b\u200b\u53ef\u200b\u7528\u4e8e\u200b\u591a\u200b\u8bed\u8a00\u200b\u4efb\u52a1\u200b\uff1a</p> <ul> <li><code>bert-base-multilingual-uncased</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b + \u200b\u4e0b\u200b\u4e00\u53e5\u200b\u9884\u6d4b\u200b\uff0c\u200b\u652f\u6301\u200b 102 \u200b\u79cd\u200b\u8bed\u8a00\u200b\uff09</li> <li><code>bert-base-multilingual-cased</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b + \u200b\u4e0b\u200b\u4e00\u53e5\u200b\u9884\u6d4b\u200b\uff0c\u200b\u652f\u6301\u200b 104 \u200b\u79cd\u200b\u8bed\u8a00\u200b\uff09</li> </ul> <p>\u200b\u8fd9\u4e9b\u200b\u6a21\u578b\u200b\u5728\u200b\u63a8\u7406\u200b\u65f6\u200b\u4e0d\u200b\u9700\u8981\u200b\u8bed\u8a00\u200b\u5d4c\u5165\u200b\u3002\u200b\u5b83\u4eec\u200b\u5e94\u8be5\u200b\u80fd\u591f\u200b\u4ece\u200b\u4e0a\u4e0b\u6587\u200b\u4e2d\u200b\u8bc6\u522b\u200b\u8bed\u8a00\u200b\u5e76\u200b\u8fdb\u884c\u200b\u76f8\u5e94\u200b\u7684\u200b\u63a8\u7406\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/multilingual/#xlm-roberta","title":"XLM-RoBERTa","text":"<p>\u200b\u4ee5\u4e0b\u200b XLM-RoBERTa \u200b\u6a21\u578b\u200b\u53ef\u200b\u7528\u4e8e\u200b\u591a\u200b\u8bed\u8a00\u200b\u4efb\u52a1\u200b\uff1a</p> <ul> <li><code>xlm-roberta-base</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0c\u200b\u652f\u6301\u200b 100 \u200b\u79cd\u200b\u8bed\u8a00\u200b\uff09</li> <li><code>xlm-roberta-large</code> \uff08\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u5efa\u6a21\u200b\uff0c\u200b\u652f\u6301\u200b 100 \u200b\u79cd\u200b\u8bed\u8a00\u200b\uff09</li> </ul> <p>XLM-RoBERTa \u200b\u4f7f\u7528\u200b 100 \u200b\u79cd\u200b\u8bed\u8a00\u200b\u7684\u200b 2.5TB \u200b\u65b0\u521b\u5efa\u200b\u548c\u200b\u6e05\u7406\u200b\u7684\u200b CommonCrawl \u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u4e86\u200b\u8bad\u7ec3\u200b\u3002\u200b\u4e0e\u200b\u4e4b\u524d\u200b\u53d1\u5e03\u200b\u7684\u200b mBERT \u200b\u6216\u200b XLM \u200b\u7b49\u200b\u591a\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u76f8\u6bd4\u200b\uff0c\u200b\u5b83\u200b\u5728\u200b\u5206\u7c7b\u200b\u3001\u200b\u5e8f\u5217\u200b\u6807\u8bb0\u200b\u548c\u200b\u95ee\u7b54\u200b\u7b49\u200b\u4e0b\u6e38\u200b\u4efb\u52a1\u200b\u4e0a\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u66f4\u200b\u5f3a\u5927\u200b\u7684\u200b\u4f18\u52bf\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/multilingual/#m2m100","title":"M2M100","text":"<p>\u200b\u4ee5\u4e0b\u200b M2M100 \u200b\u6a21\u578b\u200b\u53ef\u200b\u7528\u4e8e\u200b\u591a\u200b\u8bed\u8a00\u200b\u7ffb\u8bd1\u200b\uff1a</p> <ul> <li><code>facebook/m2m100_418M</code> \uff08\u200b\u7ffb\u8bd1\u200b\uff09</li> <li><code>facebook/m2m100_1.2B</code> \uff08\u200b\u7ffb\u8bd1\u200b\uff09</li> </ul> <p>\u200b\u5728\u200b\u6b64\u200b\u793a\u4f8b\u200b\u4e2d\u200b\uff0c\u200b\u52a0\u8f7d\u200b <code>facebook/m2m100_418M</code> \u200b\u68c0\u67e5\u70b9\u200b\u4ee5\u200b\u5c06\u200b\u4e2d\u6587\u7ffb\u8bd1\u200b\u4e3a\u200b\u82f1\u6587\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5206\u8bcd\u5668\u200b\u4e2d\u200b\u8bbe\u7f6e\u200b\u6e90\u8bed\u8a00\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n\n&gt;&gt;&gt; en_text = \"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\"\n&gt;&gt;&gt; chinese_text = \"\u200b\u4e0d\u8981\u200b\u63d2\u624b\u200b\u5deb\u5e2b\u200b\u7684\u200b\u4e8b\u52d9\u200b, \u200b\u56e0\u70ba\u200b\u4ed6\u5011\u200b\u662f\u200b\u5fae\u5999\u200b\u7684\u200b, \u200b\u5f88\u5feb\u200b\u5c31\u6703\u200b\u767c\u6012\u200b.\"\n\n&gt;&gt;&gt; tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\", src_lang=\"zh\")\n&gt;&gt;&gt; model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n</code></pre> <p>\u200b\u5bf9\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; encoded_zh = tokenizer(chinese_text, return_tensors=\"pt\")\n</code></pre> <p>M2M100 \u200b\u5f3a\u5236\u200b\u5c06\u200b\u76ee\u6807\u8bed\u8a00\u200b id \u200b\u4f5c\u4e3a\u200b\u7b2c\u4e00\u4e2a\u200b\u751f\u6210\u200b\u7684\u200b\u6807\u8bb0\u200b\uff0c\u200b\u4ee5\u200b\u8fdb\u884c\u200b\u5230\u200b\u76ee\u6807\u8bed\u8a00\u200b\u7684\u200b\u7ffb\u8bd1\u200b\u3002\u200b\u5728\u200b <code>generate</code> \u200b\u65b9\u6cd5\u200b\u4e2d\u5c06\u200b <code>forced_bos_token_id</code> \u200b\u8bbe\u7f6e\u200b\u4e3a\u200b <code>en</code> \u200b\u4ee5\u200b\u7ffb\u8bd1\u6210\u200b\u82f1\u8bed\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n&gt;&gt;&gt; tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n'Do not interfere with the matters of the witches, because they are delicate and will soon be angry.'\n</code></pre>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/multilingual/#mbart","title":"MBart","text":"<p>\u200b\u4ee5\u4e0b\u200b MBart \u200b\u6a21\u578b\u200b\u53ef\u200b\u7528\u4e8e\u200b\u591a\u200b\u8bed\u8a00\u200b\u7ffb\u8bd1\u200b\uff1a</p> <ul> <li><code>facebook/mbart-large-50-one-to-many-mmt</code> \uff08\u200b\u4e00\u5bf9\u200b\u591a\u591a\u200b\u8bed\u8a00\u200b\u673a\u5668\u7ffb\u8bd1\u200b\uff0c\u200b\u652f\u6301\u200b 50 \u200b\u79cd\u200b\u8bed\u8a00\u200b\uff09</li> <li><code>facebook/mbart-large-50-many-to-many-mmt</code> \uff08\u200b\u591a\u200b\u5bf9\u200b\u591a\u591a\u200b\u8bed\u8a00\u200b\u673a\u5668\u7ffb\u8bd1\u200b\uff0c\u200b\u652f\u6301\u200b 50 \u200b\u79cd\u200b\u8bed\u8a00\u200b\uff09</li> <li><code>facebook/mbart-large-50-many-to-one-mmt</code> \uff08\u200b\u591a\u200b\u5bf9\u200b\u4e00\u591a\u200b\u8bed\u8a00\u200b\u673a\u5668\u7ffb\u8bd1\u200b\uff0c\u200b\u652f\u6301\u200b 50 \u200b\u79cd\u200b\u8bed\u8a00\u200b\uff09</li> <li><code>facebook/mbart-large-50</code> \uff08\u200b\u591a\u200b\u8bed\u8a00\u200b\u7ffb\u8bd1\u200b\uff0c\u200b\u652f\u6301\u200b 50 \u200b\u79cd\u200b\u8bed\u8a00\u200b\uff09</li> <li><code>facebook/mbart-large-cc25</code></li> </ul> <p>\u200b\u5728\u200b\u6b64\u200b\u793a\u4f8b\u200b\u4e2d\u200b\uff0c\u200b\u52a0\u8f7d\u200b  <code>facebook/mbart-large-50-many-to-many-mmt</code> \u200b\u68c0\u67e5\u70b9\u200b\u4ee5\u200b\u5c06\u200b\u82ac\u5170\u8bed\u200b\u7ffb\u8bd1\u200b\u4e3a\u200b\u82f1\u8bed\u200b\u3002 \u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5206\u8bcd\u5668\u200b\u4e2d\u200b\u8bbe\u7f6e\u200b\u6e90\u8bed\u8a00\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n&gt;&gt;&gt; en_text = \"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\"\n&gt;&gt;&gt; fi_text = \"\u00c4l\u00e4 sekaannu velhojen asioihin, sill\u00e4 ne ovat hienovaraisia ja nopeasti vihaisia.\"\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\", src_lang=\"fi_FI\")\n&gt;&gt;&gt; model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n</code></pre> <p>\u200b\u5bf9\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; encoded_en = tokenizer(en_text, return_tensors=\"pt\")\n</code></pre> <p>MBart \u200b\u5f3a\u5236\u200b\u5c06\u200b\u76ee\u6807\u8bed\u8a00\u200b id \u200b\u4f5c\u4e3a\u200b\u7b2c\u4e00\u4e2a\u200b\u751f\u6210\u200b\u7684\u200b\u6807\u8bb0\u200b\uff0c\u200b\u4ee5\u200b\u8fdb\u884c\u200b\u5230\u200b\u76ee\u6807\u8bed\u8a00\u200b\u7684\u200b\u7ffb\u8bd1\u200b\u3002\u200b\u5728\u200b <code>generate</code> \u200b\u65b9\u6cd5\u200b\u4e2d\u5c06\u200b <code>forced_bos_token_id</code> \u200b\u8bbe\u7f6e\u200b\u4e3a\u200b <code>en</code> \u200b\u4ee5\u200b\u7ffb\u8bd1\u6210\u200b\u82f1\u8bed\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"])\n&gt;&gt;&gt; tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n\"Don't interfere with the wizard's affairs, because they are subtle, will soon get angry.\"\n</code></pre> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u4f7f\u7528\u200b\u7684\u200b\u662f\u200b <code>facebook/mbart-large-50-many-to-one-mmt</code> \u200b\u68c0\u67e5\u70b9\u200b\uff0c\u200b\u5219\u200b\u65e0\u9700\u200b\u5f3a\u5236\u200b\u76ee\u6807\u8bed\u8a00\u200b id \u200b\u4f5c\u4e3a\u200b\u7b2c\u4e00\u4e2a\u200b\u751f\u6210\u200b\u7684\u200b\u4ee4\u724c\u200b\uff0c\u200b\u5426\u5219\u200b\u7528\u6cd5\u200b\u662f\u200b\u76f8\u540c\u200b\u7684\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/serialization/","title":"Serialization","text":""},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/serialization/#onnx","title":"\u5bfc\u51fa\u200b\u4e3a\u200b ONNX","text":"<p>\u200b\u5728\u200b\u751f\u4ea7\u200b\u73af\u5883\u200b\u4e2d\u200b\u90e8\u7f72\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u901a\u5e38\u200b\u9700\u8981\u200b\u6216\u8005\u200b\u80fd\u591f\u200b\u53d7\u76ca\u200b\u4e8e\u200b\uff0c\u200b\u5c06\u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u4e3a\u200b\u53ef\u200b\u5728\u200b\u4e13\u95e8\u200b\u7684\u200b\u8fd0\u884c\u200b\u65f6\u200b\u548c\u200b\u786c\u4ef6\u200b\u4e0a\u200b\u52a0\u8f7d\u200b\u548c\u200b\u6267\u884c\u200b\u7684\u200b\u5e8f\u5217\u5316\u200b\u683c\u5f0f\u200b\u3002</p> <p>\ud83e\udd17 Optimum \u200b\u662f\u200b Transformers \u200b\u7684\u200b\u6269\u5c55\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5176\u200b <code>exporters</code> \u200b\u6a21\u5757\u200b\u5c06\u200b\u6a21\u578b\u200b\u4ece\u200b PyTorch \u200b\u6216\u200b TensorFlow \u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX \u200b\u53ca\u200b TFLite \u200b\u7b49\u200b\u5e8f\u5217\u5316\u200b\u683c\u5f0f\u200b\u3002\ud83e\udd17 Optimum \u200b\u8fd8\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u5957\u200b\u6027\u80fd\u200b\u4f18\u5316\u200b\u5de5\u5177\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5728\u200b\u76ee\u6807\u200b\u786c\u4ef6\u200b\u4e0a\u4ee5\u200b\u6700\u9ad8\u200b\u6548\u7387\u200b\u8bad\u7ec3\u200b\u548c\u200b\u8fd0\u884c\u200b\u6a21\u578b\u200b\u3002</p> <p>\u200b\u672c\u200b\u6307\u5357\u200b\u6f14\u793a\u200b\u4e86\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b \ud83e\udd17 Optimum \u200b\u5c06\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX\u3002\u200b\u6709\u5173\u200b\u5c06\u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u4e3a\u200b TFLite \u200b\u7684\u200b\u6307\u5357\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u8003\u200b \u200b\u5bfc\u51fa\u200b\u4e3a\u200b TFLite \u200b\u9875\u9762\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/serialization/#onnx_1","title":"\u5bfc\u51fa\u200b\u4e3a\u200b ONNX","text":"<p>ONNX (Open Neural Network eXchange \u200b\u5f00\u653e\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u4ea4\u6362\u200b) \u200b\u662f\u200b\u4e00\u4e2a\u200b\u5f00\u653e\u200b\u7684\u200b\u6807\u51c6\u200b\uff0c\u200b\u5b83\u200b\u5b9a\u4e49\u200b\u4e86\u200b\u4e00\u7ec4\u200b\u901a\u7528\u200b\u7684\u200b\u8fd0\u7b97\u7b26\u200b\u548c\u200b\u4e00\u79cd\u200b\u901a\u7528\u200b\u7684\u200b\u6587\u4ef6\u683c\u5f0f\u200b\uff0c\u200b\u7528\u4e8e\u200b\u8868\u793a\u200b\u5305\u62ec\u200b PyTorch \u200b\u548c\u200b TensorFlow \u200b\u5728\u5185\u200b\u7684\u200b\u5404\u79cd\u200b\u6846\u67b6\u200b\u4e2d\u200b\u7684\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\u3002\u200b\u5f53\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u88ab\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX\u200b\u65f6\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u8fd0\u7b97\u7b26\u200b\u88ab\u200b\u7528\u4e8e\u200b\u6784\u5efa\u200b\u8ba1\u7b97\u200b\u56fe\u200b\uff08\u200b\u901a\u5e38\u200b\u88ab\u200b\u79f0\u4e3a\u200b\u4e2d\u95f4\u200b\u8868\u793a\u200b\uff09\uff0c\u200b\u8be5\u56fe\u200b\u8868\u793a\u200b\u6570\u636e\u200b\u5728\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u4e2d\u200b\u7684\u200b\u6d41\u52a8\u200b\u3002</p> <p>\u200b\u901a\u8fc7\u200b\u516c\u5f00\u200b\u5177\u6709\u200b\u6807\u51c6\u5316\u200b\u8fd0\u7b97\u7b26\u200b\u548c\u200b\u6570\u636e\u7c7b\u578b\u200b\u7684\u200b\u56fe\u200b\uff0cONNX\u200b\u4f7f\u5f97\u200b\u6a21\u578b\u200b\u80fd\u591f\u200b\u8f7b\u677e\u200b\u5728\u200b\u4e0d\u540c\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6846\u67b6\u200b\u95f4\u200b\u5207\u6362\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5728\u200b PyTorch \u200b\u4e2d\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX\uff0c\u200b\u7136\u540e\u200b\u518d\u200b\u5bfc\u5165\u5230\u200b TensorFlow\uff08\u200b\u53cd\u4e4b\u4ea6\u7136\u200b\uff09\u3002</p> <p>\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX \u200b\u540e\u200b\uff0c\u200b\u6a21\u578b\u200b\u53ef\u4ee5\u200b\uff1a - \u200b\u901a\u8fc7\u200b \u200b\u56fe\u200b\u4f18\u5316\u200b\uff08graph optimization\uff09 \u200b\u548c\u200b \u200b\u91cf\u5316\u200b\uff08quantization\uff09 \u200b\u7b49\u200b\u6280\u672f\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\u4f18\u5316\u200b\u3002  - \u200b\u901a\u8fc7\u200b <code>ORTModelForXXX</code> \u200b\u7c7b\u200b \u200b\u4f7f\u7528\u200b ONNX Runtime \u200b\u8fd0\u884c\u200b\uff0c\u200b\u5b83\u200b\u540c\u6837\u200b\u9075\u5faa\u200b\u4f60\u200b\u719f\u6089\u200b\u7684\u200b Transformers \u200b\u4e2d\u200b\u7684\u200b <code>AutoModel</code> API\u3002 - \u200b\u4f7f\u7528\u200b \u200b\u4f18\u5316\u200b\u63a8\u7406\u200b\u6d41\u6c34\u7ebf\u200b\uff08pipeline\uff09 \u200b\u8fd0\u884c\u200b\uff0c\u200b\u5176\u200b API \u200b\u4e0e\u200b \ud83e\udd17 Transformers \u200b\u4e2d\u200b\u7684\u200b [<code>pipeline</code>] \u200b\u51fd\u6570\u200b\u76f8\u540c\u200b\u3002</p> <p>\ud83e\udd17 Optimum \u200b\u901a\u8fc7\u200b\u5229\u7528\u200b\u914d\u7f6e\u200b\u5bf9\u8c61\u200b\u63d0\u4f9b\u200b\u5bf9\u200b ONNX \u200b\u5bfc\u51fa\u200b\u7684\u200b\u652f\u6301\u200b\u3002\u200b\u591a\u79cd\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\u5df2\u7ecf\u200b\u6709\u200b\u73b0\u6210\u200b\u7684\u200b\u914d\u7f6e\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u5e76\u4e14\u200b\u914d\u7f6e\u200b\u5bf9\u8c61\u200b\u4e5f\u200b\u88ab\u200b\u8bbe\u8ba1\u200b\u5f97\u200b\u6613\u4e8e\u200b\u6269\u5c55\u200b\u4ee5\u200b\u9002\u7528\u200b\u4e8e\u200b\u5176\u4ed6\u200b\u67b6\u6784\u200b\u3002</p> <p>\u200b\u73b0\u6709\u200b\u7684\u200b\u914d\u7f6e\u200b\u5217\u8868\u200b\u8bf7\u200b\u53c2\u8003\u200b \ud83e\udd17 Optimum \u200b\u6587\u6863\u200b\u3002</p> <p>\u200b\u6709\u200b\u4e24\u79cd\u200b\u65b9\u5f0f\u200b\u53ef\u4ee5\u200b\u5c06\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX\uff0c\u200b\u8fd9\u91cc\u200b\u6211\u4eec\u200b\u5c55\u793a\u200b\u8fd9\u200b\u4e24\u79cd\u200b\u65b9\u6cd5\u200b\uff1a</p> <ul> <li>\u200b\u4f7f\u7528\u200b \ud83e\udd17 Optimum \u200b\u7684\u200b CLI\uff08\u200b\u547d\u4ee4\u884c\u200b\uff09\u200b\u5bfc\u51fa\u200b\u3002</li> <li>\u200b\u4f7f\u7528\u200b \ud83e\udd17 Optimum \u200b\u7684\u200b <code>optimum.onnxruntime</code> \u200b\u6a21\u5757\u200b\u5bfc\u51fa\u200b\u3002</li> </ul>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/serialization/#cli-transformers-onnx","title":"\u4f7f\u7528\u200b CLI \u200b\u5c06\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX","text":"<p>\u200b\u8981\u200b\u5c06\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX\uff0c\u200b\u9996\u5148\u200b\u9700\u8981\u200b\u5b89\u88c5\u200b\u989d\u5916\u200b\u7684\u200b\u4f9d\u8d56\u200b\u9879\u200b\uff1a</p> <pre><code>pip install optimum[exporters]\n</code></pre> <p>\u200b\u8bf7\u53c2\u9605\u200b \ud83e\udd17 Optimum \u200b\u6587\u6863\u200b \u200b\u4ee5\u200b\u67e5\u770b\u200b\u6240\u6709\u200b\u53ef\u7528\u200b\u53c2\u6570\u200b\uff0c\u200b\u6216\u8005\u200b\u5728\u200b\u547d\u4ee4\u884c\u200b\u4e2d\u200b\u67e5\u770b\u200b\u5e2e\u52a9\u200b\uff1a</p> <pre><code>optimum-cli export onnx --help\n</code></pre> <p>\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\uff0c\u200b\u4ee5\u200b\u4ece\u200b \ud83e\udd17 Hub \u200b\u5bfc\u51fa\u200b\u6a21\u578b\u200b\u7684\u200b\u68c0\u67e5\u70b9\u200b\uff08checkpoint\uff09\uff0c\u200b\u4ee5\u200b <code>distilbert-base-uncased-distilled-squad</code> \u200b\u4e3a\u4f8b\u200b\uff1a</p> <pre><code>optimum-cli export onnx --model distilbert-base-uncased-distilled-squad distilbert_base_uncased_squad_onnx/\n</code></pre> <p>\u200b\u4f60\u200b\u5e94\u8be5\u200b\u80fd\u200b\u5728\u200b\u65e5\u5fd7\u200b\u4e2d\u200b\u770b\u5230\u200b\u5bfc\u51fa\u200b\u8fdb\u5ea6\u200b\u4ee5\u53ca\u200b\u751f\u6210\u200b\u7684\u200b <code>model.onnx</code> \u200b\u6587\u4ef6\u200b\u7684\u200b\u4fdd\u5b58\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>Validating ONNX model distilbert_base_uncased_squad_onnx/model.onnx...\n    -[\u2713] ONNX model output names match reference model (start_logits, end_logits)\n    - Validating ONNX Model output \"start_logits\":\n        -[\u2713] (2, 16) matches (2, 16)\n        -[\u2713] all values close (atol: 0.0001)\n    - Validating ONNX Model output \"end_logits\":\n        -[\u2713] (2, 16) matches (2, 16)\n        -[\u2713] all values close (atol: 0.0001)\nThe ONNX export succeeded and the exported model was saved at: distilbert_base_uncased_squad_onnx\n</code></pre> <p>\u200b\u4e0a\u9762\u200b\u7684\u200b\u793a\u4f8b\u200b\u8bf4\u660e\u200b\u4e86\u200b\u4ece\u200b \ud83e\udd17 Hub \u200b\u5bfc\u51fa\u200b\u68c0\u67e5\u70b9\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u3002\u200b\u5bfc\u51fa\u200b\u672c\u5730\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u9996\u5148\u200b\u9700\u8981\u200b\u786e\u4fdd\u200b\u5c06\u200b\u6a21\u578b\u200b\u7684\u200b\u6743\u91cd\u200b\u548c\u200b\u5206\u8bcd\u5668\u200b\u6587\u4ef6\u200b\u4fdd\u5b58\u200b\u5728\u200b\u540c\u4e00\u200b\u76ee\u5f55\u200b\uff08<code>local_path</code>\uff09\u200b\u4e2d\u200b\u3002\u200b\u5728\u200b\u4f7f\u7528\u200b CLI \u200b\u65f6\u200b\uff0c\u200b\u5c06\u200b <code>local_path</code> \u200b\u4f20\u9012\u200b\u7ed9\u200b <code>model</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b \ud83e\udd17 Hub \u200b\u4e0a\u200b\u7684\u200b\u68c0\u67e5\u70b9\u200b\u540d\u79f0\u200b\uff0c\u200b\u5e76\u200b\u63d0\u4f9b\u200b <code>--task</code> \u200b\u53c2\u6570\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200b \ud83e\udd17 Optimum \u200b\u6587\u6863\u200b\u4e2d\u200b\u67e5\u770b\u200b\u652f\u6301\u200b\u7684\u200b\u4efb\u52a1\u200b\u5217\u8868\u200b\u3002\u200b\u5982\u679c\u200b\u672a\u200b\u63d0\u4f9b\u200b <code>task</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u5c06\u200b\u9ed8\u8ba4\u200b\u5bfc\u51fa\u200b\u4e0d\u5e26\u200b\u7279\u5b9a\u200b\u4efb\u52a1\u200b\u5934\u200b\u7684\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\u3002</p> <pre><code>optimum-cli export onnx --model local_path --task question-answering distilbert_base_uncased_squad_onnx/\n</code></pre> <p>\u200b\u751f\u6210\u200b\u7684\u200b <code>model.onnx</code> \u200b\u6587\u4ef6\u200b\u53ef\u4ee5\u200b\u5728\u200b\u652f\u6301\u200b ONNX \u200b\u6807\u51c6\u200b\u7684\u200b \u200b\u8bb8\u591a\u200b\u52a0\u901f\u200b\u5f15\u64ce\u200b\uff08accelerators\uff09 \u200b\u4e4b\u4e00\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b ONNX Runtime \u200b\u52a0\u8f7d\u200b\u548c\u200b\u8fd0\u884c\u200b\u6a21\u578b\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer\n&gt;&gt;&gt; from optimum.onnxruntime import ORTModelForQuestionAnswering\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"distilbert_base_uncased_squad_onnx\")\n&gt;&gt;&gt; model = ORTModelForQuestionAnswering.from_pretrained(\"distilbert_base_uncased_squad_onnx\")\n&gt;&gt;&gt; inputs = tokenizer(\"What am I using?\", \"Using DistilBERT with ONNX Runtime!\", return_tensors=\"pt\")\n&gt;&gt;&gt; outputs = model(**inputs)\n</code></pre> <p>\u200b\u4ece\u200b Hub \u200b\u5bfc\u51fa\u200b TensorFlow \u200b\u68c0\u67e5\u70b9\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u4e5f\u200b\u4e00\u6837\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4ee5\u4e0b\u200b\u662f\u4ece\u200b Keras \u200b\u7ec4\u7ec7\u200b \u200b\u5bfc\u51fa\u200b\u7eaf\u200b TensorFlow \u200b\u68c0\u67e5\u70b9\u200b\u7684\u200b\u547d\u4ee4\u200b\uff1a</p> <pre><code>optimum-cli export onnx --model keras-io/transformers-qa distilbert_base_cased_squad_onnx/\n</code></pre>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/serialization/#optimumonnxruntime-transformers-onnx","title":"\u4f7f\u7528\u200b <code>optimum.onnxruntime</code> \u200b\u5c06\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX","text":"<p>\u200b\u9664\u4e86\u200b CLI \u200b\u4e4b\u5916\u200b\uff0c\u200b\u4f60\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee3\u7801\u200b\u5c06\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from optimum.onnxruntime import ORTModelForSequenceClassification\n&gt;&gt;&gt; from transformers import AutoTokenizer\n\n&gt;&gt;&gt; model_checkpoint = \"distilbert_base_uncased_squad\"\n&gt;&gt;&gt; save_directory = \"onnx/\"\n\n&gt;&gt;&gt; # \u200b\u4ece\u200b transformers \u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX\n&gt;&gt;&gt; ort_model = ORTModelForSequenceClassification.from_pretrained(model_checkpoint, export=True)\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\n&gt;&gt;&gt; # \u200b\u4fdd\u5b58\u200b onnx \u200b\u6a21\u578b\u200b\u4ee5\u53ca\u200b\u5206\u8bcd\u5668\u200b\n&gt;&gt;&gt; ort_model.save_pretrained(save_directory)\n&gt;&gt;&gt; tokenizer.save_pretrained(save_directory)\n</code></pre>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/serialization/#_1","title":"\u5bfc\u51fa\u200b\u5c1a\u672a\u200b\u652f\u6301\u200b\u7684\u200b\u67b6\u6784\u200b\u7684\u200b\u6a21\u578b","text":"<p>\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u8981\u200b\u4e3a\u200b\u5f53\u524d\u200b\u65e0\u6cd5\u200b\u5bfc\u51fa\u200b\u7684\u200b\u6a21\u578b\u200b\u6dfb\u52a0\u200b\u652f\u6301\u200b\uff0c\u200b\u8bf7\u200b\u5148\u200b\u68c0\u67e5\u200b <code>optimum.exporters.onnx</code> \u200b\u662f\u5426\u200b\u652f\u6301\u200b\u8be5\u200b\u6a21\u578b\u200b\uff0c\u200b\u5982\u679c\u200b\u4e0d\u200b\u652f\u6301\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b \u200b\u76f4\u63a5\u200b\u4e3a\u200b \ud83e\udd17 Optimum \u200b\u8d21\u732e\u200b\u4ee3\u7801\u200b\u3002</p>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/serialization/#transformersonnx","title":"\u4f7f\u7528\u200b <code>transformers.onnx</code> \u200b\u5bfc\u51fa\u200b\u6a21\u578b","text":"<p> <p><code>tranformers.onnx</code> \u200b\u4e0d\u518d\u200b\u8fdb\u884c\u200b\u7ef4\u62a4\u200b\uff0c\u200b\u8bf7\u200b\u5982\u4e0a\u6240\u8ff0\u200b\uff0c\u200b\u4f7f\u7528\u200b \ud83e\udd17 Optimum \u200b\u5bfc\u51fa\u200b\u6a21\u578b\u200b\u3002\u200b\u8fd9\u90e8\u5206\u200b\u5185\u5bb9\u200b\u5c06\u200b\u5728\u200b\u672a\u6765\u200b\u7248\u672c\u200b\u4e2d\u200b\u5220\u9664\u200b\u3002</p> <p></p> <p>\u200b\u8981\u200b\u4f7f\u7528\u200b <code>tranformers.onnx</code> \u200b\u5c06\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX\uff0c\u200b\u8bf7\u200b\u5b89\u88c5\u200b\u989d\u5916\u200b\u7684\u200b\u4f9d\u8d56\u200b\u9879\u200b\uff1a</p> <pre><code>pip install transformers[onnx]\n</code></pre> <p>\u200b\u5c06\u200b <code>transformers.onnx</code> \u200b\u5305\u200b\u4f5c\u4e3a\u200b Python \u200b\u6a21\u5757\u200b\u4f7f\u7528\u200b\uff0c\u200b\u4ee5\u200b\u4f7f\u7528\u200b\u73b0\u6210\u200b\u7684\u200b\u914d\u7f6e\u200b\u5bfc\u51fa\u200b\u68c0\u67e5\u70b9\u200b\uff1a</p> <pre><code>python -m transformers.onnx --model=distilbert-base-uncased onnx/\n</code></pre> <p>\u200b\u4ee5\u4e0a\u200b\u4ee3\u7801\u200b\u5c06\u200b\u5bfc\u51fa\u200b\u7531\u200b <code>--model</code> \u200b\u53c2\u6570\u200b\u5b9a\u4e49\u200b\u7684\u200b\u68c0\u67e5\u70b9\u200b\u7684\u200b ONNX \u200b\u56fe\u200b\u3002\u200b\u4f20\u5165\u200b\u4efb\u4f55\u200b \ud83e\udd17 Hub \u200b\u4e0a\u200b\u6216\u8005\u200b\u5b58\u50a8\u200b\u4e0e\u200b\u672c\u5730\u200b\u7684\u200b\u68c0\u67e5\u70b9\u200b\u3002\u200b\u751f\u6210\u200b\u7684\u200b <code>model.onnx</code> \u200b\u6587\u4ef6\u200b\u53ef\u4ee5\u200b\u5728\u200b\u652f\u6301\u200b ONNX \u200b\u6807\u51c6\u200b\u7684\u200b\u4f17\u591a\u200b\u52a0\u901f\u200b\u5f15\u64ce\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4f7f\u7528\u200b ONNX Runtime \u200b\u52a0\u8f7d\u200b\u5e76\u200b\u8fd0\u884c\u200b\u6a21\u578b\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers import AutoTokenizer\n&gt;&gt;&gt; from onnxruntime import InferenceSession\n\n&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n&gt;&gt;&gt; session = InferenceSession(\"onnx/model.onnx\")\n&gt;&gt;&gt; # ONNX Runtime expects NumPy arrays as input\n&gt;&gt;&gt; inputs = tokenizer(\"Using DistilBERT with ONNX Runtime!\", return_tensors=\"np\")\n&gt;&gt;&gt; outputs = session.run(output_names=[\"last_hidden_state\"], input_feed=dict(inputs))\n</code></pre> <p>\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u67e5\u770b\u200b\u6bcf\u4e2a\u200b\u6a21\u578b\u200b\u7684\u200b ONNX \u200b\u914d\u7f6e\u200b\u6765\u200b\u83b7\u53d6\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u8f93\u51fa\u200b\u540d\u200b\uff08\u200b\u4f8b\u5982\u200b <code>[\"last_hidden_state\"]</code>\uff09\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5bf9\u4e8e\u200b DistilBERT\uff0c\u200b\u53ef\u4ee5\u200b\u7528\u200b\u4ee5\u4e0b\u200b\u4ee3\u7801\u200b\u83b7\u53d6\u200b\u8f93\u51fa\u200b\u540d\u79f0\u200b\uff1a</p> <pre><code>&gt;&gt;&gt; from transformers.models.distilbert import DistilBertConfig, DistilBertOnnxConfig\n\n&gt;&gt;&gt; config = DistilBertConfig()\n&gt;&gt;&gt; onnx_config = DistilBertOnnxConfig(config)\n&gt;&gt;&gt; print(list(onnx_config.outputs.keys()))\n[\"last_hidden_state\"]\n</code></pre> <p>\u200b\u4ece\u200b Hub \u200b\u5bfc\u51fa\u200b TensorFlow \u200b\u68c0\u67e5\u70b9\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u4e5f\u200b\u4e00\u6837\u200b\u3002\u200b\u5bfc\u51fa\u200b\u7eaf\u200b TensorFlow \u200b\u68c0\u67e5\u70b9\u200b\u7684\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b\u5982\u4e0b\u200b\uff1a</p> <pre><code>python -m transformers.onnx --model=keras-io/transformers-qa onnx/\n</code></pre> <p>\u200b\u8981\u200b\u5bfc\u51fa\u200b\u672c\u5730\u200b\u5b58\u50a8\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u8bf7\u200b\u5c06\u200b\u6a21\u578b\u200b\u7684\u200b\u6743\u91cd\u200b\u548c\u200b\u5206\u8bcd\u5668\u200b\u6587\u4ef6\u200b\u4fdd\u5b58\u200b\u5728\u200b\u540c\u4e00\u200b\u76ee\u5f55\u200b\u4e2d\u200b\uff08\u200b\u4f8b\u5982\u200b <code>local-pt-checkpoint</code>\uff09\uff0c\u200b\u7136\u540e\u200b\u901a\u8fc7\u200b\u5c06\u200b <code>transformers.onnx</code> \u200b\u5305\u200b\u7684\u200b <code>--model</code> \u200b\u53c2\u6570\u200b\u6307\u5411\u200b\u8be5\u200b\u76ee\u5f55\u200b\uff0c\u200b\u5c06\u200b\u5176\u200b\u5bfc\u51fa\u200b\u4e3a\u200b ONNX\uff1a</p> <pre><code>python -m transformers.onnx --model=local-pt-checkpoint onnx/\n</code></pre>"},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/tflite/","title":"Tflite","text":""},{"location":"3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/tflite/#tflite","title":"\u5bfc\u51fa\u200b\u4e3a\u200b TFLite","text":"<p>TensorFlow Lite \u200b\u662f\u200b\u4e00\u4e2a\u200b\u8f7b\u91cf\u7ea7\u200b\u6846\u67b6\u200b\uff0c\u200b\u7528\u4e8e\u200b\u8d44\u6e90\u200b\u53d7\u9650\u200b\u7684\u200b\u8bbe\u5907\u200b\u4e0a\u200b\uff0c\u200b\u5982\u200b\u624b\u673a\u200b\u3001\u200b\u5d4c\u5165\u5f0f\u200b\u7cfb\u7edf\u200b\u548c\u7269\u200b\u8054\u7f51\u200b\uff08IoT\uff09\u200b\u8bbe\u5907\u200b\uff0c\u200b\u90e8\u7f72\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\u3002TFLite \u200b\u65e8\u5728\u200b\u5728\u200b\u8ba1\u7b97\u80fd\u529b\u200b\u3001\u200b\u5185\u5b58\u200b\u548c\u200b\u529f\u8017\u200b\u6709\u9650\u200b\u7684\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u4f18\u5316\u200b\u548c\u200b\u9ad8\u6548\u200b\u8fd0\u884c\u200b\u6a21\u578b\u200b\u3002\u200b\u6a21\u578b\u200b\u4ee5\u200b\u4e00\u79cd\u200b\u7279\u6b8a\u200b\u7684\u200b\u9ad8\u6548\u200b\u53ef\u79fb\u690d\u200b\u683c\u5f0f\u200b\u8868\u793a\u200b\uff0c\u200b\u5176\u200b\u6587\u4ef6\u200b\u6269\u5c55\u200b\u540d\u4e3a\u200b <code>.tflite</code>\u3002</p> <p>\ud83e\udd17 Optimum \u200b\u901a\u8fc7\u200b <code>exporters.tflite</code> \u200b\u6a21\u5757\u200b\u63d0\u4f9b\u200b\u5c06\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u81f3\u200b TFLite \u200b\u683c\u5f0f\u200b\u7684\u200b\u529f\u80fd\u200b\u3002\u200b\u8bf7\u200b\u53c2\u8003\u200b \ud83e\udd17 Optimum \u200b\u6587\u6863\u200b \u200b\u4ee5\u200b\u83b7\u53d6\u200b\u652f\u6301\u200b\u7684\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\u5217\u8868\u200b\u3002</p> <p>\u200b\u8981\u200b\u5c06\u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u4e3a\u200b TFLite \u200b\u683c\u5f0f\u200b\uff0c\u200b\u8bf7\u200b\u5b89\u88c5\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u4f9d\u8d56\u200b\u9879\u200b\uff1a</p> <pre><code>pip install optimum[exporters-tf]\n</code></pre> <p>\u200b\u8bf7\u53c2\u9605\u200b \ud83e\udd17 Optimum \u200b\u6587\u6863\u200b \u200b\u4ee5\u200b\u67e5\u770b\u200b\u6240\u6709\u200b\u53ef\u7528\u200b\u53c2\u6570\u200b\uff0c\u200b\u6216\u8005\u200b\u5728\u200b\u547d\u4ee4\u884c\u200b\u4e2d\u200b\u67e5\u770b\u200b\u5e2e\u52a9\u200b\uff1a</p> <pre><code>optimum-cli export tflite --help\n</code></pre> <p>\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\uff0c\u200b\u4ee5\u200b\u4ece\u200b \ud83e\udd17 Hub \u200b\u5bfc\u51fa\u200b\u6a21\u578b\u200b\u7684\u200b\u68c0\u67e5\u70b9\u200b\uff08checkpoint\uff09\uff0c\u200b\u4ee5\u200b <code>bert-base-uncased</code> \u200b\u4e3a\u4f8b\u200b\uff1a</p> <pre><code>optimum-cli export tflite --model bert-base-uncased --sequence_length 128 bert_tflite/\n</code></pre> <p>\u200b\u4f60\u200b\u5e94\u8be5\u200b\u80fd\u200b\u5728\u200b\u65e5\u5fd7\u200b\u4e2d\u200b\u770b\u5230\u200b\u5bfc\u51fa\u200b\u8fdb\u5ea6\u200b\u4ee5\u53ca\u200b\u751f\u6210\u200b\u7684\u200b <code>model.tflite</code> \u200b\u6587\u4ef6\u200b\u7684\u200b\u4fdd\u5b58\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>Validating TFLite model...\n    -[\u2713] TFLite model output names match reference model (logits)\n    - Validating TFLite Model output \"logits\":\n        -[\u2713] (1, 128, 30522) matches (1, 128, 30522)\n        -[x] values not close enough, max diff: 5.817413330078125e-05 (atol: 1e-05)\nThe TensorFlow Lite export succeeded with the warning: The maximum absolute difference between the output of the reference model and the TFLite exported model is not within the set tolerance 1e-05:\n- logits: max diff = 5.817413330078125e-05.\n The exported model was saved at: bert_tflite\n</code></pre> <p>\u200b\u4e0a\u9762\u200b\u7684\u200b\u793a\u4f8b\u200b\u8bf4\u660e\u200b\u4e86\u200b\u4ece\u200b \ud83e\udd17 Hub \u200b\u5bfc\u51fa\u200b\u68c0\u67e5\u70b9\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u3002\u200b\u5bfc\u51fa\u200b\u672c\u5730\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u9996\u5148\u200b\u9700\u8981\u200b\u786e\u4fdd\u200b\u5c06\u200b\u6a21\u578b\u200b\u7684\u200b\u6743\u91cd\u200b\u548c\u200b\u5206\u8bcd\u5668\u200b\u6587\u4ef6\u200b\u4fdd\u5b58\u200b\u5728\u200b\u540c\u4e00\u200b\u76ee\u5f55\u200b\uff08<code>local_path</code>\uff09\u200b\u4e2d\u200b\u3002\u200b\u5728\u200b\u4f7f\u7528\u200b CLI\uff08\u200b\u547d\u4ee4\u884c\u200b\uff09\u200b\u65f6\u200b\uff0c\u200b\u5c06\u200b <code>local_path</code> \u200b\u4f20\u9012\u200b\u7ed9\u200b <code>model</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b \ud83e\udd17 Hub \u200b\u4e0a\u200b\u7684\u200b\u68c0\u67e5\u70b9\u200b\u540d\u79f0\u200b\u3002</p>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/","title":"Task summary","text":""},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#transformers","title":"\ud83e\udd17 Transformers \u200b\u80fd\u200b\u505a\u200b\u4ec0\u4e48","text":"<p>\ud83e\udd17 Transformers\u200b\u662f\u200b\u4e00\u4e2a\u200b\u7528\u4e8e\u200b\u81ea\u7136\u8bed\u8a00\u200b\u5904\u7406\u200b\uff08NLP\uff09\u3001\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u548c\u200b\u97f3\u9891\u200b\u548c\u200b\u8bed\u97f3\u200b\u5904\u7406\u200b\u4efb\u52a1\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u5e93\u200b\u3002\u200b\u8be5\u5e93\u200b\u4e0d\u4ec5\u200b\u5305\u542b\u200bTransformer\u200b\u6a21\u578b\u200b\uff0c\u200b\u8fd8\u200b\u5305\u62ec\u200b\u7528\u4e8e\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u4efb\u52a1\u200b\u7684\u200b\u73b0\u4ee3\u200b\u5377\u79ef\u200b\u7f51\u7edc\u200b\u7b49\u200b\u975e\u200bTransformer\u200b\u6a21\u578b\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u770b\u770b\u200b\u4eca\u5929\u200b\u6700\u200b\u53d7\u6b22\u8fce\u200b\u7684\u200b\u4e00\u4e9b\u200b\u6d88\u8d39\u200b\u4ea7\u54c1\u200b\uff0c\u200b\u6bd4\u5982\u200b\u667a\u80fd\u624b\u673a\u200b\u3001\u200b\u5e94\u7528\u7a0b\u5e8f\u200b\u548c\u200b\u7535\u89c6\u200b\uff0c\u200b\u5f88\u200b\u53ef\u80fd\u200b\u80cc\u540e\u200b\u90fd\u200b\u6709\u200b\u67d0\u79cd\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6280\u672f\u200b\u7684\u200b\u652f\u6301\u200b\u3002\u200b\u60f3\u8981\u200b\u4ece\u200b\u60a8\u200b\u667a\u80fd\u624b\u673a\u200b\u62cd\u6444\u200b\u7684\u200b\u7167\u7247\u200b\u4e2d\u200b\u5220\u9664\u200b\u80cc\u666f\u200b\u5bf9\u8c61\u200b\u5417\u200b\uff1f\u200b\u8fd9\u91cc\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5168\u666f\u200b\u5206\u5272\u200b\u4efb\u52a1\u200b\u7684\u200b\u4f8b\u5b50\u200b\uff08\u200b\u5982\u679c\u200b\u60a8\u200b\u8fd8\u200b\u4e0d\u200b\u4e86\u89e3\u200b\u8fd9\u662f\u200b\u4ec0\u4e48\u200b\u610f\u601d\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u5728\u200b\u4ee5\u4e0b\u200b\u90e8\u5206\u200b\u8fdb\u884c\u200b\u63cf\u8ff0\u200b\uff01\uff09\u3002</p> <p>\u200b\u672c\u200b\u9875\u9762\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4f7f\u7528\u200b\ud83e\udd17 Transformers\u200b\u5e93\u4ec5\u7528\u200b\u4e09\u884c\u200b\u4ee3\u7801\u200b\u89e3\u51b3\u200b\u4e0d\u540c\u200b\u7684\u200b\u8bed\u97f3\u200b\u548c\u200b\u97f3\u9891\u200b\u3001\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u548c\u200bNLP\u200b\u4efb\u52a1\u200b\u7684\u200b\u6982\u8ff0\u200b\uff01</p>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_1","title":"\u97f3\u9891","text":"<p>\u200b\u97f3\u9891\u200b\u548c\u200b\u8bed\u97f3\u200b\u5904\u7406\u200b\u4efb\u52a1\u200b\u4e0e\u200b\u5176\u4ed6\u200b\u6a21\u6001\u200b\u7565\u6709\u4e0d\u540c\u200b\uff0c\u200b\u4e3b\u8981\u200b\u662f\u56e0\u4e3a\u200b\u97f3\u9891\u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\u662f\u200b\u4e00\u4e2a\u200b\u8fde\u7eed\u200b\u7684\u200b\u4fe1\u53f7\u200b\u3002\u200b\u4e0e\u200b\u6587\u672c\u200b\u4e0d\u540c\u200b\uff0c\u200b\u539f\u59cb\u200b\u97f3\u9891\u200b\u6ce2\u5f62\u200b\u4e0d\u80fd\u200b\u50cf\u200b\u53e5\u5b50\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u5212\u5206\u200b\u4e3a\u200b\u5355\u8bcd\u200b\u90a3\u6837\u200b\u88ab\u200b\u6574\u9f50\u200b\u5730\u200b\u5206\u5272\u200b\u6210\u200b\u79bb\u6563\u200b\u7684\u200b\u5757\u200b\u3002\u200b\u4e3a\u4e86\u200b\u89e3\u51b3\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\uff0c\u200b\u901a\u5e38\u200b\u5728\u200b\u56fa\u5b9a\u200b\u7684\u200b\u65f6\u95f4\u200b\u95f4\u9694\u200b\u5185\u200b\u5bf9\u200b\u539f\u59cb\u200b\u97f3\u9891\u200b\u4fe1\u53f7\u200b\u8fdb\u884c\u200b\u91c7\u6837\u200b\u3002\u200b\u5982\u679c\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u65f6\u95f4\u200b\u95f4\u9694\u200b\u5185\u200b\u91c7\u6837\u200b\u66f4\u200b\u591a\u6837\u200b\u672c\u200b\uff0c\u200b\u91c7\u6837\u7387\u200b\u5c31\u200b\u4f1a\u200b\u66f4\u200b\u9ad8\u200b\uff0c\u200b\u97f3\u9891\u200b\u66f4\u200b\u63a5\u8fd1\u200b\u539f\u59cb\u200b\u97f3\u9891\u200b\u6e90\u200b\u3002</p> <p>\u200b\u4ee5\u524d\u200b\u7684\u200b\u65b9\u6cd5\u200b\u662f\u200b\u9884\u5904\u7406\u200b\u97f3\u9891\u200b\u4ee5\u200b\u4ece\u4e2d\u200b\u63d0\u53d6\u200b\u6709\u7528\u200b\u7684\u200b\u7279\u5f81\u200b\u3002\u200b\u73b0\u5728\u200b\u66f4\u200b\u5e38\u89c1\u200b\u7684\u200b\u505a\u6cd5\u200b\u662f\u200b\u76f4\u63a5\u200b\u5c06\u200b\u539f\u59cb\u200b\u97f3\u9891\u200b\u6ce2\u5f62\u200b\u8f93\u5165\u200b\u5230\u200b\u7279\u5f81\u200b\u7f16\u7801\u5668\u200b\u4e2d\u200b\uff0c\u200b\u4ee5\u200b\u63d0\u53d6\u200b\u97f3\u9891\u200b\u8868\u793a\u200b\u3002\u200b\u8fd9\u6837\u200b\u53ef\u4ee5\u200b\u7b80\u5316\u200b\u9884\u5904\u7406\u200b\u6b65\u9aa4\u200b\uff0c\u200b\u5e76\u200b\u5141\u8bb8\u200b\u6a21\u578b\u200b\u5b66\u4e60\u200b\u6700\u200b\u91cd\u8981\u200b\u7684\u200b\u7279\u5f81\u200b\u3002</p>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_2","title":"\u97f3\u9891\u200b\u5206\u7c7b","text":"<p>\u200b\u97f3\u9891\u200b\u5206\u7c7b\u200b\u662f\u200b\u4e00\u9879\u200b\u5c06\u200b\u97f3\u9891\u200b\u6570\u636e\u200b\u4ece\u200b\u9884\u5b9a\u200b\u4e49\u200b\u7684\u200b\u7c7b\u522b\u200b\u96c6\u5408\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\u7684\u200b\u4efb\u52a1\u200b\u3002\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u5e7f\u6cdb\u200b\u7684\u200b\u7c7b\u522b\u200b\uff0c\u200b\u5177\u6709\u200b\u8bb8\u591a\u200b\u5177\u4f53\u200b\u7684\u200b\u5e94\u7528\u200b\uff0c\u200b\u5176\u4e2d\u200b\u4e00\u4e9b\u200b\u5305\u62ec\u200b\uff1a</p> <ul> <li>\u200b\u58f0\u5b66\u200b\u573a\u666f\u200b\u5206\u7c7b\u200b\uff1a\u200b\u4f7f\u7528\u200b\u573a\u666f\u200b\u6807\u7b7e\u200b\uff08\"\u200b\u529e\u516c\u5ba4\u200b\"\u3001\"\u200b\u6d77\u6ee9\u200b\"\u3001\"\u200b\u4f53\u80b2\u573a\u200b\"\uff09\u200b\u5bf9\u200b\u97f3\u9891\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\u3002</li> <li>\u200b\u58f0\u5b66\u200b\u4e8b\u4ef6\u200b\u68c0\u6d4b\u200b\uff1a\u200b\u4f7f\u7528\u200b\u58f0\u97f3\u200b\u4e8b\u4ef6\u200b\u6807\u7b7e\u200b\uff08\"\u200b\u6c7d\u8f66\u200b\u5587\u53ed\u58f0\u200b\"\u3001\"\u200b\u9cb8\u9c7c\u200b\u53eb\u58f0\u200b\"\u3001\"\u200b\u73bb\u7483\u200b\u7834\u788e\u200b\u58f0\u200b\"\uff09\u200b\u5bf9\u200b\u97f3\u9891\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\u3002</li> <li>\u200b\u6807\u8bb0\u200b\uff1a\u200b\u5bf9\u200b\u5305\u542b\u200b\u591a\u79cd\u200b\u58f0\u97f3\u200b\u7684\u200b\u97f3\u9891\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\uff08\u200b\u9e1f\u9e23\u200b\u3001\u200b\u4f1a\u8bae\u200b\u4e2d\u200b\u7684\u200b\u8bf4\u8bdd\u200b\u4eba\u200b\u8bc6\u522b\u200b\uff09\u3002</li> <li>\u200b\u97f3\u4e50\u200b\u5206\u7c7b\u200b\uff1a\u200b\u4f7f\u7528\u200b\u6d41\u6d3e\u200b\u6807\u7b7e\u200b\uff08\"\u200b\u91d1\u5c5e\u200b\"\u3001\"\u200b\u563b\u54c8\u200b\"\u3001\"\u200b\u4e61\u6751\u200b\"\uff09\u200b\u5bf9\u200b\u97f3\u4e50\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\u3002</li> </ul> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; classifier = pipeline(task=\"audio-classification\", model=\"superb/hubert-base-superb-er\")\n&gt;&gt;&gt; preds = classifier(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n&gt;&gt;&gt; preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n&gt;&gt;&gt; preds\n[{'score': 0.4532, 'label': 'hap'},\n {'score': 0.3622, 'label': 'sad'},\n {'score': 0.0943, 'label': 'neu'},\n {'score': 0.0903, 'label': 'ang'}]\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_3","title":"\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b","text":"<p>\u200b\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b\uff08ASR\uff09\u200b\u5c06\u200b\u8bed\u97f3\u200b\u8f6c\u5f55\u200b\u4e3a\u200b\u6587\u672c\u200b\u3002\u200b\u8fd9\u200b\u662f\u200b\u6700\u200b\u5e38\u89c1\u200b\u7684\u200b\u97f3\u9891\u200b\u4efb\u52a1\u200b\u4e4b\u4e00\u200b\uff0c\u200b\u90e8\u5206\u200b\u539f\u56e0\u200b\u662f\u56e0\u4e3a\u200b\u8bed\u97f3\u200b\u662f\u200b\u4eba\u7c7b\u200b\u4ea4\u6d41\u200b\u7684\u200b\u81ea\u7136\u200b\u5f62\u5f0f\u200b\u3002\u200b\u5982\u4eca\u200b\uff0cASR\u200b\u7cfb\u7edf\u200b\u5d4c\u5165\u200b\u5728\u200b\u667a\u80fd\u200b\u6280\u672f\u200b\u4ea7\u54c1\u200b\u4e2d\u200b\uff0c\u200b\u5982\u200b\u626c\u58f0\u5668\u200b\u3001\u200b\u7535\u8bdd\u200b\u548c\u200b\u6c7d\u8f66\u200b\u3002\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u8981\u6c42\u200b\u865a\u62df\u200b\u52a9\u624b\u200b\u64ad\u653e\u200b\u97f3\u4e50\u200b\u3001\u200b\u8bbe\u7f6e\u200b\u63d0\u9192\u200b\u548c\u200b\u544a\u8bc9\u200b\u6211\u4eec\u200b\u5929\u6c14\u200b\u3002</p> <p>\u200b\u4f46\u662f\u200b\uff0cTransformer\u200b\u67b6\u6784\u200b\u5e2e\u52a9\u200b\u89e3\u51b3\u200b\u7684\u200b\u4e00\u4e2a\u200b\u5173\u952e\u200b\u6311\u6218\u200b\u662f\u200b\u4f4e\u200b\u8d44\u6e90\u200b\u8bed\u8a00\u200b\u3002\u200b\u901a\u8fc7\u200b\u5728\u200b\u5927\u91cf\u200b\u8bed\u97f3\u200b\u6570\u636e\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u9884\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u4ec5\u200b\u5728\u200b\u4e00\u4e2a\u200b\u4f4e\u200b\u8d44\u6e90\u200b\u8bed\u8a00\u200b\u7684\u200b\u4e00\u200b\u5c0f\u65f6\u200b\u6807\u8bb0\u200b\u8bed\u97f3\u200b\u6570\u636e\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u5fae\u8c03\u200b\uff0c\u200b\u4ecd\u7136\u200b\u53ef\u4ee5\u200b\u4ea7\u751f\u200b\u4e0e\u200b\u4ee5\u524d\u200b\u5728\u200b100\u200b\u500d\u200b\u66f4\u200b\u591a\u200b\u6807\u8bb0\u200b\u6570\u636e\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u7684\u200bASR\u200b\u7cfb\u7edf\u200b\u76f8\u6bd4\u200b\u9ad8\u8d28\u91cf\u200b\u7684\u200b\u7ed3\u679c\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; transcriber = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n&gt;&gt;&gt; transcriber(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_4","title":"\u8ba1\u7b97\u673a\u200b\u89c6\u89c9","text":"<p>\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u4efb\u52a1\u200b\u4e2d\u200b\u6700\u65e9\u200b\u6210\u529f\u200b\u4e4b\u4e00\u200b\u662f\u200b\u4f7f\u7528\u200b\u5377\u79ef\u200b\u795e\u7ecf\u7f51\u7edc\u200b\uff08CNN\uff09\u200b\u8bc6\u522b\u200b\u90ae\u653f\u7f16\u7801\u200b\u6570\u5b57\u56fe\u50cf\u200b\u3002\u200b\u56fe\u50cf\u200b\u7531\u200b\u50cf\u7d20\u200b\u7ec4\u6210\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u50cf\u7d20\u200b\u90fd\u200b\u6709\u200b\u4e00\u4e2a\u200b\u6570\u503c\u200b\u3002\u200b\u8fd9\u200b\u4f7f\u5f97\u200b\u5c06\u200b\u56fe\u50cf\u200b\u8868\u793a\u200b\u4e3a\u200b\u50cf\u7d20\u200b\u503c\u200b\u77e9\u9635\u200b\u53d8\u5f97\u200b\u5bb9\u6613\u200b\u3002\u200b\u6bcf\u4e2a\u200b\u50cf\u7d20\u200b\u503c\u200b\u7ec4\u5408\u200b\u63cf\u8ff0\u200b\u4e86\u200b\u56fe\u50cf\u200b\u7684\u200b\u989c\u8272\u200b\u3002</p> <p>\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u4efb\u52a1\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u4e24\u79cd\u200b\u901a\u7528\u200b\u65b9\u5f0f\u200b\u89e3\u51b3\u200b\uff1a</p> <ol> <li>\u200b\u4f7f\u7528\u200b\u5377\u79ef\u200b\u6765\u200b\u5b66\u4e60\u200b\u56fe\u50cf\u200b\u7684\u200b\u5c42\u6b21\u200b\u7279\u5f81\u200b\uff0c\u200b\u4ece\u200b\u4f4e\u7ea7\u200b\u7279\u5f81\u200b\u5230\u200b\u9ad8\u7ea7\u200b\u62bd\u8c61\u200b\u7279\u5f81\u200b\u3002</li> <li>\u200b\u5c06\u200b\u56fe\u50cf\u200b\u5206\u6210\u200b\u5757\u200b\uff0c\u200b\u5e76\u200b\u4f7f\u7528\u200bTransformer\u200b\u9010\u6b65\u200b\u5b66\u4e60\u200b\u6bcf\u4e2a\u200b\u56fe\u50cf\u200b\u5757\u200b\u5982\u4f55\u200b\u76f8\u4e92\u200b\u5173\u8054\u200b\u4ee5\u200b\u5f62\u6210\u200b\u56fe\u50cf\u200b\u3002\u200b\u4e0e\u200bCNN\u200b\u504f\u597d\u200b\u7684\u200b\u81ea\u200b\u5e95\u5411\u4e0a\u200b\u65b9\u6cd5\u200b\u4e0d\u540c\u200b\uff0c\u200b\u8fd9\u79cd\u200b\u65b9\u6cd5\u200b\u6709\u70b9\u50cf\u200b\u4ece\u200b\u4e00\u4e2a\u200b\u6a21\u7cca\u200b\u7684\u200b\u56fe\u50cf\u200b\u5f00\u59cb\u200b\uff0c\u200b\u7136\u540e\u200b\u9010\u6e10\u200b\u5c06\u200b\u5176\u200b\u805a\u7126\u200b\u6e05\u6670\u200b\u3002</li> </ol>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_5","title":"\u56fe\u50cf\u200b\u5206\u7c7b","text":"<p>\u200b\u56fe\u50cf\u200b\u5206\u7c7b\u200b\u5c06\u200b\u6574\u4e2a\u200b\u56fe\u50cf\u200b\u4ece\u200b\u9884\u5b9a\u200b\u4e49\u200b\u7684\u200b\u7c7b\u522b\u200b\u96c6\u5408\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\u3002\u200b\u50cf\u200b\u5927\u591a\u6570\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b\u4e00\u6837\u200b\uff0c\u200b\u56fe\u50cf\u200b\u5206\u7c7b\u200b\u6709\u200b\u8bb8\u591a\u200b\u5b9e\u9645\u200b\u7528\u4f8b\u200b\uff0c\u200b\u5176\u4e2d\u200b\u4e00\u4e9b\u200b\u5305\u62ec\u200b\uff1a</p> <ul> <li>\u200b\u533b\u7597\u4fdd\u5065\u200b\uff1a\u200b\u6807\u8bb0\u200b\u533b\u5b66\u200b\u56fe\u50cf\u200b\u4ee5\u200b\u68c0\u6d4b\u200b\u75be\u75c5\u200b\u6216\u200b\u76d1\u6d4b\u200b\u60a3\u8005\u200b\u5065\u5eb7\u72b6\u51b5\u200b</li> <li>\u200b\u73af\u5883\u200b\uff1a\u200b\u6807\u8bb0\u200b\u536b\u661f\u200b\u56fe\u50cf\u200b\u4ee5\u200b\u76d1\u6d4b\u200b\u68ee\u6797\u200b\u780d\u4f10\u200b\u3001\u200b\u63d0\u4f9b\u200b\u91ce\u5916\u200b\u7ba1\u7406\u200b\u4fe1\u606f\u200b\u6216\u200b\u68c0\u6d4b\u200b\u91ce\u706b\u200b</li> <li>\u200b\u519c\u4e1a\u200b\uff1a\u200b\u6807\u8bb0\u200b\u519c\u4f5c\u7269\u200b\u56fe\u50cf\u200b\u4ee5\u200b\u76d1\u6d4b\u200b\u690d\u7269\u200b\u5065\u5eb7\u200b\u6216\u200b\u7528\u4e8e\u200b\u571f\u5730\u200b\u4f7f\u7528\u200b\u76d1\u6d4b\u200b\u7684\u200b\u536b\u661f\u200b\u56fe\u50cf\u200b</li> <li>\u200b\u751f\u6001\u5b66\u200b\uff1a\u200b\u6807\u8bb0\u200b\u52a8\u7269\u200b\u6216\u200b\u690d\u7269\u200b\u7269\u79cd\u200b\u7684\u200b\u56fe\u50cf\u200b\u4ee5\u200b\u76d1\u6d4b\u200b\u91ce\u751f\u52a8\u7269\u200b\u79cd\u7fa4\u200b\u6216\u200b\u8ddf\u8e2a\u200b\u6fd2\u5371\u200b\u7269\u79cd\u200b</li> </ul> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; classifier = pipeline(task=\"image-classification\")\n&gt;&gt;&gt; preds = classifier(\n...     \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n... )\n&gt;&gt;&gt; preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n&gt;&gt;&gt; print(*preds, sep=\"\\n\")\n{'score': 0.4335, 'label': 'lynx, catamount'}\n{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\n{'score': 0.0239, 'label': 'Egyptian cat'}\n{'score': 0.0229, 'label': 'tiger cat'}\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_6","title":"\u76ee\u6807\u200b\u68c0\u6d4b","text":"<p>\u200b\u4e0e\u200b\u56fe\u50cf\u200b\u5206\u7c7b\u200b\u4e0d\u540c\u200b\uff0c\u200b\u76ee\u6807\u200b\u68c0\u6d4b\u200b\u5728\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u8bc6\u522b\u200b\u591a\u4e2a\u200b\u5bf9\u8c61\u200b\u4ee5\u53ca\u200b\u8fd9\u4e9b\u200b\u5bf9\u8c61\u200b\u5728\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u7684\u200b\u4f4d\u7f6e\u200b\uff08\u200b\u7531\u200b\u8fb9\u754c\u200b\u6846\u200b\u5b9a\u4e49\u200b\uff09\u3002\u200b\u76ee\u6807\u200b\u68c0\u6d4b\u200b\u7684\u200b\u4e00\u4e9b\u200b\u793a\u4f8b\u200b\u5e94\u7528\u200b\u5305\u62ec\u200b\uff1a</p> <ul> <li>\u200b\u81ea\u52a8\u200b\u9a7e\u9a76\u200b\u8f66\u8f86\u200b\uff1a\u200b\u68c0\u6d4b\u200b\u65e5\u5e38\u200b\u4ea4\u901a\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u5982\u200b\u5176\u4ed6\u200b\u8f66\u8f86\u200b\u3001\u200b\u884c\u4eba\u200b\u548c\u200b\u7ea2\u7eff\u706f\u200b</li> <li>\u200b\u9065\u611f\u200b\uff1a\u200b\u707e\u5bb3\u200b\u76d1\u6d4b\u200b\u3001\u200b\u57ce\u5e02\u89c4\u5212\u200b\u548c\u200b\u5929\u6c14\u9884\u62a5\u200b</li> <li>\u200b\u7f3a\u9677\u200b\u68c0\u6d4b\u200b\uff1a\u200b\u68c0\u6d4b\u200b\u5efa\u7b51\u7269\u200b\u4e2d\u200b\u7684\u200b\u88c2\u7f1d\u200b\u6216\u200b\u7ed3\u6784\u200b\u635f\u574f\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u5236\u9020\u4e1a\u200b\u4ea7\u54c1\u200b\u7f3a\u9677\u200b</li> </ul> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; detector = pipeline(task=\"object-detection\")\n&gt;&gt;&gt; preds = detector(\n...     \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n... )\n&gt;&gt;&gt; preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n&gt;&gt;&gt; preds\n[{'score': 0.9865,\n  'label': 'cat',\n  'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}]\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_7","title":"\u56fe\u50cf\u200b\u5206\u5272","text":"<p>\u200b\u56fe\u50cf\u200b\u5206\u5272\u200b\u662f\u200b\u4e00\u9879\u200b\u50cf\u7d20\u200b\u7ea7\u4efb\u52a1\u200b\uff0c\u200b\u5c06\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u50cf\u7d20\u200b\u5206\u914d\u200b\u7ed9\u200b\u4e00\u4e2a\u200b\u7c7b\u522b\u200b\u3002\u200b\u5b83\u200b\u4e0e\u200b\u4f7f\u7528\u200b\u8fb9\u754c\u200b\u6846\u200b\u6807\u8bb0\u200b\u548c\u200b\u9884\u6d4b\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u7684\u200b\u5bf9\u8c61\u200b\u7684\u200b\u76ee\u6807\u200b\u68c0\u6d4b\u200b\u4e0d\u540c\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5206\u5272\u200b\u66f4\u52a0\u200b\u7cbe\u7ec6\u200b\u3002\u200b\u5206\u5272\u200b\u53ef\u4ee5\u200b\u5728\u200b\u50cf\u7d20\u200b\u7ea7\u522b\u200b\u68c0\u6d4b\u200b\u5bf9\u8c61\u200b\u3002\u200b\u6709\u200b\u51e0\u79cd\u200b\u7c7b\u578b\u200b\u7684\u200b\u56fe\u50cf\u200b\u5206\u5272\u200b\uff1a</p> <ul> <li>\u200b\u5b9e\u4f8b\u200b\u5206\u5272\u200b\uff1a\u200b\u9664\u4e86\u200b\u6807\u8bb0\u200b\u5bf9\u8c61\u200b\u7684\u200b\u7c7b\u522b\u200b\u5916\u200b\uff0c\u200b\u8fd8\u200b\u6807\u8bb0\u200b\u6bcf\u4e2a\u200b\u5bf9\u8c61\u200b\u7684\u200b\u4e0d\u540c\u200b\u5b9e\u4f8b\u200b\uff08\u201cdog-1\u201d\uff0c\u201cdog-2\u201d\uff09</li> <li>\u200b\u5168\u666f\u200b\u5206\u5272\u200b\uff1a\u200b\u8bed\u4e49\u200b\u5206\u5272\u200b\u548c\u200b\u5b9e\u4f8b\u200b\u5206\u5272\u200b\u7684\u200b\u7ec4\u5408\u200b\uff1b \u200b\u5b83\u200b\u4f7f\u7528\u200b\u8bed\u4e49\u200b\u7c7b\u4e3a\u200b\u6bcf\u4e2a\u200b\u50cf\u7d20\u200b\u6807\u8bb0\u200b\u5e76\u200b\u6807\u8bb0\u200b\u6bcf\u4e2a\u200b\u5bf9\u8c61\u200b\u7684\u200b\u4e0d\u540c\u200b\u5b9e\u4f8b\u200b</li> </ul> <p>\u200b\u5206\u5272\u200b\u4efb\u52a1\u200b\u5bf9\u4e8e\u200b\u81ea\u52a8\u200b\u9a7e\u9a76\u200b\u8f66\u8f86\u200b\u5f88\u200b\u6709\u200b\u5e2e\u52a9\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u521b\u5efa\u200b\u5468\u56f4\u200b\u4e16\u754c\u200b\u7684\u200b\u50cf\u7d20\u200b\u7ea7\u200b\u5730\u56fe\u200b\uff0c\u200b\u4ee5\u4fbf\u200b\u5b83\u4eec\u200b\u53ef\u4ee5\u200b\u5728\u200b\u884c\u4eba\u200b\u548c\u200b\u5176\u4ed6\u200b\u8f66\u8f86\u200b\u5468\u56f4\u200b\u5b89\u5168\u200b\u5bfc\u822a\u200b\u3002\u200b\u5b83\u200b\u8fd8\u200b\u9002\u7528\u200b\u4e8e\u200b\u533b\u5b66\u200b\u6210\u50cf\u200b\uff0c\u200b\u5176\u4e2d\u200b\u4efb\u52a1\u200b\u7684\u200b\u66f4\u200b\u7cbe\u7ec6\u200b\u7c92\u5ea6\u200b\u53ef\u4ee5\u200b\u5e2e\u52a9\u200b\u8bc6\u522b\u200b\u5f02\u5e38\u200b\u7ec6\u80de\u200b\u6216\u200b\u5668\u5b98\u200b\u7279\u5f81\u200b\u3002\u200b\u56fe\u50cf\u200b\u5206\u5272\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u7528\u4e8e\u200b\u7535\u5b50\u5546\u52a1\u200b\uff0c\u200b\u901a\u8fc7\u200b\u60a8\u200b\u7684\u200b\u76f8\u673a\u200b\u5728\u200b\u73b0\u5b9e\u200b\u4e16\u754c\u200b\u4e2d\u200b\u8986\u76d6\u200b\u7269\u4f53\u200b\u6765\u200b\u865a\u62df\u200b\u8bd5\u7a7f\u200b\u8863\u670d\u200b\u6216\u200b\u521b\u5efa\u200b\u589e\u5f3a\u200b\u73b0\u5b9e\u200b\u4f53\u9a8c\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; segmenter = pipeline(task=\"image-segmentation\")\n&gt;&gt;&gt; preds = segmenter(\n...     \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n... )\n&gt;&gt;&gt; preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n&gt;&gt;&gt; print(*preds, sep=\"\\n\")\n{'score': 0.9879, 'label': 'LABEL_184'}\n{'score': 0.9973, 'label': 'snow'}\n{'score': 0.9972, 'label': 'cat'}\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_8","title":"\u6df1\u5ea6\u200b\u4f30\u8ba1","text":"<p>\u200b\u6df1\u5ea6\u200b\u4f30\u8ba1\u200b\u9884\u6d4b\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u6bcf\u4e2a\u200b\u50cf\u7d20\u200b\u5230\u200b\u76f8\u673a\u200b\u7684\u200b\u8ddd\u79bb\u200b\u3002\u200b\u8fd9\u4e2a\u200b\u8ba1\u7b97\u673a\u200b\u89c6\u89c9\u200b\u4efb\u52a1\u200b\u5bf9\u4e8e\u200b\u573a\u666f\u200b\u7406\u89e3\u200b\u548c\u200b\u91cd\u5efa\u200b\u5c24\u4e3a\u91cd\u8981\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5728\u200b\u81ea\u52a8\u200b\u9a7e\u9a76\u200b\u6c7d\u8f66\u200b\u4e2d\u200b\uff0c\u200b\u8f66\u8f86\u200b\u9700\u8981\u200b\u4e86\u89e3\u200b\u884c\u4eba\u200b\u3001\u200b\u4ea4\u901a\u6807\u5fd7\u200b\u548c\u200b\u5176\u4ed6\u200b\u8f66\u8f86\u200b\u7b49\u200b\u7269\u4f53\u200b\u7684\u200b\u8ddd\u79bb\u200b\uff0c\u200b\u4ee5\u200b\u907f\u514d\u200b\u969c\u788d\u7269\u200b\u548c\u200b\u78b0\u649e\u200b\u3002\u200b\u6df1\u5ea6\u200b\u4fe1\u606f\u200b\u8fd8\u200b\u6709\u52a9\u4e8e\u200b\u4ece\u200b2D\u200b\u56fe\u50cf\u200b\u6784\u5efa\u200b3D\u200b\u8868\u793a\u200b\uff0c\u200b\u5e76\u200b\u53ef\u200b\u7528\u4e8e\u200b\u521b\u5efa\u200b\u751f\u7269\u200b\u7ed3\u6784\u200b\u6216\u200b\u5efa\u7b51\u7269\u200b\u7684\u200b\u9ad8\u8d28\u91cf\u200b3D\u200b\u8868\u793a\u200b\u3002</p> <p>\u200b\u6709\u200b\u4e24\u79cd\u200b\u65b9\u6cd5\u200b\u53ef\u4ee5\u200b\u8fdb\u884c\u200b\u6df1\u5ea6\u200b\u4f30\u8ba1\u200b\uff1a</p> <ul> <li>stereo\uff08\u200b\u7acb\u4f53\u200b\uff09\uff1a\u200b\u901a\u8fc7\u200b\u6bd4\u8f83\u200b\u540c\u4e00\u200b\u56fe\u50cf\u200b\u7684\u200b\u4e24\u4e2a\u200b\u7565\u5fae\u200b\u4e0d\u540c\u200b\u89d2\u5ea6\u200b\u7684\u200b\u56fe\u50cf\u200b\u6765\u200b\u4f30\u8ba1\u200b\u6df1\u5ea6\u200b</li> <li>monocular\uff08\u200b\u5355\u76ee\u200b\uff09\uff1a\u200b\u4ece\u200b\u5355\u4e2a\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u4f30\u8ba1\u200b\u6df1\u5ea6\u200b</li> </ul> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; depth_estimator = pipeline(task=\"depth-estimation\")\n&gt;&gt;&gt; preds = depth_estimator(\n...     \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n... )\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_9","title":"\u81ea\u7136\u8bed\u8a00\u200b\u5904\u7406","text":"<p>NLP\u200b\u4efb\u52a1\u200b\u662f\u200b\u6700\u200b\u5e38\u89c1\u200b\u7684\u200b\u7c7b\u578b\u200b\u4e4b\u4e00\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6587\u672c\u200b\u662f\u200b\u6211\u4eec\u200b\u8fdb\u884c\u200b\u4ea4\u6d41\u200b\u7684\u200b\u81ea\u7136\u200b\u65b9\u5f0f\u200b\u3002\u200b\u4e3a\u4e86\u200b\u8ba9\u200b\u6587\u672c\u200b\u53d8\u6210\u200b\u6a21\u578b\u200b\u8bc6\u522b\u200b\u7684\u200b\u683c\u5f0f\u200b\uff0c\u200b\u9700\u8981\u200b\u5bf9\u200b\u5176\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\u3002\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u5c06\u200b\u4e00\u6bb5\u200b\u6587\u672c\u200b\u5206\u6210\u200b\u5355\u72ec\u200b\u7684\u200b\u5355\u8bcd\u200b\u6216\u5b50\u200b\u8bcd\u200b\uff08<code>tokens</code>\uff09\uff0c\u200b\u7136\u540e\u200b\u5c06\u200b\u8fd9\u4e9b\u200b<code>tokens</code>\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6570\u5b57\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u4e00\u6bb5\u200b\u6587\u672c\u200b\u8868\u793a\u200b\u4e3a\u200b\u4e00\u7cfb\u5217\u200b\u6570\u5b57\u200b\uff0c\u200b\u4e00\u65e6\u200b\u6709\u200b\u4e86\u200b\u4e00\u7cfb\u5217\u200b\u7684\u200b\u6570\u5b57\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u5176\u200b\u8f93\u5165\u200b\u5230\u200b\u6a21\u578b\u200b\u4e2d\u4ee5\u200b\u89e3\u51b3\u200b\u5404\u79cd\u200bNLP\u200b\u4efb\u52a1\u200b\uff01</p>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_10","title":"\u6587\u672c\u200b\u5206\u7c7b","text":"<p>\u200b\u50cf\u200b\u4efb\u4f55\u200b\u6a21\u6001\u200b\u7684\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b\u4e00\u6837\u200b\uff0c\u200b\u6587\u672c\u200b\u5206\u7c7b\u200b\u5c06\u200b\u4e00\u6bb5\u200b\u6587\u672c\u200b\uff08\u200b\u53ef\u4ee5\u200b\u662f\u200b\u53e5\u5b50\u200b\u7ea7\u522b\u200b\u3001\u200b\u6bb5\u843d\u200b\u6216\u200b\u6587\u6863\u200b\uff09\u200b\u4ece\u200b\u9884\u5b9a\u200b\u4e49\u200b\u7684\u200b\u7c7b\u522b\u200b\u96c6\u5408\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\u3002\u200b\u6587\u672c\u200b\u5206\u7c7b\u200b\u6709\u200b\u8bb8\u591a\u200b\u5b9e\u9645\u200b\u5e94\u7528\u200b\uff0c\u200b\u5176\u4e2d\u200b\u4e00\u4e9b\u200b\u5305\u62ec\u200b\uff1a</p> <ul> <li>\u200b\u60c5\u611f\u200b\u5206\u6790\u200b\uff1a\u200b\u6839\u636e\u200b\u67d0\u4e9b\u200b\u6781\u6027\u200b\uff08\u200b\u5982\u200b<code>\u200b\u79ef\u6781\u200b</code>\u200b\u6216\u200b<code>\u200b\u6d88\u6781\u200b</code>\uff09\u200b\u5bf9\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u652f\u6301\u200b\u653f\u6cbb\u200b\u3001\u200b\u91d1\u878d\u200b\u548c\u200b\u8425\u9500\u200b\u7b49\u200b\u9886\u57df\u200b\u7684\u200b\u51b3\u7b56\u5236\u5b9a\u200b</li> <li>\u200b\u5185\u5bb9\u200b\u5206\u7c7b\u200b\uff1a\u200b\u6839\u636e\u200b\u67d0\u4e9b\u200b\u4e3b\u9898\u200b\u5bf9\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\uff0c\u200b\u6709\u52a9\u4e8e\u200b\u7ec4\u7ec7\u200b\u548c\u200b\u8fc7\u6ee4\u200b\u65b0\u95fb\u200b\u548c\u200b\u793e\u4ea4\u200b\u5a92\u4f53\u200b\u63d0\u8981\u200b\u4e2d\u200b\u7684\u200b\u4fe1\u606f\u200b\uff08<code>\u200b\u5929\u6c14\u200b</code>\u3001<code>\u200b\u4f53\u80b2\u200b</code>\u3001<code>\u200b\u91d1\u878d\u200b</code>\u200b\u7b49\u200b\uff09</li> </ul> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; classifier = pipeline(task=\"sentiment-analysis\")\n&gt;&gt;&gt; preds = classifier(\"Hugging Face is the best thing since sliced bread!\")\n&gt;&gt;&gt; preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n&gt;&gt;&gt; preds\n[{'score': 0.9991, 'label': 'POSITIVE'}]\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#token","title":"Token\u200b\u5206\u7c7b","text":"<p>\u200b\u5728\u200b\u4efb\u4f55\u200bNLP\u200b\u4efb\u52a1\u200b\u4e2d\u200b\uff0c\u200b\u6587\u672c\u200b\u90fd\u200b\u7ecf\u8fc7\u200b\u9884\u5904\u7406\u200b\uff0c\u200b\u5c06\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u5206\u6210\u200b\u5355\u4e2a\u200b\u5355\u8bcd\u200b\u6216\u5b50\u200b\u8bcd\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u88ab\u200b\u79f0\u4e3a\u200btokens\u3002Token\u200b\u5206\u7c7b\u200b\u5c06\u200b\u6bcf\u4e2a\u200b<code>token</code>\u200b\u5206\u914d\u200b\u4e00\u4e2a\u200b\u6765\u81ea\u200b\u9884\u5b9a\u200b\u4e49\u200b\u7c7b\u522b\u200b\u96c6\u200b\u7684\u200b\u6807\u7b7e\u200b\u3002</p> <p>\u200b\u4e24\u79cd\u200b\u5e38\u89c1\u200b\u7684\u200bToken\u200b\u5206\u7c7b\u200b\u662f\u200b\uff1a</p> <ul> <li>\u200b\u547d\u540d\u200b\u5b9e\u4f53\u200b\u8bc6\u522b\u200b\uff08NER\uff09\uff1a\u200b\u6839\u636e\u200b\u5b9e\u4f53\u200b\u7c7b\u522b\u200b\uff08\u200b\u5982\u200b\u7ec4\u7ec7\u200b\u3001\u200b\u4eba\u5458\u200b\u3001\u200b\u4f4d\u7f6e\u200b\u6216\u200b\u65e5\u671f\u200b\uff09\u200b\u5bf9\u200b<code>token</code>\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\u3002NER\u200b\u5728\u200b\u751f\u7269\u533b\u5b66\u200b\u8bbe\u7f6e\u200b\u4e2d\u200b\u7279\u522b\u200b\u53d7\u6b22\u8fce\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u6807\u8bb0\u200b\u57fa\u56e0\u200b\u3001\u200b\u86cb\u767d\u8d28\u200b\u548c\u200b\u836f\u7269\u200b\u540d\u79f0\u200b\u3002</li> <li>\u200b\u8bcd\u6027\u200b\u6807\u6ce8\u200b\uff08POS\uff09\uff1a\u200b\u6839\u636e\u200b\u5176\u200b\u8bcd\u6027\u200b\uff08\u200b\u5982\u200b\u540d\u8bcd\u200b\u3001\u200b\u52a8\u8bcd\u200b\u6216\u200b\u5f62\u5bb9\u8bcd\u200b\uff09\u200b\u5bf9\u200b\u6807\u8bb0\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\u3002POS\u200b\u5bf9\u4e8e\u200b\u5e2e\u52a9\u200b\u7ffb\u8bd1\u200b\u7cfb\u7edf\u200b\u4e86\u89e3\u200b\u4e24\u4e2a\u200b\u76f8\u540c\u200b\u7684\u200b\u5355\u8bcd\u200b\u5982\u4f55\u200b\u5728\u200b\u8bed\u6cd5\u200b\u4e0a\u200b\u4e0d\u540c\u200b\u5f88\u200b\u6709\u7528\u200b\uff08\u200b\u4f5c\u4e3a\u200b\u540d\u8bcd\u200b\u7684\u200b\u94f6\u884c\u200b\u4e0e\u200b\u4f5c\u4e3a\u200b\u52a8\u8bcd\u200b\u7684\u200b\u94f6\u884c\u200b\uff09\u3002</li> </ul> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; classifier = pipeline(task=\"ner\")\n&gt;&gt;&gt; preds = classifier(\"Hugging Face is a French company based in New York City.\")\n&gt;&gt;&gt; preds = [\n...     {\n...         \"entity\": pred[\"entity\"],\n...         \"score\": round(pred[\"score\"], 4),\n...         \"index\": pred[\"index\"],\n...         \"word\": pred[\"word\"],\n...         \"start\": pred[\"start\"],\n...         \"end\": pred[\"end\"],\n...     }\n...     for pred in preds\n... ]\n&gt;&gt;&gt; print(*preds, sep=\"\\n\")\n{'entity': 'I-ORG', 'score': 0.9968, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n{'entity': 'I-ORG', 'score': 0.9293, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n{'entity': 'I-ORG', 'score': 0.9763, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n{'entity': 'I-MISC', 'score': 0.9983, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n{'entity': 'I-LOC', 'score': 0.999, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n{'entity': 'I-LOC', 'score': 0.9987, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n{'entity': 'I-LOC', 'score': 0.9992, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_11","title":"\u95ee\u7b54","text":"<p>\u200b\u95ee\u7b54\u200b\u662f\u200b\u53e6\u200b\u4e00\u4e2a\u200b<code>token-level</code>\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u8fd4\u56de\u200b\u4e00\u4e2a\u200b\u95ee\u9898\u200b\u7684\u200b\u7b54\u6848\u200b\uff0c\u200b\u6709\u65f6\u200b\u5e26\u6709\u200b\u4e0a\u4e0b\u6587\u200b\uff08\u200b\u5f00\u653e\u200b\u9886\u57df\u200b\uff09\uff0c\u200b\u6709\u65f6\u200b\u4e0d\u5e26\u200b\u4e0a\u4e0b\u6587\u200b\uff08\u200b\u5c01\u95ed\u200b\u9886\u57df\u200b\uff09\u3002\u200b\u6bcf\u5f53\u200b\u6211\u4eec\u200b\u5411\u200b\u865a\u62df\u200b\u52a9\u624b\u200b\u63d0\u51fa\u200b\u95ee\u9898\u200b\u65f6\u200b\uff0c\u200b\u4f8b\u5982\u200b\u8be2\u95ee\u200b\u4e00\u5bb6\u200b\u9910\u5385\u200b\u662f\u5426\u200b\u8425\u4e1a\u200b\uff0c\u200b\u5c31\u200b\u4f1a\u200b\u53d1\u751f\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u3002\u200b\u5b83\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u63d0\u4f9b\u200b\u5ba2\u6237\u200b\u6216\u200b\u6280\u672f\u652f\u6301\u200b\uff0c\u200b\u5e76\u200b\u5e2e\u52a9\u200b\u641c\u7d22\u5f15\u64ce\u200b\u68c0\u7d22\u200b\u60a8\u200b\u8981\u6c42\u200b\u7684\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u6709\u200b\u4e24\u79cd\u200b\u5e38\u89c1\u200b\u7684\u200b\u95ee\u7b54\u200b\u7c7b\u578b\u200b\uff1a</p> <ul> <li>\u200b\u63d0\u53d6\u200b\u5f0f\u200b\uff1a\u200b\u7ed9\u5b9a\u200b\u4e00\u4e2a\u200b\u95ee\u9898\u200b\u548c\u200b\u4e00\u4e9b\u200b\u4e0a\u4e0b\u6587\u200b\uff0c\u200b\u7b54\u6848\u200b\u662f\u4ece\u200b\u6a21\u578b\u200b\u5fc5\u987b\u200b\u63d0\u53d6\u200b\u7684\u200b\u4e0a\u4e0b\u6587\u200b\u4e2d\u200b\u7684\u200b\u4e00\u6bb5\u200b\u6587\u672c\u200b\u8de8\u5ea6\u200b\u3002</li> <li>\u200b\u62bd\u8c61\u200b\u5f0f\u200b\uff1a\u200b\u7ed9\u5b9a\u200b\u4e00\u4e2a\u200b\u95ee\u9898\u200b\u548c\u200b\u4e00\u4e9b\u200b\u4e0a\u4e0b\u6587\u200b\uff0c\u200b\u7b54\u6848\u200b\u4ece\u200b\u4e0a\u4e0b\u6587\u200b\u4e2d\u200b\u751f\u6210\u200b\uff1b\u200b\u8fd9\u79cd\u200b\u65b9\u6cd5\u200b\u7531\u200b[<code>Text2TextGenerationPipeline</code>]\u200b\u5904\u7406\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u4e0b\u9762\u200b\u663e\u793a\u200b\u7684\u200b[<code>QuestionAnsweringPipeline</code>]\u3002</li> </ul> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; question_answerer = pipeline(task=\"question-answering\")\n&gt;&gt;&gt; preds = question_answerer(\n...     question=\"What is the name of the repository?\",\n...     context=\"The name of the repository is huggingface/transformers\",\n... )\n&gt;&gt;&gt; print(\n...     f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n... )\nscore: 0.9327, start: 30, end: 54, answer: huggingface/transformers\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_12","title":"\u6458\u8981","text":"<p>\u200b\u6458\u8981\u200b\u4ece\u200b\u8f83\u200b\u957f\u200b\u7684\u200b\u6587\u672c\u200b\u4e2d\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u8f83\u200b\u77ed\u200b\u7684\u200b\u7248\u672c\u200b\uff0c\u200b\u540c\u65f6\u200b\u5c3d\u53ef\u80fd\u200b\u4fdd\u7559\u200b\u539f\u59cb\u200b\u6587\u6863\u200b\u7684\u200b\u5927\u90e8\u5206\u200b\u542b\u4e49\u200b\u3002\u200b\u6458\u8981\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5e8f\u5217\u200b\u5230\u200b\u5e8f\u5217\u200b\u7684\u200b\u4efb\u52a1\u200b\uff1b\u200b\u5b83\u200b\u8f93\u51fa\u200b\u6bd4\u200b\u8f93\u5165\u200b\u66f4\u200b\u77ed\u200b\u7684\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u3002\u200b\u6709\u200b\u8bb8\u591a\u200b\u957f\u7bc7\u200b\u6587\u6863\u200b\u53ef\u4ee5\u200b\u8fdb\u884c\u200b\u6458\u8981\u200b\uff0c\u200b\u4ee5\u200b\u5e2e\u52a9\u200b\u8bfb\u8005\u200b\u5feb\u901f\u200b\u4e86\u89e3\u200b\u4e3b\u8981\u200b\u8981\u70b9\u200b\u3002\u200b\u6cd5\u6848\u200b\u3001\u200b\u6cd5\u5f8b\u200b\u548c\u200b\u8d22\u52a1\u200b\u6587\u4ef6\u200b\u3001\u200b\u4e13\u5229\u200b\u548c\u200b\u79d1\u5b66\u8bba\u6587\u200b\u7b49\u200b\u6587\u6863\u200b\u53ef\u4ee5\u200b\u6458\u8981\u200b\uff0c\u200b\u4ee5\u200b\u8282\u7701\u200b\u8bfb\u8005\u200b\u7684\u200b\u65f6\u95f4\u200b\u5e76\u200b\u4f5c\u4e3a\u200b\u9605\u8bfb\u200b\u8f85\u52a9\u5de5\u5177\u200b\u3002</p> <p>\u200b\u50cf\u200b\u95ee\u7b54\u200b\u4e00\u6837\u200b\uff0c\u200b\u6458\u8981\u200b\u6709\u200b\u4e24\u79cd\u200b\u7c7b\u578b\u200b\uff1a</p> <ul> <li>\u200b\u63d0\u53d6\u200b\u5f0f\u200b\uff1a\u200b\u4ece\u200b\u539f\u59cb\u200b\u6587\u672c\u200b\u4e2d\u200b\u8bc6\u522b\u200b\u548c\u200b\u63d0\u53d6\u200b\u6700\u200b\u91cd\u8981\u200b\u7684\u200b\u53e5\u5b50\u200b</li> <li>\u200b\u62bd\u8c61\u200b\u5f0f\u200b\uff1a\u200b\u4ece\u200b\u539f\u59cb\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u76ee\u6807\u200b\u6458\u8981\u200b\uff08\u200b\u53ef\u80fd\u200b\u5305\u62ec\u200b\u4e0d\u200b\u5728\u200b\u8f93\u5165\u200b\u6587\u6863\u200b\u4e2d\u200b\u7684\u200b\u65b0\u200b\u5355\u8bcd\u200b\uff09\uff1b[<code>SummarizationPipeline</code>]\u200b\u4f7f\u7528\u200b\u62bd\u8c61\u200b\u65b9\u6cd5\u200b\u3002</li> </ul> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; summarizer = pipeline(task=\"summarization\")\n&gt;&gt;&gt; summarizer(\n...     \"In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.\"\n... )\n[{'summary_text': ' The Transformer is the first sequence transduction model based entirely on attention . It replaces the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention . For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers .'}]\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_13","title":"\u7ffb\u8bd1","text":"<p>\u200b\u7ffb\u8bd1\u200b\u5c06\u200b\u4e00\u79cd\u200b\u8bed\u8a00\u200b\u7684\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u53e6\u200b\u4e00\u79cd\u200b\u8bed\u8a00\u200b\u3002\u200b\u5b83\u200b\u5bf9\u4e8e\u200b\u5e2e\u52a9\u200b\u6765\u81ea\u200b\u4e0d\u540c\u200b\u80cc\u666f\u200b\u7684\u200b\u4eba\u4eec\u200b\u76f8\u4e92\u200b\u4ea4\u6d41\u200b\u3001\u200b\u5e2e\u52a9\u200b\u7ffb\u8bd1\u200b\u5185\u5bb9\u200b\u4ee5\u200b\u5438\u5f15\u200b\u66f4\u200b\u5e7f\u6cdb\u200b\u7684\u200b\u53d7\u4f17\u200b\uff0c\u200b\u751a\u81f3\u200b\u6210\u4e3a\u200b\u5b66\u4e60\u200b\u5de5\u5177\u200b\u4ee5\u200b\u5e2e\u52a9\u200b\u4eba\u4eec\u200b\u5b66\u4e60\u200b\u4e00\u95e8\u200b\u65b0\u200b\u8bed\u8a00\u200b\u90fd\u200b\u975e\u5e38\u200b\u91cd\u8981\u200b\u3002\u200b\u9664\u4e86\u200b\u6458\u8981\u200b\u4e4b\u5916\u200b\uff0c\u200b\u7ffb\u8bd1\u200b\u4e5f\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5e8f\u5217\u200b\u5230\u200b\u5e8f\u5217\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u610f\u5473\u7740\u200b\u6a21\u578b\u200b\u63a5\u6536\u200b\u8f93\u5165\u200b\u5e8f\u5217\u200b\u5e76\u200b\u8fd4\u56de\u200b\u76ee\u6807\u200b\u8f93\u51fa\u200b\u5e8f\u5217\u200b\u3002</p> <p>\u200b\u5728\u200b\u65e9\u671f\u200b\uff0c\u200b\u7ffb\u8bd1\u200b\u6a21\u578b\u200b\u5927\u591a\u200b\u662f\u200b\u5355\u8bed\u200b\u7684\u200b\uff0c\u200b\u4f46\u200b\u6700\u8fd1\u200b\uff0c\u200b\u8d8a\u6765\u8d8a\u200b\u591a\u200b\u7684\u200b\u4eba\u200b\u5bf9\u200b\u53ef\u4ee5\u200b\u5728\u200b\u591a\u79cd\u8bed\u8a00\u200b\u4e4b\u95f4\u200b\u8fdb\u884c\u200b\u7ffb\u8bd1\u200b\u7684\u200b\u591a\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u611f\u5174\u8da3\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; text = \"translate English to French: Hugging Face is a community-based open-source platform for machine learning.\"\n&gt;&gt;&gt; translator = pipeline(task=\"translation\", model=\"t5-small\")\n&gt;&gt;&gt; translator(text)\n[{'translation_text': \"Hugging Face est une tribune communautaire de l'apprentissage des machines.\"}]\n</code></pre>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_14","title":"\u8bed\u8a00\u200b\u6a21\u578b","text":"<p>\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u662f\u200b\u4e00\u79cd\u200b\u9884\u6d4b\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u4e2d\u200b\u5355\u8bcd\u200b\u7684\u200b\u4efb\u52a1\u200b\u3002\u200b\u5b83\u200b\u5df2\u200b\u6210\u4e3a\u200b\u4e00\u79cd\u200b\u975e\u5e38\u200b\u6d41\u884c\u200b\u7684\u200bNLP\u200b\u4efb\u52a1\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u53ef\u4ee5\u200b\u5fae\u8c03\u200b\u7528\u4e8e\u200b\u8bb8\u591a\u200b\u5176\u4ed6\u200b\u4e0b\u6e38\u200b\u4efb\u52a1\u200b\u3002\u200b\u6700\u8fd1\u200b\uff0c\u200b\u4eba\u4eec\u200b\u5bf9\u200b\u5927\u578b\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff08LLMs\uff09\u200b\u8868\u73b0\u200b\u51fa\u200b\u4e86\u200b\u6781\u5927\u200b\u7684\u200b\u5174\u8da3\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u6a21\u578b\u200b\u5c55\u793a\u200b\u4e86\u200b<code>zero learning</code>\u200b\u6216\u200b<code>few-shot learning</code>\u200b\u7684\u200b\u80fd\u529b\u200b\u3002\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u6a21\u578b\u200b\u53ef\u4ee5\u200b\u89e3\u51b3\u200b\u5b83\u200b\u672a\u200b\u88ab\u200b\u660e\u786e\u200b\u8bad\u7ec3\u200b\u8fc7\u200b\u7684\u200b\u4efb\u52a1\u200b\uff01\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u53ef\u200b\u7528\u4e8e\u200b\u751f\u6210\u200b\u6d41\u7545\u200b\u548c\u200b\u4ee4\u4eba\u4fe1\u670d\u200b\u7684\u200b\u6587\u672c\u200b\uff0c\u200b\u4f46\u200b\u9700\u8981\u200b\u5c0f\u5fc3\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6587\u672c\u200b\u53ef\u80fd\u200b\u5e76\u200b\u4e0d\u200b\u603b\u662f\u200b\u51c6\u786e\u200b\u7684\u200b\u3002</p> <p>\u200b\u6709\u200b\u4e24\u79cd\u200b\u7c7b\u578b\u200b\u7684\u200b\u8bdd\u8bed\u200b\u6a21\u578b\u200b\uff1a</p> <ul> <li> <p>causal\uff1a\u200b\u6a21\u578b\u200b\u7684\u200b\u76ee\u6807\u200b\u662f\u200b\u9884\u6d4b\u200b\u5e8f\u5217\u200b\u4e2d\u200b\u7684\u200b\u4e0b\u200b\u4e00\u4e2a\u200b<code>token</code>\uff0c\u200b\u800c\u200b\u672a\u6765\u200b\u7684\u200b<code>tokens</code>\u200b\u88ab\u200b\u906e\u76d6\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n\n&gt;&gt;&gt; prompt = \"Hugging Face is a community-based open-source platform for machine learning.\"\n&gt;&gt;&gt; generator = pipeline(task=\"text-generation\")\n&gt;&gt;&gt; generator(prompt)  # doctest: +SKIP\n</code></pre> </li> <li> <p>masked\uff1a\u200b\u6a21\u578b\u200b\u7684\u200b\u76ee\u6807\u200b\u662f\u200b\u9884\u6d4b\u200b\u5e8f\u5217\u200b\u4e2d\u200b\u88ab\u200b\u906e\u853d\u200b\u7684\u200b<code>token</code>\uff0c\u200b\u540c\u65f6\u200b\u5177\u6709\u200b\u5bf9\u200b\u5e8f\u5217\u200b\u4e2d\u200b\u6240\u6709\u200b<code>tokens</code>\u200b\u7684\u200b\u5b8c\u5168\u200b\u8bbf\u95ee\u200b\u6743\u9650\u200b\u3002</p> <pre><code>&gt;&gt;&gt; text = \"Hugging Face is a community-based open-source &lt;mask&gt; for machine learning.\"\n&gt;&gt;&gt; fill_mask = pipeline(task=\"fill-mask\")\n&gt;&gt;&gt; preds = fill_mask(text, top_k=1)\n&gt;&gt;&gt; preds = [\n...     {\n...         \"score\": round(pred[\"score\"], 4),\n...         \"token\": pred[\"token\"],\n...         \"token_str\": pred[\"token_str\"],\n...         \"sequence\": pred[\"sequence\"],\n...     }\n...     for pred in preds\n... ]\n&gt;&gt;&gt; preds\n[{'score': 0.2236,\n  'token': 1761,\n  'token_str': ' platform',\n  'sequence': 'Hugging Face is a community-based open-source platform for machine learning.'}]\n</code></pre> </li> </ul>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_15","title":"\u591a\u200b\u6a21\u6001","text":"<p>\u200b\u591a\u200b\u6a21\u6001\u200b\u4efb\u52a1\u200b\u8981\u6c42\u200b\u6a21\u578b\u200b\u5904\u7406\u200b\u591a\u79cd\u200b\u6570\u636e\u200b\u6a21\u6001\u200b\uff08\u200b\u6587\u672c\u200b\u3001\u200b\u56fe\u50cf\u200b\u3001\u200b\u97f3\u9891\u200b\u3001\u200b\u89c6\u9891\u200b\uff09\u200b\u4ee5\u200b\u89e3\u51b3\u200b\u7279\u5b9a\u200b\u95ee\u9898\u200b\u3002\u200b\u56fe\u50cf\u200b\u63cf\u8ff0\u200b\u662f\u200b\u4e00\u4e2a\u591a\u200b\u6a21\u6001\u200b\u4efb\u52a1\u200b\u7684\u200b\u4f8b\u5b50\u200b\uff0c\u200b\u5176\u4e2d\u200b\u6a21\u578b\u200b\u5c06\u200b\u56fe\u50cf\u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\u5e76\u200b\u8f93\u51fa\u200b\u63cf\u8ff0\u200b\u56fe\u50cf\u200b\u6216\u200b\u56fe\u50cf\u200b\u67d0\u4e9b\u200b\u5c5e\u6027\u200b\u7684\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u3002</p> <p>\u200b\u867d\u7136\u200b\u591a\u200b\u6a21\u6001\u200b\u6a21\u578b\u200b\u5904\u7406\u200b\u4e0d\u540c\u200b\u7684\u200b\u6570\u636e\u7c7b\u578b\u200b\u6216\u200b\u6a21\u6001\u200b\uff0c\u200b\u4f46\u200b\u5185\u90e8\u200b\u9884\u5904\u7406\u200b\u6b65\u9aa4\u200b\u5e2e\u52a9\u200b\u6a21\u578b\u200b\u5c06\u200b\u6240\u6709\u200b\u6570\u636e\u200b\u7c7b\u578b\u8f6c\u6362\u200b\u4e3a\u200b<code>embeddings</code>\uff08\u200b\u5411\u91cf\u200b\u6216\u200b\u6570\u5b57\u200b\u5217\u8868\u200b\uff0c\u200b\u5305\u542b\u200b\u6709\u5173\u200b\u6570\u636e\u200b\u7684\u200b\u6709\u200b\u610f\u4e49\u200b\u4fe1\u606f\u200b\uff09\u3002\u200b\u5bf9\u4e8e\u200b\u50cf\u200b\u56fe\u50cf\u200b\u63cf\u8ff0\u200b\u8fd9\u6837\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u6a21\u578b\u200b\u5b66\u4e60\u200b\u56fe\u50cf\u200b\u5d4c\u5165\u200b\u548c\u200b\u6587\u672c\u200b\u5d4c\u5165\u200b\u4e4b\u95f4\u200b\u7684\u200b\u5173\u7cfb\u200b\u3002</p>"},{"location":"4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/#_16","title":"\u6587\u6863\u200b\u95ee\u7b54","text":"<p>\u200b\u6587\u6863\u200b\u95ee\u7b54\u200b\u662f\u4ece\u200b\u6587\u6863\u200b\u4e2d\u200b\u56de\u7b54\u200b\u81ea\u7136\u8bed\u8a00\u200b\u95ee\u9898\u200b\u7684\u200b\u4efb\u52a1\u200b\u3002\u200b\u4e0e\u200b<code>token-level</code>\u200b\u95ee\u7b54\u200b\u4efb\u52a1\u200b\u4e0d\u540c\u200b\uff0c\u200b\u6587\u6863\u200b\u95ee\u7b54\u200b\u5c06\u200b\u5305\u542b\u200b\u95ee\u9898\u200b\u7684\u200b\u6587\u6863\u200b\u7684\u200b\u56fe\u50cf\u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\uff0c\u200b\u5e76\u200b\u8fd4\u56de\u200b\u7b54\u6848\u200b\u3002\u200b\u6587\u6863\u200b\u95ee\u7b54\u200b\u53ef\u200b\u7528\u4e8e\u200b\u89e3\u6790\u200b\u7ed3\u6784\u5316\u200b\u6587\u6863\u200b\u5e76\u200b\u4ece\u4e2d\u200b\u63d0\u53d6\u200b\u5173\u952e\u200b\u4fe1\u606f\u200b\u3002\u200b\u5728\u200b\u4e0b\u9762\u200b\u7684\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u6536\u636e\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u603b\u91d1\u989d\u200b\u548c\u200b\u627e\u96f6\u200b\u91d1\u989d\u200b\u3002</p> <pre><code>&gt;&gt;&gt; from transformers import pipeline\n&gt;&gt;&gt; from PIL import Image\n&gt;&gt;&gt; import requests\n\n&gt;&gt;&gt; url = \"https://datasets-server.huggingface.co/assets/hf-internal-testing/example-documents/--/hf-internal-testing--example-documents/test/2/image/image.jpg\"\n&gt;&gt;&gt; image = Image.open(requests.get(url, stream=True).raw)\n\n&gt;&gt;&gt; doc_question_answerer = pipeline(\"document-question-answering\", model=\"magorshunov/layoutlm-invoices\")\n&gt;&gt;&gt; preds = doc_question_answerer(\n...     question=\"What is the total amount?\",\n...     image=image,\n... )\n&gt;&gt;&gt; preds\n[{'score': 0.8531, 'answer': '17,000', 'start': 4, 'end': 4}]\n</code></pre> <p>\u200b\u5e0c\u671b\u200b\u8fd9\u4e2a\u200b\u9875\u9762\u200b\u4e3a\u200b\u60a8\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e9b\u200b\u6709\u5173\u200b\u6bcf\u79cd\u200b\u6a21\u6001\u200b\u4e2d\u200b\u6240\u6709\u200b\u7c7b\u578b\u200b\u4efb\u52a1\u200b\u7684\u200b\u80cc\u666f\u200b\u4fe1\u606f\u200b\u4ee5\u53ca\u200b\u6bcf\u4e2a\u200b\u4efb\u52a1\u200b\u7684\u200b\u5b9e\u9645\u200b\u91cd\u8981\u6027\u200b\u3002\u200b\u5728\u200b\u4e0b\u200b\u4e00\u8282\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u4e86\u89e3\u200bTransformers\u200b\u5982\u4f55\u200b\u89e3\u51b3\u200b\u8fd9\u4e9b\u200b\u4efb\u52a1\u200b\u3002</p>"},{"location":"main_classes/deepspeed/","title":"Deepspeed","text":""},{"location":"main_classes/deepspeed/#deepspeed","title":"DeepSpeed\u200b\u96c6\u6210","text":"<p>DeepSpeed\u200b\u5b9e\u73b0\u200b\u4e86\u200bZeRO\u200b\u8bba\u6587\u200b\u4e2d\u200b\u63cf\u8ff0\u200b\u7684\u200b\u6240\u6709\u200b\u5185\u5bb9\u200b\u3002\u200b\u76ee\u524d\u200b\uff0c\u200b\u5b83\u200b\u63d0\u4f9b\u200b\u5bf9\u200b\u4ee5\u4e0b\u200b\u529f\u80fd\u200b\u7684\u200b\u5168\u9762\u200b\u652f\u6301\u200b\uff1a</p> <ol> <li>\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u5206\u533a\u200b\uff08ZeRO stage 1\uff09</li> <li>\u200b\u68af\u5ea6\u200b\u5206\u533a\u200b\uff08ZeRO stage 2\uff09</li> <li>\u200b\u53c2\u6570\u200b\u5206\u533a\u200b\uff08ZeRO stage 3\uff09</li> <li>\u200b\u81ea\u5b9a\u4e49\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u5904\u7406\u200b</li> <li>\u200b\u4e00\u7cfb\u5217\u200b\u57fa\u4e8e\u200bCUDA\u200b\u6269\u5c55\u200b\u7684\u200b\u5feb\u901f\u200b\u4f18\u5316\u200b\u5668\u200b</li> <li>ZeRO-Offload \u200b\u5230\u200b CPU \u200b\u548c\u200b NVMe</li> </ol> <p>ZeRO-Offload\u200b\u6709\u200b\u5176\u200b\u81ea\u5df1\u200b\u7684\u200b\u4e13\u95e8\u200b\u8bba\u6587\u200b\uff1aZeRO-Offload: Democratizing Billion-Scale Model Training\u3002\u200b\u800c\u200bNVMe\u200b\u652f\u6301\u200b\u5728\u200b\u8bba\u6587\u200bZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u4e86\u200b\u63cf\u8ff0\u200b\u3002</p> <p>DeepSpeed ZeRO-2\u200b\u4e3b\u8981\u200b\u7528\u4e8e\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u7684\u200b\u7279\u6027\u200b\u5bf9\u200b\u63a8\u7406\u200b\u6ca1\u6709\u200b\u7528\u5904\u200b\u3002</p> <p>DeepSpeed ZeRO-3\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u7528\u4e8e\u200b\u63a8\u7406\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u5141\u8bb8\u200b\u5c06\u200b\u5355\u4e2a\u200bGPU\u200b\u65e0\u6cd5\u200b\u52a0\u8f7d\u200b\u7684\u200b\u5927\u200b\u6a21\u578b\u200b\u52a0\u8f7d\u200b\u5230\u200b\u591a\u4e2a\u200bGPU\u200b\u4e0a\u200b\u3002</p> <p>\ud83e\udd17 Transformers\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u4e24\u79cd\u200b\u65b9\u5f0f\u200b\u96c6\u6210\u200b\u4e86\u200bDeepSpeed\uff1a</p> <ol> <li>\u200b\u901a\u8fc7\u200b[<code>Trainer</code>]\u200b\u96c6\u6210\u200b\u6838\u5fc3\u200b\u7684\u200bDeepSpeed\u200b\u529f\u80fd\u200b\u3002\u200b\u8fd9\u662f\u200b\u4e00\u79cd\u200b\u201c\u200b\u4e3a\u200b\u60a8\u200b\u5b8c\u6210\u200b\u4e00\u5207\u200b\u201d\u200b\u5f0f\u200b\u7684\u200b\u96c6\u6210\u200b - \u200b\u60a8\u200b\u53ea\u200b\u9700\u200b\u63d0\u4f9b\u200b\u81ea\u5b9a\u4e49\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u6216\u200b\u4f7f\u7528\u200b\u6211\u4eec\u200b\u7684\u200b\u6a21\u677f\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u3002\u200b\u672c\u200b\u6587\u6863\u200b\u7684\u200b\u5927\u90e8\u5206\u200b\u5185\u5bb9\u200b\u90fd\u200b\u96c6\u4e2d\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u529f\u80fd\u200b\u4e0a\u200b\u3002</li> <li>\u200b\u5982\u679c\u200b\u60a8\u200b\u4e0d\u200b\u4f7f\u7528\u200b[<code>Trainer</code>]\u200b\u5e76\u200b\u5e0c\u671b\u200b\u5728\u200b\u81ea\u5df1\u200b\u7684\u200bTrainer\u200b\u4e2d\u200b\u96c6\u6210\u200bDeepSpeed\uff0c\u200b\u90a3\u4e48\u200b\u50cf\u200b<code>from_pretrained</code>\u200b\u548c\u200b<code>from_config</code>\u200b\u8fd9\u6837\u200b\u7684\u200b\u6838\u5fc3\u200b\u529f\u80fd\u200b\u51fd\u6570\u200b\u5c06\u200b\u5305\u62ec\u200bZeRO stage 3\u200b\u53ca\u200b\u4ee5\u4e0a\u200b\u7684\u200bDeepSpeed\u200b\u7684\u200b\u57fa\u7840\u200b\u90e8\u5206\u200b\uff0c\u200b\u5982\u200b<code>zero.Init</code>\u3002\u200b\u8981\u200b\u5229\u7528\u200b\u6b64\u200b\u529f\u80fd\u200b\uff0c\u200b\u8bf7\u200b\u9605\u8bfb\u200b\u6709\u5173\u200b\u975e\u200bTrainer DeepSpeed\u200b\u96c6\u6210\u200b\u7684\u200b\u6587\u6863\u200b\u3002</li> </ol> <p>\u200b\u96c6\u6210\u200b\u7684\u200b\u5185\u5bb9\u200b\uff1a</p> <p>\u200b\u8bad\u7ec3\u200b\uff1a</p> <ol> <li>DeepSpeed ZeRO\u200b\u8bad\u7ec3\u200b\u652f\u6301\u200b\u5b8c\u6574\u200b\u7684\u200bZeRO stages 1\u30012\u200b\u548c\u200b3\uff0c\u200b\u4ee5\u53ca\u200bZeRO-Infinity\uff08CPU\u200b\u548c\u200bNVMe offload\uff09\u3002</li> </ol> <p>\u200b\u63a8\u7406\u200b\uff1a</p> <ol> <li>DeepSpeed ZeRO\u200b\u63a8\u7406\u200b\u652f\u6301\u200bZeRO stage 3\u200b\u548c\u200bZeRO-Infinity\u3002\u200b\u5b83\u200b\u4f7f\u7528\u200b\u4e0e\u200b\u8bad\u7ec3\u200b\u76f8\u540c\u200b\u7684\u200bZeRO\u200b\u534f\u8bae\u200b\uff0c\u200b\u4f46\u200b\u4e0d\u200b\u4f7f\u7528\u200b\u4f18\u5316\u200b\u5668\u200b\u548c\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u5ea6\u200b\u5668\u200b\uff0c\u200b\u53ea\u6709\u200bstage 3\u200b\u4e0e\u200b\u63a8\u7406\u200b\u76f8\u5173\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\u8bf7\u53c2\u9605\u200b\uff1azero-inference\u3002</li> </ol> <p>\u200b\u6b64\u5916\u200b\u8fd8\u6709\u200bDeepSpeed\u200b\u63a8\u7406\u200b - \u200b\u8fd9\u662f\u200b\u4e00\u79cd\u200b\u5b8c\u5168\u200b\u4e0d\u540c\u200b\u7684\u200b\u6280\u672f\u200b\uff0c\u200b\u5b83\u200b\u4f7f\u7528\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u800c\u200b\u4e0d\u662f\u200bZeRO\uff08\u200b\u5373\u5c06\u200b\u63a8\u51fa\u200b\uff09\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#trainer-deepspeed","title":"Trainer DeepSpeed \u200b\u96c6\u6210","text":""},{"location":"main_classes/deepspeed/#_1","title":"\u5b89\u88c5","text":"<p>\u200b\u901a\u8fc7\u200bpypi\u200b\u5b89\u88c5\u200b\u5e93\u200b\uff1a</p> <pre><code>pip install deepspeed\n</code></pre> <p>\u200b\u6216\u200b\u901a\u8fc7\u200b <code>transformers</code> \u200b\u7684\u200b <code>extras</code>\u200b\u5b89\u88c5\u200b\uff1a</p> <pre><code>pip install transformers[deepspeed]\n</code></pre> <p>\u200b\u6216\u200b\u5728\u200b DeepSpeed \u200b\u7684\u200b GitHub \u200b\u9875\u9762\u200b \u200b\u548c\u200b \u200b\u9ad8\u7ea7\u200b\u5b89\u88c5\u200b \u200b\u4e2d\u200b\u67e5\u627e\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u6784\u5efa\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u4ecd\u7136\u200b\u9047\u5230\u200b\u95ee\u9898\u200b\uff0c\u200b\u8bf7\u200b\u9996\u5148\u200b\u786e\u4fdd\u200b\u9605\u8bfb\u200b CUDA \u200b\u6269\u5c55\u200b\u5b89\u88c5\u200b\u6ce8\u610f\u4e8b\u9879\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u6ca1\u6709\u200b\u9884\u5148\u200b\u6784\u5efa\u200b\u6269\u5c55\u200b\u800c\u662f\u200b\u5728\u200b\u8fd0\u884c\u200b\u65f6\u200b\u6784\u5efa\u200b\u5b83\u4eec\u200b\uff0c\u200b\u800c\u4e14\u200b\u60a8\u200b\u5c1d\u8bd5\u200b\u4e86\u200b\u4ee5\u4e0a\u200b\u6240\u6709\u200b\u89e3\u51b3\u65b9\u6848\u200b\u90fd\u200b\u65e0\u6548\u200b\uff0c\u200b\u4e0b\u200b\u4e00\u6b65\u200b\u53ef\u4ee5\u200b\u5c1d\u8bd5\u200b\u5728\u200b\u5b89\u88c5\u200b\u4e4b\u524d\u200b\u9884\u5148\u200b\u6784\u5efa\u200b\u6269\u5c55\u200b\u3002</p> <p>\u200b\u8fdb\u884c\u200b DeepSpeed \u200b\u7684\u200b\u672c\u5730\u200b\u6784\u5efa\u200b\uff1a</p> <pre><code>git clone https://github.com/microsoft/DeepSpeed/\ncd DeepSpeed\nrm -rf build\nTORCH_CUDA_ARCH_LIST=\"8.6\" DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1 pip install . \\\n--global-option=\"build_ext\" --global-option=\"-j8\" --no-cache -v \\\n--disable-pip-version-check 2&gt;&amp;1 | tee build.log\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u6253\u7b97\u200b\u4f7f\u7528\u200b NVMe offload\uff0c\u200b\u60a8\u200b\u8fd8\u200b\u9700\u8981\u200b\u5728\u200b\u4e0a\u8ff0\u200b\u8bf4\u660e\u200b\u4e2d\u200b\u6dfb\u52a0\u200b <code>DS_BUILD_AIO=1</code>\uff08\u200b\u5e76\u4e14\u200b\u8fd8\u200b\u9700\u8981\u200b\u5728\u200b\u7cfb\u7edf\u200b\u8303\u56f4\u200b\u5185\u200b\u5b89\u88c5\u200b libaio-dev\uff09\u3002</p> <p>\u200b\u7f16\u8f91\u200b <code>TORCH_CUDA_ARCH_LIST</code> \u200b\u4ee5\u200b\u63d2\u5165\u200b\u60a8\u200b\u6253\u7b97\u200b\u4f7f\u7528\u200b\u7684\u200b GPU \u200b\u5361\u200b\u7684\u200b\u67b6\u6784\u200b\u4ee3\u7801\u200b\u3002\u200b\u5047\u8bbe\u200b\u60a8\u200b\u7684\u200b\u6240\u6709\u200b\u5361\u200b\u90fd\u200b\u662f\u200b\u76f8\u540c\u200b\u7684\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u83b7\u53d6\u200b\u67b6\u6784\u200b\uff1a</p> <pre><code>CUDA_VISIBLE_DEVICES=0 python -c \"import torch; print(torch.cuda.get_device_capability())\"\n</code></pre> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u5f97\u5230\u200b <code>8, 6</code>\uff0c\u200b\u5219\u200b\u4f7f\u7528\u200b <code>TORCH_CUDA_ARCH_LIST=\"8.6\"</code>\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200b\u591a\u4e2a\u200b\u4e0d\u540c\u200b\u7684\u200b\u5361\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u50cf\u200b\u8fd9\u6837\u200b\u5217\u51fa\u200b\u6240\u6709\u200b\u5361\u200b <code>TORCH_CUDA_ARCH_LIST=\"6.1;8.6\"</code>\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u9700\u8981\u200b\u5728\u200b\u591a\u53f0\u200b\u673a\u5668\u200b\u4e0a\u200b\u4f7f\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u8bbe\u7f6e\u200b\uff0c\u200b\u8bf7\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u4e8c\u8fdb\u5236\u200b wheel\uff1a</p> <pre><code>git clone https://github.com/microsoft/DeepSpeed/\ncd DeepSpeed\nrm -rf build\nTORCH_CUDA_ARCH_LIST=\"8.6\" DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1 \\\npython setup.py build_ext -j8 bdist_wheel\n</code></pre> <p>\u200b\u5b83\u200b\u5c06\u200b\u751f\u6210\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b <code>dist/deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl</code> \u200b\u7684\u200b\u6587\u4ef6\u200b\uff0c\u200b\u73b0\u5728\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u672c\u5730\u200b\u6216\u200b\u4efb\u4f55\u200b\u5176\u4ed6\u200b\u673a\u5668\u200b\u4e0a\u200b\u5b89\u88c5\u200b\u5b83\u200b\uff0c\u200b\u5982\u200b <code>pip install deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl</code>\u3002</p> <p>\u200b\u518d\u6b21\u200b\u63d0\u9192\u200b\u786e\u4fdd\u200b\u8c03\u6574\u200b <code>TORCH_CUDA_ARCH_LIST</code> \u200b\u4ee5\u200b\u5339\u914d\u200b\u76ee\u6807\u200b\u67b6\u6784\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u8fd9\u91cc\u200b\u627e\u5230\u200b\u5b8c\u6574\u200b\u7684\u200b NVIDIA GPU \u200b\u5217\u8868\u200b\u53ca\u5176\u200b\u5bf9\u5e94\u200b\u7684\u200b \u200b\u8ba1\u7b97\u80fd\u529b\u200b\uff08\u200b\u4e0e\u200b\u6b64\u200b\u4e0a\u4e0b\u6587\u200b\u4e2d\u200b\u7684\u200b\u67b6\u6784\u200b\u76f8\u540c\u200b\uff09\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u68c0\u67e5\u200b PyTorch \u200b\u6784\u5efa\u200b\u65f6\u200b\u4f7f\u7528\u200b\u7684\u200b\u67b6\u6784\u200b\uff1a</p> <pre><code>python -c \"import torch; print(torch.cuda.get_arch_list())\"\n</code></pre> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u5982\u4f55\u200b\u67e5\u627e\u200b\u5df2\u200b\u5b89\u88c5\u200b GPU \u200b\u4e2d\u200b\u7684\u200b\u4e00\u5f20\u200b\u5361\u200b\u7684\u200b\u67b6\u6784\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5bf9\u4e8e\u200b GPU 0\uff1a</p> <pre><code>CUDA_VISIBLE_DEVICES=0 python -c \"import torch; \\\nprint(torch.cuda.get_device_properties(torch.device('cuda')))\"\n</code></pre> <p>\u200b\u5982\u679c\u200b\u8f93\u51fa\u200b\u7ed3\u679c\u200b\u5982\u4e0b\u200b\uff1a</p> <pre><code>_CudaDeviceProperties(name='GeForce RTX 3090', major=8, minor=6, total_memory=24268MB, multi_processor_count=82)\n</code></pre> <p>\u200b\u7136\u540e\u200b\u60a8\u200b\u5c31\u200b\u77e5\u9053\u200b\u8fd9\u200b\u5f20\u5361\u200b\u7684\u200b\u67b6\u6784\u200b\u662f\u200b <code>8.6</code>\u3002</p> <p>\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u5b8c\u5168\u200b\u7701\u7565\u200b <code>TORCH_CUDA_ARCH_LIST</code>\uff0c\u200b\u7136\u540e\u200b\u6784\u5efa\u200b\u7a0b\u5e8f\u200b\u5c06\u200b\u81ea\u52a8\u200b\u67e5\u8be2\u200b\u6784\u5efa\u200b\u6240\u5728\u200b\u7684\u200b GPU \u200b\u7684\u200b\u67b6\u6784\u200b\u3002\u200b\u8fd9\u200b\u53ef\u80fd\u200b\u4e0e\u200b\u76ee\u6807\u200b\u673a\u5668\u200b\u4e0a\u200b\u7684\u200b GPU \u200b\u4e0d\u200b\u5339\u914d\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6700\u597d\u200b\u660e\u786e\u200b\u6307\u5b9a\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u67b6\u6784\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u5c1d\u8bd5\u200b\u4e86\u200b\u6240\u6709\u200b\u5efa\u8bae\u200b\u7684\u200b\u65b9\u6cd5\u200b\u4ecd\u7136\u200b\u9047\u5230\u200b\u6784\u5efa\u200b\u95ee\u9898\u200b\uff0c\u200b\u8bf7\u200b\u7ee7\u7eed\u200b\u5728\u200b Deepspeed\u200b\u7684\u200b GitHub Issue \u200b\u4e0a\u200b\u63d0\u4ea4\u200b\u95ee\u9898\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#gpu","title":"\u591a\u200bGPU\u200b\u542f\u7528","text":"<p>\u200b\u4e3a\u4e86\u200b\u542f\u7528\u200bDeepSpeed \u200b\u96c6\u6210\u200b\uff0c\u200b\u8c03\u6574\u200b [<code>Trainer</code>] \u200b\u7684\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\uff0c\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b\u53c2\u6570\u200b <code>--deepspeed ds_config.json</code>\uff0c\u200b\u5176\u4e2d\u200b <code>ds_config.json</code> \u200b\u662f\u200b DeepSpeed \u200b\u914d\u7f6e\u6587\u4ef6\u200b\uff0c\u200b\u5982\u200b\u6587\u6863\u200b \u200b\u8fd9\u91cc\u200b \u200b\u6240\u8ff0\u200b\u3002\u200b\u6587\u4ef6\u200b\u547d\u540d\u200b\u7531\u200b\u60a8\u200b\u51b3\u5b9a\u200b\u3002 \u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200b DeepSpeed \u200b\u7684\u200b <code>add_config_arguments</code> \u200b\u7a0b\u5e8f\u200b\u5c06\u200b\u5fc5\u8981\u200b\u7684\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u6dfb\u52a0\u200b\u5230\u200b\u60a8\u200b\u7684\u200b\u4ee3\u7801\u200b\u4e2d\u200b\u3002 \u200b\u6709\u5173\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b DeepSpeed \u200b\u7684\u200b\u53c2\u6570\u200b\u89e3\u6790\u200b \u200b\u6587\u6863\u200b\u3002</p> <p>\u200b\u5728\u200b\u8fd9\u91cc\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u60a8\u200b\u559c\u6b22\u200b\u7684\u200b\u542f\u52a8\u5668\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u7ee7\u7eed\u200b\u4f7f\u7528\u200b PyTorch \u200b\u542f\u52a8\u5668\u200b\uff1a</p> <pre><code>torch.distributed.run --nproc_per_node=2 your_program.py &lt;normal cl args&gt; --deepspeed ds_config.json\n</code></pre> <p>\u200b\u6216\u200b\u4f7f\u7528\u200b\u7531\u200b <code>deepspeed</code> \u200b\u63d0\u4f9b\u200b\u7684\u200b\u542f\u52a8\u5668\u200b\uff1a</p> <pre><code>deepspeed --num_gpus=2 your_program.py &lt;normal cl args&gt; --deepspeed ds_config.json\n</code></pre> <p>\u200b\u6b63\u5982\u200b\u60a8\u200b\u6240\u89c1\u200b\uff0c\u200b\u8fd9\u200b\u4e24\u4e2a\u200b\u542f\u52a8\u5668\u200b\u7684\u200b\u53c2\u6570\u200b\u4e0d\u540c\u200b\uff0c\u200b\u4f46\u200b\u5bf9\u4e8e\u200b\u5927\u591a\u6570\u200b\u9700\u6c42\u200b\uff0c\u200b\u4efb\u4f55\u200b\u4e00\u4e2a\u200b\u90fd\u200b\u53ef\u4ee5\u200b\u6ee1\u8db3\u200b\u5de5\u4f5c\u200b\u9700\u6c42\u200b\u3002\u200b\u6709\u5173\u200b\u5982\u4f55\u200b\u914d\u7f6e\u200b\u5404\u4e2a\u200b\u8282\u70b9\u200b\u548c\u200b GPU \u200b\u7684\u200b\u5b8c\u6574\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u200b\u67e5\u770b\u200b \u200b\u6b64\u5904\u200b\u3002</p> <p>\u200b\u5f53\u200b\u60a8\u200b\u4f7f\u7528\u200b <code>deepspeed</code> \u200b\u542f\u52a8\u5668\u200b\u5e76\u4e14\u200b\u5e0c\u671b\u200b\u4f7f\u7528\u200b\u6240\u6709\u200b\u53ef\u7528\u200b\u7684\u200b GPU \u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u7b80\u5355\u200b\u5730\u200b\u7701\u7565\u200b <code>--num_gpus</code> \u200b\u6807\u5fd7\u200b\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u5728\u200b DeepSpeed \u200b\u4e2d\u200b\u542f\u7528\u200b\u4f7f\u7528\u200b\u6240\u6709\u200b\u53ef\u7528\u200b GPU\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c \u200b\u8fd0\u884c\u200b <code>run_translation.py</code> \u200b\u7684\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>deepspeed examples/pytorch/translation/run_translation.py \\\n--deepspeed tests/deepspeed/ds_config_zero3.json \\\n--model_name_or_path t5-small --per_device_train_batch_size 1 \\\n--output_dir output_dir --overwrite_output_dir --fp16 \\\n--do_train --max_train_samples 500 --num_train_epochs 1 \\\n--dataset_name wmt16 --dataset_config \"ro-en\" \\\n--source_lang en --target_lang ro\n</code></pre> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u5728\u200b DeepSpeed \u200b\u6587\u6863\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u770b\u5230\u200b <code>--deepspeed --deepspeed_config ds_config.json</code> - \u200b\u5373\u200b\u4e24\u4e2a\u200b\u4e0e\u200b DeepSpeed \u200b\u76f8\u5173\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u4f46\u200b\u4e3a\u200b\u7b80\u5355\u200b\u8d77\u200b\u89c1\u200b\uff0c\u200b\u5e76\u4e14\u200b\u56e0\u4e3a\u200b\u5df2\u7ecf\u200b\u6709\u200b\u5f88\u591a\u200b\u53c2\u6570\u200b\u8981\u200b\u5904\u7406\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u4e24\u8005\u200b\u5408\u5e76\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u5355\u4e00\u200b\u53c2\u6570\u200b\u3002</p> <p>\u200b\u6709\u5173\u200b\u4e00\u4e9b\u200b\u5b9e\u9645\u200b\u4f7f\u7528\u200b\u793a\u4f8b\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b \u200b\u6b64\u5e16\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#gpu_1","title":"\u5355\u200bGPU\u200b\u542f\u7528","text":"<p>\u200b\u8981\u200b\u4f7f\u7528\u200b\u4e00\u5f20\u200b GPU \u200b\u542f\u7528\u200b DeepSpeed\uff0c\u200b\u8c03\u6574\u200b [<code>Trainer</code>] \u200b\u7684\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u5982\u4e0b\u200b\uff1a</p> <pre><code>deepspeed --num_gpus=1 examples/pytorch/translation/run_translation.py \\\n--deepspeed tests/deepspeed/ds_config_zero2.json \\\n--model_name_or_path t5-small --per_device_train_batch_size 1 \\\n--output_dir output_dir --overwrite_output_dir --fp16 \\\n--do_train --max_train_samples 500 --num_train_epochs 1 \\\n--dataset_name wmt16 --dataset_config \"ro-en\" \\\n--source_lang en --target_lang ro\n</code></pre> <p>\u200b\u8fd9\u200b\u4e0e\u200b\u591a\u200b GPU \u200b\u7684\u200b\u60c5\u51b5\u200b\u51e0\u4e4e\u200b\u76f8\u540c\u200b\uff0c\u200b\u4f46\u200b\u5728\u200b\u8fd9\u91cc\u200b\u6211\u4eec\u200b\u901a\u8fc7\u200b <code>--num_gpus=1</code> \u200b\u660e\u786e\u200b\u544a\u8bc9\u200b DeepSpeed \u200b\u4ec5\u200b\u4f7f\u7528\u200b\u4e00\u5f20\u200b GPU\u3002\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0cDeepSpeed \u200b\u542f\u7528\u200b\u7ed9\u5b9a\u200b\u8282\u70b9\u200b\u4e0a\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200b\u7684\u200b\u6240\u6709\u200b GPU\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u4e00\u200b\u5f00\u59cb\u200b\u53ea\u6709\u200b\u4e00\u5f20\u200b GPU\uff0c\u200b\u90a3\u4e48\u200b\u60a8\u200b\u4e0d\u200b\u9700\u8981\u200b\u8fd9\u4e2a\u200b\u53c2\u6570\u200b\u3002\u200b\u4ee5\u4e0b\u200b \u200b\u6587\u6863\u200b \u200b\u8ba8\u8bba\u200b\u4e86\u200b\u542f\u52a8\u5668\u200b\u7684\u200b\u9009\u9879\u200b\u3002</p> <p>\u200b\u4e3a\u4ec0\u4e48\u200b\u8981\u200b\u5728\u200b\u4ec5\u200b\u4f7f\u7528\u200b\u4e00\u5f20\u200b GPU \u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4f7f\u7528\u200b DeepSpeed \u200b\u5462\u200b\uff1f</p> <ol> <li>\u200b\u5b83\u200b\u5177\u6709\u200b ZeRO-offload \u200b\u529f\u80fd\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u4e00\u4e9b\u200b\u8ba1\u7b97\u200b\u548c\u200b\u5185\u5b58\u200b\u59d4\u6258\u200b\u7ed9\u200b\u4e3b\u673a\u200b\u7684\u200b CPU \u200b\u548c\u200b \u200b\u5185\u5b58\u200b\uff0c\u200b\u4ece\u800c\u200b\u4e3a\u200b\u6a21\u578b\u200b\u7684\u200b\u9700\u6c42\u200b\u4fdd\u7559\u200b\u66f4\u200b\u591a\u200b GPU \u200b\u8d44\u6e90\u200b - \u200b\u4f8b\u5982\u200b\u66f4\u5927\u200b\u7684\u200b\u6279\u5904\u7406\u200b\u5927\u5c0f\u200b\uff0c\u200b\u6216\u200b\u542f\u7528\u200b\u6b63\u5e38\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u65e0\u6cd5\u200b\u5bb9\u7eb3\u200b\u7684\u200b\u975e\u5e38\u200b\u5927\u200b\u6a21\u578b\u200b\u3002</li> <li>\u200b\u5b83\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u667a\u80fd\u200b\u7684\u200b GPU \u200b\u5185\u5b58\u200b\u7ba1\u7406\u7cfb\u7edf\u200b\uff0c\u200b\u6700\u5c0f\u5316\u200b\u5185\u5b58\u200b\u788e\u7247\u200b\uff0c\u200b\u8fd9\u200b\u518d\u6b21\u200b\u5141\u8bb8\u200b\u60a8\u200b\u5bb9\u7eb3\u200b\u66f4\u5927\u200b\u7684\u200b\u6a21\u578b\u200b\u548c\u200b\u6570\u636e\u200b\u6279\u6b21\u200b\u3002</li> </ol> <p>\u200b\u867d\u7136\u200b\u63a5\u4e0b\u6765\u200b\u6211\u4eec\u200b\u5c06\u200b\u8be6\u7ec6\u200b\u8ba8\u8bba\u200b\u914d\u7f6e\u200b\uff0c\u200b\u4f46\u200b\u5728\u200b\u5355\u4e2a\u200b GPU \u200b\u4e0a\u200b\u901a\u8fc7\u200b DeepSpeed \u200b\u5b9e\u73b0\u200b\u5de8\u5927\u200b\u6027\u80fd\u200b\u63d0\u5347\u200b\u7684\u200b\u5173\u952e\u200b\u662f\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u81f3\u5c11\u200b\u6709\u200b\u4ee5\u4e0b\u200b\u914d\u7f6e\u200b\uff1a</p> <pre><code>{\n  \"zero_optimization\": {\n     \"stage\": 2,\n     \"offload_optimizer\": {\n         \"device\": \"cpu\",\n         \"pin_memory\": true\n     },\n     \"allgather_partitions\": true,\n     \"allgather_bucket_size\": 2e8,\n     \"reduce_scatter\": true,\n     \"reduce_bucket_size\": 2e8,\n     \"overlap_comm\": true,\n     \"contiguous_gradients\": true\n  }\n}\n</code></pre> <p>\u200b\u8fd9\u4f1a\u200b\u542f\u7528\u200b<code>optimizer offload</code>\u200b\u548c\u200b\u4e00\u4e9b\u200b\u5176\u4ed6\u200b\u91cd\u8981\u200b\u529f\u80fd\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c1d\u8bd5\u200b\u4e0d\u540c\u200b\u7684\u200bbuffer\u200b\u5927\u5c0f\u200b\uff0c\u200b\u6709\u5173\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u89c1\u200b\u4e0b\u9762\u200b\u7684\u200b\u8ba8\u8bba\u200b\u3002</p> <p>\u200b\u5173\u4e8e\u200b\u8fd9\u79cd\u200b\u542f\u7528\u200b\u7c7b\u578b\u200b\u7684\u200b\u5b9e\u9645\u200b\u4f7f\u7528\u200b\u793a\u4f8b\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b \u200b\u6b64\u5e16\u200b\u3002</p> <p>\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u5c1d\u8bd5\u200b\u4f7f\u7528\u200b\u672c\u6587\u200b\u540e\u9762\u200b\u8fdb\u4e00\u6b65\u200b\u89e3\u91ca\u200b\u7684\u200b\u652f\u6301\u200b<code>CPU \u200b\u548c\u200b NVMe offload</code>\u200b\u529f\u80fd\u200b\u7684\u200bZeRO-3 \u3002</p> <p>\u200b\u6ce8\u610f\u200b\uff1a</p> <ul> <li>\u200b\u5982\u679c\u200b\u60a8\u200b\u9700\u8981\u200b\u5728\u200b\u7279\u5b9a\u200b\u7684\u200b GPU \u200b\u4e0a\u200b\u8fd0\u884c\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b GPU 0\uff0c\u200b\u5219\u200b\u65e0\u6cd5\u200b\u4f7f\u7528\u200b <code>CUDA_VISIBLE_DEVICES</code> \u200b\u6765\u200b\u9650\u5236\u200b\u53ef\u7528\u200b GPU \u200b\u7684\u200b\u53ef\u89c1\u200b\u8303\u56f4\u200b\u3002\u200b\u76f8\u53cd\u200b\uff0c\u200b\u60a8\u200b\u5fc5\u987b\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u8bed\u6cd5\u200b\uff1a</li> </ul> <pre><code>deepspeed --include localhost:1 examples/pytorch/translation/run_translation.py ...\n</code></pre> <p>\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u544a\u8bc9\u200b DeepSpeed \u200b\u4f7f\u7528\u200b GPU 1\uff08\u200b\u7b2c\u4e8c\u4e2a\u200b GPU\uff09\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#_2","title":"\u591a\u200b\u8282\u70b9\u200b\u542f\u7528","text":"<p>\u200b\u8fd9\u200b\u4e00\u90e8\u5206\u200b\u7684\u200b\u4fe1\u606f\u200b\u4e0d\u4ec5\u200b\u9002\u7528\u200b\u4e8e\u200b DeepSpeed \u200b\u96c6\u6210\u200b\uff0c\u200b\u4e5f\u200b\u9002\u7528\u200b\u4e8e\u200b\u4efb\u4f55\u200b\u591a\u200b\u8282\u70b9\u200b\u7a0b\u5e8f\u200b\u3002\u200b\u4f46\u200b DeepSpeed \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u6bd4\u200b\u5176\u4ed6\u200b\u542f\u52a8\u5668\u200b\u66f4\u200b\u6613\u4e8e\u200b\u4f7f\u7528\u200b\u7684\u200b <code>deepspeed</code> \u200b\u542f\u52a8\u5668\u200b\uff0c\u200b\u9664\u975e\u200b\u60a8\u200b\u5728\u200b SLURM \u200b\u73af\u5883\u200b\u4e2d\u200b\u3002</p> <p>\u200b\u5728\u200b\u672c\u8282\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u5047\u8bbe\u200b\u60a8\u200b\u6709\u200b\u4e24\u4e2a\u200b\u8282\u70b9\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u8282\u70b9\u200b\u6709\u200b 8 \u200b\u5f20\u200b GPU\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b <code>ssh hostname1</code> \u200b\u8bbf\u95ee\u200b\u7b2c\u4e00\u4e2a\u200b\u8282\u70b9\u200b\uff0c\u200b\u901a\u8fc7\u200b <code>ssh hostname2</code> \u200b\u8bbf\u95ee\u200b\u7b2c\u4e8c\u4e2a\u200b\u8282\u70b9\u200b\uff0c\u200b\u4e24\u8005\u200b\u5fc5\u987b\u200b\u80fd\u591f\u200b\u5728\u200b\u672c\u5730\u200b\u901a\u8fc7\u200b ssh \u200b\u65e0\u200b\u5bc6\u7801\u200b\u65b9\u5f0f\u200b\u76f8\u4e92\u200b\u8bbf\u95ee\u200b\u3002\u200b\u5f53\u7136\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5c06\u200b\u8fd9\u4e9b\u200b\u4e3b\u673a\u200b\uff08\u200b\u8282\u70b9\u200b\uff09\u200b\u540d\u79f0\u200b\u91cd\u547d\u540d\u200b\u4e3a\u200b\u60a8\u200b\u5b9e\u9645\u200b\u4f7f\u7528\u200b\u7684\u200b\u4e3b\u673a\u200b\u540d\u79f0\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#torchdistributedrun","title":"torch.distributed.run\u200b\u542f\u52a8\u5668","text":"<p>\u200b\u4f8b\u5982\u200b\uff0c\u200b\u8981\u200b\u4f7f\u7528\u200b <code>torch.distributed.run</code>\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\uff1a</p> <pre><code>python -m torch.distributed.run --nproc_per_node=8 --nnode=2 --node_rank=0 --master_addr=hostname1 \\\n--master_port=9901 your_program.py &lt;normal cl args&gt; --deepspeed ds_config.json\n</code></pre> <p>\u200b\u60a8\u200b\u5fc5\u987b\u200b ssh \u200b\u5230\u200b\u6bcf\u4e2a\u200b\u8282\u70b9\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u8282\u70b9\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u76f8\u540c\u200b\u7684\u200b\u547d\u4ee4\u200b\uff01\u200b\u4e0d\u7528\u200b\u62c5\u5fc3\u200b\uff0c\u200b\u542f\u52a8\u5668\u200b\u4f1a\u200b\u7b49\u5f85\u200b\u4e24\u4e2a\u200b\u8282\u70b9\u200b\u540c\u6b65\u200b\u5b8c\u6210\u200b\u3002</p> <p>\u200b\u6709\u5173\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b torchrun\u3002\u200b\u987a\u4fbf\u200b\u8bf4\u200b\u4e00\u4e0b\u200b\uff0c\u200b\u8fd9\u200b\u4e5f\u200b\u662f\u200b\u66ff\u4ee3\u200b\u4e86\u200b\u51e0\u4e2a\u200b PyTorch \u200b\u7248\u672c\u200b\u524d\u200b\u7684\u200b <code>torch.distributed.launch</code> \u200b\u7684\u200b\u542f\u52a8\u5668\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#deepspeed_1","title":"deepspeed\u200b\u542f\u52a8\u5668","text":"<p>\u200b\u8981\u200b\u6539\u7528\u200b <code>deepspeed</code> \u200b\u542f\u52a8\u5668\u200b\uff0c\u200b\u9996\u5148\u200b\u9700\u8981\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b <code>hostfile</code> \u200b\u6587\u4ef6\u200b\uff1a</p> <p><pre><code>hostname1 slots=8\nhostname2 slots=8\n</code></pre> \u200b\u7136\u540e\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8fd9\u6837\u200b\u542f\u52a8\u200b\uff1a</p> <pre><code>deepspeed --num_gpus 8 --num_nodes 2 --hostfile hostfile --master_addr hostname1 --master_port=9901 \\\nyour_program.py &lt;normal cl args&gt; --deepspeed ds_config.json\n</code></pre> <p>\u200b\u4e0e\u200b <code>torch.distributed.run</code> \u200b\u542f\u52a8\u5668\u200b\u4e0d\u540c\u200b\uff0c<code>deepspeed</code> \u200b\u5c06\u200b\u81ea\u52a8\u200b\u5728\u200b\u4e24\u4e2a\u200b\u8282\u70b9\u200b\u4e0a\u200b\u542f\u52a8\u200b\u6b64\u200b\u547d\u4ee4\u200b\uff01</p> <p>\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u8d44\u6e90\u914d\u7f6e\u200b\uff08\u200b\u591a\u200b\u8282\u70b9\u200b\uff09\u3002</p>"},{"location":"main_classes/deepspeed/#slurm","title":"\u5728\u200b SLURM \u200b\u73af\u5883\u200b\u4e2d\u200b\u542f\u52a8","text":"<p>\u200b\u5728\u200b SLURM \u200b\u73af\u5883\u200b\u4e2d\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u91c7\u7528\u200b\u4ee5\u4e0b\u200b\u65b9\u6cd5\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u4e00\u4e2a\u200b SLURM \u200b\u811a\u672c\u200b <code>launch.slurm</code>\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u6839\u636e\u200b\u60a8\u200b\u7684\u200b\u5177\u4f53\u200b SLURM \u200b\u73af\u5883\u200b\u8fdb\u884c\u200b\u8c03\u6574\u200b\u3002</p> <pre><code>#SBATCH --job-name=test-nodes        # name\n#SBATCH --nodes=2                    # nodes\n#SBATCH --ntasks-per-node=1          # crucial - only 1 task per dist per node!\n#SBATCH --cpus-per-task=10           # number of cores per tasks\n#SBATCH --gres=gpu:8                 # number of gpus\n#SBATCH --time 20:00:00              # maximum execution time (HH:MM:SS)\n#SBATCH --output=%x-%j.out           # output file name\n\nexport GPUS_PER_NODE=8\nexport MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)\nexport MASTER_PORT=9901\n\nsrun --jobid $SLURM_JOBID bash -c 'python -m torch.distributed.run \\\n --nproc_per_node $GPUS_PER_NODE --nnodes $SLURM_NNODES --node_rank $SLURM_PROCID \\\n --master_addr $MASTER_ADDR --master_port $MASTER_PORT \\\nyour_program.py &lt;normal cl args&gt; --deepspeed ds_config.json'\n</code></pre> <p>\u200b\u5269\u4e0b\u200b\u7684\u200b\u5c31\u662f\u200b\u8fd0\u884c\u200b\u5b83\u200b\uff1a</p> <pre><code>sbatch launch.slurm\n</code></pre> <p><code>srun</code> \u200b\u5c06\u200b\u8d1f\u8d23\u200b\u5728\u200b\u6240\u6709\u200b\u8282\u70b9\u200b\u4e0a\u200b\u540c\u65f6\u200b\u542f\u52a8\u200b\u7a0b\u5e8f\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#_3","title":"\u4f7f\u7528\u200b\u975e\u200b\u5171\u4eab\u200b\u6587\u4ef6\u7cfb\u7edf","text":"<p>\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0cDeepSpeed \u200b\u5047\u5b9a\u200b\u591a\u200b\u8282\u70b9\u200b\u73af\u5883\u200b\u4f7f\u7528\u200b\u5171\u4eab\u200b\u5b58\u50a8\u200b\u3002\u200b\u5982\u679c\u200b\u4e0d\u662f\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u8282\u70b9\u200b\u53ea\u80fd\u200b\u770b\u5230\u200b\u672c\u5730\u200b\u6587\u4ef6\u7cfb\u7edf\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u8c03\u6574\u200b\u914d\u7f6e\u6587\u4ef6\u200b\uff0c\u200b\u5305\u542b\u200b\u4e00\u4e2a\u200b <code>checkpoint</code> \u200b\u90e8\u5206\u200b\u5e76\u200b\u8bbe\u7f6e\u200b\u5982\u4e0b\u200b\u9009\u9879\u200b\uff1a</p> <pre><code>{\n  \"checkpoint\": {\n    \"use_node_local_storage\": true\n  }\n}\n</code></pre> <p>\u200b\u6216\u8005\u200b\uff0c\u200b\u4f60\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b [<code>Trainer</code>] \u200b\u7684\u200b <code>--save_on_each_node</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u4e0a\u8ff0\u200b\u914d\u7f6e\u200b\u5c06\u200b\u81ea\u52a8\u200b\u6dfb\u52a0\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#notebooks","title":"\u5728\u200bNotebooks\u200b\u542f\u7528","text":"<p>\u200b\u5728\u200b\u5c06\u200b<code>notebook cells</code>\u200b\u4f5c\u4e3a\u200b\u811a\u672c\u200b\u8fd0\u884c\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u95ee\u9898\u200b\u5728\u4e8e\u200b\u6ca1\u6709\u200b\u6b63\u5e38\u200b\u7684\u200b <code>deepspeed</code> \u200b\u542f\u52a8\u5668\u200b\u53ef\u200b\u4f9d\u8d56\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5728\u200b\u67d0\u4e9b\u200b\u8bbe\u7f6e\u200b\u4e0b\u200b\uff0c\u200b\u6211\u4eec\u200b\u5fc5\u987b\u200b\u4eff\u771f\u200b\u8fd0\u884c\u200b\u5b83\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u53ea\u200b\u4f7f\u7528\u200b\u4e00\u4e2a\u200b GPU\uff0c\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u5982\u4f55\u200b\u8c03\u6574\u200bnotebook\u200b\u4e2d\u200b\u7684\u200b\u8bad\u7ec3\u200b\u4ee3\u7801\u200b\u4ee5\u200b\u4f7f\u7528\u200b DeepSpeed\u3002</p> <pre><code># DeepSpeed requires a distributed environment even when only one process is used.\n# This emulates a launcher in the notebook\nimport os\n\nos.environ[\"MASTER_ADDR\"] = \"localhost\"\nos.environ[\"MASTER_PORT\"] = \"9994\"  # modify if RuntimeError: Address already in use\nos.environ[\"RANK\"] = \"0\"\nos.environ[\"LOCAL_RANK\"] = \"0\"\nos.environ[\"WORLD_SIZE\"] = \"1\"\n\n# Now proceed as normal, plus pass the deepspeed config file\ntraining_args = TrainingArguments(..., deepspeed=\"ds_config_zero3.json\")\ntrainer = Trainer(...)\ntrainer.train()\n</code></pre> <p>\u200b\u6ce8\u610f\u200b\uff1a<code>...</code> \u200b\u4ee3\u8868\u200b\u60a8\u200b\u4f20\u9012\u200b\u7ed9\u200b\u51fd\u6570\u200b\u7684\u200b\u6b63\u5e38\u200b\u53c2\u6570\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u8981\u200b\u4f7f\u7528\u200b\u591a\u4e8e\u200b\u4e00\u4e2a\u200b GPU\uff0c\u200b\u60a8\u200b\u5fc5\u987b\u200b\u5728\u200b DeepSpeed \u200b\u4e2d\u200b\u4f7f\u7528\u200b\u591a\u200b\u8fdb\u7a0b\u200b\u73af\u5883\u200b\u3002\u200b\u4e5f\u5c31\u662f\u8bf4\u200b\uff0c\u200b\u60a8\u200b\u5fc5\u987b\u200b\u4f7f\u7528\u200b\u4e13\u95e8\u200b\u7684\u200b\u542f\u52a8\u5668\u200b\u6765\u200b\u5b9e\u73b0\u200b\u8fd9\u4e00\u200b\u76ee\u7684\u200b\uff0c\u200b\u800c\u200b\u4e0d\u80fd\u200b\u901a\u8fc7\u200b\u4eff\u771f\u200b\u672c\u200b\u8282\u200b\u5f00\u5934\u200b\u5448\u73b0\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u73af\u5883\u200b\u6765\u200b\u5b8c\u6210\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60f3\u8981\u200b\u5728\u200bnotebook\u200b\u4e2d\u200b\u52a8\u6001\u521b\u5efa\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u5e76\u200b\u4fdd\u5b58\u200b\u5728\u200b\u5f53\u524d\u76ee\u5f55\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u4e00\u4e2a\u200b\u4e13\u7528\u200b\u7684\u200bcell\u200b\u4e2d\u200b\u4f7f\u7528\u200b\uff1a</p> <p>```python no-style %%bash cat &lt;&lt;'EOT' &gt; ds_config_zero3.json {     \"fp16\": {         \"enabled\": \"auto\",         \"loss_scale\": 0,         \"loss_scale_window\": 1000,         \"initial_scale_power\": 16,         \"hysteresis\": 2,         \"min_loss_scale\": 1     },</p> <pre><code>\"optimizer\": {\n    \"type\": \"AdamW\",\n    \"params\": {\n        \"lr\": \"auto\",\n        \"betas\": \"auto\",\n        \"eps\": \"auto\",\n        \"weight_decay\": \"auto\"\n    }\n},\n\n\"scheduler\": {\n    \"type\": \"WarmupLR\",\n    \"params\": {\n        \"warmup_min_lr\": \"auto\",\n        \"warmup_max_lr\": \"auto\",\n        \"warmup_num_steps\": \"auto\"\n    }\n},\n\n\"zero_optimization\": {\n    \"stage\": 3,\n    \"offload_optimizer\": {\n        \"device\": \"cpu\",\n        \"pin_memory\": true\n    },\n    \"offload_param\": {\n        \"device\": \"cpu\",\n        \"pin_memory\": true\n    },\n    \"overlap_comm\": true,\n    \"contiguous_gradients\": true,\n    \"sub_group_size\": 1e9,\n    \"reduce_bucket_size\": \"auto\",\n    \"stage3_prefetch_bucket_size\": \"auto\",\n    \"stage3_param_persistence_threshold\": \"auto\",\n    \"stage3_max_live_parameters\": 1e9,\n    \"stage3_max_reuse_distance\": 1e9,\n    \"stage3_gather_16bit_weights_on_model_save\": true\n},\n\n\"gradient_accumulation_steps\": \"auto\",\n\"gradient_clipping\": \"auto\",\n\"steps_per_print\": 2000,\n\"train_batch_size\": \"auto\",\n\"train_micro_batch_size_per_gpu\": \"auto\",\n\"wall_clock_breakdown\": false\n</code></pre> <p>} EOT <code>\u200b\u5982\u679c\u200b\u8bad\u7ec3\u200b\u811a\u672c\u200b\u5728\u200b\u4e00\u4e2a\u200b\u666e\u901a\u200b\u6587\u4ef6\u200b\u4e2d\u200b\u800c\u200b\u4e0d\u662f\u200b\u5728\u200bnotebook cells\u200b\u4e2d\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u7b14\u8bb0\u672c\u200b\u4e2d\u200b\u7684\u200b shell \u200b\u6b63\u5e38\u200b\u542f\u52a8\u200b `deepspeed`\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u8981\u200b\u4f7f\u7528\u200b `run_translation.py`\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8fd9\u6837\u200b\u542f\u52a8\u200b\uff1a</code>python no-style !git clone https://github.com/huggingface/transformers !cd transformers; deepspeed examples/pytorch/translation/run_translation.py ... ```</p> <p>\u200b\u6216\u8005\u200b\u4f7f\u7528\u200b <code>%%bash</code> \u200b\u9b54\u672f\u200b\u547d\u4ee4\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u7f16\u5199\u200b\u591a\u884c\u200b\u4ee3\u7801\u200b\uff0c\u200b\u7528\u4e8e\u200b\u8fd0\u884c\u200b shell \u200b\u7a0b\u5e8f\u200b\uff1a</p> <p>```python no-style %%bash</p> <p>git clone https://github.com/huggingface/transformers cd transformers deepspeed examples/pytorch/translation/run_translation.py ... <pre><code>\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u4e0d\u200b\u9700\u8981\u200b\u672c\u200b\u8282\u200b\u5f00\u5934\u200b\u5448\u73b0\u200b\u7684\u200b\u4efb\u4f55\u200b\u4ee3\u7801\u200b\u3002\n\n\u200b\u6ce8\u610f\u200b\uff1a\u200b\u867d\u7136\u200b `%%bash` \u200b\u9b54\u672f\u200b\u547d\u4ee4\u200b\u5f88\u200b\u65b9\u4fbf\u200b\uff0c\u200b\u4f46\u200b\u76ee\u524d\u200b\u5b83\u4f1a\u200b\u7f13\u51b2\u200b\u8f93\u51fa\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5728\u200b\u8fdb\u7a0b\u200b\u5b8c\u6210\u200b\u4e4b\u524d\u200b\u60a8\u200b\u770b\u4e0d\u5230\u200b\u65e5\u5fd7\u200b\u3002\n\n\n&lt;a id='deepspeed-config'&gt;&lt;/a&gt;\n\n### \u200b\u914d\u7f6e\u200b\n\n\u200b\u6709\u5173\u200b\u53ef\u4ee5\u200b\u5728\u200b DeepSpeed \u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u7684\u200b\u5b8c\u6574\u200b\u914d\u7f6e\u200b\u9009\u9879\u200b\u7684\u200b\u8be6\u7ec6\u200b\u6307\u5357\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b[\u200b\u4ee5\u4e0b\u200b\u6587\u6863\u200b](https://www.deepspeed.ai/docs/config-json/)\u3002\n\n\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b [DeepSpeedExamples \u200b\u4ed3\u5e93\u200b](https://github.com/microsoft/DeepSpeedExamples)\u200b\u4e2d\u200b\u627e\u5230\u200b\u89e3\u51b3\u200b\u5404\u79cd\u200b\u5b9e\u9645\u200b\u9700\u6c42\u200b\u7684\u200b\u6570\u5341\u4e2a\u200b DeepSpeed \u200b\u914d\u7f6e\u200b\u793a\u4f8b\u200b\u3002\n\n```bash\ngit clone https://github.com/microsoft/DeepSpeedExamples\ncd DeepSpeedExamples\nfind . -name '*json'\n</code></pre></p> <p>\u200b\u5ef6\u7eed\u200b\u4e0a\u9762\u200b\u7684\u200b\u4ee3\u7801\u200b\uff0c\u200b\u5047\u8bbe\u200b\u60a8\u200b\u8981\u200b\u914d\u7f6e\u200b Lamb \u200b\u4f18\u5316\u200b\u5668\u200b\u3002\u200b\u90a3\u4e48\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u5728\u200b\u793a\u4f8b\u200b\u7684\u200b <code>.json</code> \u200b\u6587\u4ef6\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u641c\u7d22\u200b\uff1a</p> <pre><code>grep -i Lamb $(find . -name '*json')\n</code></pre> <p>\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u4e3b\u4ed3\u200b\u4e2d\u200b\u627e\u5230\u200b\u66f4\u200b\u591a\u200b\u793a\u4f8b\u200b\u3002</p> <p>\u200b\u5728\u200b\u4f7f\u7528\u200b DeepSpeed \u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u603b\u662f\u200b\u9700\u8981\u200b\u63d0\u4f9b\u200b\u4e00\u4e2a\u200b DeepSpeed \u200b\u914d\u7f6e\u6587\u4ef6\u200b\uff0c\u200b\u4f46\u662f\u200b\u4e00\u4e9b\u200b\u914d\u7f6e\u200b\u53c2\u6570\u200b\u5fc5\u987b\u200b\u901a\u8fc7\u200b\u547d\u4ee4\u884c\u200b\u8fdb\u884c\u200b\u914d\u7f6e\u200b\u3002\u200b\u60a8\u200b\u5c06\u200b\u5728\u200b\u672c\u200b\u6307\u5357\u200b\u7684\u200b\u5269\u4f59\u200b\u7ae0\u8282\u200b\u627e\u5230\u200b\u8fd9\u4e9b\u200b\u7ec6\u5fae\u5dee\u522b\u200b\u3002</p> <p>\u200b\u4e3a\u4e86\u200b\u4e86\u89e3\u200b DeepSpeed \u200b\u914d\u7f6e\u6587\u4ef6\u200b\uff0c\u200b\u8fd9\u91cc\u200b\u6709\u200b\u4e00\u4e2a\u200b\u6fc0\u6d3b\u200b ZeRO stage 2 \u200b\u529f\u80fd\u200b\u7684\u200b\u793a\u4f8b\u200b\uff0c\u200b\u5305\u62ec\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u7684\u200b CPU offload\uff0c\u200b\u4f7f\u7528\u200b <code>AdamW</code> \u200b\u4f18\u5316\u200b\u5668\u200b\u548c\u200b <code>WarmupLR</code>  \u200b\u8c03\u5ea6\u200b\u5668\u200b\uff0c\u200b\u5e76\u4e14\u200b\u5982\u679c\u200b\u4f20\u9012\u200b\u4e86\u200b <code>--fp16</code> \u200b\u53c2\u6570\u200b\u5c06\u200b\u542f\u7528\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\uff1a</p> <pre><code>{\n    \"fp16\": {\n        \"enabled\": \"auto\",\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    },\n\n    \"optimizer\": {\n        \"type\": \"AdamW\",\n        \"params\": {\n            \"lr\": \"auto\",\n            \"betas\": \"auto\",\n            \"eps\": \"auto\",\n            \"weight_decay\": \"auto\"\n        }\n    },\n\n    \"scheduler\": {\n        \"type\": \"WarmupLR\",\n        \"params\": {\n            \"warmup_min_lr\": \"auto\",\n            \"warmup_max_lr\": \"auto\",\n            \"warmup_num_steps\": \"auto\"\n        }\n    },\n\n    \"zero_optimization\": {\n        \"stage\": 2,\n        \"offload_optimizer\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": true\n        },\n        \"allgather_partitions\": true,\n        \"allgather_bucket_size\": 2e8,\n        \"overlap_comm\": true,\n        \"reduce_scatter\": true,\n        \"reduce_bucket_size\": 2e8,\n        \"contiguous_gradients\": true\n    },\n\n    \"gradient_accumulation_steps\": \"auto\",\n    \"gradient_clipping\": \"auto\",\n    \"train_batch_size\": \"auto\",\n    \"train_micro_batch_size_per_gpu\": \"auto\",\n}\n</code></pre> <p>\u200b\u5f53\u200b\u60a8\u200b\u6267\u884c\u7a0b\u5e8f\u200b\u65f6\u200b\uff0cDeepSpeed \u200b\u5c06\u200b\u628a\u200b\u5b83\u200b\u4ece\u200b [<code>Trainer</code>] \u200b\u6536\u5230\u200b\u7684\u200b\u914d\u7f6e\u200b\u65e5\u5fd7\u200b\u8f93\u51fa\u200b\u5230\u200bconsole\uff0c\u200b\u56e0\u6b64\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200b\u4f20\u9012\u200b\u7ed9\u200b\u5b83\u200b\u7684\u200b\u6700\u7ec8\u200b\u914d\u7f6e\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#_4","title":"\u4f20\u9012\u200b\u914d\u7f6e","text":"<p>\u200b\u6b63\u5982\u200b\u672c\u200b\u6587\u6863\u200b\u8ba8\u8bba\u200b\u7684\u200b\u90a3\u6837\u200b\uff0c\u200b\u901a\u5e38\u200b\u5c06\u200b DeepSpeed \u200b\u914d\u7f6e\u200b\u4f5c\u4e3a\u200b\u6307\u5411\u200b JSON \u200b\u6587\u4ef6\u200b\u7684\u200b\u8def\u5f84\u200b\u4f20\u9012\u200b\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u60a8\u200b\u6ca1\u6709\u200b\u4f7f\u7528\u200b\u547d\u4ee4\u884c\u200b\u754c\u9762\u200b\u914d\u7f6e\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u800c\u662f\u200b\u901a\u8fc7\u200b [<code>TrainingArguments</code>] \u200b\u5b9e\u4f8b\u200b\u5316\u200b [<code>Trainer</code>]\uff0c\u200b\u90a3\u4e48\u200b\u5bf9\u4e8e\u200b <code>deepspeed</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f20\u9012\u200b\u4e00\u4e2a\u200b\u5d4c\u5957\u200b\u7684\u200b <code>dict</code>\u3002\u200b\u8fd9\u4f7f\u200b\u60a8\u200b\u80fd\u591f\u200b\u5373\u65f6\u200b\u521b\u5efa\u200b\u914d\u7f6e\u200b\uff0c\u200b\u800c\u200b\u65e0\u9700\u200b\u5728\u200b\u5c06\u200b\u5176\u200b\u4f20\u9012\u200b\u7ed9\u200b [<code>TrainingArguments</code>] \u200b\u4e4b\u524d\u200b\u5c06\u200b\u5176\u200b\u5199\u5165\u200b\u6587\u4ef6\u7cfb\u7edf\u200b\u3002</p> <p>\u200b\u603b\u7ed3\u200b\u8d77\u6765\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8fd9\u6837\u200b\u505a\u200b\uff1a</p> <pre><code>TrainingArguments(..., deepspeed=\"/path/to/ds_config.json\")\n</code></pre> <p>\u200b\u6216\u8005\u200b:</p> <pre><code>ds_config_dict = dict(scheduler=scheduler_params, optimizer=optimizer_params)\nTrainingArguments(..., deepspeed=ds_config_dict)\n</code></pre> <p></p>"},{"location":"main_classes/deepspeed/#_5","title":"\u5171\u4eab\u200b\u914d\u7f6e","text":"<p> <p>\u200b\u8fd9\u200b\u4e00\u90e8\u5206\u200b\u662f\u200b\u5fc5\u8bfb\u200b\u7684\u200b\u3002</p> <p></p> <p>\u200b\u4e00\u4e9b\u200b\u914d\u7f6e\u200b\u503c\u200b\u5bf9\u4e8e\u200b [<code>Trainer</code>] \u200b\u548c\u200b DeepSpeed \u200b\u6b63\u5e38\u200b\u8fd0\u884c\u200b\u90fd\u200b\u662f\u200b\u5fc5\u9700\u200b\u7684\u200b\uff0c\u200b\u56e0\u6b64\u200b\uff0c\u200b\u4e3a\u4e86\u200b\u9632\u6b62\u200b\u5b9a\u4e49\u200b\u51b2\u7a81\u200b\u53ca\u200b\u5bfc\u81f4\u200b\u7684\u200b\u96be\u4ee5\u200b\u68c0\u6d4b\u200b\u7684\u200b\u9519\u8bef\u200b\uff0c\u200b\u6211\u4eec\u200b\u9009\u62e9\u200b\u901a\u8fc7\u200b [<code>Trainer</code>] \u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u914d\u7f6e\u200b\u8fd9\u4e9b\u200b\u503c\u200b\u3002</p> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u4e00\u4e9b\u200b\u914d\u7f6e\u200b\u503c\u200b\u662f\u200b\u57fa\u4e8e\u200b\u6a21\u578b\u200b\u7684\u200b\u914d\u7f6e\u200b\u81ea\u52a8\u200b\u6d3e\u751f\u200b\u7684\u200b\uff0c\u200b\u56e0\u6b64\u200b\uff0c\u200b\u4e0e\u5176\u200b\u8bb0\u4f4f\u200b\u624b\u52a8\u200b\u8c03\u6574\u200b\u591a\u4e2a\u200b\u503c\u200b\uff0c\u200b\u6700\u597d\u200b\u8ba9\u200b [<code>Trainer</code>] \u200b\u4e3a\u200b\u60a8\u200b\u505a\u200b\u5927\u90e8\u5206\u200b\u914d\u7f6e\u200b\u3002</p> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5728\u200b\u672c\u200b\u6307\u5357\u200b\u7684\u200b\u5176\u4f59\u90e8\u5206\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u627e\u5230\u200b\u4e00\u4e2a\u200b\u7279\u6b8a\u200b\u7684\u200b\u914d\u7f6e\u200b\u503c\u200b\uff1a<code>auto</code>\uff0c\u200b\u5f53\u200b\u8bbe\u7f6e\u200b\u65f6\u200b\u5c06\u200b\u81ea\u52a8\u200b\u5c06\u200b\u53c2\u6570\u200b\u66ff\u6362\u200b\u4e3a\u200b\u6b63\u786e\u200b\u6216\u200b\u6700\u200b\u6709\u6548\u200b\u7684\u200b\u503c\u200b\u3002\u200b\u8bf7\u200b\u968f\u610f\u200b\u9009\u62e9\u200b\u5ffd\u7565\u200b\u6b64\u200b\u5efa\u8bae\u200b\u6216\u200b\u663e\u5f0f\u200b\u8bbe\u7f6e\u200b\u8be5\u503c\u200b\uff0c\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u8bf7\u200b\u52a1\u5fc5\u200b\u786e\u4fdd\u200b [<code>Trainer</code>] \u200b\u53c2\u6570\u200b\u548c\u200b DeepSpeed \u200b\u914d\u7f6e\u200b\u4fdd\u6301\u4e00\u81f4\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u60a8\u200b\u662f\u5426\u200b\u4f7f\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u5b66\u4e60\u200b\u7387\u200b\u3001\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\u6216\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u8bbe\u7f6e\u200b\uff1f\u200b\u5982\u679c\u200b\u8fd9\u4e9b\u200b\u4e0d\u200b\u5339\u914d\u200b\uff0c\u200b\u8bad\u7ec3\u200b\u53ef\u80fd\u200b\u4ee5\u200b\u975e\u5e38\u200b\u96be\u4ee5\u200b\u68c0\u6d4b\u200b\u7684\u200b\u65b9\u5f0f\u200b\u5931\u8d25\u200b\u3002\u200b\u8bf7\u200b\u91cd\u89c6\u200b\u8be5\u200b\u8b66\u544a\u200b\u3002</p> <p>\u200b\u8fd8\u6709\u200b\u4e00\u4e9b\u200b\u53c2\u6570\u200b\u662f\u200b\u4ec5\u200b\u9002\u7528\u200b\u4e8e\u200b DeepSpeed \u200b\u7684\u200b\uff0c\u200b\u5e76\u4e14\u200b\u8fd9\u4e9b\u200b\u53c2\u6570\u200b\u5fc5\u987b\u200b\u624b\u52a8\u200b\u8bbe\u7f6e\u200b\u4ee5\u200b\u9002\u5e94\u200b\u60a8\u200b\u7684\u200b\u9700\u6c42\u200b\u3002</p> <p>\u200b\u5728\u200b\u60a8\u200b\u81ea\u5df1\u200b\u7684\u200b\u7a0b\u5e8f\u200b\u4e2d\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u8981\u200b\u4f5c\u4e3a\u200b\u4e3b\u52a8\u200b\u4fee\u6539\u200b DeepSpeed \u200b\u914d\u7f6e\u200b\u5e76\u200b\u4ee5\u6b64\u200b\u914d\u7f6e\u200b [<code>TrainingArguments</code>]\uff0c\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u65b9\u6cd5\u200b\u3002\u200b\u6b65\u9aa4\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u521b\u5efa\u200b\u6216\u200b\u52a0\u8f7d\u200b\u8981\u200b\u7528\u4f5c\u200b\u4e3b\u200b\u914d\u7f6e\u200b\u7684\u200b DeepSpeed \u200b\u914d\u7f6e\u200b</li> <li>\u200b\u6839\u636e\u200b\u8fd9\u4e9b\u200b\u53c2\u6570\u503c\u200b\u521b\u5efa\u200b [<code>TrainingArguments</code>] \u200b\u5bf9\u8c61\u200b</li> </ol> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u4e00\u4e9b\u200b\u503c\u200b\uff0c\u200b\u6bd4\u5982\u200b <code>scheduler.params.total_num_steps</code>\uff0c\u200b\u662f\u200b\u5728\u200b [<code>Trainer</code>] \u200b\u7684\u200b <code>train</code> \u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u8ba1\u7b97\u200b\u7684\u200b\uff0c\u200b\u4f46\u200b\u5f53\u7136\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u81ea\u5df1\u200b\u8ba1\u7b97\u200b\u8fd9\u4e9b\u200b\u503c\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#zero","title":"ZeRO","text":"<p>Zero Redundancy Optimizer (ZeRO) \u200b\u662f\u200b DeepSpeed \u200b\u7684\u200b\u5de5\u4f5c\u200b\u6838\u5fc3\u200b\u3002\u200b\u5b83\u200b\u652f\u6301\u200b3\u200b\u4e2a\u200b\u4e0d\u540c\u200b\u7ea7\u522b\u200b\uff08stages\uff09\u200b\u7684\u200b\u4f18\u5316\u200b\u3002Stage 1 \u200b\u5bf9\u4e8e\u200b\u6269\u5c55\u6027\u200b\u6765\u8bf4\u200b\u4e0d\u662f\u200b\u5f88\u200b\u6709\u8da3\u200b\uff0c\u200b\u56e0\u6b64\u200b\u672c\u200b\u6587\u6863\u200b\u91cd\u70b9\u200b\u5173\u6ce8\u200bStage 2\u200b\u548c\u200bStage 3\u3002Stage 3\u200b\u901a\u8fc7\u200b\u6700\u65b0\u200b\u7684\u200b ZeRO-Infinity \u200b\u8fdb\u4e00\u6b65\u200b\u6539\u8fdb\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200b DeepSpeed \u200b\u6587\u6863\u200b\u4e2d\u200b\u627e\u5230\u200b\u66f4\u200b\u8be6\u7ec6\u200b\u7684\u200b\u4fe1\u606f\u200b\u3002</p> <p>\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u7684\u200b <code>zero_optimization</code> \u200b\u90e8\u5206\u200b\u662f\u200b\u6700\u200b\u91cd\u8981\u200b\u7684\u200b\u90e8\u5206\u200b\uff08\u200b\u6587\u6863\u200b\uff09\uff0c\u200b\u56e0\u4e3a\u200b\u5728\u200b\u8fd9\u91cc\u200b\u60a8\u200b\u5b9a\u4e49\u200b\u4e86\u200b\u8981\u200b\u542f\u7528\u200b\u54ea\u4e9b\u200b ZeRO stages \u200b\u4ee5\u53ca\u200b\u5982\u4f55\u200b\u914d\u7f6e\u200b\u5b83\u4eec\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b DeepSpeed \u200b\u6587\u6863\u200b\u4e2d\u200b\u627e\u5230\u200b\u6bcf\u4e2a\u200b\u53c2\u6570\u200b\u7684\u200b\u89e3\u91ca\u200b\u3002</p> <p>\u200b\u8fd9\u200b\u4e00\u90e8\u5206\u200b\u5fc5\u987b\u200b\u901a\u8fc7\u200b DeepSpeed \u200b\u914d\u7f6e\u6587\u4ef6\u200b\u5355\u72ec\u200b\u914d\u7f6e\u200b - [<code>Trainer</code>] \u200b\u4e0d\u200b\u63d0\u4f9b\u200b\u76f8\u5e94\u200b\u7684\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u3002</p> <p>\u200b\u6ce8\u610f\u200b\uff1a\u200b\u76ee\u524d\u200b DeepSpeed \u200b\u4e0d\u200b\u9a8c\u8bc1\u200b\u53c2\u6570\u200b\u540d\u79f0\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5982\u679c\u200b\u60a8\u200b\u62fc\u9519\u200b\u4e86\u200b\u4efb\u4f55\u200b\u53c2\u6570\u200b\uff0c\u200b\u5b83\u200b\u5c06\u200b\u4f7f\u7528\u200b\u62fc\u5199\u9519\u8bef\u200b\u7684\u200b\u53c2\u6570\u200b\u7684\u200b\u9ed8\u8ba4\u8bbe\u7f6e\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u89c2\u5bdf\u200b DeepSpeed \u200b\u5f15\u64ce\u200b\u542f\u52a8\u200b\u65e5\u5fd7\u200b\u6d88\u606f\u200b\uff0c\u200b\u770b\u770b\u200b\u5b83\u200b\u5c06\u200b\u4f7f\u7528\u200b\u54ea\u4e9b\u200b\u503c\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#zero-2","title":"ZeRO-2 \u200b\u914d\u7f6e","text":"<p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b ZeRO stage 2 \u200b\u7684\u200b\u914d\u7f6e\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>{\n    \"zero_optimization\": {\n        \"stage\": 2,\n        \"offload_optimizer\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": true\n        },\n        \"allgather_partitions\": true,\n        \"allgather_bucket_size\": 5e8,\n        \"overlap_comm\": true,\n        \"reduce_scatter\": true,\n        \"reduce_bucket_size\": 5e8,\n        \"contiguous_gradients\": true\n    }\n}\n</code></pre> <p>\u200b\u6027\u80fd\u200b\u8c03\u4f18\u200b\uff1a</p> <ul> <li>\u200b\u542f\u7528\u200b <code>offload_optimizer</code> \u200b\u5e94\u8be5\u200b\u51cf\u5c11\u200b GPU \u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\uff08\u200b\u9700\u8981\u200b <code>\"stage\": 2</code>\uff09\u3002</li> <li><code>\"overlap_comm\": true</code> \u200b\u901a\u8fc7\u200b\u589e\u52a0\u200b GPU \u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u6765\u200b\u964d\u4f4e\u200ball-reduce \u200b\u7684\u200b\u5ef6\u8fdf\u200b\u3002 <code>overlap_comm</code> \u200b\u4f7f\u7528\u200b\u4e86\u200b <code>allgather_bucket_size</code> \u200b\u548c\u200b <code>reduce_bucket_size</code> \u200b\u503c\u200b\u7684\u200b4.5\u200b\u500d\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u5b83\u4eec\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b <code>5e8</code>\uff0c\u200b\u8fd9\u200b\u5c06\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b9GB\u200b\u7684\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\uff08<code>5e8 x 2Bytes x 2 x 4.5</code>\uff09\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b GPU \u200b\u5185\u5b58\u200b\u4e3a\u200b8GB\u200b\u6216\u200b\u66f4\u200b\u5c0f\u200b\uff0c\u200b\u4e3a\u4e86\u200b\u907f\u514d\u51fa\u73b0\u200bOOM\u200b\u9519\u8bef\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u5c06\u200b\u8fd9\u4e9b\u200b\u53c2\u6570\u200b\u51cf\u5c0f\u200b\u5230\u200b\u7ea6\u200b <code>2e8</code>\uff0c\u200b\u8fd9\u200b\u5c06\u200b\u9700\u8981\u200b3.6GB\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b GPU \u200b\u5bb9\u91cf\u200b\u66f4\u5927\u200b\uff0c\u200b\u5f53\u200b\u60a8\u200b\u5f00\u59cb\u200b\u9047\u5230\u200bOOM\u200b\u65f6\u200b\uff0c\u200b\u4f60\u200b\u53ef\u80fd\u200b\u4e5f\u200b\u9700\u8981\u200b\u8fd9\u6837\u200b\u505a\u200b\u3002</li> <li>\u200b\u5f53\u200b\u51cf\u5c0f\u200b\u8fd9\u4e9b\u200bbuffers\u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u4ee5\u200b\u66f4\u6162\u200b\u7684\u200b\u901a\u4fe1\u200b\u901f\u5ea6\u200b\u6765\u200b\u6362\u53d6\u200b\u66f4\u200b\u591a\u200b\u7684\u200b GPU \u200b\u5185\u5b58\u200b\u3002buffers\u200b\u5927\u5c0f\u200b\u8d8a\u5c0f\u200b\uff0c\u200b\u901a\u4fe1\u200b\u901f\u5ea6\u200b\u8d8a\u6162\u200b\uff0cGPU \u200b\u53ef\u200b\u7528\u4e8e\u200b\u5176\u4ed6\u200b\u4efb\u52a1\u200b\u7684\u200b\u5185\u5b58\u200b\u5c31\u200b\u8d8a\u200b\u591a\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u66f4\u5927\u200b\u7684\u200b\u6279\u5904\u7406\u200b\u5927\u5c0f\u200b\u5f88\u200b\u91cd\u8981\u200b\uff0c\u200b\u90a3\u4e48\u200b\u7a0d\u5fae\u200b\u51cf\u6162\u200b\u8bad\u7ec3\u200b\u65f6\u95f4\u200b\u53ef\u80fd\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5f88\u200b\u597d\u200b\u7684\u200b\u6743\u8861\u200b\u3002</li> </ul> <p>\u200b\u6b64\u5916\u200b\uff0c<code>deepspeed==0.4.4</code> \u200b\u6dfb\u52a0\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u9009\u9879\u200b <code>round_robin_gradients</code>\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u542f\u7528\u200b\uff1a</p> <p><pre><code>{\n    \"zero_optimization\": {\n        \"round_robin_gradients\": true\n    }\n}\n</code></pre> \u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u7528\u4e8e\u200b CPU offloading \u200b\u7684\u200bstage 2\u200b\u4f18\u5316\u200b\uff0c\u200b\u901a\u8fc7\u200b\u7ec6\u7c92\u5ea6\u200b\u68af\u5ea6\u200b\u5206\u533a\u200b\u5728\u200b ranks \u200b\u4e4b\u95f4\u200b\u5e76\u884c\u590d\u5236\u200b\u5230\u200b CPU \u200b\u5185\u5b58\u200b\uff0c\u200b\u4ece\u800c\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u6027\u80fd\u200b\u7684\u200b\u63d0\u5347\u200b\u3002\u200b\u6027\u80fd\u200b\u4f18\u52bf\u200b\u968f\u7740\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u6b65\u9aa4\u200b\uff08\u200b\u5728\u200b\u4f18\u5316\u200b\u5668\u200b\u6b65\u9aa4\u200b\u4e4b\u95f4\u200b\u8fdb\u884c\u200b\u66f4\u200b\u591a\u200b\u590d\u5236\u200b\uff09\u200b\u6216\u200b GPU \u200b\u6570\u91cf\u200b\uff08\u200b\u589e\u52a0\u200b\u5e76\u884c\u6027\u200b\uff09\u200b\u589e\u52a0\u200b\u800c\u200b\u589e\u52a0\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#zero-3","title":"ZeRO-3 \u200b\u914d\u7f6e","text":"<p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b ZeRO stage 3\u200b\u7684\u200b\u914d\u7f6e\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>{\n    \"zero_optimization\": {\n        \"stage\": 3,\n        \"offload_optimizer\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": true\n        },\n        \"offload_param\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": true\n        },\n        \"overlap_comm\": true,\n        \"contiguous_gradients\": true,\n        \"sub_group_size\": 1e9,\n        \"reduce_bucket_size\": \"auto\",\n        \"stage3_prefetch_bucket_size\": \"auto\",\n        \"stage3_param_persistence_threshold\": \"auto\",\n        \"stage3_max_live_parameters\": 1e9,\n        \"stage3_max_reuse_distance\": 1e9,\n        \"stage3_gather_16bit_weights_on_model_save\": true\n    }\n}\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u56e0\u4e3a\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u6216\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u8d85\u8fc7\u200b GPU \u200b\u5185\u5b58\u200b\u800c\u200b\u9047\u5230\u200bOOM\u200b\u95ee\u9898\u200b\uff0c\u200b\u5e76\u4e14\u200b\u60a8\u200b\u6709\u200b\u672a\u200b\u4f7f\u7528\u200b\u7684\u200b CPU \u200b\u5185\u5b58\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u901a\u200b\u80a1\u7968\u200b\u4f7f\u7528\u200b <code>\"device\": \"cpu\"</code> \u200b\u5c06\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u548c\u200b\u53c2\u6570\u200b\u5378\u8f7d\u200b\u5230\u200b CPU \u200b\u5185\u5b58\u200b\u4e2d\u200b\uff0c\u200b\u6765\u200b\u89e3\u51b3\u200b\u8fd9\u4e2a\u200b\u9650\u5236\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u4e0d\u60f3\u200b\u5378\u8f7d\u200b\u5230\u200b CPU \u200b\u5185\u5b58\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5728\u200b <code>device</code> \u200b\u6761\u76ee\u200b\u4e2d\u200b\u4f7f\u7528\u200b <code>none</code> \u200b\u4ee3\u66ff\u200b <code>cpu</code>\u3002\u200b\u5c06\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u5378\u8f7d\u200b\u5230\u200b NVMe \u200b\u4e0a\u4f1a\u200b\u5728\u200b\u540e\u9762\u200b\u8fdb\u4e00\u6b65\u200b\u8ba8\u8bba\u200b\u3002</p> <p>\u200b\u901a\u8fc7\u200b\u5c06\u200b <code>pin_memory</code> \u200b\u8bbe\u7f6e\u200b\u4e3a\u200b <code>true</code> \u200b\u542f\u7528\u200b\u56fa\u5b9a\u200b\u5185\u5b58\u200b\u3002\u200b\u6b64\u200b\u529f\u80fd\u200b\u4f1a\u4ee5\u200b\u51cf\u5c11\u200b\u53ef\u200b\u7528\u4e8e\u200b\u5176\u4ed6\u200b\u8fdb\u7a0b\u200b\u7684\u200b\u5185\u5b58\u200b\u4e3a\u200b\u4ee3\u4ef7\u200b\u6765\u200b\u63d0\u9ad8\u200b\u541e\u5410\u91cf\u200b\u3002\u200b\u56fa\u5b9a\u200b\u5185\u5b58\u200b\u88ab\u200b\u5206\u914d\u200b\u7ed9\u200b\u7279\u5b9a\u200b\u8bf7\u6c42\u200b\u5b83\u200b\u7684\u200b\u8fdb\u7a0b\u200b\uff0c\u200b\u901a\u5e38\u200b\u6bd4\u200b\u666e\u901a\u200b CPU \u200b\u5185\u5b58\u200b\u8bbf\u95ee\u901f\u5ea6\u200b\u66f4\u200b\u5feb\u200b\u3002</p> <p>\u200b\u6027\u80fd\u200b\u8c03\u4f18\u200b\uff1a</p> <ul> <li><code>stage3_max_live_parameters</code>: <code>1e9</code></li> <li><code>stage3_max_reuse_distance</code>: <code>1e9</code></li> </ul> <p>\u200b\u5982\u679c\u200b\u9047\u5230\u200bOOM\u200b\u95ee\u9898\u200b\uff0c\u200b\u8bf7\u200b\u51cf\u5c0f\u200b <code>stage3_max_live_parameters</code> \u200b\u548c\u200b <code>stage3_max_reuse_distance</code>\u3002\u200b\u5b83\u4eec\u200b\u5bf9\u200b\u6027\u80fd\u200b\u7684\u200b\u5f71\u54cd\u200b\u5e94\u8be5\u200b\u5f88\u5c0f\u200b\uff0c\u200b\u9664\u975e\u200b\u60a8\u200b\u6b63\u5728\u200b\u8fdb\u884c\u200b\u6fc0\u6d3b\u200b\u503c\u200bcheckpointing\u3002<code>1e9</code> \u200b\u5927\u7ea6\u200b\u4f1a\u200b\u6d88\u8017\u200b ~2GB\u3002\u200b\u5185\u5b58\u200b\u7531\u200b <code>stage3_max_live_parameters</code> \u200b\u548c\u200b <code>stage3_max_reuse_distance</code> \u200b\u5171\u4eab\u200b\uff0c\u200b\u6240\u4ee5\u200b\u5b83\u200b\u4e0d\u662f\u200b\u53e0\u52a0\u200b\u7684\u200b\uff0c\u200b\u800c\u662f\u200b\u603b\u5171\u200b2GB\u3002</p> <p><code>stage3_max_live_parameters</code> \u200b\u662f\u200b\u5728\u200b\u4efb\u4f55\u200b\u7ed9\u5b9a\u200b\u65f6\u95f4\u200b\u8981\u200b\u5728\u200b GPU \u200b\u4e0a\u200b\u4fdd\u7559\u200b\u591a\u5c11\u200b\u4e2a\u200b\u5b8c\u6574\u200b\u53c2\u6570\u200b\u7684\u200b\u4e0a\u9650\u200b\u3002\"reuse distance\" \u200b\u662f\u200b\u6211\u4eec\u200b\u7528\u6765\u200b\u786e\u5b9a\u200b\u53c2\u6570\u200b\u5728\u200b\u5c06\u6765\u200b\u4f55\u65f6\u200b\u4f1a\u200b\u518d\u6b21\u200b\u4f7f\u7528\u200b\u7684\u200b\u5ea6\u91cf\u200b\u6807\u51c6\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b <code>stage3_max_reuse_distance</code> \u200b\u6765\u200b\u51b3\u5b9a\u200b\u662f\u200b\u4e22\u5f03\u200b\u53c2\u6570\u200b\u8fd8\u662f\u200b\u4fdd\u7559\u200b\u53c2\u6570\u200b\u3002\u200b\u5982\u679c\u200b\u4e00\u4e2a\u200b\u53c2\u6570\u200b\u5728\u200b\u4e0d\u4e45\u200b\u7684\u200b\u5c06\u6765\u200b\uff08\u200b\u5c0f\u4e8e\u200b <code>stage3_max_reuse_distance</code>\uff09\u200b\u5c06\u200b\u88ab\u200b\u518d\u6b21\u200b\u4f7f\u7528\u200b\uff0c\u200b\u90a3\u4e48\u200b\u6211\u4eec\u200b\u5c06\u200b\u5176\u200b\u4fdd\u7559\u200b\u4ee5\u200b\u51cf\u5c11\u200b\u901a\u4fe1\u200b\u5f00\u9500\u200b\u3002\u200b\u8fd9\u200b\u5728\u200b\u542f\u7528\u200b\u6fc0\u6d3b\u200b\u503c\u200bcheckpoing\u200b\u65f6\u200b\u975e\u5e38\u200b\u6709\u7528\u200b\uff0c\u200b\u5176\u4e2d\u200b\u6211\u4eec\u200b\u4ee5\u200b\u5355\u5c42\u200b\u7c92\u5ea6\u200b\u8fdb\u884c\u200b\u524d\u5411\u91cd\u200b\u8ba1\u7b97\u200b\u548c\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\uff0c\u200b\u5e76\u200b\u5e0c\u671b\u200b\u5728\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\u671f\u95f4\u200b\u4fdd\u7559\u200b\u524d\u5411\u91cd\u200b\u8ba1\u7b97\u200b\u4e2d\u200b\u7684\u200b\u53c2\u6570\u200b\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u914d\u7f6e\u200b\u503c\u200b\u53d6\u51b3\u4e8e\u200b\u6a21\u578b\u200b\u7684\u200b\u9690\u85cf\u200b\u5927\u5c0f\u200b\uff1a</p> <ul> <li><code>reduce_bucket_size</code>: <code>hidden_size*hidden_size</code></li> <li><code>stage3_prefetch_bucket_size</code>: <code>0.9 * hidden_size * hidden_size</code></li> <li><code>stage3_param_persistence_threshold</code>: <code>10 * hidden_size</code></li> </ul> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5c06\u200b\u8fd9\u4e9b\u200b\u503c\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b <code>auto</code>\uff0c[<code>Trainer</code>] \u200b\u5c06\u200b\u81ea\u52a8\u200b\u5206\u914d\u200b\u63a8\u8350\u200b\u7684\u200b\u53c2\u6570\u503c\u200b\u3002\u200b\u5f53\u7136\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u613f\u610f\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u663e\u5f0f\u200b\u8bbe\u7f6e\u200b\u8fd9\u4e9b\u200b\u503c\u200b\u3002</p> <p><code>stage3_gather_16bit_weights_on_model_save</code> \u200b\u5728\u200b\u6a21\u578b\u200b\u4fdd\u5b58\u200b\u65f6\u200b\u542f\u7528\u200b\u6a21\u578b\u200b\u7684\u200b fp16 \u200b\u6743\u91cd\u200b\u6574\u5408\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u5927\u200b\u6a21\u578b\u200b\u548c\u200b\u591a\u4e2a\u200b GPU\uff0c\u200b\u65e0\u8bba\u662f\u200b\u5728\u200b\u5185\u5b58\u200b\u8fd8\u662f\u200b\u901f\u5ea6\u200b\u65b9\u9762\u200b\uff0c\u200b\u8fd9\u200b\u90fd\u200b\u662f\u200b\u4e00\u9879\u200b\u6602\u8d35\u200b\u7684\u200b\u64cd\u4f5c\u200b\u3002\u200b\u76ee\u524d\u200b\u5982\u679c\u200b\u8ba1\u5212\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u8fd9\u662f\u200b\u5fc5\u9700\u200b\u7684\u200b\u3002\u200b\u8bf7\u200b\u6ce8\u610f\u200b\u672a\u6765\u200b\u7684\u200b\u66f4\u65b0\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5220\u9664\u200b\u6b64\u200b\u9650\u5236\u200b\u5e76\u200b\u8ba9\u200b\u4f7f\u7528\u200b\u66f4\u52a0\u200b\u7075\u6d3b\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u4ece\u200b ZeRO-2 \u200b\u914d\u7f6e\u200b\u8fc1\u79fb\u200b\uff0c\u200b\u8bf7\u200b\u6ce8\u610f\u200b <code>allgather_partitions</code>\u3001<code>allgather_bucket_size</code> \u200b\u548c\u200b <code>reduce_scatter</code> \u200b\u914d\u7f6e\u200b\u53c2\u6570\u200b\u5728\u200b ZeRO-3 \u200b\u4e2d\u200b\u4e0d\u200b\u88ab\u200b\u4f7f\u7528\u200b\u3002\u200b\u5982\u679c\u200b\u4fdd\u7559\u200b\u8fd9\u4e9b\u200b\u914d\u7f6e\u6587\u4ef6\u200b\uff0c\u200b\u5b83\u4eec\u200b\u5c06\u200b\u88ab\u200b\u5ffd\u7565\u200b\u3002</p> <ul> <li><code>sub_group_size</code>: <code>1e9</code></li> </ul> <p><code>sub_group_size</code> \u200b\u63a7\u5236\u200b\u5728\u200b\u4f18\u5316\u200b\u5668\u200b\u6b65\u9aa4\u200b\u671f\u95f4\u200b\u66f4\u65b0\u200b\u53c2\u6570\u200b\u7684\u200b\u7c92\u5ea6\u200b\u3002\u200b\u53c2\u6570\u200b\u88ab\u200b\u5206\u7ec4\u200b\u5230\u200b\u5927\u5c0f\u200b\u4e3a\u200b <code>sub_group_size</code> \u200b\u7684\u200b\u6876\u200b\u4e2d\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u6876\u200b\u9010\u4e2a\u200b\u66f4\u65b0\u200b\u3002\u200b\u5728\u200b ZeRO-Infinity \u200b\u4e2d\u200b\u4e0e\u200b NVMe offload\u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\u65f6\u200b\uff0c<code>sub_group_size</code> \u200b\u63a7\u5236\u200b\u4e86\u200b\u5728\u200b\u4f18\u5316\u200b\u5668\u200b\u6b65\u9aa4\u200b\u671f\u95f4\u200b\u5728\u200b NVMe \u200b\u548c\u200b CPU \u200b\u5185\u5b58\u200b\u4e4b\u95f4\u200b\u79fb\u52a8\u200b\u6a21\u578b\u200b\u72b6\u6001\u200b\u7684\u200b\u7c92\u5ea6\u200b\u3002\u200b\u8fd9\u200b\u53ef\u4ee5\u200b\u9632\u6b62\u200b\u975e\u5e38\u200b\u5927\u200b\u7684\u200b\u6a21\u578b\u200b\u8017\u5c3d\u200b CPU \u200b\u5185\u5b58\u200b\u3002</p> <p>\u200b\u5f53\u200b\u4e0d\u200b\u4f7f\u7528\u200b NVMe offload\u200b\u65f6\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5c06\u200b <code>sub_group_size</code> \u200b\u4fdd\u7559\u200b\u4e3a\u200b\u5176\u200b\u9ed8\u8ba4\u503c\u200b 1e9\u3002\u200b\u5728\u200b\u4ee5\u4e0b\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u66f4\u6539\u200b\u5176\u200b\u9ed8\u8ba4\u503c\u200b\uff1a</p> <ol> <li>\u200b\u5728\u200b\u4f18\u5316\u200b\u5668\u200b\u6b65\u9aa4\u200b\u4e2d\u200b\u9047\u5230\u200bOOM\uff1a\u200b\u51cf\u5c0f\u200b <code>sub_group_size</code> \u200b\u4ee5\u200b\u51cf\u5c11\u200b\u4e34\u65f6\u200bbuffers\u200b\u7684\u200b\u5185\u5b58\u200b\u5229\u7528\u200b</li> <li>\u200b\u4f18\u5316\u200b\u5668\u200b\u6b65\u9aa4\u200b\u82b1\u8d39\u200b\u5f88\u200b\u957f\u65f6\u95f4\u200b\uff1a\u200b\u589e\u52a0\u200b <code>sub_group_size</code> \u200b\u4ee5\u200b\u63d0\u9ad8\u200b\u7531\u4e8e\u200b\u589e\u52a0\u200b\u7684\u200b\u6570\u636e\u200bbuffers\u200b\u800c\u200b\u5bfc\u81f4\u200b\u7684\u200b\u5e26\u5bbd\u200b\u5229\u7528\u7387\u200b\u3002</li> </ol>"},{"location":"main_classes/deepspeed/#zero-0","title":"ZeRO-0 \u200b\u914d\u7f6e","text":"<p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b Stage 0 \u200b\u548c\u200b 1 \u200b\u653e\u5728\u200b\u6700\u540e\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u4eec\u200b\u5f88\u5c11\u200b\u4f7f\u7528\u200b\u3002</p> <p>Stage 0 \u200b\u7981\u7528\u200b\u4e86\u200b\u6240\u6709\u200b\u7c7b\u578b\u200b\u7684\u200b\u5206\u7247\u200b\uff0c\u200b\u53ea\u662f\u200b\u5c06\u200b DeepSpeed \u200b\u4f5c\u4e3a\u200b DDP \u200b\u4f7f\u7528\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u542f\u7528\u200b\uff1a</p> <pre><code>{\n    \"zero_optimization\": {\n        \"stage\": 0\n    }\n}\n</code></pre> <p>\u200b\u8fd9\u200b\u5c06\u200b\u5b9e\u8d28\u200b\u4e0a\u200b\u7981\u7528\u200b ZeRO\uff0c\u200b\u800c\u200b\u65e0\u9700\u200b\u66f4\u6539\u200b\u5176\u4ed6\u200b\u4efb\u4f55\u200b\u5185\u5bb9\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#zero-1","title":"ZeRO-1 \u200b\u914d\u7f6e","text":"<p>Stage 1 \u200b\u7b49\u540c\u4e8e\u200b Stage 2 \u200b\u51cf\u53bb\u200b\u68af\u5ea6\u200b\u5206\u7247\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c1d\u8bd5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u914d\u7f6e\u200b\uff0c\u200b\u4ec5\u200b\u5bf9\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u8fdb\u884c\u200b\u5206\u7247\u200b\uff0c\u200b\u4ee5\u200b\u7a0d\u5fae\u200b\u52a0\u901f\u200b\uff1a</p> <pre><code>{\n    \"zero_optimization\": {\n        \"stage\": 1\n    }\n}\n</code></pre> <p></p>"},{"location":"main_classes/deepspeed/#nvme","title":"NVMe \u200b\u652f\u6301","text":"<p>ZeRO-Infinity \u200b\u901a\u8fc7\u200b\u4f7f\u7528\u200b NVMe \u200b\u5185\u5b58\u200b\u6269\u5c55\u200b GPU \u200b\u548c\u200b CPU \u200b\u5185\u5b58\u200b\uff0c\u200b\u4ece\u800c\u200b\u5141\u8bb8\u200b\u8bad\u7ec3\u200b\u975e\u5e38\u200b\u5927\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u7531\u4e8e\u200b\u667a\u80fd\u200b\u5206\u533a\u200b\u548c\u5e73\u200b\u94fa\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u5728\u200boffload\u200b\u671f\u95f4\u200b\u6bcf\u4e2a\u200b GPU \u200b\u9700\u8981\u200b\u53d1\u9001\u200b\u548c\u200b\u63a5\u6536\u200b\u975e\u5e38\u200b\u5c0f\u91cf\u200b\u7684\u200b\u6570\u636e\u200b\uff0c\u200b\u56e0\u6b64\u200b NVMe \u200b\u88ab\u200b\u8bc1\u660e\u200b\u9002\u7528\u200b\u4e8e\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u63d0\u4f9b\u200b\u66f4\u5927\u200b\u7684\u200b\u603b\u200b\u5185\u5b58\u200b\u6c60\u200b\u3002ZeRO-Infinity \u200b\u9700\u8981\u200b\u542f\u7528\u200b ZeRO-3\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u914d\u7f6e\u200b\u793a\u4f8b\u200b\u542f\u7528\u200b NVMe \u200b\u6765\u200boffload\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u548c\u200b\u53c2\u6570\u200b\uff1a</p> <pre><code>{\n    \"zero_optimization\": {\n        \"stage\": 3,\n        \"offload_optimizer\": {\n            \"device\": \"nvme\",\n            \"nvme_path\": \"/local_nvme\",\n            \"pin_memory\": true,\n            \"buffer_count\": 4,\n            \"fast_init\": false\n        },\n        \"offload_param\": {\n            \"device\": \"nvme\",\n            \"nvme_path\": \"/local_nvme\",\n            \"pin_memory\": true,\n            \"buffer_count\": 5,\n            \"buffer_size\": 1e8,\n            \"max_in_cpu\": 1e9\n        },\n        \"aio\": {\n            \"block_size\": 262144,\n            \"queue_depth\": 32,\n            \"thread_count\": 1,\n            \"single_submit\": false,\n            \"overlap_events\": true\n        },\n        \"overlap_comm\": true,\n        \"contiguous_gradients\": true,\n        \"sub_group_size\": 1e9,\n        \"reduce_bucket_size\": \"auto\",\n        \"stage3_prefetch_bucket_size\": \"auto\",\n        \"stage3_param_persistence_threshold\": \"auto\",\n        \"stage3_max_live_parameters\": 1e9,\n        \"stage3_max_reuse_distance\": 1e9,\n        \"stage3_gather_16bit_weights_on_model_save\": true\n    },\n}\n</code></pre> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u9009\u62e9\u200b\u5c06\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u548c\u200b\u53c2\u6570\u200b\u90fd\u200b\u5378\u8f7d\u200b\u5230\u200b NVMe\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u53ea\u200b\u9009\u62e9\u200b\u5176\u4e2d\u200b\u4e00\u4e2a\u200b\uff0c\u200b\u6216\u8005\u200b\u90fd\u200b\u4e0d\u200b\u9009\u62e9\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200b\u5927\u91cf\u200b\u7684\u200b CPU \u200b\u5185\u5b58\u200b\u53ef\u7528\u200b\uff0c\u200b\u53ea\u200b\u5378\u8f7d\u200b\u5230\u200b CPU \u200b\u5185\u5b58\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\u4f1a\u200b\u66f4\u200b\u5feb\u200b\uff08\u200b\u63d0\u793a\u200b\uff1a\"device\": \"cpu\"\uff09\u3002</p> <p>\u200b\u8fd9\u662f\u200b\u6709\u5173\u200b\u5378\u8f7d\u200b \u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b \u200b\u548c\u200b \u200b\u53c2\u6570\u200b \u200b\u7684\u200b\u5b8c\u6574\u200b\u6587\u6863\u200b\u3002</p> <p>\u200b\u786e\u4fdd\u60a8\u200b\u7684\u200b <code>nvme_path</code> \u200b\u5b9e\u9645\u4e0a\u200b\u662f\u200b\u4e00\u4e2a\u200b NVMe\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u4e0e\u200b\u666e\u901a\u200b\u786c\u76d8\u200b\u6216\u200b SSD \u200b\u4e00\u8d77\u200b\u5de5\u4f5c\u200b\uff0c\u200b\u4f46\u200b\u901f\u5ea6\u200b\u4f1a\u6162\u200b\u5f97\u200b\u591a\u200b\u3002\u200b\u5feb\u901f\u200b\u53ef\u200b\u6269\u5c55\u200b\u7684\u200b\u8bad\u7ec3\u200b\u662f\u200b\u6839\u636e\u200b\u73b0\u4ee3\u200b NVMe \u200b\u4f20\u8f93\u901f\u5ea6\u200b\u8bbe\u8ba1\u200b\u7684\u200b\uff08\u200b\u622a\u81f3\u200b\u672c\u6587\u200b\u64b0\u5199\u200b\u65f6\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u8fbe\u5230\u200b ~3.5GB/s \u200b\u8bfb\u53d6\u200b\uff0c~3GB/s \u200b\u5199\u5165\u200b\u7684\u200b\u5cf0\u503c\u200b\u901f\u5ea6\u200b\uff09\u3002</p> <p>\u200b\u4e3a\u4e86\u200b\u627e\u51fa\u200b\u6700\u4f73\u200b\u7684\u200b <code>aio</code> \u200b\u914d\u7f6e\u200b\u5757\u200b\uff0c\u200b\u60a8\u200b\u5fc5\u987b\u200b\u5728\u200b\u76ee\u6807\u200b\u8bbe\u7f6e\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u4e00\u4e2a\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b\uff0c\u200b\u5177\u4f53\u64cd\u4f5c\u200b\u8bf7\u200b\u53c2\u89c1\u200b\u8bf4\u660e\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#zero-2-zero-3","title":"ZeRO-2 \u200b\u548c\u200b ZeRO-3 \u200b\u6027\u80fd\u200b\u5bf9\u6bd4","text":"<p>\u200b\u5982\u679c\u200b\u5176\u4ed6\u200b\u4e00\u5207\u200b\u90fd\u200b\u914d\u7f6e\u200b\u76f8\u540c\u200b\uff0cZeRO-3 \u200b\u53ef\u80fd\u200b\u6bd4\u200b ZeRO-2 \u200b\u6162\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u524d\u8005\u200b\u9664\u4e86\u200b ZeRO-2 \u200b\u7684\u200b\u64cd\u4f5c\u200b\u5916\u200b\uff0c\u200b\u8fd8\u200b\u5fc5\u987b\u200b\u6536\u96c6\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u3002\u200b\u5982\u679c\u200b ZeRO-2 \u200b\u6ee1\u8db3\u200b\u60a8\u200b\u7684\u200b\u9700\u6c42\u200b\uff0c\u200b\u800c\u4e14\u200b\u60a8\u200b\u4e0d\u200b\u9700\u8981\u200b\u6269\u5c55\u200b\u5230\u200b\u51e0\u4e2a\u200b GPU \u200b\u4ee5\u4e0a\u200b\uff0c\u200b\u90a3\u4e48\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u9009\u62e9\u200b\u7ee7\u7eed\u200b\u4f7f\u7528\u200b\u5b83\u200b\u3002\u200b\u91cd\u8981\u200b\u7684\u200b\u662f\u200b\u8981\u200b\u7406\u89e3\u200b\uff0cZeRO-3 \u200b\u4ee5\u200b\u901f\u5ea6\u200b\u4e3a\u200b\u4ee3\u4ef7\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u66f4\u200b\u9ad8\u200b\u7684\u200b\u53ef\u6269\u5c55\u6027\u200b\u3002</p> <p>\u200b\u53ef\u4ee5\u200b\u8c03\u6574\u200b ZeRO-3 \u200b\u914d\u7f6e\u200b\u4f7f\u200b\u5176\u200b\u6027\u80fd\u200b\u63a5\u8fd1\u200b ZeRO-2\uff1a</p> <ul> <li>\u200b\u5c06\u200b <code>stage3_param_persistence_threshold</code> \u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u975e\u5e38\u200b\u5927\u200b\u7684\u200b\u6570\u5b57\u200b - \u200b\u5927\u4e8e\u200b\u6700\u5927\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u4f8b\u5982\u200b <code>6 * hidden_size * hidden_size</code>\u3002\u200b\u8fd9\u200b\u5c06\u200b\u4fdd\u7559\u200b\u53c2\u6570\u200b\u5728\u200b GPU \u200b\u4e0a\u200b\u3002</li> <li>\u200b\u5173\u95ed\u200b <code>offload_params</code>\uff0c\u200b\u56e0\u4e3a\u200b ZeRO-2 \u200b\u6ca1\u6709\u200b\u8fd9\u4e2a\u200b\u9009\u9879\u200b\u3002</li> </ul> <p>\u200b\u5373\u4f7f\u200b\u4e0d\u200b\u66f4\u6539\u200b <code>stage3_param_persistence_threshold</code>\uff0c\u200b\u4ec5\u200b\u5c06\u200b <code>offload_params</code> \u200b\u5173\u95ed\u200b\uff0c\u200b\u6027\u80fd\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u663e\u8457\u200b\u63d0\u9ad8\u200b\u3002\u200b\u5f53\u7136\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u66f4\u6539\u200b\u5c06\u200b\u5f71\u54cd\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u7684\u200b\u5927\u5c0f\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u66f4\u6539\u200b\u53ef\u200b\u6839\u636e\u200b\u9700\u6c42\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u5728\u200b\u53ef\u6269\u5c55\u6027\u200b\u548c\u200b\u901f\u5ea6\u200b\u4e4b\u95f4\u200b\u8fdb\u884c\u200b\u6743\u8861\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#zero-2_1","title":"ZeRO-2 \u200b\u793a\u4f8b","text":"<p>\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u5b8c\u6574\u200b\u7684\u200b ZeRO-2 \u200b\u81ea\u52a8\u200b\u914d\u7f6e\u6587\u4ef6\u200b <code>ds_config_zero2.json</code>\uff1a</p> <pre><code>{\n    \"fp16\": {\n        \"enabled\": \"auto\",\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    },\n\n    \"optimizer\": {\n        \"type\": \"AdamW\",\n        \"params\": {\n            \"lr\": \"auto\",\n            \"betas\": \"auto\",\n            \"eps\": \"auto\",\n            \"weight_decay\": \"auto\"\n        }\n    },\n\n    \"scheduler\": {\n        \"type\": \"WarmupLR\",\n        \"params\": {\n            \"warmup_min_lr\": \"auto\",\n            \"warmup_max_lr\": \"auto\",\n            \"warmup_num_steps\": \"auto\"\n        }\n    },\n\n    \"zero_optimization\": {\n        \"stage\": 2,\n        \"offload_optimizer\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": true\n        },\n        \"allgather_partitions\": true,\n        \"allgather_bucket_size\": 2e8,\n        \"overlap_comm\": true,\n        \"reduce_scatter\": true,\n        \"reduce_bucket_size\": 2e8,\n        \"contiguous_gradients\": true\n    },\n\n    \"gradient_accumulation_steps\": \"auto\",\n    \"gradient_clipping\": \"auto\",\n    \"steps_per_print\": 2000,\n    \"train_batch_size\": \"auto\",\n    \"train_micro_batch_size_per_gpu\": \"auto\",\n    \"wall_clock_breakdown\": false\n}\n</code></pre> <p>\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u5b8c\u6574\u200b\u7684\u200b\u624b\u52a8\u200b\u8bbe\u7f6e\u200b\u7684\u200b\u542f\u7528\u200b\u6240\u6709\u200b\u529f\u80fd\u200b\u7684\u200b ZeRO-2 \u200b\u914d\u7f6e\u6587\u4ef6\u200b\u3002\u200b\u4e3b\u8981\u200b\u662f\u200b\u4e3a\u4e86\u200b\u8ba9\u200b\u60a8\u200b\u770b\u5230\u200b\u5178\u578b\u200b\u7684\u200b\u53c2\u6570\u503c\u200b\u662f\u200b\u4ec0\u4e48\u6837\u200b\u7684\u200b\uff0c\u200b\u4f46\u200b\u6211\u4eec\u200b\u5f3a\u70c8\u5efa\u8bae\u200b\u4f7f\u7528\u200b\u5176\u4e2d\u200b\u5305\u542b\u200b\u591a\u4e2a\u200b <code>auto</code> \u200b\u8bbe\u7f6e\u200b\u7684\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u3002</p> <pre><code>{\n    \"fp16\": {\n        \"enabled\": true,\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    },\n\n    \"optimizer\": {\n        \"type\": \"AdamW\",\n        \"params\": {\n            \"lr\": 3e-5,\n            \"betas\": [0.8, 0.999],\n            \"eps\": 1e-8,\n            \"weight_decay\": 3e-7\n        }\n    },\n\n    \"scheduler\": {\n        \"type\": \"WarmupLR\",\n        \"params\": {\n            \"warmup_min_lr\": 0,\n            \"warmup_max_lr\": 3e-5,\n            \"warmup_num_steps\": 500\n        }\n    },\n\n    \"zero_optimization\": {\n        \"stage\": 2,\n        \"offload_optimizer\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": true\n        },\n        \"allgather_partitions\": true,\n        \"allgather_bucket_size\": 2e8,\n        \"overlap_comm\": true,\n        \"reduce_scatter\": true,\n        \"reduce_bucket_size\": 2e8,\n        \"contiguous_gradients\": true\n    },\n\n    \"steps_per_print\": 2000,\n    \"wall_clock_breakdown\": false\n}\n</code></pre> <p></p>"},{"location":"main_classes/deepspeed/#zero-3_1","title":"ZeRO-3 \u200b\u793a\u4f8b","text":"<p>\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u5b8c\u6574\u200b\u7684\u200b ZeRO-3 \u200b\u81ea\u52a8\u200b\u914d\u7f6e\u6587\u4ef6\u200b <code>ds_config_zero3.json</code>\uff1a</p> <pre><code>{\n    \"fp16\": {\n        \"enabled\": \"auto\",\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    },\n\n    \"optimizer\": {\n        \"type\": \"AdamW\",\n        \"params\": {\n            \"lr\": \"auto\",\n            \"betas\": \"auto\",\n            \"eps\": \"auto\",\n            \"weight_decay\": \"auto\"\n        }\n    },\n\n    \"scheduler\": {\n        \"type\": \"WarmupLR\",\n        \"params\": {\n            \"warmup_min_lr\": \"auto\",\n            \"warmup_max_lr\": \"auto\",\n            \"warmup_num_steps\": \"auto\"\n        }\n    },\n\n    \"zero_optimization\": {\n        \"stage\": 3,\n        \"offload_optimizer\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": true\n        },\n        \"offload_param\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": true\n        },\n        \"overlap_comm\": true,\n        \"contiguous_gradients\": true,\n        \"sub_group_size\": 1e9,\n        \"reduce_bucket_size\": \"auto\",\n        \"stage3_prefetch_bucket_size\": \"auto\",\n        \"stage3_param_persistence_threshold\": \"auto\",\n        \"stage3_max_live_parameters\": 1e9,\n        \"stage3_max_reuse_distance\": 1e9,\n        \"stage3_gather_16bit_weights_on_model_save\": true\n    },\n\n    \"gradient_accumulation_steps\": \"auto\",\n    \"gradient_clipping\": \"auto\",\n    \"steps_per_print\": 2000,\n    \"train_batch_size\": \"auto\",\n    \"train_micro_batch_size_per_gpu\": \"auto\",\n    \"wall_clock_breakdown\": false\n}\n</code></pre> <p>\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u5b8c\u6574\u200b\u7684\u200b \u200b\u624b\u52a8\u200b\u8bbe\u7f6e\u200b\u7684\u200b\u542f\u7528\u200b\u6240\u6709\u200b\u529f\u80fd\u200b\u7684\u200bZeRO-3 \u200b\u914d\u7f6e\u6587\u4ef6\u200b\u3002\u200b\u4e3b\u8981\u200b\u662f\u200b\u4e3a\u4e86\u200b\u8ba9\u200b\u60a8\u200b\u770b\u5230\u200b\u5178\u578b\u200b\u7684\u200b\u53c2\u6570\u503c\u200b\u662f\u200b\u4ec0\u4e48\u6837\u200b\u7684\u200b\uff0c\u200b\u4f46\u200b\u6211\u4eec\u200b\u5f3a\u70c8\u5efa\u8bae\u200b\u4f7f\u7528\u200b\u5176\u4e2d\u200b\u5305\u542b\u200b\u591a\u4e2a\u200b <code>auto</code> \u200b\u8bbe\u7f6e\u200b\u7684\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u3002</p> <pre><code>{\n    \"fp16\": {\n        \"enabled\": true,\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    },\n\n    \"optimizer\": {\n        \"type\": \"AdamW\",\n        \"params\": {\n            \"lr\": 3e-5,\n            \"betas\": [0.8, 0.999],\n            \"eps\": 1e-8,\n            \"weight_decay\": 3e-7\n        }\n    },\n\n    \"scheduler\": {\n        \"type\": \"WarmupLR\",\n        \"params\": {\n            \"warmup_min_lr\": 0,\n            \"warmup_max_lr\": 3e-5,\n            \"warmup_num_steps\": 500\n        }\n    },\n\n    \"zero_optimization\": {\n        \"stage\": 3,\n        \"offload_optimizer\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": true\n        },\n        \"offload_param\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": true\n        },\n        \"overlap_comm\": true,\n        \"contiguous_gradients\": true,\n        \"sub_group_size\": 1e9,\n        \"reduce_bucket_size\": 1e6,\n        \"stage3_prefetch_bucket_size\": 0.94e6,\n        \"stage3_param_persistence_threshold\": 1e4,\n        \"stage3_max_live_parameters\": 1e9,\n        \"stage3_max_reuse_distance\": 1e9,\n        \"stage3_gather_16bit_weights_on_model_save\": true\n    },\n\n    \"steps_per_print\": 2000,\n    \"wall_clock_breakdown\": false\n}\n</code></pre>"},{"location":"main_classes/deepspeed/#zero-stage-offloads","title":"\u5982\u4f55\u200b\u9009\u62e9\u200b\u6700\u4f73\u200b\u6027\u80fd\u200b\u7684\u200bZeRO Stage\u200b\u548c\u200b offloads","text":"<p>\u200b\u4e86\u89e3\u200b\u4e86\u200b\u8fd9\u4e9b\u200b\u4e0d\u540c\u200bstages\u200b\u540e\u200b\uff0c\u200b\u73b0\u5728\u200b\u60a8\u200b\u9700\u8981\u200b\u51b3\u5b9a\u200b\u4f7f\u7528\u200b\u54ea\u4e2a\u200bstage\u3002\u200b\u672c\u8282\u200b\u5c06\u200b\u5c1d\u8bd5\u200b\u56de\u7b54\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\u3002</p> <p>\u200b\u901a\u5e38\u200b\uff0c\u200b\u4ee5\u4e0b\u200b\u89c4\u5219\u200b\u9002\u7528\u200b\uff1a</p> <ul> <li>\u200b\u901f\u5ea6\u200b\u65b9\u9762\u200b\uff08\u200b\u5de6\u8fb9\u200b\u6bd4\u200b\u53f3\u8fb9\u200b\u5feb\u200b\uff09</li> </ul> <p>stage 0\uff08DDP\uff09 &gt; stage 1 &gt; stage 2 &gt; stage 2 + offload  &gt; stage 3 &gt; stage3 + offload</p> <ul> <li>GPU\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u65b9\u9762\u200b\uff08\u200b\u53f3\u8fb9\u200b\u6bd4\u200b\u5de6\u8fb9\u200b\u66f4\u200b\u8282\u7701\u200bGPU\u200b\u5185\u5b58\u200b\uff09</li> </ul> <p>stage 0\uff08DDP\uff09 &lt; stage 1 &lt; stage 2 &lt; stage 2 + offload &lt; stage 3 &lt; stage 3 + offload</p> <p>\u200b\u6240\u4ee5\u200b\uff0c\u200b\u5f53\u200b\u60a8\u200b\u5e0c\u671b\u200b\u5728\u200b\u5c3d\u91cf\u200b\u4f7f\u7528\u200b\u8f83\u200b\u5c11\u200b\u6570\u91cf\u200b\u7684\u200bGPU\u200b\u7684\u200b\u540c\u65f6\u200b\u83b7\u5f97\u200b\u6700\u5feb\u200b\u7684\u200b\u6267\u884c\u200b\u901f\u5ea6\u200b\u65f6\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u6309\u7167\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u8fdb\u884c\u200b\u3002\u200b\u6211\u4eec\u200b\u4ece\u200b\u6700\u5feb\u200b\u7684\u200b\u65b9\u6cd5\u200b\u5f00\u59cb\u200b\uff0c\u200b\u5982\u679c\u200b\u9047\u5230\u200bGPU\u200b\u5185\u5b58\u200b\u6ea2\u51fa\u200b\uff0c\u200b\u7136\u540e\u200b\u5207\u6362\u200b\u5230\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u901f\u5ea6\u200b\u8f83\u6162\u200b\u4f46\u200b\u4f7f\u7528\u200b\u7684\u200bGPU\u200b\u5185\u5b58\u200b\u66f4\u5c11\u200b\u7684\u200b\u65b9\u6cd5\u200b\u3002\u200b\u4ee5\u6b64\u7c7b\u63a8\u200b\u3002</p> <p>\u200b\u9996\u5148\u200b\uff0c\u200b\u5c06\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b1\uff08\u200b\u60a8\u200b\u59cb\u7ec8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\u6765\u200b\u83b7\u5f97\u200b\u4efb\u4f55\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u6709\u6548\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\uff09\u3002</p> <ol> <li>\u200b\u542f\u7528\u200b <code>--gradient_checkpointing 1</code>\uff08HF Trainer\uff09\u200b\u6216\u200b\u76f4\u63a5\u200b <code>model.gradient_checkpointing_enable()</code> - \u200b\u5982\u679c\u200b\u53d1\u751f\u200bOOM\uff08Out of Memory\uff09\uff0c\u200b\u5219\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u3002</li> <li>\u200b\u9996\u5148\u200b\u5c1d\u8bd5\u200b ZeRO stage 2\u3002\u200b\u5982\u679c\u200b\u53d1\u751f\u200bOOM\uff0c\u200b\u5219\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u3002</li> <li>\u200b\u5c1d\u8bd5\u200b ZeRO stage 2 + <code>offload_optimizer</code> - \u200b\u5982\u679c\u200b\u53d1\u751f\u200bOOM\uff0c\u200b\u5219\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u3002</li> <li>\u200b\u5207\u6362\u200b\u5230\u200b ZeRO stage 3 - \u200b\u5982\u679c\u200b\u53d1\u751f\u200bOOM\uff0c\u200b\u5219\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u3002</li> <li>\u200b\u542f\u7528\u200b <code>offload_param</code> \u200b\u5230\u200b <code>cpu</code> - \u200b\u5982\u679c\u200b\u53d1\u751f\u200bOOM\uff0c\u200b\u5219\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u3002</li> <li>\u200b\u542f\u7528\u200b <code>offload_optimizer</code> \u200b\u5230\u200b <code>cpu</code> - \u200b\u5982\u679c\u200b\u53d1\u751f\u200bOOM\uff0c\u200b\u5219\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u3002</li> <li>\u200b\u5982\u679c\u200b\u4ecd\u7136\u200b\u65e0\u6cd5\u200b\u9002\u5e94\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\u4e3a\u200b1\uff0c\u200b\u8bf7\u200b\u9996\u5148\u200b\u68c0\u67e5\u200b\u5404\u79cd\u200b\u9ed8\u8ba4\u503c\u200b\u5e76\u200b\u5c3d\u53ef\u80fd\u200b\u964d\u4f4e\u200b\u5b83\u4eec\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u4f7f\u7528\u200b <code>generate</code> \u200b\u5e76\u4e14\u200b\u4e0d\u200b\u4f7f\u7528\u200b\u5bbd\u200b\u641c\u7d22\u200b\u675f\u200b\uff0c\u200b\u5c06\u200b\u5176\u200b\u7f29\u5c0f\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u4f1a\u200b\u5360\u7528\u200b\u5927\u91cf\u200b\u5185\u5b58\u200b\u3002</li> <li>\u200b\u7edd\u5bf9\u200b\u8981\u200b\u4f7f\u7528\u200b\u6df7\u5408\u200b\u534a\u200b\u7cbe\u5ea6\u200b\u800c\u200b\u975e\u200bfp32 - \u200b\u5728\u200bAmpere\u200b\u53ca\u200b\u66f4\u200b\u9ad8\u200b\u7684\u200bGPU\u200b\u4e0a\u200b\u4f7f\u7528\u200bbf16\uff0c\u200b\u5728\u200b\u65e7\u200b\u7684\u200bGPU\u200b\u4f53\u7cfb\u7ed3\u6784\u200b\u4e0a\u200b\u4f7f\u7528\u200bfp16\u3002</li> <li>\u200b\u5982\u679c\u200b\u4ecd\u7136\u200b\u53d1\u751f\u200bOOM\uff0c\u200b\u53ef\u4ee5\u200b\u6dfb\u52a0\u200b\u66f4\u200b\u591a\u200b\u786c\u4ef6\u200b\u6216\u200b\u542f\u7528\u200bZeRO-Infinity - \u200b\u5373\u200b\u5207\u6362\u200b <code>offload_param</code> \u200b\u548c\u200b <code>offload_optimizer</code> \u200b\u5230\u200b <code>nvme</code>\u3002\u200b\u60a8\u200b\u9700\u8981\u200b\u786e\u4fdd\u200b\u5b83\u200b\u662f\u200b\u975e\u5e38\u200b\u5feb\u200b\u7684\u200bNVMe\u3002\u200b\u4f5c\u4e3a\u200b\u8da3\u95fb\u200b\uff0c\u200b\u6211\u200b\u66fe\u7ecf\u200b\u80fd\u591f\u200b\u5728\u200b\u4e00\u4e2a\u200b\u5c0f\u578b\u200bGPU\u200b\u4e0a\u200b\u4f7f\u7528\u200bBLOOM-176B\u200b\u8fdb\u884c\u200b\u63a8\u7406\u200b\uff0c\u200b\u4f7f\u7528\u200b\u4e86\u200bZeRO-Infinity\uff0c\u200b\u5c3d\u7ba1\u200b\u901f\u5ea6\u200b\u975e\u5e38\u200b\u6162\u200b\u3002\u200b\u4f46\u200b\u5b83\u200b\u594f\u6548\u200b\u4e86\u200b\uff01</li> </ol> <p>\u200b\u5f53\u7136\u200b\uff0c\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u6309\u200b\u76f8\u53cd\u200b\u7684\u200b\u987a\u5e8f\u200b\u8fdb\u884c\u200b\u8fd9\u4e9b\u200b\u6b65\u9aa4\u200b\uff0c\u200b\u4ece\u200b\u6700\u200b\u8282\u7701\u200bGPU\u200b\u5185\u5b58\u200b\u7684\u200b\u914d\u7f6e\u200b\u5f00\u59cb\u200b\uff0c\u200b\u7136\u540e\u200b\u9010\u6b65\u200b\u53cd\u5411\u200b\u8fdb\u884c\u200b\uff0c\u200b\u6216\u8005\u200b\u5c1d\u8bd5\u200b\u8fdb\u884c\u200b\u4e8c\u5206\u6cd5\u200b\u3002</p> <p>\u200b\u4e00\u65e6\u200b\u60a8\u200b\u7684\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\u4e3a\u200b1\u200b\u4e0d\u4f1a\u200b\u5bfc\u81f4\u200bOOM\uff0c\u200b\u5c31\u200b\u6d4b\u91cf\u200b\u60a8\u200b\u7684\u200b\u6709\u6548\u200b\u541e\u5410\u91cf\u200b\u3002</p> <p>\u200b\u63a5\u4e0b\u6765\u200b\u5c1d\u8bd5\u200b\u5c06\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\u589e\u52a0\u200b\u5230\u200b\u5c3d\u53ef\u80fd\u200b\u5927\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\u8d8a\u5927\u200b\uff0cGPU\u200b\u7684\u200b\u6548\u7387\u200b\u8d8a\u9ad8\u200b\uff0c\u200b\u7279\u522b\u200b\u662f\u200b\u5728\u200b\u5b83\u4eec\u200b\u4e58\u6cd5\u200b\u8fd0\u7b97\u200b\u7684\u200b\u77e9\u9635\u200b\u5f88\u5927\u200b\u65f6\u200b\u3002</p> <p>\u200b\u73b0\u5728\u200b\u6027\u80fd\u200b\u4f18\u5316\u200b\u6e38\u620f\u200b\u5f00\u59cb\u200b\u4e86\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5173\u95ed\u200b\u4e00\u4e9b\u200boffload\u200b\u7279\u6027\u200b\uff0c\u200b\u6216\u8005\u200b\u964d\u4f4e\u200bZeRO stage\uff0c\u200b\u5e76\u200b\u589e\u52a0\u200b/\u200b\u51cf\u5c11\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\uff0c\u200b\u518d\u6b21\u200b\u6d4b\u91cf\u200b\u6709\u6548\u200b\u541e\u5410\u91cf\u200b\u3002\u200b\u53cd\u590d\u200b\u5c1d\u8bd5\u200b\uff0c\u200b\u76f4\u5230\u200b\u6ee1\u610f\u200b\u4e3a\u6b62\u200b\u3002</p> <p>\u200b\u4e0d\u8981\u200b\u82b1\u8d39\u200b\u592a\u200b\u591a\u200b\u65f6\u95f4\u200b\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u60a8\u200b\u5373\u5c06\u200b\u5f00\u59cb\u200b\u4e00\u4e2a\u200b\u4e3a\u671f\u200b3\u200b\u4e2a\u200b\u6708\u200b\u7684\u200b\u8bad\u7ec3\u200b - \u200b\u8bf7\u82b1\u200b\u51e0\u5929\u200b\u65f6\u95f4\u200b\u627e\u5230\u200b\u541e\u5410\u91cf\u200b\u65b9\u9762\u200b\u6700\u200b\u6709\u6548\u200b\u7684\u200b\u8bbe\u7f6e\u200b\u3002\u200b\u8fd9\u6837\u200b\u60a8\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6210\u672c\u200b\u5c06\u200b\u6700\u4f4e\u200b\uff0c\u200b\u800c\u4e14\u200b\u60a8\u200b\u4f1a\u200b\u66f4\u200b\u5feb\u200b\u5730\u200b\u5b8c\u6210\u200b\u8bad\u7ec3\u200b\u3002\u200b\u5728\u200b\u5f53\u524d\u200b\u5feb\u8282\u594f\u200b\u7684\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u4e16\u754c\u200b\u4e2d\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u82b1\u8d39\u200b\u4e00\u4e2a\u200b\u989d\u5916\u200b\u7684\u200b\u6708\u4efd\u200b\u6765\u200b\u8bad\u7ec3\u200b\u67d0\u6837\u200b\u4e1c\u897f\u200b\uff0c\u200b\u4f60\u200b\u5f88\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u9519\u8fc7\u200b\u4e00\u4e2a\u200b\u9ec4\u91d1\u200b\u673a\u4f1a\u200b\u3002\u200b\u5f53\u7136\u200b\uff0c\u200b\u8fd9\u200b\u53ea\u662f\u200b\u6211\u200b\u5206\u4eab\u200b\u7684\u200b\u4e00\u79cd\u200b\u89c2\u5bdf\u200b\uff0c\u200b\u6211\u200b\u5e76\u200b\u4e0d\u662f\u200b\u5728\u200b\u50ac\u4fc3\u200b\u4f60\u200b\u3002\u200b\u5728\u200b\u5f00\u59cb\u200b\u8bad\u7ec3\u200bBLOOM-176B\u200b\u4e4b\u524d\u200b\uff0c\u200b\u6211\u82b1\u200b\u4e86\u200b2\u200b\u5929\u200b\u65f6\u95f4\u200b\u8fdb\u884c\u200b\u8fd9\u4e2a\u200b\u8fc7\u7a0b\u200b\uff0c\u200b\u6210\u529f\u200b\u5c06\u200b\u541e\u5410\u91cf\u200b\u4ece\u200b90 TFLOPs\u200b\u63d0\u9ad8\u200b\u5230\u200b150 TFLOPs\uff01\u200b\u8fd9\u4e00\u200b\u52aa\u529b\u200b\u4e3a\u200b\u6211\u4eec\u200b\u8282\u7701\u200b\u4e86\u200b\u4e00\u4e2a\u591a\u6708\u200b\u7684\u200b\u8bad\u7ec3\u200b\u65f6\u95f4\u200b\u3002</p> <p>\u200b\u8fd9\u4e9b\u200b\u6ce8\u91ca\u200b\u4e3b\u8981\u200b\u662f\u200b\u4e3a\u200b\u8bad\u7ec3\u200b\u6a21\u5f0f\u200b\u7f16\u5199\u200b\u7684\u200b\uff0c\u200b\u4f46\u200b\u5b83\u4eec\u200b\u5728\u200b\u63a8\u7406\u200b\u4e2d\u200b\u4e5f\u200b\u5e94\u8be5\u200b\u5927\u90e8\u5206\u200b\u9002\u7528\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5728\u200b\u63a8\u7406\u200b\u4e2d\u200b\uff0cGradient Checkpointing \u200b\u662f\u200b\u65e0\u7528\u200b\u7684\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u53ea\u200b\u5728\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u6709\u7528\u200b\u3002\u200b\u6b64\u5916\u200b\uff0c\u200b\u6211\u4eec\u200b\u53d1\u73b0\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u6b63\u5728\u200b\u8fdb\u884c\u200b\u591a\u200bGPU\u200b\u63a8\u7406\u200b\u5e76\u4e14\u200b\u4e0d\u200b\u4f7f\u7528\u200b DeepSpeed-Inference\uff0cAccelerate \u200b\u5e94\u8be5\u200b\u63d0\u4f9b\u200b\u66f4\u4f18\u8d8a\u200b\u7684\u200b\u6027\u80fd\u200b\u3002</p> <p>\u200b\u5176\u4ed6\u200b\u4e0e\u200b\u6027\u80fd\u200b\u76f8\u5173\u200b\u7684\u200b\u5feb\u901f\u200b\u6ce8\u91ca\u200b\uff1a - \u200b\u5982\u679c\u200b\u60a8\u200b\u4ece\u5934\u5f00\u59cb\u200b\u8bad\u7ec3\u200b\u67d0\u4e2a\u200b\u6a21\u578b\u200b\uff0c\u200b\u8bf7\u200b\u5c3d\u91cf\u200b\u786e\u4fdd\u200b\u5f20\u91cf\u200b\u7684\u200b\u5f62\u72b6\u200b\u53ef\u4ee5\u200b\u88ab\u200b16\u200b\u6574\u9664\u200b\uff08\u200b\u4f8b\u5982\u200b\u9690\u85cf\u200b\u5c42\u200b\u5927\u5c0f\u200b\uff09\u3002\u200b\u5bf9\u4e8e\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\uff0c\u200b\u81f3\u5c11\u200b\u5c1d\u8bd5\u200b\u53ef\u200b\u88ab\u200b2\u200b\u6574\u9664\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u4ece\u200bGPU\u200b\u4e2d\u6324\u200b\u53d6\u200b\u66f4\u200b\u9ad8\u6027\u80fd\u200b\uff0c\u200b\u8fd8\u6709\u200b\u4e00\u4e9b\u200b\u786c\u4ef6\u200b\u7279\u5b9a\u200b\u7684\u200bwave\u200b\u548c\u200btile\u200b\u91cf\u5316\u200b\u7684\u200b\u53ef\u200b\u6574\u9664\u200b\u6027\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#activation-checkpointing-gradient-checkpointing","title":"Activation Checkpointing \u200b\u6216\u200b Gradient Checkpointing","text":"<p>Activation Checkpointing\u200b\u548c\u200bGradient Checkpointing\u200b\u662f\u200b\u6307\u200b\u76f8\u540c\u200b\u65b9\u6cd5\u200b\u7684\u200b\u4e24\u4e2a\u200b\u4e0d\u540c\u200b\u672f\u8bed\u200b\u3002\u200b\u8fd9\u200b\u786e\u5b9e\u200b\u8ba9\u200b\u4eba\u200b\u611f\u5230\u200b\u56f0\u60d1\u200b\uff0c\u200b\u4f46\u200b\u4e8b\u5b9e\u200b\u5c31\u662f\u200b\u8fd9\u6837\u200b\u3002</p> <p>Gradient Checkpointing\u200b\u5141\u8bb8\u200b\u901a\u8fc7\u200b\u727a\u7272\u200b\u901f\u5ea6\u200b\u6765\u200b\u6362\u53d6\u200bGPU\u200b\u5185\u5b58\u200b\uff0c\u200b\u8fd9\u200b\u8981\u4e48\u200b\u4f7f\u200b\u60a8\u200b\u80fd\u591f\u200b\u514b\u670d\u200bGPU\u200b\u5185\u5b58\u200b\u6ea2\u51fa\u200b\uff0c\u200b\u8981\u4e48\u200b\u589e\u52a0\u200b\u6279\u91cf\u200b\u5927\u5c0f\u200b\u6765\u200b\u83b7\u5f97\u200b\u66f4\u597d\u200b\u7684\u200b\u6027\u80fd\u200b\u3002</p> <p>HF Transformers \u200b\u6a21\u578b\u200b\u5bf9\u200bDeepSpeed\u200b\u7684\u200bActivation Checkpointing\u200b\u4e00\u65e0\u6240\u77e5\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5982\u679c\u200b\u5c1d\u8bd5\u200b\u5728\u200bDeepSpeed\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u542f\u7528\u200b\u8be5\u200b\u529f\u80fd\u200b\uff0c\u200b\u4ec0\u4e48\u200b\u90fd\u200b\u4e0d\u4f1a\u200b\u53d1\u751f\u200b\u3002</p> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u60a8\u200b\u6709\u200b\u4e24\u79cd\u200b\u65b9\u6cd5\u200b\u53ef\u4ee5\u200b\u5229\u7528\u200b\u8fd9\u4e2a\u200b\u975e\u5e38\u200b\u6709\u76ca\u200b\u7684\u200b\u529f\u80fd\u200b\uff1a</p> <ol> <li>\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u4f7f\u7528\u200b HF Transformers \u200b\u6a21\u578b\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>model.gradient_checkpointing_enable()</code> \u200b\u6216\u200b\u5728\u200b HF Trainer \u200b\u4e2d\u200b\u4f7f\u7528\u200b <code>--gradient_checkpointing</code>\uff0c\u200b\u5b83\u4f1a\u200b\u81ea\u52a8\u200b\u4e3a\u200b\u60a8\u200b\u542f\u7528\u200b\u8fd9\u4e2a\u200b\u529f\u80fd\u200b\u3002\u200b\u5728\u200b\u8fd9\u91cc\u200b\u4f7f\u7528\u200b\u4e86\u200b <code>torch.utils.checkpoint</code>\u3002</li> <li>\u200b\u5982\u679c\u200b\u60a8\u200b\u7f16\u5199\u200b\u81ea\u5df1\u200b\u7684\u200b\u6a21\u578b\u200b\u5e76\u200b\u5e0c\u671b\u200b\u4f7f\u7528\u200bDeepSpeed\u200b\u7684\u200bActivation Checkpointing\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u89c4\u5b9a\u200b\u7684\u200bAPI\u3002\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b HF Transformers \u200b\u7684\u200b\u6a21\u578b\u200b\u4ee3\u7801\u200b\uff0c\u200b\u5c06\u200b <code>torch.utils.checkpoint</code> \u200b\u66ff\u6362\u200b\u4e3a\u200b DeepSpeed \u200b\u7684\u200bAPI\u3002\u200b\u540e\u8005\u200b\u66f4\u200b\u7075\u6d3b\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u5141\u8bb8\u200b\u60a8\u200b\u5c06\u200b\u524d\u200b\u5411\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u5378\u8f7d\u200b\u5230\u200bCPU\u200b\u5185\u5b58\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u91cd\u65b0\u200b\u8ba1\u7b97\u200b\u5b83\u4eec\u200b\u3002</li> </ol>"},{"location":"main_classes/deepspeed/#optimizer-scheduler","title":"Optimizer \u200b\u548c\u200b Scheduler","text":"<p>\u200b\u53ea\u8981\u200b\u4f60\u200b\u4e0d\u200b\u542f\u7528\u200b <code>offload_optimizer</code>\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u6df7\u5408\u200b\u4f7f\u7528\u200bDeepSpeed\u200b\u548c\u200bHuggingFace\u200b\u7684\u200b\u8c03\u5ea6\u200b\u5668\u200b\u548c\u200b\u4f18\u5316\u200b\u5668\u200b\uff0c\u200b\u4f46\u200b\u6709\u200b\u4e00\u4e2a\u200b\u4f8b\u5916\u200b\uff0c\u200b\u5373\u200b\u4e0d\u8981\u200b\u4f7f\u7528\u200bHuggingFace\u200b\u8c03\u5ea6\u200b\u5668\u200b\u548c\u200bDeepSpeed\u200b\u4f18\u5316\u200b\u5668\u200b\u7684\u200b\u7ec4\u5408\u200b\uff1a</p> Combos HF Scheduler DS Scheduler HF Optimizer Yes Yes DS Optimizer No Yes <p>\u200b\u5728\u200b\u542f\u7528\u200b <code>offload_optimizer</code> \u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u975e\u200bDeepSpeed\u200b\u4f18\u5316\u200b\u5668\u200b\uff0c\u200b\u53ea\u8981\u200b\u8be5\u200b\u4f18\u5316\u200b\u5668\u5177\u200b\u6709\u200bCPU\u200b\u548c\u200bGPU\u200b\u7684\u200b\u5b9e\u73b0\u200b\uff08\u200b\u9664\u4e86\u200bLAMB\uff09\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#optimizer","title":"Optimizer","text":"<p>DeepSpeed\u200b\u7684\u200b\u4e3b\u8981\u200b\u4f18\u5316\u200b\u5668\u200b\u5305\u62ec\u200bAdam\u3001AdamW\u3001OneBitAdam\u200b\u548c\u200bLamb\u3002\u200b\u8fd9\u4e9b\u200b\u4f18\u5316\u200b\u5668\u200b\u5df2\u7ecf\u200b\u4e0e\u200bZeRO\u200b\u8fdb\u884c\u200b\u4e86\u200b\u5f7b\u5e95\u200b\u7684\u200b\u6d4b\u8bd5\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200b\u5b83\u4eec\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u5bfc\u5165\u200b<code>torch</code>\u200b\u4e2d\u200b\u7684\u200b\u5176\u4ed6\u200b\u4f18\u5316\u200b\u5668\u200b\u3002\u200b\u5b8c\u6574\u200b\u7684\u200b\u6587\u6863\u200b\u5728\u200b\u8fd9\u91cc\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u4e0d\u200b\u914d\u7f6e\u200b<code>optimizer</code>\u200b\u6761\u76ee\u200b\uff0c[<code>Trainer</code>] \u200b\u5c06\u200b\u81ea\u52a8\u200b\u5c06\u200b\u5176\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b <code>AdamW</code>\uff0c\u200b\u5e76\u200b\u4f7f\u7528\u200b\u63d0\u4f9b\u200b\u7684\u200b\u503c\u200b\u6216\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u7684\u200b\u9ed8\u8ba4\u503c\u200b\uff1a<code>--learning_rate</code>\u3001<code>--adam_beta1</code>\u3001<code>--adam_beta2</code>\u3001<code>--adam_epsilon</code> \u200b\u548c\u200b <code>--weight_decay</code>\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b<code>AdamW</code> \u200b\u7684\u200b\u81ea\u52a8\u200b\u914d\u7f6e\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>{\n   \"optimizer\": {\n       \"type\": \"AdamW\",\n       \"params\": {\n         \"lr\": \"auto\",\n         \"betas\": \"auto\",\n         \"eps\": \"auto\",\n         \"weight_decay\": \"auto\"\n       }\n   }\n}\n</code></pre> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u5c06\u200b\u8bbe\u7f6e\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u7684\u200b\u503c\u200b\u3002\u200b\u8fd9\u662f\u200b\u4e3a\u4e86\u200b\u6709\u200b\u4e00\u4e2a\u200b\u660e\u786e\u200b\u7684\u200b\u503c\u200b\u6765\u6e90\u200b\uff0c\u200b\u5e76\u200b\u907f\u514d\u200b\u5728\u200b\u4e0d\u540c\u200b\u5730\u65b9\u200b\u8bbe\u7f6e\u200b\u5b66\u4e60\u200b\u7387\u200b\u7b49\u503c\u200b\u65f6\u200b\u96be\u4ee5\u200b\u627e\u5230\u200b\u7684\u200b\u9519\u8bef\u200b\u3002\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u914d\u7f6e\u200b\u9ad8\u4e8e\u200b\u5176\u4ed6\u200b\u3002\u200b\u88ab\u200b\u8986\u76d6\u200b\u7684\u200b\u503c\u200b\u5305\u62ec\u200b\uff1a</p> <ul> <li><code>lr</code> \u200b\u7684\u200b\u503c\u200b\u4e3a\u200b <code>--learning_rate</code></li> <li><code>betas</code> \u200b\u7684\u200b\u503c\u200b\u4e3a\u200b <code>--adam_beta1 --adam_beta2</code></li> <li><code>eps</code> \u200b\u7684\u200b\u503c\u200b\u4e3a\u200b <code>--adam_epsilon</code></li> <li><code>weight_decay</code> \u200b\u7684\u200b\u503c\u200b\u4e3a\u200b <code>--weight_decay</code></li> </ul> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u8bf7\u200b\u8bb0\u4f4f\u200b\u5728\u200b\u547d\u4ee4\u884c\u200b\u4e0a\u200b\u8c03\u6574\u200b\u5171\u4eab\u200b\u7684\u200b\u8d85\u200b\u53c2\u6570\u200b\u3002</p> <p>\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u663e\u5f0f\u200b\u5730\u200b\u8bbe\u7f6e\u200b\u8fd9\u4e9b\u200b\u503c\u200b\uff1a</p> <pre><code>{\n   \"optimizer\": {\n       \"type\": \"AdamW\",\n       \"params\": {\n         \"lr\": 0.001,\n         \"betas\": [0.8, 0.999],\n         \"eps\": 1e-8,\n         \"weight_decay\": 3e-7\n       }\n   }\n}\n</code></pre> <p>\u200b\u4f46\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u81ea\u5df1\u200b\u540c\u6b65\u200b[<code>Trainer</code>]\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u548c\u200bDeepSpeed\u200b\u914d\u7f6e\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u4f7f\u7528\u200b\u4e0a\u9762\u200b\u672a\u200b\u5217\u51fa\u200b\u7684\u200b\u5176\u4ed6\u200b\u4f18\u5316\u200b\u5668\u200b\uff0c\u200b\u60a8\u200b\u5c06\u200b\u4e0d\u5f97\u4e0d\u200b\u5c06\u200b\u5176\u200b\u6dfb\u52a0\u200b\u5230\u200b\u9876\u5c42\u200b\u914d\u7f6e\u200b\u4e2d\u200b\u3002</p> <pre><code>{\n   \"zero_allow_untested_optimizer\": true\n}\n</code></pre> <p>\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b <code>AdamW</code>\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u914d\u7f6e\u200b\u5176\u4ed6\u200b\u5b98\u65b9\u200b\u652f\u6301\u200b\u7684\u200b\u4f18\u5316\u200b\u5668\u200b\u3002\u200b\u53ea\u662f\u200b\u8bb0\u4f4f\u200b\u8fd9\u4e9b\u200b\u53ef\u80fd\u200b\u6709\u200b\u4e0d\u540c\u200b\u7684\u200b\u914d\u7f6e\u200b\u503c\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5bf9\u4e8e\u200bAdam\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u5c06\u200b <code>weight_decay</code> \u200b\u8bbe\u7f6e\u200b\u5728\u200b <code>0.01</code> \u200b\u5de6\u53f3\u200b\u3002</p> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u5f53\u200b\u4e0e\u200bDeepSpeed\u200b\u7684\u200bCPU Adam\u200b\u4f18\u5316\u200b\u5668\u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\u65f6\u200b\uff0coffload\u200b\u7684\u200b\u6548\u679c\u200b\u6700\u597d\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u5728\u200boffload\u200b\u65f6\u200b\u4f7f\u7528\u200b\u4e0d\u540c\u200b\u7684\u200b\u4f18\u5316\u200b\u5668\u200b\uff0c\u200b\u81ea\u200b <code>deepspeed==0.8.3</code> \u200b\u8d77\u200b\uff0c\u200b\u60a8\u200b\u8fd8\u200b\u9700\u8981\u200b\u6dfb\u52a0\u200b\uff1a</p> <p><pre><code>{\n   \"zero_force_ds_cpu_optimizer\": false\n}\n</code></pre> \u200b\u5230\u200b\u9876\u5c42\u200b\u914d\u7f6e\u200b\u4e2d\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#scheduler","title":"Scheduler","text":"<p>DeepSpeed\u200b\u652f\u6301\u200b<code>LRRangeTest</code>\u3001<code>OneCycle</code>\u3001<code>WarmupLR</code>\u200b\u548c\u200b<code>WarmupDecayLR</code>\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u5ea6\u200b\u5668\u200b\u3002\u200b\u5b8c\u6574\u200b\u6587\u6863\u200b\u5728\u200b\u8fd9\u91cc\u200b\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\ud83e\udd17 Transformers \u200b\u548c\u200b DeepSpeed \u200b\u4e4b\u95f4\u200b\u7684\u200b\u8c03\u5ea6\u200b\u5668\u200b\u91cd\u53e0\u200b\u90e8\u5206\u200b\uff1a</p> <ul> <li>\u200b\u901a\u8fc7\u200b <code>--lr_scheduler_type constant_with_warmup</code> \u200b\u5b9e\u73b0\u200b <code>WarmupLR</code></li> <li>\u200b\u901a\u8fc7\u200b <code>--lr_scheduler_type linear</code> \u200b\u5b9e\u73b0\u200b <code>WarmupDecayLR</code>\u3002\u200b\u8fd9\u200b\u4e5f\u200b\u662f\u200b <code>--lr_scheduler_type</code> \u200b\u7684\u200b\u9ed8\u8ba4\u503c\u200b\uff0c\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u4e0d\u200b\u914d\u7f6e\u200b\u8c03\u5ea6\u200b\u5668\u200b\uff0c\u200b\u8fd9\u200b\u5c06\u200b\u662f\u200b\u9ed8\u8ba4\u200b\u914d\u7f6e\u200b\u7684\u200b\u8c03\u5ea6\u200b\u5668\u200b\u3002</li> </ul> <p>\u200b\u5982\u679c\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u4e0d\u200b\u914d\u7f6e\u200b <code>scheduler</code> \u200b\u6761\u76ee\u200b\uff0c[<code>Trainer</code>] \u200b\u5c06\u200b\u4f7f\u7528\u200b <code>--lr_scheduler_type</code>\u3001<code>--learning_rate</code> \u200b\u548c\u200b <code>--warmup_steps</code> \u200b\u6216\u200b <code>--warmup_ratio</code> \u200b\u7684\u200b\u503c\u6765\u200b\u914d\u7f6e\u200b\u5176\u200b\ud83e\udd17 Transformers \u200b\u7248\u672c\u200b\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b <code>WarmupLR</code> \u200b\u7684\u200b\u81ea\u52a8\u200b\u914d\u7f6e\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>{\n   \"scheduler\": {\n         \"type\": \"WarmupLR\",\n         \"params\": {\n             \"warmup_min_lr\": \"auto\",\n             \"warmup_max_lr\": \"auto\",\n             \"warmup_num_steps\": \"auto\"\n         }\n     }\n}\n</code></pre> <p>\u200b\u7531\u4e8e\u200b\u4f7f\u7528\u200b\u4e86\u200b \"auto\"\uff0c[<code>Trainer</code>] \u200b\u7684\u200b\u53c2\u6570\u200b\u5c06\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u8bbe\u7f6e\u200b\u6b63\u786e\u200b\u7684\u200b\u503c\u200b\u3002\u200b\u8fd9\u662f\u200b\u4e3a\u4e86\u200b\u6709\u200b\u4e00\u4e2a\u200b\u660e\u786e\u200b\u7684\u200b\u503c\u200b\u6765\u6e90\u200b\uff0c\u200b\u5e76\u200b\u907f\u514d\u200b\u5728\u200b\u4e0d\u540c\u200b\u5730\u65b9\u200b\u8bbe\u7f6e\u200b\u5b66\u4e60\u200b\u7387\u200b\u7b49\u503c\u200b\u65f6\u200b\u96be\u4ee5\u200b\u627e\u5230\u200b\u7684\u200b\u9519\u8bef\u200b\u3002\u200b\u547d\u4ee4\u884c\u200b\u914d\u7f6e\u200b\u9ad8\u4e8e\u200b\u5176\u4ed6\u200b\u3002\u200b\u88ab\u200b\u8bbe\u7f6e\u200b\u7684\u200b\u503c\u200b\u5305\u62ec\u200b\uff1a</p> <ul> <li><code>warmup_min_lr</code> \u200b\u7684\u200b\u503c\u200b\u4e3a\u200b <code>0</code>\u3002</li> <li><code>warmup_max_lr</code> \u200b\u7684\u200b\u503c\u200b\u4e3a\u200b <code>--learning_rate</code>\u3002</li> <li><code>warmup_num_steps</code> \u200b\u7684\u200b\u503c\u200b\u4e3a\u200b <code>--warmup_steps</code>\uff08\u200b\u5982\u679c\u200b\u63d0\u4f9b\u200b\uff09\u3002\u200b\u5426\u5219\u200b\uff0c\u200b\u5c06\u200b\u4f7f\u7528\u200b <code>--warmup_ratio</code> \u200b\u4e58\u4ee5\u200b\u8bad\u7ec3\u200b\u6b65\u9aa4\u200b\u7684\u200b\u6570\u91cf\u200b\uff0c\u200b\u5e76\u200b\u56db\u820d\u4e94\u5165\u200b\u3002</li> <li><code>total_num_steps</code> \u200b\u7684\u200b\u503c\u200b\u4e3a\u200b <code>--max_steps</code> \u200b\u6216\u8005\u200b\u5982\u679c\u200b\u6ca1\u6709\u200b\u63d0\u4f9b\u200b\uff0c\u200b\u5c06\u200b\u5728\u200b\u8fd0\u884c\u200b\u65f6\u200b\u6839\u636e\u200b\u73af\u5883\u200b\u3001\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u5927\u5c0f\u200b\u548c\u200b\u5176\u4ed6\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\uff08\u200b\u5bf9\u4e8e\u200b <code>WarmupDecayLR</code> \u200b\u6765\u8bf4\u200b\u9700\u8981\u200b\uff09\u200b\u81ea\u52a8\u200b\u63a8\u5bfc\u200b\u3002</li> </ul> <p>\u200b\u5f53\u7136\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u63a5\u7ba1\u200b\u4efb\u4f55\u200b\u6216\u200b\u6240\u6709\u200b\u7684\u200b\u914d\u7f6e\u200b\u503c\u200b\uff0c\u200b\u5e76\u200b\u81ea\u884c\u200b\u8bbe\u7f6e\u200b\u8fd9\u4e9b\u200b\u503c\u200b\uff1a</p> <pre><code>{\n   \"scheduler\": {\n         \"type\": \"WarmupLR\",\n         \"params\": {\n             \"warmup_min_lr\": 0,\n             \"warmup_max_lr\": 0.001,\n             \"warmup_num_steps\": 1000\n         }\n     }\n}\n</code></pre> <p>\u200b\u4f46\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u81ea\u5df1\u200b\u540c\u6b65\u200b[<code>Trainer</code>]\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u548c\u200bDeepSpeed\u200b\u914d\u7f6e\u200b\u3002</p> <p>\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5bf9\u4e8e\u200b <code>WarmupDecayLR</code>\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u6761\u76ee\u200b\uff1a</p> <pre><code>{\n   \"scheduler\": {\n         \"type\": \"WarmupDecayLR\",\n         \"params\": {\n             \"last_batch_iteration\": -1,\n             \"total_num_steps\": \"auto\",\n             \"warmup_min_lr\": \"auto\",\n             \"warmup_max_lr\": \"auto\",\n             \"warmup_num_steps\": \"auto\"\n         }\n     }\n}\n</code></pre> <p>\u200b\u7136\u540e\u200b\uff0c<code>total_num_steps</code>\u3001<code>warmup_max_lr</code>\u3001<code>warmup_num_steps</code> \u200b\u548c\u200b <code>total_num_steps</code> \u200b\u5c06\u200b\u5728\u200b\u52a0\u8f7d\u200b\u65f6\u200b\u8bbe\u7f6e\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#fp32","title":"fp32\u200b\u7cbe\u5ea6","text":"<p>DeepSpeed\u200b\u652f\u6301\u200b\u5b8c\u6574\u200b\u7684\u200bfp32\u200b\u548c\u200bfp16\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u3002</p> <p>\u200b\u7531\u4e8e\u200bfp16\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u5177\u6709\u200b\u66f4\u200b\u5c0f\u200b\u7684\u200b\u5185\u5b58\u200b\u9700\u6c42\u200b\u548c\u200b\u66f4\u200b\u5feb\u200b\u7684\u200b\u901f\u5ea6\u200b\uff0c\u200b\u552f\u4e00\u200b\u4e0d\u200b\u4f7f\u7528\u200b\u5b83\u200b\u7684\u200b\u65f6\u5019\u200b\u662f\u200b\u5f53\u200b\u60a8\u200b\u4f7f\u7528\u200b\u7684\u200b\u6a21\u578b\u200b\u5728\u200b\u8fd9\u79cd\u200b\u8bad\u7ec3\u200b\u6a21\u5f0f\u200b\u4e0b\u200b\u8868\u73b0\u200b\u4e0d\u4f73\u65f6\u200b\u3002\u200b\u901a\u5e38\u200b\uff0c\u200b\u5f53\u200b\u6a21\u578b\u200b\u6ca1\u6709\u200b\u5728\u200bfp16\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u4e0b\u200b\u8fdb\u884c\u200b\u9884\u200b\u8bad\u7ec3\u200b\u65f6\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0cbf16\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7ecf\u5e38\u51fa\u73b0\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\uff09\uff0c\u200b\u4f1a\u200b\u51fa\u73b0\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u3002\u200b\u8fd9\u6837\u200b\u7684\u200b\u6a21\u578b\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u53d1\u751f\u200b\u6ea2\u51fa\u200b\u6216\u200b\u4e0b\u6ea2\u200b\uff0c\u200b\u5bfc\u81f4\u200b <code>NaN</code> \u200b\u635f\u5931\u200b\u3002\u200b\u5982\u679c\u200b\u662f\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\uff0c\u200b\u90a3\u4e48\u200b\u60a8\u200b\u5c06\u200b\u5e0c\u671b\u200b\u4f7f\u7528\u200b\u5b8c\u6574\u200b\u7684\u200bfp32\u200b\u6a21\u5f0f\u200b\uff0c\u200b\u901a\u8fc7\u200b\u663e\u5f0f\u200b\u7981\u7528\u200b\u9ed8\u8ba4\u200b\u542f\u7528\u200b\u7684\u200bfp16\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u6a21\u5f0f\u200b\uff1a</p> <pre><code>{\n    \"fp16\": {\n        \"enabled\": false,\n    }\n}\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u4f7f\u7528\u200b\u57fa\u4e8e\u200bAmpere\u200b\u67b6\u6784\u200b\u7684\u200bGPU\uff0cPyTorch\u200b\u7248\u672c\u200b1.7\u200b\u53ca\u200b\u66f4\u200b\u9ad8\u200b\u7248\u672c\u200b\u5c06\u200b\u81ea\u52a8\u200b\u5207\u6362\u200b\u5230\u200b\u4f7f\u7528\u200b\u66f4\u200b\u9ad8\u6548\u200b\u7684\u200btf32\u200b\u683c\u5f0f\u200b\u8fdb\u884c\u200b\u4e00\u4e9b\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u4f46\u200b\u7ed3\u679c\u200b\u4ecd\u200b\u5c06\u200b\u4ee5\u200bfp32\u200b\u683c\u5f0f\u200b\u5448\u73b0\u200b\u3002\u200b\u6709\u5173\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\u548c\u200b\u57fa\u51c6\u200b\u6d4b\u8bd5\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u89c1\u200bTensorFloat-32(TF32) on Ampere devices\u3002\u200b\u5982\u679c\u200b\u51fa\u4e8e\u200b\u67d0\u79cd\u539f\u56e0\u200b\u60a8\u200b\u4e0d\u200b\u5e0c\u671b\u200b\u4f7f\u7528\u200b\u5b83\u200b\uff0c\u200b\u8be5\u200b\u6587\u6863\u200b\u5305\u62ec\u200b\u6709\u5173\u200b\u5982\u4f55\u200b\u7981\u7528\u200b\u6b64\u200b\u81ea\u52a8\u200b\u8f6c\u6362\u200b\u7684\u200b\u8bf4\u660e\u200b\u3002</p> <p>\u200b\u5728\u200b\ud83e\udd17 Trainer\u200b\u4e2d\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>--tf32</code> \u200b\u6765\u200b\u542f\u7528\u200b\u5b83\u200b\uff0c\u200b\u6216\u200b\u4f7f\u7528\u200b <code>--tf32 0</code> \u200b\u6216\u200b <code>--no_tf32</code> \u200b\u6765\u200b\u7981\u7528\u200b\u5b83\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u4f7f\u7528\u200bPyTorch\u200b\u7684\u200b\u9ed8\u8ba4\u8bbe\u7f6e\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#_6","title":"\u81ea\u52a8\u200b\u6df7\u5408\u200b\u7cbe\u5ea6","text":"<p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u81ea\u52a8\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u9009\u62e9\u200b\u4f7f\u7528\u200b\u7c7b\u4f3c\u200b PyTorch AMP \u200b\u7684\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u9009\u62e9\u200b\u4f7f\u7528\u200b\u7c7b\u4f3c\u200b Apex \u200b\u7684\u200b\u65b9\u5f0f\u200b\uff1a</p>"},{"location":"main_classes/deepspeed/#fp16","title":"fp16","text":"<p>\u200b\u8981\u200b\u914d\u7f6e\u200bPyTorch AMP-like \u200b\u7684\u200b fp16\uff08float16\uff09 \u200b\u6a21\u5f0f\u200b\uff0c\u200b\u8bf7\u200b\u8bbe\u7f6e\u200b\uff1a</p> <pre><code>{\n    \"fp16\": {\n        \"enabled\": \"auto\",\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    }\n}\n</code></pre> <p>\u200b\u5e76\u4e14\u200b\uff0c[<code>Trainer</code>]\u200b\u5c06\u200b\u6839\u636e\u200b<code>args.fp16_backend</code>\u200b\u7684\u200b\u503c\u200b\u81ea\u52a8\u200b\u542f\u7528\u200b\u6216\u200b\u7981\u7528\u200b\u5b83\u200b\u3002\u200b\u5176\u4f59\u200b\u7684\u200b\u914d\u7f6e\u200b\u503c\u200b\u7531\u200b\u60a8\u200b\u51b3\u5b9a\u200b\u3002</p> <p>\u200b\u5f53\u200b\u4f20\u9012\u200b<code>--fp16 --fp16_backend amp</code>\u200b\u6216\u200b<code>--fp16_full_eval</code>\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u65f6\u200b\uff0c\u200b\u6b64\u200b\u6a21\u5f0f\u200b\u5c06\u200b\u88ab\u200b\u542f\u7528\u200b\u3002</p> <p>\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u663e\u5f0f\u200b\u5730\u200b\u542f\u7528\u200b/\u200b\u7981\u7528\u200b\u6b64\u200b\u6a21\u5f0f\u200b\uff1a</p> <pre><code>{\n    \"fp16\": {\n        \"enabled\": true,\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    }\n}\n</code></pre> <p>\u200b\u4f46\u662f\u200b\u4e4b\u540e\u200b\u60a8\u200b\u9700\u8981\u200b\u81ea\u5df1\u200b\u540c\u6b65\u200b[<code>Trainer</code>]\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u548c\u200bDeepSpeed\u200b\u914d\u7f6e\u200b\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u76f8\u5173\u200b\u6587\u6863\u200b</p>"},{"location":"main_classes/deepspeed/#bf16","title":"bf16","text":"<p>\u200b\u5982\u679c\u200b\u9700\u8981\u200b\u4f7f\u7528\u200bbfloat16\u200b\u800c\u200b\u4e0d\u662f\u200bfp16\uff0c\u200b\u90a3\u4e48\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u914d\u7f6e\u200b\u90e8\u5206\u200b\uff1a</p> <pre><code>{\n    \"bf16\": {\n        \"enabled\": \"auto\"\n    }\n}\n</code></pre> <p>bf16\u200b\u5177\u6709\u200b\u4e0e\u200bfp32\u200b\u76f8\u540c\u200b\u7684\u200b\u52a8\u6001\u200b\u8303\u56f4\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4e0d\u200b\u9700\u8981\u200b\u635f\u5931\u200b\u7f29\u653e\u200b\u3002</p> <p>\u200b\u5f53\u200b\u4f20\u9012\u200b<code>--bf16</code>\u200b\u6216\u200b<code>--bf16_full_eval</code>\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u65f6\u200b\uff0c\u200b\u542f\u7528\u200b\u6b64\u200b\u6a21\u5f0f\u200b\u3002</p> <p>\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u663e\u5f0f\u200b\u5730\u200b\u542f\u7528\u200b/\u200b\u7981\u7528\u200b\u6b64\u200b\u6a21\u5f0f\u200b\uff1a</p> <pre><code>{\n    \"bf16\": {\n        \"enabled\": true\n    }\n}\n</code></pre> <p> <p>\u200b\u5728\u200b<code>deepspeed==0.6.0</code>\u200b\u7248\u672c\u200b\u4e2d\u200b\uff0cbf16\u200b\u652f\u6301\u200b\u662f\u200b\u65b0\u200b\u7684\u200b\u5b9e\u9a8c\u200b\u6027\u529f\u80fd\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u542f\u7528\u200b\u4e86\u200bbf16\u200b\u6765\u200b\u8fdb\u884c\u200b\u68af\u5ea6\u200b\u7d2f\u79ef\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u610f\u8bc6\u200b\u5230\u200b\u5b83\u200b\u4f1a\u200b\u4ee5\u200bbf16\u200b\u7d2f\u79ef\u200b\u68af\u5ea6\u200b\uff0c\u200b\u8fd9\u200b\u53ef\u80fd\u200b\u4e0d\u662f\u200b\u60a8\u200b\u60f3\u8981\u200b\u7684\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u8fd9\u79cd\u200b\u683c\u5f0f\u200b\u7684\u200b\u4f4e\u200b\u7cbe\u5ea6\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5bfc\u81f4\u200blossy accumulation\u3002</p> <p>\u200b\u4fee\u590d\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\u7684\u200b\u5de5\u4f5c\u200b\u6b63\u5728\u200b\u52aa\u529b\u200b\u8fdb\u884c\u200b\uff0c\u200b\u540c\u65f6\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4f7f\u7528\u200b\u66f4\u200b\u9ad8\u7cbe\u5ea6\u200b\u7684\u200b<code>dtype</code>\uff08fp16\u200b\u6216\u200bfp32\uff09\u200b\u7684\u200b\u9009\u9879\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#nccl","title":"NCCL\u200b\u96c6\u5408","text":"<p>\u200b\u5728\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6709\u200b\u4e24\u79cd\u200b\u6570\u636e\u7c7b\u578b\u200b\uff1a<code>dtype</code>\u200b\u548c\u200b\u7528\u4e8e\u200b\u901a\u4fe1\u200b\u6536\u96c6\u200b\u64cd\u4f5c\u200b\u7684\u200b<code>dtype</code>\uff0c\u200b\u5982\u200b\u5404\u79cd\u200b\u5f52\u7ea6\u200b\u548c\u200b\u6536\u96c6\u200b/\u200b\u5206\u6563\u200b\u64cd\u4f5c\u200b\u3002</p> <p>\u200b\u6240\u6709\u200b\u7684\u200bgather/scatter\u200b\u64cd\u4f5c\u200b\u90fd\u200b\u662f\u200b\u5728\u200b\u6570\u636e\u200b\u76f8\u540c\u200b\u7684\u200b<code>dtype</code>\u200b\u4e2d\u200b\u6267\u884c\u200b\u7684\u200b\uff0c\u200b\u6240\u4ee5\u200b\u5982\u679c\u200b\u60a8\u200b\u6b63\u5728\u200b\u4f7f\u7528\u200bbf16\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6a21\u5f0f\u200b\uff0c\u200b\u90a3\u4e48\u200b\u5b83\u200b\u5c06\u200b\u5728\u200bbf16\u200b\u4e2d\u200b\u8fdb\u884c\u200bgather\u200b\u64cd\u4f5c\u200b - gather\u200b\u64cd\u4f5c\u200b\u662f\u975e\u200b\u635f\u5931\u200b\u6027\u200b\u7684\u200b\u3002</p> <p>\u200b\u5404\u79cd\u200breduce\u200b\u64cd\u4f5c\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u662f\u200b\u975e\u5e38\u200b\u635f\u5931\u200b\u6027\u200b\u7684\u200b\uff0c\u200b\u4f8b\u5982\u200b\u5f53\u200b\u68af\u5ea6\u200b\u5728\u200b\u591a\u4e2a\u200bgpu\u200b\u4e0a\u200b\u5e73\u5747\u200b\u65f6\u200b\uff0c\u200b\u5982\u679c\u200b\u901a\u4fe1\u200b\u662f\u200b\u5728\u200bfp16\u200b\u6216\u200bbf16\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u7684\u200b\uff0c\u200b\u90a3\u4e48\u200b\u7ed3\u679c\u200b\u53ef\u80fd\u200b\u662f\u200b\u6709\u200b\u635f\u5931\u200b\u6027\u200b\u7684\u200b - \u200b\u56e0\u4e3a\u200b\u5f53\u200b\u5728\u200b\u4e00\u4e2a\u200b\u4f4e\u200b\u7cbe\u5ea6\u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u591a\u4e2a\u200b\u6570\u5b57\u200b\u65f6\u200b\uff0c\u200b\u7ed3\u679c\u200b\u53ef\u80fd\u200b\u4e0d\u662f\u200b\u7cbe\u786e\u200b\u7684\u200b\u3002\u200b\u66f4\u200b\u7cdf\u7cd5\u200b\u7684\u200b\u662f\u200b\uff0cbf16\u200b\u6bd4\u200bfp16\u200b\u5177\u6709\u200b\u66f4\u200b\u4f4e\u200b\u7684\u200b\u7cbe\u5ea6\u200b\u3002\u200b\u901a\u5e38\u200b\uff0c\u200b\u5f53\u200b\u5e73\u5747\u200b\u68af\u5ea6\u200b\u65f6\u200b\uff0c\u200b\u635f\u5931\u200b\u6700\u5c0f\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u68af\u5ea6\u200b\u901a\u5e38\u200b\u975e\u5e38\u200b\u5c0f\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u534a\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0cfp16\u200b\u88ab\u200b\u7528\u4f5c\u200breduction\u200b\u64cd\u4f5c\u200b\u7684\u200b\u9ed8\u8ba4\u503c\u200b\u3002\u200b\u4f46\u662f\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5b8c\u5168\u200b\u63a7\u5236\u200b\u8fd9\u4e2a\u200b\u529f\u80fd\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u9009\u62e9\u200b\u7684\u8bdd\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u5c0f\u200b\u7684\u200b\u5f00\u9500\u200b\uff0c\u200b\u5e76\u200b\u786e\u4fdd\u200breductions\u200b\u5c06\u200b\u4f7f\u7528\u200bfp32\u200b\u4f5c\u4e3a\u200b\u7d2f\u79ef\u200b\u6570\u636e\u7c7b\u578b\u200b\uff0c\u200b\u53ea\u6709\u200b\u5f53\u200b\u7ed3\u679c\u200b\u51c6\u5907\u200b\u597d\u65f6\u200b\uff0c\u200b\u5b83\u200b\u624d\u200b\u4f1a\u200b\u964d\u7ea7\u200b\u5230\u200b\u60a8\u200b\u5728\u200b\u8bad\u7ec3\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u7684\u200b\u534a\u200b\u7cbe\u5ea6\u200b<code>dtype</code>\u3002</p> <p>\u200b\u8981\u200b\u8986\u76d6\u200b\u9ed8\u8ba4\u8bbe\u7f6e\u200b\uff0c\u200b\u60a8\u200b\u53ea\u200b\u9700\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b\u914d\u7f6e\u200b\u6761\u76ee\u200b\uff1a</p> <pre><code>{\n    \"communication_data_type\": \"fp32\"\n}\n</code></pre> <p>\u200b\u6839\u636e\u200b\u8fd9\u4e2a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u6709\u6548\u200b\u7684\u200b\u503c\u200b\u5305\u62ec\u200b\"fp16\"\u3001\"bfp16\"\u200b\u548c\u200b\"fp32\"\u3002</p> <p>\u200b\u6ce8\u610f\u200b\uff1a\u200b\u5728\u200bstage zero 3\u200b\u4e2d\u200b\uff0cbf16\u200b\u901a\u4fe1\u200b\u6570\u636e\u7c7b\u578b\u200b\u5b58\u5728\u200b\u4e00\u4e2a\u200bbug\uff0c\u200b\u8be5\u200b\u95ee\u9898\u200b\u5df2\u200b\u5728\u200b<code>deepspeed==0.8.1</code>\u200b\u7248\u672c\u200b\u4e2d\u200b\u5f97\u5230\u200b\u4fee\u590d\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#apex","title":"apex","text":"<p>\u200b\u914d\u7f6e\u200bapex AMP-like\u200b\u6a21\u5f0f\u200b\uff1a</p> <pre><code>\"amp\": {\n    \"enabled\": \"auto\",\n    \"opt_level\": \"auto\"\n}\n</code></pre> <p>\u200b\u5e76\u4e14\u200b\uff0c[<code>Trainer</code>]\u200b\u5c06\u200b\u6839\u636e\u200b<code>args.fp16_backend</code>\u200b\u548c\u200b<code>args.fp16_opt_level</code>\u200b\u7684\u200b\u503c\u200b\u81ea\u52a8\u200b\u914d\u7f6e\u200b\u5b83\u200b\u3002</p> <p>\u200b\u5f53\u200b\u4f20\u9012\u200b<code>--fp16 --fp16_backend apex --fp16_opt_level 01</code>\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u65f6\u200b\uff0c\u200b\u6b64\u200b\u6a21\u5f0f\u200b\u5c06\u200b\u88ab\u200b\u542f\u7528\u200b\u3002</p> <p>\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u663e\u5f0f\u200b\u914d\u7f6e\u200b\u6b64\u200b\u6a21\u5f0f\u200b\uff1a</p> <pre><code>{\n    \"amp\": {\n        \"enabled\": true,\n        \"opt_level\": \"O1\"\n    }\n}\n</code></pre> <p>\u200b\u4f46\u662f\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u81ea\u5df1\u200b\u540c\u6b65\u200b[<code>Trainer</code>]\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u548c\u200bDeepSpeed\u200b\u914d\u7f6e\u200b\u3002</p> <p>\u200b\u8fd9\u91cc\u200b\u662f\u200b\u6587\u6863\u200b</p> <p></p>"},{"location":"main_classes/deepspeed/#batch-size","title":"Batch Size","text":"<p>\u200b\u914d\u7f6e\u200bbatch size\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u5982\u4e0b\u200b\u53c2\u6570\u200b:</p> <pre><code>{\n    \"train_batch_size\": \"auto\",\n    \"train_micro_batch_size_per_gpu\": \"auto\"\n}\n</code></pre> <p>\u200b\u5e76\u4e14\u200b\uff0c[<code>Trainer</code>]\u200b\u5c06\u200b\u81ea\u52a8\u200b\u5c06\u200b<code>train_micro_batch_size_per_gpu</code>\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b<code>args.per_device_train_batch_size</code>\u200b\u7684\u200b\u503c\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200b<code>train_batch_size</code>\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b<code>args.world_size * args.per_device_train_batch_size * args.gradient_accumulation_steps</code>\u3002</p> <p>\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u663e\u5f0f\u200b\u8bbe\u7f6e\u200b\u8fd9\u4e9b\u200b\u503c\u200b\uff1a</p> <pre><code>{\n    \"train_batch_size\": 12,\n    \"train_micro_batch_size_per_gpu\": 4\n}\n</code></pre> <p>\u200b\u4f46\u662f\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u81ea\u5df1\u200b\u540c\u6b65\u200b[<code>Trainer</code>]\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u548c\u200bDeepSpeed\u200b\u914d\u7f6e\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#gradient-accumulation","title":"Gradient Accumulation","text":"<p>\u200b\u914d\u7f6e\u200bgradient accumulation\u200b\u8bbe\u7f6e\u200b\u5982\u4e0b\u200b:</p> <pre><code>{\n    \"gradient_accumulation_steps\": \"auto\"\n}\n</code></pre> <p>\u200b\u5e76\u4e14\u200b\uff0c[<code>Trainer</code>]\u200b\u5c06\u200b\u81ea\u52a8\u200b\u5c06\u200b\u5176\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b<code>args.gradient_accumulation_steps</code>\u200b\u7684\u200b\u503c\u200b\u3002</p> <p>\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u663e\u5f0f\u200b\u8bbe\u7f6e\u200b\u8fd9\u4e2a\u200b\u503c\u200b\uff1a</p> <pre><code>{\n    \"gradient_accumulation_steps\": 3\n}\n</code></pre> <p>\u200b\u4f46\u662f\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u81ea\u5df1\u200b\u540c\u6b65\u200b[<code>Trainer</code>]\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u548c\u200bDeepSpeed\u200b\u914d\u7f6e\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#gradient-clipping","title":"Gradient Clipping","text":"<p>\u200b\u914d\u7f6e\u200bgradient clipping\u200b\u5982\u4e0b\u200b:</p> <pre><code>{\n    \"gradient_clipping\": \"auto\"\n}\n</code></pre> <p>\u200b\u5e76\u4e14\u200b\uff0c[<code>Trainer</code>]\u200b\u5c06\u200b\u81ea\u52a8\u200b\u5c06\u200b\u5176\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b<code>args.max_grad_norm</code>\u200b\u7684\u200b\u503c\u200b\u3002</p> <p>\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u663e\u5f0f\u200b\u8bbe\u7f6e\u200b\u8fd9\u4e2a\u200b\u503c\u200b\uff1a</p> <pre><code>{\n    \"gradient_clipping\": 1.0\n}\n</code></pre> <p>\u200b\u4f46\u662f\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u81ea\u5df1\u200b\u540c\u6b65\u200b[<code>Trainer</code>]\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u548c\u200bDeepSpeed\u200b\u914d\u7f6e\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#_7","title":"\u83b7\u53d6\u200b\u6a21\u578b\u200b\u6743\u91cd","text":"<p>\u200b\u53ea\u8981\u200b\u60a8\u200b\u7ee7\u7eed\u200b\u4f7f\u7528\u200bDeepSpeed\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u548c\u200b\u6062\u590d\u200b\uff0c\u200b\u60a8\u200b\u5c31\u200b\u4e0d\u200b\u9700\u8981\u200b\u62c5\u5fc3\u200b\u4efb\u4f55\u200b\u4e8b\u60c5\u200b\u3002DeepSpeed\u200b\u5728\u200b\u5176\u200b\u81ea\u5b9a\u4e49\u200b\u68c0\u67e5\u70b9\u200b\u4f18\u5316\u200b\u5668\u200b\u6587\u4ef6\u200b\u4e2d\u200b\u5b58\u50a8\u200bfp32\u200b\u4e3b\u6743\u200b\u91cd\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u6587\u4ef6\u200b\u662f\u200b<code>global_step*/*optim_states.pt</code>\uff08\u200b\u8fd9\u662f\u200bglob\u200b\u6a21\u5f0f\u200b\uff09\uff0c\u200b\u5e76\u200b\u4fdd\u5b58\u200b\u5728\u200b\u6b63\u5e38\u200b\u7684\u200bcheckpoint\u200b\u4e0b\u200b\u3002</p> <p>FP16\u200b\u6743\u91cd\u200b\uff1a</p> <p>\u200b\u5f53\u200b\u6a21\u578b\u200b\u4fdd\u5b58\u200b\u5728\u200bZeRO-2\u200b\u4e0b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u6700\u7ec8\u200b\u4f1a\u200b\u5f97\u5230\u200b\u4e00\u4e2a\u200b\u5305\u542b\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u7684\u200b\u666e\u901a\u200b<code>pytorch_model.bin</code>\u200b\u6587\u4ef6\u200b\uff0c\u200b\u4f46\u200b\u5b83\u4eec\u200b\u53ea\u662f\u200b\u6743\u91cd\u200b\u7684\u200bfp16\u200b\u7248\u672c\u200b\u3002</p> <p>\u200b\u5728\u200bZeRO-3\u200b\u4e0b\u200b\uff0c\u200b\u4e8b\u60c5\u200b\u8981\u200b\u590d\u6742\u200b\u5f97\u200b\u591a\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u5206\u5e03\u200b\u5728\u200b\u591a\u4e2a\u200bGPU\u200b\u4e0a\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b<code>\"stage3_gather_16bit_weights_on_model_save\": true</code>\u200b\u624d\u80fd\u200b\u8ba9\u200b<code>Trainer</code>\u200b\u4fdd\u5b58\u200bfp16\u200b\u7248\u672c\u200b\u7684\u200b\u6743\u91cd\u200b\u3002\u200b\u5982\u679c\u200b\u8fd9\u4e2a\u200b\u8bbe\u7f6e\u200b\u662f\u200b<code>False</code>\uff0c<code>pytorch_model.bin</code>\u200b\u5c06\u200b\u4e0d\u4f1a\u200b\u88ab\u200b\u521b\u5efa\u200b\u3002\u200b\u8fd9\u200b\u662f\u56e0\u4e3a\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0cDeepSpeed\u200b\u7684\u200b<code>state_dict</code>\u200b\u5305\u542b\u200b\u4e00\u4e2a\u200b\u5360\u4f4d\u200b\u7b26\u800c\u200b\u4e0d\u662f\u200b\u5b9e\u9645\u200b\u7684\u200b\u6743\u91cd\u200b\u3002\u200b\u5982\u679c\u200b\u6211\u4eec\u200b\u4fdd\u5b58\u200b\u8fd9\u4e2a\u200b<code>state_dict</code>\uff0c\u200b\u5c31\u200b\u65e0\u6cd5\u200b\u518d\u200b\u52a0\u8f7d\u200b\u5b83\u200b\u4e86\u200b\u3002</p> <pre><code>{\n    \"zero_optimization\": {\n        \"stage3_gather_16bit_weights_on_model_save\": true\n    }\n}\n</code></pre> <p>FP32\u200b\u6743\u91cd\u200b\uff1a</p> <p>\u200b\u867d\u7136\u200bfp16\u200b\u6743\u91cd\u200b\u9002\u5408\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u60a8\u200b\u5b8c\u6210\u200b\u4e86\u200b\u6a21\u578b\u200b\u7684\u200b\u5fae\u8c03\u200b\u5e76\u200b\u5e0c\u671b\u200b\u5c06\u200b\u5176\u200b\u4e0a\u200b\u4f20\u5230\u200bmodels hub\u200b\u6216\u200b\u4f20\u9012\u200b\u7ed9\u200b\u5176\u4ed6\u4eba\u200b\uff0c\u200b\u60a8\u200b\u5f88\u200b\u53ef\u80fd\u200b\u60f3\u8981\u200b\u83b7\u53d6\u200bfp32\u200b\u6743\u91cd\u200b\u3002\u200b\u8fd9\u200b\u6700\u597d\u200b\u4e0d\u8981\u200b\u5728\u200b\u8bad\u7ec3\u200b\u671f\u95f4\u200b\u5b8c\u6210\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u8fd9\u200b\u9700\u8981\u200b\u5927\u91cf\u200b\u5185\u5b58\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6700\u597d\u200b\u5728\u200b\u8bad\u7ec3\u200b\u5b8c\u6210\u200b\u540e\u200b\u79bb\u7ebf\u200b\u8fdb\u884c\u200b\u3002\u200b\u4f46\u662f\u200b\uff0c\u200b\u5982\u679c\u200b\u9700\u8981\u200b\u5e76\u4e14\u200b\u6709\u200b\u5145\u8db3\u200b\u7684\u200b\u7a7a\u95f2\u200bCPU\u200b\u5185\u5b58\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5728\u200b\u76f8\u540c\u200b\u7684\u200b\u8bad\u7ec3\u200b\u811a\u672c\u200b\u4e2d\u200b\u5b8c\u6210\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u90e8\u5206\u200b\u5c06\u200b\u8ba8\u8bba\u200b\u8fd9\u200b\u4e24\u79cd\u200b\u65b9\u6cd5\u200b\u3002</p> <p>\u200b\u5b9e\u65f6\u200bFP32\u200b\u6743\u91cd\u200b\u6062\u590d\u200b\uff1a</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u5f88\u5927\u200b\uff0c\u200b\u5e76\u4e14\u200b\u5728\u200b\u8bad\u7ec3\u200b\u7ed3\u675f\u200b\u65f6\u200b\u51e0\u4e4e\u200b\u6ca1\u6709\u200b\u5269\u4f59\u200b\u7684\u200b\u7a7a\u95f2\u200bCPU\u200b\u5185\u5b58\u200b\uff0c\u200b\u8fd9\u79cd\u200b\u65b9\u6cd5\u200b\u53ef\u80fd\u200b\u4e0d\u8d77\u4f5c\u7528\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u81f3\u5c11\u200b\u4fdd\u5b58\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u68c0\u67e5\u70b9\u200b\uff0c\u200b\u5e76\u4e14\u200b\u60f3\u8981\u200b\u4f7f\u7528\u200b\u6700\u65b0\u200b\u7684\u200b\u4e00\u4e2a\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u6309\u7167\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u64cd\u4f5c\u200b\uff1a</p> <pre><code>from transformers.trainer_utils import get_last_checkpoint\nfrom deepspeed.utils.zero_to_fp32 import load_state_dict_from_zero_checkpoint\n\ncheckpoint_dir = get_last_checkpoint(trainer.args.output_dir)\nfp32_model = load_state_dict_from_zero_checkpoint(trainer.model, checkpoint_dir)\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u5728\u200b\u4f7f\u7528\u200b<code>--load_best_model_at_end</code>\u200b\u7c7b\u200b\uff1a~transformers.TrainingArguments\u200b\u53c2\u6570\u200b\uff08\u200b\u7528\u4e8e\u200b\u8ddf\u8e2a\u200b\u6700\u4f73\u200b \u200b\u68c0\u67e5\u70b9\u200b\uff09\uff0c\u200b\u90a3\u4e48\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u9996\u5148\u200b\u663e\u5f0f\u200b\u5730\u200b\u4fdd\u5b58\u200b\u6700\u7ec8\u200b\u6a21\u578b\u200b\uff0c\u200b\u7136\u540e\u200b\u518d\u200b\u6267\u884c\u200b\u76f8\u540c\u200b\u7684\u200b\u64cd\u4f5c\u200b\uff1a</p> <pre><code>from deepspeed.utils.zero_to_fp32 import load_state_dict_from_zero_checkpoint\n\ncheckpoint_dir = os.path.join(trainer.args.output_dir, \"checkpoint-final\")\ntrainer.deepspeed.save_checkpoint(checkpoint_dir)\nfp32_model = load_state_dict_from_zero_checkpoint(trainer.model, checkpoint_dir)\n</code></pre> <p> <p>\u200b\u6ce8\u610f\u200b\uff0c\u200b\u4e00\u65e6\u200b\u8fd0\u884c\u200b\u4e86\u200b<code>load_state_dict_from_zero_checkpoint</code>\uff0c\u200b\u8be5\u200b\u6a21\u578b\u200b\u5c06\u200b\u4e0d\u518d\u200b\u53ef\u4ee5\u200b\u5728\u200b\u76f8\u540c\u200b\u7684\u200b\u5e94\u7528\u7a0b\u5e8f\u200b\u7684\u200bDeepSpeed\u200b\u4e0a\u4e0b\u6587\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u3002\u200b\u4e5f\u5c31\u662f\u8bf4\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u91cd\u65b0\u200b\u521d\u59cb\u5316\u200bdeepspeed\u200b\u5f15\u64ce\u200b\uff0c\u200b\u56e0\u4e3a\u200b<code>model.load_state_dict(state_dict)</code>\u200b\u4f1a\u200b\u4ece\u200b\u5176\u4e2d\u200b\u79fb\u9664\u200b\u6240\u6709\u200b\u7684\u200bDeepSpeed\u200b\u76f8\u5173\u200b\u70b9\u200b\u3002\u200b\u6240\u4ee5\u200b\u60a8\u200b\u53ea\u80fd\u200b\u8bad\u7ec3\u200b\u7ed3\u675f\u200b\u65f6\u200b\u8fd9\u6837\u200b\u505a\u200b\u3002</p> <p></p> <p>\u200b\u5f53\u7136\u200b\uff0c\u200b\u60a8\u200b\u4e0d\u5fc5\u200b\u4f7f\u7528\u200b\u7c7b\u200b\uff1a~transformers.Trainer\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u6839\u636e\u200b\u4f60\u200b\u7684\u200b\u9700\u6c42\u200b\u8c03\u6574\u200b\u4e0a\u9762\u200b\u7684\u200b\u793a\u4f8b\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u51fa\u4e8e\u200b\u67d0\u79cd\u539f\u56e0\u200b\u60f3\u8981\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u4f18\u5316\u200b\uff0c\u200b\u60a8\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u63d0\u53d6\u200b\u6743\u91cd\u200b\u7684\u200bfp32 <code>state_dict</code>\u200b\u5e76\u200b\u6309\u7167\u200b\u4ee5\u4e0b\u200b\u793a\u4f8b\u200b\u8fdb\u884c\u200b\u64cd\u4f5c\u200b\uff1a</p> <pre><code>from deepspeed.utils.zero_to_fp32 import get_fp32_state_dict_from_zero_checkpoint\n\nstate_dict = get_fp32_state_dict_from_zero_checkpoint(checkpoint_dir)  # already on cpu\nmodel = model.cpu()\nmodel.load_state_dict(state_dict)\n</code></pre> <p>\u200b\u79bb\u7ebf\u200bFP32\u200b\u6743\u91cd\u200b\u6062\u590d\u200b\uff1a</p> <p>DeepSpeed\u200b\u4f1a\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u7279\u6b8a\u200b\u7684\u200b\u8f6c\u6362\u200b\u811a\u672c\u200b<code>zero_to_fp32.py</code>\uff0c\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u653e\u7f6e\u200b\u5728\u200bcheckpoint\u200b\u6587\u4ef6\u5939\u200b\u7684\u200b\u9876\u5c42\u200b\u3002\u200b\u4f7f\u7528\u200b\u6b64\u200b\u811a\u672c\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b\u4efb\u4f55\u200b\u65f6\u5019\u200b\u63d0\u53d6\u200b\u6743\u91cd\u200b\u3002\u200b\u8be5\u200b\u811a\u672c\u200b\u662f\u200b\u72ec\u7acb\u200b\u7684\u200b\uff0c\u200b\u60a8\u200b\u4e0d\u518d\u200b\u9700\u8981\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u6216\u200b<code>Trainer</code>\u200b\u6765\u200b\u6267\u884c\u200b\u63d0\u53d6\u200b\u64cd\u4f5c\u200b\u3002</p> <p>\u200b\u5047\u8bbe\u200b\u60a8\u200b\u7684\u200bcheckpoint\u200b\u6587\u4ef6\u5939\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>$ ls -l output_dir/checkpoint-1/\n-rw-rw-r-- 1 stas stas 1.4K Mar 27 20:42 config.json\ndrwxrwxr-x 2 stas stas 4.0K Mar 25 19:52 global_step1/\n-rw-rw-r-- 1 stas stas   12 Mar 27 13:16 latest\n-rw-rw-r-- 1 stas stas 827K Mar 27 20:42 optimizer.pt\n-rw-rw-r-- 1 stas stas 231M Mar 27 20:42 pytorch_model.bin\n-rw-rw-r-- 1 stas stas  623 Mar 27 20:42 scheduler.pt\n-rw-rw-r-- 1 stas stas 1.8K Mar 27 20:42 special_tokens_map.json\n-rw-rw-r-- 1 stas stas 774K Mar 27 20:42 spiece.model\n-rw-rw-r-- 1 stas stas 1.9K Mar 27 20:42 tokenizer_config.json\n-rw-rw-r-- 1 stas stas  339 Mar 27 20:42 trainer_state.json\n-rw-rw-r-- 1 stas stas 2.3K Mar 27 20:42 training_args.bin\n-rwxrw-r-- 1 stas stas 5.5K Mar 27 13:16 zero_to_fp32.py*\n</code></pre> <p>\u200b\u5728\u200b\u8fd9\u4e2a\u200b\u4f8b\u5b50\u200b\u4e2d\u200b\uff0c\u200b\u53ea\u6709\u200b\u4e00\u4e2a\u200bDeepSpeed\u200b\u68c0\u67e5\u200b\u70b9\u5b50\u200b\u6587\u4ef6\u5939\u200bglobal_step1\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u8981\u200b\u91cd\u6784\u200bfp32\u200b\u6743\u91cd\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u8fd0\u884c\u200b\uff1a</p> <pre><code>python zero_to_fp32.py . pytorch_model.bin\n</code></pre> <p>\u200b\u8fd9\u200b\u5c31\u662f\u200b\u5b83\u200b\u3002<code>pytorch_model.bin</code>\u200b\u73b0\u5728\u200b\u5c06\u200b\u5305\u542b\u200b\u4ece\u200b\u591a\u4e2a\u200bGPUs\u200b\u5408\u5e76\u200b\u7684\u200b\u5b8c\u6574\u200b\u7684\u200bfp32\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u3002</p> <p>\u200b\u8be5\u200b\u811a\u672c\u200b\u5c06\u200b\u81ea\u52a8\u200b\u80fd\u591f\u200b\u5904\u7406\u200bZeRO-2\u200b\u6216\u200bZeRO-3 checkpoint\u3002</p> <p><code>python zero_to_fp32.py -h</code>\u200b\u5c06\u200b\u4e3a\u200b\u60a8\u200b\u63d0\u4f9b\u200b\u4f7f\u7528\u200b\u7ec6\u8282\u200b\u3002</p> <p>\u200b\u8be5\u200b\u811a\u672c\u200b\u5c06\u200b\u901a\u8fc7\u200b\u6587\u4ef6\u200b<code>latest</code>\u200b\u7684\u200b\u5185\u5bb9\u200b\u81ea\u52a8\u200b\u53d1\u73b0\u200bdeepspeed\u200b\u5b50\u200b\u6587\u4ef6\u5939\u200b\uff0c\u200b\u5728\u200b\u5f53\u524d\u200b\u793a\u4f8b\u200b\u4e2d\u200b\uff0c\u200b\u5b83\u200b\u5c06\u200b\u5305\u542b\u200b<code>global_step1</code>\u3002</p> <p>\u200b\u6ce8\u610f\u200b\uff1a\u200b\u76ee\u524d\u200b\u8be5\u200b\u811a\u672c\u200b\u9700\u8981\u200b2\u200b\u500d\u200b\u4e8e\u200b\u6700\u7ec8\u200bfp32\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u7684\u200b\u901a\u7528\u200b\u5185\u5b58\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#zero-3-infinity-nuances","title":"ZeRO-3 \u200b\u548c\u200b Infinity Nuances","text":"<p>ZeRO-3\u200b\u4e0e\u200bZeRO-2\u200b\u6709\u200b\u5f88\u5927\u200b\u7684\u200b\u4e0d\u540c\u200b\uff0c\u200b\u4e3b\u8981\u200b\u662f\u56e0\u4e3a\u200b\u5b83\u200b\u7684\u200b\u53c2\u6570\u200b\u5206\u7247\u200b\u529f\u80fd\u200b\u3002</p> <p>ZeRO-Infinity\u200b\u8fdb\u4e00\u6b65\u200b\u6269\u5c55\u200b\u4e86\u200bZeRO-3\uff0c\u200b\u4ee5\u200b\u652f\u6301\u200bNVMe\u200b\u5185\u5b58\u200b\u548c\u200b\u5176\u4ed6\u200b\u901f\u5ea6\u200b\u548c\u200b\u53ef\u6269\u5c55\u6027\u200b\u6539\u8fdb\u200b\u3002</p> <p>\u200b\u5c3d\u7ba1\u200b\u6240\u6709\u200b\u52aa\u529b\u200b\u90fd\u200b\u662f\u200b\u4e3a\u4e86\u200b\u5728\u200b\u4e0d\u200b\u9700\u8981\u200b\u5bf9\u6a21\u578b\u200b\u8fdb\u884c\u200b\u4efb\u4f55\u200b\u7279\u6b8a\u200b\u66f4\u6539\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u5c31\u200b\u80fd\u200b\u6b63\u5e38\u200b\u8fd0\u884c\u200b\uff0c\u200b\u4f46\u200b\u5728\u200b\u67d0\u4e9b\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u4ee5\u4e0b\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#_8","title":"\u6784\u5efa\u200b\u5927\u200b\u6a21\u578b","text":"<p>DeepSpeed/ZeRO-3\u200b\u53ef\u4ee5\u200b\u5904\u7406\u200b\u53c2\u200b\u6570\u91cf\u200b\u8fbe\u5230\u200b\u6570\u4e07\u200b\u4ebf\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u6a21\u578b\u200b\u53ef\u80fd\u200b\u65e0\u6cd5\u200b\u9002\u5e94\u200b\u73b0\u6709\u200b\u7684\u200b\u5185\u5b58\u200b\u3002\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u8fd8\u662f\u200b\u5e0c\u671b\u200b\u521d\u59cb\u5316\u200b\u66f4\u5feb\u200b\u5730\u200b\u53d1\u751f\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200bdeepspeed.zero.Init()\u200b\u4e0a\u4e0b\u6587\u200b\u7ba1\u7406\u5668\u200b\uff08\u200b\u4e5f\u200b\u662f\u200b\u4e00\u4e2a\u200b\u51fd\u6570\u200b\u88c5\u9970\u200b\u5668\u200b\uff09\u200b\u6765\u200b\u521d\u59cb\u5316\u200b\u6a21\u578b\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>from transformers import T5ForConditionalGeneration, T5Config\nimport deepspeed\n\nwith deepspeed.zero.Init():\n    config = T5Config.from_pretrained(\"t5-small\")\n    model = T5ForConditionalGeneration(config)\n</code></pre> <p>\u200b\u5982\u200b\u60a8\u200b\u6240\u89c1\u200b\uff0c\u200b\u8fd9\u4f1a\u200b\u4e3a\u200b\u60a8\u200b\u968f\u673a\u200b\u521d\u59cb\u5316\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff0c<code>model_class.from_pretrained</code>\u200b\u5c06\u200b\u5728\u200b<code>is_deepspeed_zero3_enabled()</code>\u200b\u8fd4\u56de\u200b<code>True</code>\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u6fc0\u6d3b\u200b\u6b64\u200b\u529f\u80fd\u200b\uff0c\u200b\u76ee\u524d\u200b\u8fd9\u662f\u200b\u901a\u8fc7\u200b\u4f20\u9012\u200b\u7684\u200bDeepSpeed\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u7684\u200bZeRO-3\u200b\u914d\u7f6e\u200b\u90e8\u5206\u200b\u8bbe\u7f6e\u200b\u7684\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5728\u200b\u8c03\u7528\u200b<code>from_pretrained</code>\u200b\u4e4b\u524d\u200b\uff0c\u200b\u60a8\u200b\u5fc5\u987b\u200b\u521b\u5efa\u200bTrainingArguments\u200b\u5bf9\u8c61\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u53ef\u80fd\u200b\u7684\u200b\u987a\u5e8f\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>from transformers import AutoModel, Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(..., deepspeed=ds_config)\nmodel = AutoModel.from_pretrained(\"t5-small\")\ntrainer = Trainer(model=model, args=training_args, ...)\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u4f7f\u7528\u200b\u7684\u200b\u662f\u200b\u5b98\u65b9\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\uff0c\u200b\u5e76\u4e14\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u4e2d\u200b\u5305\u542b\u200b<code>--deepspeed ds_config.json</code>\u200b\u4e14\u200b\u542f\u7528\u200b\u4e86\u200bZeRO-3\u200b\u914d\u7f6e\u200b\uff0c\u200b\u90a3\u4e48\u200b\u4e00\u5207\u200b\u90fd\u200b\u5df2\u7ecf\u200b\u4e3a\u200b\u60a8\u200b\u51c6\u5907\u200b\u597d\u200b\u4e86\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u8fd9\u662f\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\u7684\u200b\u7f16\u5199\u200b\u65b9\u5f0f\u200b\u3002</p> <p>\u200b\u6ce8\u610f\u200b\uff1a\u200b\u5982\u679c\u200b\u6a21\u578b\u200b\u7684\u200bfp16\u200b\u6743\u91cd\u200b\u65e0\u6cd5\u200b\u9002\u5e94\u200b\u5355\u4e2a\u200bGPU\u200b\u7684\u200b\u5185\u5b58\u200b\uff0c\u200b\u5219\u200b\u5fc5\u987b\u200b\u4f7f\u7528\u200b\u6b64\u200b\u529f\u80fd\u200b\u3002</p> <p>\u200b\u6709\u5173\u200b\u6b64\u200b\u65b9\u6cd5\u200b\u548c\u200b\u5176\u4ed6\u200b\u76f8\u5173\u200b\u529f\u80fd\u200b\u7684\u200b\u5b8c\u6574\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u6784\u5efa\u200b\u5927\u200b\u6a21\u578b\u200b\u3002</p> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u5728\u200b\u52a0\u8f7d\u200bfp16\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u60a8\u200b\u5e0c\u671b\u200b<code>from_pretrained</code>\u200b\u4f7f\u7528\u200b<code>torch_dtype=torch.float16</code>\u3002\u200b\u8be6\u60c5\u8bf7\u200b\u53c2\u89c1\u200bfrom_pretrained-torch-dtype\u3002</p>"},{"location":"main_classes/deepspeed/#_9","title":"\u53c2\u6570\u200b\u6536\u96c6","text":"<p>\u200b\u5728\u200b\u591a\u4e2a\u200bGPU\u200b\u4e0a\u200b\u4f7f\u7528\u200bZeRO-3\u200b\u65f6\u200b\uff0c\u200b\u6ca1\u6709\u200b\u4e00\u4e2a\u200bGPU\u200b\u62e5\u6709\u200b\u6240\u6709\u200b\u53c2\u6570\u200b\uff0c\u200b\u9664\u975e\u200b\u5b83\u200b\u662f\u200b\u5f53\u524d\u200b\u6267\u884c\u5c42\u200b\u7684\u200b\u53c2\u6570\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u9700\u8981\u200b\u4e00\u6b21\u200b\u8bbf\u95ee\u200b\u6240\u6709\u200b\u5c42\u200b\u7684\u200b\u6240\u6709\u200b\u53c2\u6570\u200b\uff0c\u200b\u6709\u200b\u4e00\u4e2a\u200b\u7279\u5b9a\u200b\u7684\u200b\u65b9\u6cd5\u200b\u53ef\u4ee5\u200b\u5b9e\u73b0\u200b\u3002 \u200b\u60a8\u200b\u53ef\u80fd\u200b\u4e0d\u200b\u9700\u8981\u200b\u5b83\u200b\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u60a8\u200b\u9700\u8981\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u8003\u200b\u53c2\u6570\u200b\u6536\u96c6\u200b\u3002</p> <p>\u200b\u7136\u800c\u200b\uff0c\u200b\u6211\u4eec\u200b\u5728\u200b\u591a\u4e2a\u200b\u5730\u65b9\u200b\u786e\u5b9e\u200b\u4f7f\u7528\u200b\u4e86\u200b\u5b83\u200b\uff0c\u200b\u5176\u4e2d\u200b\u4e00\u4e2a\u200b\u4f8b\u5b50\u200b\u662f\u200b\u5728\u200b<code>from_pretrained</code>\u200b\u4e2d\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u3002\u200b\u6211\u4eec\u200b\u4e00\u6b21\u200b\u52a0\u8f7d\u200b\u4e00\u5c42\u200b\uff0c\u200b\u7136\u540e\u200b\u7acb\u5373\u200b\u5c06\u200b\u5176\u200b\u5206\u533a\u200b\u5230\u200b\u6240\u6709\u200b\u53c2\u4e0e\u200b\u7684\u200bGPU\u200b\u4e0a\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5bf9\u4e8e\u200b\u975e\u5e38\u200b\u5927\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u65e0\u6cd5\u200b\u5728\u200b\u4e00\u4e2a\u200bGPU\u200b\u4e0a\u200b\u4e00\u6b21\u6027\u200b\u52a0\u8f7d\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u5206\u5e03\u200b\u5230\u200b\u591a\u4e2a\u200bGPU\u200b\u4e0a\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5185\u5b58\u200b\u9650\u5236\u200b\u3002</p> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u5728\u200bZeRO-3\u200b\u4e0b\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u7f16\u5199\u200b\u81ea\u5df1\u200b\u7684\u200b\u4ee3\u7801\u200b\u5e76\u200b\u9047\u5230\u200b\u770b\u8d77\u6765\u200b\u50cf\u200b\u8fd9\u6837\u200b\u7684\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u6743\u91cd\u200b\uff1a</p> <pre><code>tensor([1.0], device=\"cuda:0\", dtype=torch.float16, requires_grad=True)\n</code></pre> <p>\u200b\u5f3a\u8c03\u200b<code>tensor([1.])</code>\uff0c\u200b\u6216\u8005\u200b\u5982\u679c\u200b\u60a8\u200b\u9047\u5230\u200b\u4e00\u4e2a\u200b\u9519\u8bef\u200b\uff0c\u200b\u5b83\u200b\u8bf4\u200b\u53c2\u6570\u200b\u7684\u200b\u5927\u5c0f\u200b\u662f\u200b<code>1</code>\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u67d0\u4e2a\u200b\u66f4\u5927\u200b\u7684\u200b\u591a\u7ef4\u200b\u5f62\u72b6\u200b\uff0c\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u53c2\u6570\u200b\u88ab\u200b\u5212\u5206\u200b\u4e86\u200b\uff0c\u200b\u4f60\u200b\u770b\u5230\u200b\u7684\u200b\u662f\u200b\u4e00\u4e2a\u200bZeRO-3\u200b\u5360\u4f4d\u200b\u7b26\u200b\u3002</p> <p></p>"},{"location":"main_classes/deepspeed/#zero_1","title":"ZeRO \u200b\u63a8\u7406","text":"<p>\"ZeRO \u200b\u63a8\u65ad\u200b\" \u200b\u4f7f\u7528\u200b\u4e0e\u200b \"ZeRO-3 \u200b\u8bad\u7ec3\u200b\" \u200b\u76f8\u540c\u200b\u7684\u200b\u914d\u7f6e\u200b\u3002\u200b\u60a8\u200b\u53ea\u200b\u9700\u8981\u200b\u53bb\u6389\u200b\u4f18\u5316\u200b\u5668\u200b\u548c\u200b\u8c03\u5ea6\u200b\u5668\u200b\u90e8\u5206\u200b\u3002\u200b\u5b9e\u9645\u4e0a\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u5e0c\u671b\u200b\u4e0e\u200b\u8bad\u7ec3\u200b\u5171\u4eab\u200b\u76f8\u540c\u200b\u7684\u200b\u914d\u7f6e\u6587\u4ef6\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u5b83\u4eec\u200b\u4fdd\u7559\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\uff0c\u200b\u5b83\u4eec\u200b\u53ea\u4f1a\u200b\u88ab\u200b\u5ffd\u7565\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ea\u200b\u9700\u8981\u200b\u4f20\u9012\u200b\u901a\u5e38\u200b\u7684\u200b[<code>TrainingArguments</code>]\u200b\u53c2\u6570\u200b\u3002\u200b\u4f8b\u5982\u200b\uff1a</p> <pre><code>deepspeed --num_gpus=2 your_program.py &lt;normal cl args&gt; --do_eval --deepspeed ds_config.json\n</code></pre> <p>\u200b\u552f\u4e00\u200b\u7684\u200b\u91cd\u8981\u200b\u4e8b\u60c5\u200b\u662f\u200b\u60a8\u200b\u9700\u8981\u200b\u4f7f\u7528\u200bZeRO-3\u200b\u914d\u7f6e\u200b\uff0c\u200b\u56e0\u4e3a\u200bZeRO-2\u200b\u5bf9\u4e8e\u200b\u63a8\u7406\u200b\u6ca1\u6709\u200b\u4efb\u4f55\u200b\u4f18\u52bf\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u53ea\u6709\u200bZeRO-3\u200b\u624d\u200b\u5bf9\u200b\u53c2\u6570\u200b\u8fdb\u884c\u200b\u5206\u7247\u200b\uff0c\u200b\u800c\u200bZeRO-1\u200b\u5219\u200b\u5bf9\u200b\u68af\u5ea6\u200b\u548c\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u8fdb\u884c\u200b\u5206\u7247\u200b\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u5728\u200bDeepSpeed\u200b\u4e0b\u200b\u8fd0\u884c\u200b<code>run_translation.py</code>\u200b\u542f\u7528\u200b\u6240\u6709\u200b\u53ef\u7528\u200bGPU\u200b\u7684\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>deepspeed examples/pytorch/translation/run_translation.py \\\n--deepspeed tests/deepspeed/ds_config_zero3.json \\\n--model_name_or_path t5-small --output_dir output_dir \\\n--do_eval --max_eval_samples 50 --warmup_steps 50  \\\n--max_source_length 128 --val_max_target_length 128 \\\n--overwrite_output_dir --per_device_eval_batch_size 4 \\\n--predict_with_generate --dataset_config \"ro-en\" --fp16 \\\n--source_lang en --target_lang ro --dataset_name wmt16 \\\n--source_prefix \"translate English to Romanian: \"\n</code></pre> <p>\u200b\u7531\u4e8e\u200b\u5728\u200b\u63a8\u7406\u200b\u9636\u6bb5\u200b\uff0c\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u548c\u200b\u68af\u5ea6\u200b\u4e0d\u200b\u9700\u8981\u200b\u989d\u5916\u200b\u7684\u200b\u5927\u91cf\u200b\u5185\u5b58\u200b\uff0c\u200b\u60a8\u200b\u5e94\u8be5\u200b\u80fd\u591f\u200b\u5c06\u200b\u66f4\u200b\u5927\u200b\u7684\u200b\u6279\u6b21\u200b\u548c\u200b/\u200b\u6216\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u653e\u5230\u200b\u76f8\u540c\u200b\u7684\u200b\u786c\u4ef6\u200b\u4e0a\u200b\u3002</p> <p>\u200b\u6b64\u5916\u200b\uff0cDeepSpeed\u200b\u76ee\u524d\u200b\u6b63\u5728\u200b\u5f00\u53d1\u200b\u4e00\u4e2a\u200b\u540d\u4e3a\u200bDeepspeed-Inference\u200b\u7684\u200b\u76f8\u5173\u200b\u4ea7\u54c1\u200b\uff0c\u200b\u5b83\u200b\u4e0e\u200bZeRO\u200b\u6280\u672f\u200b\u65e0\u5173\u200b\uff0c\u200b\u800c\u662f\u200b\u4f7f\u7528\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200b\u6765\u200b\u6269\u5c55\u200b\u65e0\u6cd5\u200b\u9002\u5e94\u200b\u5355\u4e2a\u200bGPU\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u6b63\u5728\u200b\u8fdb\u884c\u200b\u7684\u200b\u5de5\u4f5c\u200b\uff0c\u200b\u4e00\u65e6\u200b\u8be5\u200b\u4ea7\u54c1\u200b\u5b8c\u6210\u200b\uff0c\u200b\u6211\u4eec\u200b\u5c06\u200b\u63d0\u4f9b\u200b\u96c6\u6210\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#_10","title":"\u5185\u5b58\u200b\u8981\u6c42","text":"<p>\u200b\u7531\u4e8e\u200b DeepSpeed ZeRO \u200b\u53ef\u4ee5\u200b\u5c06\u200b\u5185\u5b58\u200b\u5378\u8f7d\u200b\u5230\u200b CPU\uff08\u200b\u548c\u200b NVMe\uff09\uff0c\u200b\u8be5\u200b\u6846\u67b6\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e9b\u200b\u5de5\u5177\u200b\uff0c\u200b\u5141\u8bb8\u200b\u6839\u636e\u200b\u4f7f\u7528\u200b\u7684\u200b GPU \u200b\u6570\u91cf\u200b\u544a\u77e5\u200b\u5c06\u200b\u9700\u8981\u200b\u591a\u5c11\u200b CPU \u200b\u548c\u200b GPU \u200b\u5185\u5b58\u200b\u3002</p> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4f30\u8ba1\u200b\u5728\u200b\u5355\u4e2a\u200bGPU\u200b\u4e0a\u200b\u5fae\u8c03\u200b\"bigscience/T0_3B\"\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u5185\u5b58\u200b\uff1a</p> <pre><code>$ python -c 'from transformers import AutoModel; \\\nfrom deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \\\nmodel = AutoModel.from_pretrained(\"bigscience/T0_3B\"); \\\nestimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=1, num_nodes=1)'\n[...]\nEstimated memory needed for params, optim states and gradients for a:\nHW: Setup with 1 node, 1 GPU per node.\nSW: Model with 2783M total params, 65M largest layer params.\n  per CPU  |  per GPU |   Options\n   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=1\n   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=0\n   62.23GB |   5.43GB | offload_param=none, offload_optimizer=cpu , zero_init=1\n   62.23GB |   5.43GB | offload_param=none, offload_optimizer=cpu , zero_init=0\n    0.37GB |  46.91GB | offload_param=none, offload_optimizer=none, zero_init=1\n   15.56GB |  46.91GB | offload_param=none, offload_optimizer=none, zero_init=0\n</code></pre> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u6a21\u578b\u200b\u62df\u5408\u200b\u5728\u200b\u5355\u4e2a\u200b80GB\u200b\u7684\u200bGPU\u200b\u4e0a\u200b\uff0c\u200b\u4e0d\u200b\u8fdb\u884c\u200bCPU offload\uff0c\u200b\u6216\u8005\u200b\u4f7f\u7528\u200b\u5fae\u5c0f\u200b\u7684\u200b8GB GPU\uff0c\u200b\u4f46\u200b\u9700\u8981\u200b\u7ea6\u200b60GB\u200b\u7684\u200bCPU\u200b\u5185\u5b58\u200b\u3002\uff08\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u8fd9\u4ec5\u200b\u662f\u200b\u53c2\u6570\u200b\u3001\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u548c\u200b\u68af\u5ea6\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u5185\u5b58\u200b - \u200b\u60a8\u200b\u8fd8\u200b\u9700\u8981\u200b\u4e3a\u200bCUDA\u200b\u5185\u6838\u200b\u3001\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u548c\u200b\u4e34\u65f6\u200b\u53d8\u91cf\u200b\u5206\u914d\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u5185\u5b58\u200b\u3002\uff09</p> <p>\u200b\u7136\u540e\u200b\uff0c\u200b\u8fd9\u662f\u200b\u6210\u672c\u200b\u4e0e\u200b\u901f\u5ea6\u200b\u7684\u200b\u6743\u8861\u200b\u3002\u200b\u8d2d\u4e70\u200b/\u200b\u79df\u7528\u200b\u8f83\u200b\u5c0f\u200b\u7684\u200b GPU\uff08\u200b\u6216\u200b\u8f83\u200b\u5c11\u200b\u7684\u200b GPU\uff0c\u200b\u56e0\u4e3a\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u591a\u4e2a\u200b GPU \u200b\u8fdb\u884c\u200b Deepspeed ZeRO\uff09\u3002\u200b\u4f46\u200b\u8fd9\u6837\u200b\u4f1a\u200b\u66f4\u6162\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5373\u4f7f\u200b\u60a8\u200b\u4e0d\u200b\u5173\u5fc3\u200b\u5b8c\u6210\u200b\u67d0\u9879\u200b\u4efb\u52a1\u200b\u7684\u200b\u901f\u5ea6\u200b\uff0c\u200b\u51cf\u901f\u200b\u4e5f\u200b\u76f4\u63a5\u200b\u5f71\u54cd\u200b GPU \u200b\u4f7f\u7528\u200b\u7684\u200b\u6301\u7eed\u65f6\u95f4\u200b\uff0c\u200b\u4ece\u800c\u200b\u5bfc\u81f4\u200b\u66f4\u5927\u200b\u7684\u200b\u6210\u672c\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u8bf7\u200b\u8fdb\u884c\u200b\u5b9e\u9a8c\u200b\u5e76\u200b\u6bd4\u8f83\u200b\u54ea\u200b\u79cd\u200b\u65b9\u6cd5\u200b\u6548\u679c\u200b\u6700\u597d\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200b\u8db3\u591f\u200b\u7684\u200bGPU\u200b\u5185\u5b58\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200b\u7981\u7528\u200bCPU/NVMe\u200b\u5378\u8f7d\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u8fd9\u4f1a\u200b\u4f7f\u200b\u6240\u6709\u200b\u64cd\u4f5c\u200b\u66f4\u200b\u5feb\u200b\u3002</p> <p>\u200b\u4f8b\u5982\u200b\uff0c\u200b\u8ba9\u200b\u6211\u4eec\u200b\u91cd\u590d\u200b\u76f8\u540c\u200b\u7684\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u4f7f\u7528\u200b2\u200b\u4e2a\u200bGPU\uff1a</p> <pre><code>$ python -c 'from transformers import AutoModel; \\\nfrom deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \\\nmodel = AutoModel.from_pretrained(\"bigscience/T0_3B\"); \\\nestimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=2, num_nodes=1)'\n[...]\nEstimated memory needed for params, optim states and gradients for a:\nHW: Setup with 1 node, 2 GPUs per node.\nSW: Model with 2783M total params, 65M largest layer params.\n  per CPU  |  per GPU |   Options\n   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=1\n   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=0\n   62.23GB |   2.84GB | offload_param=none, offload_optimizer=cpu , zero_init=1\n   62.23GB |   2.84GB | offload_param=none, offload_optimizer=cpu , zero_init=0\n    0.74GB |  23.58GB | offload_param=none, offload_optimizer=none, zero_init=1\n   31.11GB |  23.58GB | offload_param=none, offload_optimizer=none, zero_init=0\n</code></pre> <p>\u200b\u6240\u4ee5\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b2\u200b\u4e2a\u200b32GB\u200b\u6216\u200b\u66f4\u200b\u9ad8\u200b\u7684\u200bGPU\uff0c\u200b\u4e14\u200b\u4e0d\u200b\u8fdb\u884c\u200bCPU\u200b\u5378\u8f7d\u200b\u3002</p> <p>\u200b\u5982\u9700\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u5185\u5b58\u200b\u4f30\u7b97\u200b\u5668\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#issues","title":"\u5f52\u6863\u200bIssues","text":"<p>\u200b\u8bf7\u200b\u6309\u7167\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u63d0\u4ea4\u200b\u95ee\u9898\u200b\uff0c\u200b\u4ee5\u4fbf\u200b\u6211\u4eec\u200b\u80fd\u591f\u200b\u8fc5\u901f\u200b\u627e\u5230\u200b\u95ee\u9898\u200b\u5e76\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u89e3\u9664\u200b\u5de5\u4f5c\u200b\u963b\u585e\u200b\u3002</p> <p>\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u62a5\u544a\u200b\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u59cb\u7ec8\u200b\u5305\u62ec\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a</p> <ol> <li>\u200b\u5b8c\u6574\u200b\u7684\u200bDeepspeed\u200b\u914d\u7f6e\u6587\u4ef6\u200b</li> <li>\u200b\u5982\u679c\u200b\u4f7f\u7528\u200b\u4e86\u200b[<code>Trainer</code>]\uff0c\u200b\u5219\u200b\u5305\u62ec\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\uff1b\u200b\u5982\u679c\u200b\u81ea\u5df1\u200b\u7f16\u5199\u200b\u4e86\u200bTrainer\u200b\u8bbe\u7f6e\u200b\uff0c\u200b\u5219\u200b\u5305\u62ec\u200b[<code>TrainingArguments</code>]\u200b\u53c2\u6570\u200b\u3002\u200b\u8bf7\u200b\u4e0d\u8981\u200b\u5bfc\u51fa\u200b[<code>TrainingArguments</code>]\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u6709\u200b\u51e0\u5341\u4e2a\u200b\u4e0e\u200b\u95ee\u9898\u200b\u65e0\u5173\u200b\u7684\u200b\u6761\u76ee\u200b\u3002</li> <li> <p>\u200b\u8f93\u51fa\u200b\uff1a</p> <pre><code>python -c 'import torch; print(f\"torch: {torch.__version__}\")'\npython -c 'import transformers; print(f\"transformers: {transformers.__version__}\")'\npython -c 'import deepspeed; print(f\"deepspeed: {deepspeed.__version__}\")'\n</code></pre> </li> <li> <p>\u200b\u5982\u679c\u200b\u53ef\u80fd\u200b\uff0c\u200b\u8bf7\u200b\u5305\u542b\u200b\u4e00\u4e2a\u200bGoogle Colab notebook\u200b\u94fe\u63a5\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u5b83\u200b\u6765\u200b\u91cd\u73b0\u200b\u95ee\u9898\u200b\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200bnotebook\u200b\u4f5c\u4e3a\u200b\u8d77\u70b9\u200b\u3002</p> </li> <li>\u200b\u9664\u975e\u200b\u4e0d\u200b\u53ef\u80fd\u200b\uff0c\u200b\u5426\u5219\u8bf7\u200b\u59cb\u7ec8\u200b\u4f7f\u7528\u200b\u6807\u51c6\u200b\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u81ea\u200b\u5b9a\u4e49\u6570\u636e\u200b\u96c6\u200b\u3002</li> <li>\u200b\u5982\u679c\u200b\u53ef\u80fd\u200b\uff0c\u200b\u5c1d\u8bd5\u200b\u4f7f\u7528\u200b\u73b0\u6709\u200b\u793a\u4f8b\u200b\u4e4b\u4e00\u200b\u6765\u200b\u91cd\u73b0\u200b\u95ee\u9898\u200b\u3002</li> </ol> <p>\u200b\u9700\u8981\u200b\u8003\u8651\u200b\u7684\u200b\u56e0\u7d20\u200b\uff1a</p> <ul> <li>Deepspeed\u200b\u901a\u5e38\u200b\u4e0d\u662f\u200b\u95ee\u9898\u200b\u7684\u200b\u539f\u56e0\u200b\u3002</li> </ul> <p>\u200b\u4e00\u4e9b\u200b\u5df2\u200b\u63d0\u4ea4\u200b\u7684\u200b\u95ee\u9898\u200b\u88ab\u200b\u8bc1\u660e\u200b\u4e0e\u200bDeepspeed\u200b\u65e0\u5173\u200b\u3002\u200b\u4e5f\u5c31\u662f\u8bf4\u200b\uff0c\u200b\u4e00\u65e6\u200b\u5c06\u200bDeepspeed\u200b\u4ece\u200b\u8bbe\u7f6e\u200b\u4e2d\u200b\u79fb\u9664\u200b\uff0c\u200b\u95ee\u9898\u200b\u4ecd\u7136\u200b\u5b58\u5728\u200b\u3002</p> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u95ee\u9898\u200b\u660e\u663e\u200b\u4e0e\u200bDeepSpeed\u200b\u76f8\u5173\u200b\uff0c\u200b\u4f8b\u5982\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200b\u6709\u200b\u4e00\u4e2a\u200b\u5f02\u5e38\u200b\u5e76\u4e14\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200bDeepSpeed\u200b\u6a21\u5757\u200b\u6d89\u53ca\u200b\u5176\u4e2d\u200b\uff0c\u200b\u8bf7\u200b\u5148\u200b\u91cd\u65b0\u200b\u6d4b\u8bd5\u200b\u6ca1\u6709\u200bDeepSpeed\u200b\u7684\u200b\u8bbe\u7f6e\u200b\u3002\u200b\u53ea\u6709\u200b\u5f53\u200b\u95ee\u9898\u200b\u4ecd\u7136\u200b\u5b58\u5728\u200b\u65f6\u200b\uff0c\u200b\u624d\u200b\u5411\u200bDeepspeed\u200b\u63d0\u4f9b\u200b\u6240\u6709\u200b\u5fc5\u9700\u200b\u7684\u200b\u7ec6\u8282\u200b\u3002</p> <ul> <li>\u200b\u5982\u679c\u200b\u60a8\u200b\u660e\u786e\u200b\u95ee\u9898\u200b\u662f\u200b\u5728\u200bDeepspeed\u200b\u6838\u5fc3\u200b\u4e2d\u200b\u800c\u200b\u4e0d\u662f\u200b\u96c6\u6210\u200b\u90e8\u5206\u200b\uff0c\u200b\u8bf7\u200b\u76f4\u63a5\u200b\u5411\u200bDeepspeed\u200b\u63d0\u4ea4\u200b\u95ee\u9898\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u4e0d\u200b\u786e\u5b9a\u200b\uff0c\u200b\u8bf7\u200b\u4e0d\u8981\u200b\u62c5\u5fc3\u200b\uff0c\u200b\u65e0\u8bba\u200b\u4f7f\u7528\u200b\u54ea\u4e2a\u200bissue\u200b\u8ddf\u8e2a\u200b\u95ee\u9898\u200b\u90fd\u200b\u53ef\u4ee5\u200b\uff0c\u200b\u4e00\u65e6\u200b\u60a8\u200b\u53d1\u5e03\u200b\u95ee\u9898\u200b\uff0c\u200b\u6211\u4eec\u200b\u4f1a\u200b\u5f04\u6e05\u695a\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u91cd\u5b9a\u5411\u200b\u5230\u200b\u53e6\u200b\u4e00\u4e2a\u200bissue\u200b\u8ddf\u8e2a\u200b\uff08\u200b\u5982\u679c\u200b\u9700\u8981\u7684\u8bdd\u200b\uff09\u3002</li> </ul>"},{"location":"main_classes/deepspeed/#troubleshooting","title":"Troubleshooting","text":""},{"location":"main_classes/deepspeed/#deepspeed_2","title":"\u542f\u52a8\u200b\u65f6\u200b<code>deepspeed</code>\u200b\u8fdb\u7a0b\u200b\u88ab\u200b\u7ec8\u6b62\u200b\uff0c\u200b\u6ca1\u6709\u200b\u56de\u6eaf","text":"<p>\u200b\u5982\u679c\u200b\u542f\u52a8\u200b\u65f6\u200b<code>deepspeed</code>\u200b\u8fdb\u7a0b\u200b\u88ab\u200b\u7ec8\u6b62\u200b\uff0c\u200b\u6ca1\u6709\u200b\u56de\u6eaf\u200b\uff0c\u200b\u8fd9\u200b\u901a\u5e38\u200b\u610f\u5473\u7740\u200b\u7a0b\u5e8f\u200b\u5c1d\u8bd5\u200b\u5206\u914d\u200b\u7684\u200bCPU\u200b\u5185\u5b58\u200b\u8d85\u8fc7\u200b\u4e86\u200b\u7cfb\u7edf\u200b\u7684\u200b\u9650\u5236\u200b\u6216\u200b\u8fdb\u7a0b\u200b\u88ab\u200b\u5141\u8bb8\u200b\u5206\u914d\u200b\u7684\u200b\u5185\u5b58\u200b\uff0c\u200b\u64cd\u4f5c\u7cfb\u7edf\u200b\u5185\u6838\u200b\u6740\u6b7b\u200b\u4e86\u200b\u8be5\u200b\u8fdb\u7a0b\u200b\u3002\u200b\u8fd9\u200b\u662f\u56e0\u4e3a\u200b\u60a8\u200b\u7684\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u5f88\u200b\u53ef\u80fd\u200b\u5c06\u200b<code>offload_optimizer</code>\u200b\u6216\u200b<code>offload_param</code>\u200b\u6216\u200b\u4e24\u8005\u200b\u90fd\u200b\u914d\u7f6e\u200b\u4e3a\u200b\u5378\u8f7d\u200b\u5230\u200b<code>cpu</code>\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200bNVMe\uff0c\u200b\u53ef\u4ee5\u200b\u5c1d\u8bd5\u200b\u5728\u200bZeRO-3\u200b\u4e0b\u200b\u5378\u8f7d\u200b\u5230\u200bNVMe\u3002\u200b\u8fd9\u91cc\u200b\u662f\u200b\u5982\u4f55\u200b\u4f30\u8ba1\u200b\u7279\u5b9a\u200b\u6a21\u578b\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u5185\u5b58\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#lossnan","title":"\u8bad\u7ec3\u200b\u548c\u200b/\u200b\u6216\u200b\u8bc4\u4f30\u200b/\u200b\u9884\u6d4b\u200bloss\u200b\u4e3a\u200b<code>NaN</code>","text":"<p>\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u901a\u5e38\u200b\u53d1\u751f\u200b\u5728\u200b\u4f7f\u7528\u200bbf16\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u6a21\u5f0f\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u8bd5\u56fe\u200b\u5728\u200bfp16\uff08\u200b\u5e26\u200b\u6216\u200b\u4e0d\u5e26\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\uff09\u200b\u4e0b\u200b\u4f7f\u7528\u200b\u65f6\u200b\u3002\u200b\u5927\u591a\u6570\u200b\u5728\u200bTPU\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u4ee5\u53ca\u200b\u7531\u8c37\u6b4c\u200b\u53d1\u5e03\u200b\u7684\u200b\u6a21\u578b\u200b\u90fd\u200b\u5c5e\u4e8e\u200b\u8fd9\u4e2a\u200b\u7c7b\u522b\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u51e0\u4e4e\u200b\u6240\u6709\u200b\u57fa\u4e8e\u200bt5\u200b\u7684\u200b\u6a21\u578b\u200b\uff09\u3002\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u89e3\u51b3\u65b9\u6848\u200b\u662f\u200b\u8981\u4e48\u200b\u4f7f\u7528\u200bfp32\uff0c\u200b\u8981\u4e48\u200b\u5728\u200b\u652f\u6301\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4f7f\u7528\u200bbf16\uff08\u200b\u5982\u200bTPU\u3001Ampere GPU\u200b\u6216\u200b\u66f4\u65b0\u200b\u7684\u200b\u7248\u672c\u200b\uff09\u3002</p> <p>\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u95ee\u9898\u200b\u53ef\u80fd\u200b\u4e0e\u200b\u4f7f\u7528\u200bfp16\u200b\u6709\u5173\u200b\u3002\u200b\u5f53\u200b\u60a8\u200b\u914d\u7f6e\u200b\u6b64\u200b\u90e8\u5206\u200b\u65f6\u200b\uff1a</p> <pre><code>{\n    \"fp16\": {\n        \"enabled\": \"auto\",\n        \"loss_scale\": 0,\n        \"loss_scale_window\": 1000,\n        \"initial_scale_power\": 16,\n        \"hysteresis\": 2,\n        \"min_loss_scale\": 1\n    }\n}\n</code></pre> <p>\u200b\u5e76\u4e14\u200b\u60a8\u200b\u5728\u200b\u65e5\u5fd7\u200b\u4e2d\u200b\u770b\u5230\u200bDeepspeed\u200b\u62a5\u544a\u200b<code>OVERFLOW</code>\u200b\u5982\u4e0b\u200b</p> <pre><code>0%|                                                                                                                             | 0/189 [00:00&lt;?, ?it/s]\n [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 262144\n  1%|\u258c                                                                                                                    | 1/189 [00:00&lt;01:26,  2.17it/s]\n [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072.0\n  1%|\u2588\u258f\n [...]\n [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1\n 14%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                                                   | 27/189 [00:14&lt;01:13,  2.21it/s]\n [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1\n 15%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                                                                  | 28/189 [00:14&lt;01:13,  2.18it/s]\n [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1\n 15%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                                                                  | 29/189 [00:15&lt;01:13,  2.18it/s]\n [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1\n[...]\n</code></pre> <p>\u200b\u8fd9\u200b\u610f\u5473\u7740\u200bDeepspeed\u200b\u635f\u5931\u200b\u7f29\u653e\u200b\u5668\u200b\u65e0\u6cd5\u200b\u627e\u5230\u200b\u4e00\u4e2a\u200b\u514b\u670d\u200b\u635f\u5931\u200b\u6ea2\u51fa\u200b\u7684\u200b\u7f29\u653e\u200b\u7cfb\u6570\u200b\u3002</p> <p>\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u901a\u5e38\u200b\u9700\u8981\u200b\u63d0\u9ad8\u200b<code>initial_scale_power</code>\u200b\u7684\u200b\u503c\u200b\u3002\u200b\u5c06\u200b\u5176\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b<code>\"initial_scale_power\": 32</code>\u200b\u901a\u5e38\u200b\u4f1a\u200b\u89e3\u51b3\u95ee\u9898\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#_11","title":"\u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>DeepSpeed \u200b\u4e0e\u200b PyTorch [<code>Trainer</code>] \u200b\u4e00\u8d77\u200b\u5de5\u4f5c\u200b\uff0c\u200b\u4f46\u200b\u4e0d\u200b\u4e0e\u200b TF [<code>TFTrainer</code>] \u200b\u4e00\u8d77\u200b\u5de5\u4f5c\u200b\u3002</li> <li>\u200b\u5c3d\u7ba1\u200b DeepSpeed \u200b\u6709\u200b\u4e00\u4e2a\u200b\u53ef\u200b\u5b89\u88c5\u200b\u7684\u200b PyPI \u200b\u5305\u200b\uff0c\u200b\u4f46\u200b\u5f3a\u70c8\u5efa\u8bae\u200b\u4ece\u200b\u6e90\u4ee3\u7801\u200b\u5b89\u88c5\u200b\u5b83\u200b\uff0c\u200b\u4ee5\u200b\u6700\u597d\u200b\u5730\u200b\u5339\u914d\u200b\u60a8\u200b\u7684\u200b\u786c\u4ef6\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u9700\u8981\u200b\u542f\u7528\u200b\u67d0\u4e9b\u200b\u529f\u80fd\u200b\uff0c\u200b\u5982\u200b 1-bit Adam\uff0c\u200b\u8fd9\u4e9b\u200b\u529f\u80fd\u200b\u5728\u200b pypi \u200b\u53d1\u884c\u7248\u200b\u4e2d\u200b\u4e0d\u53ef\u200b\u7528\u200b\u3002</li> <li>\u200b\u60a8\u200b\u4e0d\u5fc5\u200b\u4f7f\u7528\u200b\ud83e\udd17  Transformers\u200b\u7684\u200b [<code>Trainer</code>] \u200b\u6765\u200b\u4f7f\u7528\u200b DeepSpeed   - \u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4efb\u4f55\u200b\u6a21\u578b\u200b\u4e0e\u200b\u81ea\u5df1\u200b\u7684\u200b\u8bad\u7ec3\u5668\u200b\uff0c\u200b\u60a8\u200b\u8fd8\u200b\u9700\u8981\u200b\u6839\u636e\u200b DeepSpeed \u200b\u96c6\u6210\u200b\u8bf4\u660e\u200b \u200b\u8c03\u6574\u200b\u540e\u8005\u200b\u3002</li> </ul>"},{"location":"main_classes/deepspeed/#non-trainer-deepspeed","title":"Non-Trainer Deepspeed\u200b\u96c6\u6210","text":"<p>\u200b\u5f53\u200b<code>Trainer</code>\u200b\u6ca1\u6709\u200b\u88ab\u200b\u4f7f\u7528\u200b\u65f6\u200b\uff0c<code>~integrations.HfDeepSpeedConfig</code>\u200b\u88ab\u200b\u7528\u6765\u200b\u5c06\u200bDeepspeed\u200b\u96c6\u6210\u200b\u5230\u200bhuggingface\u200b\u7684\u200bTransformers\u200b\u6838\u5fc3\u200b\u529f\u80fd\u200b\u4e2d\u200b\u3002\u200b\u5b83\u200b\u552f\u4e00\u200b\u505a\u200b\u7684\u200b\u4e8b\u60c5\u200b\u5c31\u662f\u200b\u5728\u200b<code>from_pretrained</code>\u200b\u8c03\u7528\u200b\u671f\u95f4\u200b\u5904\u7406\u200bDeepspeed ZeRO-3\u200b\u53c2\u6570\u200b\u6536\u96c6\u200b\u548c\u200b\u5c06\u200b\u6a21\u578b\u200b\u81ea\u52a8\u200b\u5206\u5272\u200b\u5230\u200b\u591a\u4e2a\u200bGPU\u200b\u4e0a\u200b\u3002\u200b\u9664\u6b64\u4e4b\u5916\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u81ea\u5df1\u200b\u5b8c\u6210\u200b\u5176\u4ed6\u200b\u6240\u6709\u200b\u5de5\u4f5c\u200b\u3002</p> <p>\u200b\u5f53\u200b\u4f7f\u7528\u200b<code>Trainer</code>\u200b\u65f6\u200b\uff0c\u200b\u6240\u6709\u200b\u4e8b\u60c5\u200b\u90fd\u200b\u81ea\u52a8\u200b\u5f97\u5230\u200b\u4e86\u200b\u5904\u7406\u200b\u3002</p> <p>\u200b\u5f53\u200b\u4e0d\u200b\u4f7f\u7528\u200b<code>Trainer</code>\u200b\u65f6\u200b\uff0c\u200b\u4e3a\u4e86\u200b\u9ad8\u6548\u200b\u5730\u200b\u90e8\u7f72\u200bDeepspeed ZeRO-3\uff0c\u200b\u60a8\u200b\u5fc5\u987b\u200b\u5728\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u6a21\u578b\u200b\u4e4b\u524d\u200b\u5b9e\u4f8b\u200b\u5316\u200b<code>~integrations.HfDeepSpeedConfig</code>\u200b\u5bf9\u8c61\u200b\u5e76\u200b\u4fdd\u6301\u200b\u8be5\u200b\u5bf9\u8c61\u200b\u6d3b\u8dc3\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u6b63\u5728\u200b\u4f7f\u7528\u200bDeepspeed ZeRO-1\u200b\u6216\u200bZeRO-2\uff0c\u200b\u60a8\u200b\u6839\u672c\u200b\u4e0d\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b<code>HfDeepSpeedConfig</code>\u3002</p> <p>\u200b\u4ee5\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4e3a\u4f8b\u200b:</p> <pre><code>from transformers.integrations import HfDeepSpeedConfig\nfrom transformers import AutoModel\nimport deepspeed\n\nds_config = {...}  # deepspeed config object or path to the file\n# must run before instantiating the model to detect zero 3\ndschf = HfDeepSpeedConfig(ds_config)  # keep this object alive\nmodel = AutoModel.from_pretrained(\"gpt2\")\nengine = deepspeed.initialize(model=model, config_params=ds_config, ...)\n</code></pre> <p>\u200b\u6216\u8005\u200b\u4ee5\u975e\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u4e3a\u4f8b\u200b\uff1a</p> <pre><code>from transformers.integrations import HfDeepSpeedConfig\nfrom transformers import AutoModel, AutoConfig\nimport deepspeed\n\nds_config = {...}  # deepspeed config object or path to the file\n# must run before instantiating the model to detect zero 3\ndschf = HfDeepSpeedConfig(ds_config)  # keep this object alive\nconfig = AutoConfig.from_pretrained(\"gpt2\")\nmodel = AutoModel.from_config(config)\nengine = deepspeed.initialize(model=model, config_params=ds_config, ...)\n</code></pre> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u6ca1\u6709\u200b\u4f7f\u7528\u200b[<code>Trainer</code>]\u200b\u96c6\u6210\u200b\uff0c\u200b\u60a8\u200b\u5b8c\u5168\u200b\u9700\u8981\u200b\u81ea\u5df1\u200b\u52a8\u624b\u200b\u3002\u200b\u57fa\u672c\u4e0a\u200b\u9075\u5faa\u200bDeepspeed\u200b\u7f51\u7ad9\u200b\u4e0a\u200b\u7684\u200b\u6587\u6863\u200b\u3002\u200b\u540c\u65f6\u200b\uff0c\u200b\u60a8\u200b\u5fc5\u987b\u200b\u663e\u5f0f\u200b\u914d\u7f6e\u200b\u914d\u7f6e\u6587\u4ef6\u200b - \u200b\u4e0d\u80fd\u200b\u4f7f\u7528\u200b<code>\"auto\"</code>\u200b\u503c\u200b\uff0c\u200b\u800c\u200b\u5fc5\u987b\u200b\u653e\u5165\u200b\u5b9e\u9645\u200b\u503c\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#hfdeepspeedconfig","title":"HfDeepSpeedConfig","text":"<p>[[autodoc]] integrations.HfDeepSpeedConfig     - all</p>"},{"location":"main_classes/deepspeed/#deepspeed-zero","title":"\u81ea\u5b9a\u4e49\u200bDeepSpeed ZeRO\u200b\u63a8\u7406","text":"<p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u4e00\u4e2a\u200b\u793a\u4f8b\u200b\uff0c\u200b\u6f14\u793a\u200b\u4e86\u200b\u5728\u200b\u65e0\u6cd5\u200b\u5c06\u200b\u6a21\u578b\u200b\u653e\u5165\u200b\u5355\u4e2a\u200b GPU \u200b\u65f6\u200b\u5982\u679c\u200b\u4e0d\u200b\u4f7f\u7528\u200b[Trainer]\u200b\u8fdb\u884c\u200b DeepSpeed ZeRO \u200b\u63a8\u7406\u200b \u3002\u200b\u8be5\u200b\u89e3\u51b3\u65b9\u6848\u200b\u5305\u62ec\u200b\u4f7f\u7528\u200b\u989d\u5916\u200b\u7684\u200b GPU \u200b\u6216\u200b/\u200b\u548c\u200b\u5c06\u200b GPU \u200b\u5185\u5b58\u200b\u5378\u8f7d\u200b\u5230\u200b CPU \u200b\u5185\u5b58\u200b\u3002</p> <p>\u200b\u8fd9\u91cc\u200b\u8981\u200b\u7406\u89e3\u200b\u7684\u200b\u91cd\u8981\u200b\u7ec6\u5fae\u5dee\u522b\u200b\u662f\u200b\uff0cZeRO\u200b\u7684\u200b\u8bbe\u8ba1\u200b\u65b9\u5f0f\u200b\u53ef\u4ee5\u200b\u8ba9\u200b\u60a8\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200bGPU\u200b\u4e0a\u200b\u5e76\u884c\u5904\u7406\u200b\u4e0d\u540c\u200b\u7684\u200b\u8f93\u5165\u200b\u3002</p> <p>\u200b\u8fd9\u4e2a\u200b\u4f8b\u5b50\u200b\u6709\u200b\u5f88\u591a\u200b\u6ce8\u91ca\u200b\uff0c\u200b\u5e76\u4e14\u200b\u662f\u200b\u81ea\u200b\u6587\u6863\u200b\u5316\u200b\u7684\u200b\u3002</p> <p>\u200b\u8bf7\u200b\u786e\u4fdd\u200b\uff1a</p> <ol> <li>\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200b\u8db3\u591f\u200b\u7684\u200bGPU\u200b\u5185\u5b58\u200b\uff08\u200b\u56e0\u4e3a\u200b\u8fd9\u4f1a\u200b\u51cf\u6162\u200b\u901f\u5ea6\u200b\uff09\uff0c\u200b\u7981\u7528\u200bCPU offload\u3002</li> <li>\u200b\u5982\u679c\u200b\u60a8\u200b\u62e5\u6709\u200bAmpere\u200b\u67b6\u6784\u200b\u6216\u200b\u66f4\u65b0\u200b\u7684\u200bGPU\uff0c\u200b\u542f\u7528\u200bbf16\u200b\u4ee5\u200b\u52a0\u5feb\u901f\u5ea6\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u6ca1\u6709\u200b\u8fd9\u79cd\u200b\u786c\u4ef6\u200b\uff0c\u200b\u53ea\u8981\u200b\u4e0d\u200b\u4f7f\u7528\u200b\u4efb\u4f55\u200b\u5728\u200bbf16\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u4e0b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\uff08\u200b\u5982\u200b\u5927\u591a\u6570\u200bt5\u200b\u6a21\u578b\u200b\uff09\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u542f\u7528\u200bfp16\u3002\u200b\u5426\u5219\u200b\u8fd9\u4e9b\u200b\u6a21\u578b\u200b\u901a\u5e38\u200b\u5728\u200bfp16\u200b\u4e2d\u200b\u6ea2\u51fa\u200b\uff0c\u200b\u60a8\u200b\u4f1a\u200b\u770b\u5230\u200b\u8f93\u51fa\u200b\u65e0\u6548\u200b\u7ed3\u679c\u200b\u3002</li> </ol> <pre><code>#!/usr/bin/env python\n\n# This script demonstrates how to use Deepspeed ZeRO in an inference mode when one can't fit a model\n# into a single GPU\n#\n# 1. Use 1 GPU with CPU offload\n# 2. Or use multiple GPUs instead\n#\n# First you need to install deepspeed: pip install deepspeed\n#\n# Here we use a 3B \"bigscience/T0_3B\" model which needs about 15GB GPU RAM - so 1 largish or 2\n# small GPUs can handle it. or 1 small GPU and a lot of CPU memory.\n#\n# To use a larger model like \"bigscience/T0\" which needs about 50GB, unless you have an 80GB GPU -\n# you will need 2-4 gpus. And then you can adapt the script to handle more gpus if you want to\n# process multiple inputs at once.\n#\n# The provided deepspeed config also activates CPU memory offloading, so chances are that if you\n# have a lot of available CPU memory and you don't mind a slowdown you should be able to load a\n# model that doesn't normally fit into a single GPU. If you have enough GPU memory the program will\n# run faster if you don't want offload to CPU - so disable that section then.\n#\n# To deploy on 1 gpu:\n#\n# deepspeed --num_gpus 1 t0.py\n# or:\n# python -m torch.distributed.run --nproc_per_node=1 t0.py\n#\n# To deploy on 2 gpus:\n#\n# deepspeed --num_gpus 2 t0.py\n# or:\n# python -m torch.distributed.run --nproc_per_node=2 t0.py\n\n\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForSeq2SeqLM\nfrom transformers.integrations import HfDeepSpeedConfig\nimport deepspeed\nimport os\nimport torch\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # To avoid warnings about parallelism in tokenizers\n\n# distributed setup\nlocal_rank = int(os.getenv(\"LOCAL_RANK\", \"0\"))\nworld_size = int(os.getenv(\"WORLD_SIZE\", \"1\"))\ntorch.cuda.set_device(local_rank)\ndeepspeed.init_distributed()\n\nmodel_name = \"bigscience/T0_3B\"\n\nconfig = AutoConfig.from_pretrained(model_name)\nmodel_hidden_size = config.d_model\n\n# batch size has to be divisible by world_size, but can be bigger than world_size\ntrain_batch_size = 1 * world_size\n\n# ds_config notes\n#\n# - enable bf16 if you use Ampere or higher GPU - this will run in mixed precision and will be\n# faster.\n#\n# - for older GPUs you can enable fp16, but it'll only work for non-bf16 pretrained models - e.g.\n# all official t5 models are bf16-pretrained\n#\n# - set offload_param.device to \"none\" or completely remove the `offload_param` section if you don't\n# - want CPU offload\n#\n# - if using `offload_param` you can manually finetune stage3_param_persistence_threshold to control\n# - which params should remain on gpus - the larger the value the smaller the offload size\n#\n# For indepth info on Deepspeed config see\n# https://huggingface.co/docs/transformers/main/main_classes/deepspeed\n\n# keeping the same format as json for consistency, except it uses lower case for true/false\n# fmt: off\nds_config = {\n    \"fp16\": {\n        \"enabled\": False\n    },\n    \"bf16\": {\n        \"enabled\": False\n    },\n    \"zero_optimization\": {\n        \"stage\": 3,\n        \"offload_param\": {\n            \"device\": \"cpu\",\n            \"pin_memory\": True\n        },\n        \"overlap_comm\": True,\n        \"contiguous_gradients\": True,\n        \"reduce_bucket_size\": model_hidden_size * model_hidden_size,\n        \"stage3_prefetch_bucket_size\": 0.9 * model_hidden_size * model_hidden_size,\n        \"stage3_param_persistence_threshold\": 10 * model_hidden_size\n    },\n    \"steps_per_print\": 2000,\n    \"train_batch_size\": train_batch_size,\n    \"train_micro_batch_size_per_gpu\": 1,\n    \"wall_clock_breakdown\": False\n}\n# fmt: on\n\n# next line instructs transformers to partition the model directly over multiple gpus using\n# deepspeed.zero.Init when model's `from_pretrained` method is called.\n#\n# **it has to be run before loading the model AutoModelForSeq2SeqLM.from_pretrained(model_name)**\n#\n# otherwise the model will first be loaded normally and only partitioned at forward time which is\n# less efficient and when there is little CPU RAM may fail\ndschf = HfDeepSpeedConfig(ds_config)  # keep this object alive\n\n# now a model can be loaded.\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n# initialise Deepspeed ZeRO and store only the engine object\nds_engine = deepspeed.initialize(model=model, config_params=ds_config)[0]\nds_engine.module.eval()  # inference\n\n# Deepspeed ZeRO can process unrelated inputs on each GPU. So for 2 gpus you process 2 inputs at once.\n# If you use more GPUs adjust for more.\n# And of course if you have just one input to process you then need to pass the same string to both gpus\n# If you use only one GPU, then you will have only rank 0.\nrank = torch.distributed.get_rank()\nif rank == 0:\n    text_in = \"Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy\"\nelif rank == 1:\n    text_in = \"Is this review positive or negative? Review: this is the worst restaurant ever\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ninputs = tokenizer.encode(text_in, return_tensors=\"pt\").to(device=local_rank)\nwith torch.no_grad():\n    outputs = ds_engine.module.generate(inputs, synced_gpus=True)\ntext_out = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(f\"rank{rank}:\\n   in={text_in}\\n  out={text_out}\")\n</code></pre> <p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u4fdd\u5b58\u200b\u5b83\u200b\u4e3a\u200b <code>t0.py</code>\u200b\u5e76\u200b\u8fd0\u884c\u200b\uff1a <pre><code>$ deepspeed --num_gpus 2 t0.py\nrank0:\n   in=Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy\n  out=Positive\nrank1:\n   in=Is this review positive or negative? Review: this is the worst restaurant ever\n  out=negative\n</code></pre></p> <p>\u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u975e\u5e38\u200b\u57fa\u672c\u200b\u7684\u200b\u4f8b\u5b50\u200b\uff0c\u200b\u60a8\u200b\u9700\u8981\u200b\u6839\u636e\u200b\u81ea\u5df1\u200b\u7684\u200b\u9700\u6c42\u200b\u8fdb\u884c\u200b\u4fee\u6539\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#generate","title":"<code>generate</code> \u200b\u7684\u200b\u5dee\u5f02","text":"<p>\u200b\u5728\u200b\u4f7f\u7528\u200bZeRO stage 3\u200b\u7684\u200b\u591a\u200bGPU\u200b\u65f6\u200b\uff0c\u200b\u9700\u8981\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200b<code>generate(..., synced_gpus=True)</code>\u200b\u6765\u200b\u540c\u6b65\u200bGPU\u3002\u200b\u5982\u679c\u200b\u4e00\u4e2a\u200bGPU\u200b\u5728\u200b\u5176\u5b83\u200bGPU\u200b\u4e4b\u524d\u200b\u5b8c\u6210\u200b\u751f\u6210\u200b\uff0c\u200b\u6574\u4e2a\u200b\u7cfb\u7edf\u200b\u5c06\u200b\u6302\u200b\u8d77\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5176\u4ed6\u200bGPU\u200b\u65e0\u6cd5\u200b\u4ece\u200b\u505c\u6b62\u200b\u751f\u6210\u200b\u7684\u200bGPU\u200b\u63a5\u6536\u200b\u6743\u91cd\u200b\u5206\u7247\u200b\u3002</p> <p>\u200b\u4ece\u200b<code>transformers&gt;=4.28</code>\u200b\u5f00\u59cb\u200b\uff0c\u200b\u5982\u679c\u200b\u6ca1\u6709\u200b\u660e\u786e\u200b\u6307\u5b9a\u200b<code>synced_gpus</code>\uff0c\u200b\u68c0\u6d4b\u200b\u5230\u200b\u8fd9\u4e9b\u200b\u6761\u4ef6\u200b\u540e\u200b\u5b83\u200b\u5c06\u200b\u81ea\u52a8\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b<code>True</code>\u3002\u200b\u4f46\u200b\u5982\u679c\u200b\u60a8\u200b\u9700\u8981\u200b\u8986\u76d6\u200b<code>synced_gpus</code>\u200b\u7684\u200b\u503c\u200b\uff0c\u200b\u4ecd\u7136\u200b\u53ef\u4ee5\u200b\u8fd9\u6837\u200b\u505a\u200b\u3002</p>"},{"location":"main_classes/deepspeed/#deepspeed_3","title":"\u6d4b\u8bd5\u200b DeepSpeed \u200b\u96c6\u6210","text":"<p>\u200b\u5982\u679c\u200b\u60a8\u200b\u63d0\u4ea4\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u6d89\u53ca\u200bDeepSpeed\u200b\u96c6\u6210\u200b\u7684\u200bPR\uff0c\u200b\u8bf7\u200b\u6ce8\u610f\u200b\u6211\u4eec\u200b\u7684\u200bCircleCI PR CI\u200b\u8bbe\u7f6e\u200b\u6ca1\u6709\u200bGPU\uff0c\u200b\u56e0\u6b64\u200b\u6211\u4eec\u200b\u53ea\u200b\u5728\u200b\u53e6\u200b\u4e00\u4e2a\u200bCI\u200b\u591c\u95f4\u200b\u8fd0\u884c\u200b\u9700\u8981\u200bGPU\u200b\u7684\u200b\u6d4b\u8bd5\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u5728\u200bPR\u200b\u4e2d\u200b\u83b7\u5f97\u200b\u7eff\u8272\u200b\u7684\u200bCI\u200b\u62a5\u544a\u200b\uff0c\u200b\u5e76\u200b\u4e0d\u200b\u610f\u5473\u7740\u200bDeepSpeed\u200b\u6d4b\u8bd5\u901a\u8fc7\u200b\u3002</p> <p>\u200b\u8981\u200b\u8fd0\u884c\u200bDeepSpeed\u200b\u6d4b\u8bd5\u200b\uff0c\u200b\u8bf7\u200b\u81f3\u5c11\u200b\u8fd0\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\uff1a</p> <pre><code>RUN_SLOW=1 pytest tests/deepspeed/test_deepspeed.py\n</code></pre> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u66f4\u6539\u200b\u4e86\u200b\u4efb\u4f55\u200b\u6a21\u578b\u200b\u6216\u200bPyTorch\u200b\u793a\u4f8b\u200b\u4ee3\u7801\u200b\uff0c\u200b\u8bf7\u200b\u540c\u65f6\u200b\u8fd0\u884c\u200b\u591a\u200b\u6a21\u578b\u200b\u6d4b\u8bd5\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u5c06\u200b\u8fd0\u884c\u200b\u6240\u6709\u200bDeepSpeed\u200b\u6d4b\u8bd5\u200b\uff1a</p> <pre><code>RUN_SLOW=1 pytest tests/deepspeed\n</code></pre>"},{"location":"main_classes/deepspeed/#deepspeed_4","title":"\u4e3b\u8981\u200b\u7684\u200bDeepSpeed\u200b\u8d44\u6e90","text":"<ul> <li>\u200b\u9879\u76ee\u200bGitHub</li> <li>\u200b\u4f7f\u7528\u200b\u6587\u6863\u200b</li> <li>API\u200b\u6587\u6863\u200b</li> <li>\u200b\u535a\u5ba2\u200b\u6587\u7ae0\u200b</li> </ul> <p>\u200b\u8bba\u6587\u200b:</p> <ul> <li>ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</li> <li>ZeRO-Offload: Democratizing Billion-Scale Model Training</li> <li>ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</li> </ul> <p>\u200b\u6700\u540e\u200b\uff0c\u200b\u8bf7\u200b\u8bb0\u4f4f\u200b\uff0cHuggingFace [<code>Trainer</code>]\u200b\u4ec5\u200b\u96c6\u6210\u200b\u4e86\u200bDeepSpeed\uff0c\u200b\u56e0\u6b64\u200b\u5982\u679c\u200b\u60a8\u200b\u5728\u200b\u4f7f\u7528\u200bDeepSpeed\u200b\u65f6\u200b\u9047\u5230\u200b\u4efb\u4f55\u200b\u95ee\u9898\u200b\u6216\u200b\u7591\u95ee\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200bDeepSpeed GitHub\u200b\u4e0a\u200b\u63d0\u4ea4\u200b\u4e00\u4e2a\u200bissue\u3002</p>"},{"location":"main_classes/model/","title":"Model","text":""},{"location":"main_classes/model/#_1","title":"\u6a21\u578b","text":"<p>\u200b\u57fa\u7c7b\u200b [<code>PreTrainedModel</code>]\u3001[<code>TFPreTrainedModel</code>] \u200b\u548c\u200b [<code>FlaxPreTrainedModel</code>] \u200b\u5b9e\u73b0\u200b\u4e86\u200b\u4ece\u200b\u672c\u5730\u200b\u6587\u4ef6\u200b\u6216\u200b\u76ee\u5f55\u200b\u52a0\u8f7d\u200b/\u200b\u4fdd\u5b58\u200b\u6a21\u578b\u200b\u7684\u200b\u5e38\u7528\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u6216\u8005\u200b\u4ece\u5e93\u200b\u4e0a\u200b\u63d0\u4f9b\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u914d\u7f6e\u200b\uff08\u200b\u4ece\u200b HuggingFace \u200b\u7684\u200b AWS S3 \u200b\u5b58\u50a8\u200b\u5e93\u200b\u4e0b\u8f7d\u200b\uff09\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\u3002</p> <p>[<code>PreTrainedModel</code>] \u200b\u548c\u200b [<code>TFPreTrainedModel</code>] \u200b\u8fd8\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u4e00\u4e9b\u200b\u6240\u6709\u200b\u6a21\u578b\u200b\u5171\u6709\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff1a</p> <ul> <li>\u200b\u5728\u200b\u5411\u200b\u91cf\u8bcd\u200b\u5d4c\u5165\u200b\u589e\u52a0\u200b\u65b0\u8bcd\u6c47\u200b\u65f6\u200b\u8c03\u6574\u200b\u8f93\u5165\u200b\u6807\u8bb0\u200b\uff08token\uff09\u200b\u7684\u200b\u5927\u5c0f\u200b</li> <li>\u200b\u5bf9\u6a21\u578b\u200b\u7684\u200b\u6ce8\u610f\u529b\u200b\u5934\u200b\u8fdb\u884c\u200b\u4fee\u526a\u200b\u3002</li> </ul> <p>\u200b\u5176\u4ed6\u200b\u7684\u200b\u901a\u7528\u200b\u65b9\u6cd5\u200b\u5728\u200b [<code>~modeling_utils.ModuleUtilsMixin</code>]\uff08\u200b\u7528\u4e8e\u200b PyTorch \u200b\u6a21\u578b\u200b\uff09\u200b\u548c\u200b [<code>~modeling_tf_utils.TFModuleUtilsMixin</code>]\uff08\u200b\u7528\u4e8e\u200b TensorFlow \u200b\u6a21\u578b\u200b\uff09\u200b\u4e2d\u200b\u5b9a\u4e49\u200b\uff1b\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u65b9\u9762\u200b\u7684\u200b\u65b9\u6cd5\u200b\u5219\u200b\u5b9a\u4e49\u200b\u5728\u200b [<code>~generation.GenerationMixin</code>]\uff08\u200b\u7528\u4e8e\u200b PyTorch \u200b\u6a21\u578b\u200b\uff09\u3001[<code>~generation.TFGenerationMixin</code>]\uff08\u200b\u7528\u4e8e\u200b TensorFlow \u200b\u6a21\u578b\u200b\uff09\u200b\u548c\u200b [<code>~generation.FlaxGenerationMixin</code>]\uff08\u200b\u7528\u4e8e\u200b Flax/JAX \u200b\u6a21\u578b\u200b\uff09\u200b\u4e2d\u200b\u3002</p>"},{"location":"main_classes/model/#pretrainedmodel","title":"PreTrainedModel","text":"<p>[[autodoc]] PreTrainedModel     - push_to_hub     - all</p> <p></p>"},{"location":"main_classes/model/#_2","title":"\u5927\u200b\u6a21\u578b\u200b\u52a0\u8f7d","text":"<p>\u200b\u5728\u200b Transformers 4.20.0 \u200b\u4e2d\u200b\uff0c[<code>~PreTrainedModel.from_pretrained</code>] \u200b\u65b9\u6cd5\u200b\u5df2\u200b\u91cd\u65b0\u200b\u8bbe\u8ba1\u200b\uff0c\u200b\u4ee5\u200b\u9002\u5e94\u200b\u4f7f\u7528\u200b Accelerate \u200b\u52a0\u8f7d\u200b\u5927\u578b\u200b\u6a21\u578b\u200b\u7684\u200b\u573a\u666f\u200b\u3002\u200b\u8fd9\u200b\u9700\u8981\u200b\u60a8\u200b\u4f7f\u7528\u200b\u7684\u200b Accelerate \u200b\u548c\u200b PyTorch \u200b\u7248\u672c\u200b\u6ee1\u8db3\u200b\uff1a Accelerate &gt;= 0.9.0\uff0c PyTorch &gt;= 1.9.0\u3002\u200b\u9664\u4e86\u200b\u521b\u5efa\u200b\u5b8c\u6574\u200b\u6a21\u578b\u200b\uff0c\u200b\u7136\u540e\u200b\u5728\u200b\u5176\u4e2d\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\uff08\u200b\u8fd9\u4f1a\u200b\u5360\u7528\u200b\u4e24\u500d\u200b\u4e8e\u200b\u6a21\u578b\u200b\u5927\u5c0f\u200b\u7684\u200b\u5185\u5b58\u7a7a\u95f4\u200b\uff0c\u200b\u4e00\u4e2a\u200b\u7528\u4e8e\u200b\u968f\u673a\u200b\u521d\u59cb\u5316\u200b\u6a21\u578b\u200b\uff0c\u200b\u4e00\u4e2a\u200b\u7528\u4e8e\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\uff09\uff0c\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u79cd\u200b\u9009\u9879\u200b\uff0c\u200b\u5c06\u200b\u6a21\u578b\u200b\u521b\u5efa\u200b\u4e3a\u200b\u7a7a\u58f3\u200b\uff0c\u200b\u7136\u540e\u200b\u53ea\u6709\u200b\u5728\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\u65f6\u624d\u200b\u5b9e\u4f8b\u200b\u5316\u5176\u200b\u53c2\u6570\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>low_cpu_mem_usage=True</code> \u200b\u6fc0\u6d3b\u200b\u6b64\u200b\u9009\u9879\u200b\u3002\u200b\u9996\u5148\u200b\uff0c\u200b\u5728\u200b Meta \u200b\u8bbe\u5907\u200b\u4e0a\u200b\u521b\u5efa\u200b\u6a21\u578b\u200b\uff08\u200b\u5e26\u6709\u200b\u7a7a\u200b\u6743\u91cd\u200b\uff09\uff0c\u200b\u7136\u540e\u200b\u5c06\u200b\u72b6\u6001\u200b\u5b57\u5178\u200b\u52a0\u8f7d\u200b\u5230\u200b\u5176\u4e2d\u200b\uff08\u200b\u5728\u200b\u5206\u7247\u200b\u68c0\u67e5\u70b9\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u9010\u7247\u200b\u52a0\u8f7d\u200b\uff09\u3002\u200b\u8fd9\u6837\u200b\uff0c\u200b\u6700\u5927\u200b\u4f7f\u7528\u200b\u7684\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\u4ec5\u4e3a\u200b\u6a21\u578b\u200b\u7684\u200b\u5b8c\u6574\u200b\u5927\u5c0f\u200b\u3002</p> <pre><code>from transformers import AutoModelForSeq2SeqLM\n\nt0pp = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0pp\", low_cpu_mem_usage=True)\n</code></pre> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u5982\u679c\u200b\u5185\u5b58\u200b\u4e0d\u8db3\u4ee5\u200b\u653e\u4e0b\u200b\u52a0\u8f7d\u200b\u6574\u4e2a\u200b\u6a21\u578b\u200b\uff08\u200b\u76ee\u524d\u200b\u4ec5\u200b\u9002\u7528\u200b\u4e8e\u200b\u63a8\u7406\u200b\uff09\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u5c06\u200b\u6a21\u578b\u200b\u653e\u7f6e\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u3002\u200b\u4f7f\u7528\u200b <code>device_map=\"auto\"</code>\uff0cAccelerate \u200b\u5c06\u200b\u786e\u5b9a\u200b\u5c06\u200b\u6bcf\u200b\u4e00\u5c42\u200b\u653e\u7f6e\u200b\u5728\u200b\u54ea\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\uff0c\u200b\u4ee5\u200b\u6700\u5927\u5316\u200b\u4f7f\u7528\u200b\u6700\u5feb\u200b\u7684\u200b\u8bbe\u5907\u200b\uff08GPU\uff09\uff0c\u200b\u5e76\u200b\u5c06\u200b\u5176\u4f59\u90e8\u5206\u200b\u5378\u8f7d\u200b\u5230\u200b CPU\uff0c\u200b\u751a\u81f3\u200b\u786c\u76d8\u200b\u4e0a\u200b\uff08\u200b\u5982\u679c\u200b\u60a8\u200b\u6ca1\u6709\u200b\u8db3\u591f\u200b\u7684\u200b GPU \u200b\u5185\u5b58\u200b \u200b\u6216\u200b CPU \u200b\u5185\u5b58\u200b\uff09\u3002\u200b\u5373\u4f7f\u200b\u6a21\u578b\u200b\u5206\u5e03\u200b\u5728\u200b\u51e0\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\uff0c\u200b\u5b83\u200b\u4e5f\u200b\u5c06\u200b\u50cf\u200b\u60a8\u200b\u901a\u5e38\u200b\u671f\u671b\u200b\u7684\u200b\u90a3\u6837\u200b\u8fd0\u884c\u200b\u3002</p> <p>\u200b\u5728\u200b\u4f20\u9012\u200b <code>device_map</code> \u200b\u65f6\u200b\uff0c<code>low_cpu_mem_usage</code> \u200b\u4f1a\u200b\u81ea\u52a8\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b <code>True</code>\uff0c\u200b\u56e0\u6b64\u200b\u60a8\u200b\u4e0d\u200b\u9700\u8981\u200b\u6307\u5b9a\u200b\u5b83\u200b\uff1a</p> <pre><code>from transformers import AutoModelForSeq2SeqLM\n\nt0pp = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0pp\", device_map=\"auto\")\n</code></pre> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b <code>hf_device_map</code> \u200b\u5c5e\u6027\u200b\u6765\u200b\u67e5\u770b\u200b\u6a21\u578b\u200b\u662f\u200b\u5982\u4f55\u200b\u5728\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u5206\u5272\u200b\u7684\u200b\uff1a</p> <pre><code>t0pp.hf_device_map\n{'shared': 0,\n 'decoder.embed_tokens': 0,\n 'encoder': 0,\n 'decoder.block.0': 0,\n 'decoder.block.1': 1,\n 'decoder.block.2': 1,\n 'decoder.block.3': 1,\n 'decoder.block.4': 1,\n 'decoder.block.5': 1,\n 'decoder.block.6': 1,\n 'decoder.block.7': 1,\n 'decoder.block.8': 1,\n 'decoder.block.9': 1,\n 'decoder.block.10': 1,\n 'decoder.block.11': 1,\n 'decoder.block.12': 1,\n 'decoder.block.13': 1,\n 'decoder.block.14': 1,\n 'decoder.block.15': 1,\n 'decoder.block.16': 1,\n 'decoder.block.17': 1,\n 'decoder.block.18': 1,\n 'decoder.block.19': 1,\n 'decoder.block.20': 1,\n 'decoder.block.21': 1,\n 'decoder.block.22': 'cpu',\n 'decoder.block.23': 'cpu',\n 'decoder.final_layer_norm': 'cpu',\n 'decoder.dropout': 'cpu',\n 'lm_head': 'cpu'}\n</code></pre> <p>\u200b\u60a8\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u6309\u7167\u200b\u76f8\u540c\u200b\u7684\u200b\u683c\u5f0f\u200b\uff08\u200b\u4e00\u4e2a\u200b\u5c42\u200b\u540d\u79f0\u200b\u5230\u200b\u8bbe\u5907\u200b\u7684\u200b\u6620\u5c04\u200b\u5173\u7cfb\u200b\u7684\u200b\u5b57\u5178\u200b\uff09\u200b\u7f16\u5199\u200b\u81ea\u5df1\u200b\u7684\u200b\u8bbe\u5907\u200b\u6620\u5c04\u200b\u89c4\u5219\u200b\u3002\u200b\u5b83\u200b\u5e94\u8be5\u200b\u5c06\u200b\u6a21\u578b\u200b\u7684\u200b\u6240\u6709\u200b\u53c2\u6570\u200b\u6620\u5c04\u200b\u5230\u200b\u7ed9\u5b9a\u200b\u7684\u200b\u8bbe\u5907\u200b\u4e0a\u200b\uff0c\u200b\u5982\u679c\u200b\u8be5\u5c42\u200b\u7684\u200b\u6240\u6709\u200b\u5b50\u200b\u6a21\u5757\u200b\u90fd\u200b\u5728\u200b\u540c\u4e00\u200b\u8bbe\u5907\u200b\u4e0a\u200b\uff0c\u200b\u60a8\u200b\u4e0d\u5fc5\u200b\u8be6\u7ec6\u200b\u8bf4\u660e\u200b\u5176\u4e2d\u200b\u6240\u6709\u200b\u5b50\u200b\u6a21\u5757\u200b\u7684\u200b\u4f4d\u7f6e\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4ee5\u4e0b\u200b\u8bbe\u5907\u200b\u6620\u5c04\u200b\u5bf9\u4e8e\u200b T0pp \u200b\u5c06\u200b\u6b63\u5e38\u200b\u5de5\u4f5c\u200b\uff08\u200b\u53ea\u8981\u200b\u60a8\u200b\u6709\u200b GPU \u200b\u5185\u5b58\u200b\uff09\uff1a</p> <pre><code>device_map = {\"shared\": 0, \"encoder\": 0, \"decoder\": 1, \"lm_head\": 1}\n</code></pre> <p>\u200b\u53e6\u200b\u4e00\u79cd\u200b\u51cf\u5c11\u200b\u6a21\u578b\u200b\u5185\u5b58\u200b\u5f71\u54cd\u200b\u7684\u200b\u65b9\u6cd5\u200b\u662f\u200b\u4ee5\u200b\u8f83\u200b\u4f4e\u200b\u7cbe\u5ea6\u200b\u7684\u200b dtype\uff08\u200b\u4f8b\u5982\u200b <code>torch.float16</code>\uff09\u200b\u5b9e\u4f8b\u200b\u5316\u5b83\u200b\uff0c\u200b\u6216\u8005\u200b\u4f7f\u7528\u200b\u4e0b\u9762\u200b\u4ecb\u7ecd\u200b\u7684\u200b\u76f4\u63a5\u200b\u91cf\u5316\u200b\u6280\u672f\u200b\u3002</p>"},{"location":"main_classes/model/#dtype","title":"\u6a21\u578b\u200b\u5b9e\u4f8b\u200b\u5316\u200b dtype","text":"<p>\u200b\u5728\u200b PyTorch \u200b\u4e0b\u200b\uff0c\u200b\u6a21\u578b\u200b\u901a\u5e38\u200b\u4ee5\u200b <code>torch.float32</code> \u200b\u683c\u5f0f\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u3002\u200b\u5982\u679c\u200b\u5c1d\u8bd5\u200b\u52a0\u8f7d\u200b\u6743\u91cd\u200b\u4e3a\u200b fp16 \u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u8fd9\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5bfc\u81f4\u200b\u95ee\u9898\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u5c06\u200b\u9700\u8981\u200b\u4e24\u500d\u200b\u7684\u200b\u5185\u5b58\u200b\u3002\u200b\u4e3a\u4e86\u200b\u514b\u670d\u200b\u6b64\u200b\u9650\u5236\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>torch_dtype</code> \u200b\u53c2\u200b\u6570\u663e\u5f0f\u200b\u4f20\u9012\u200b\u6240\u200b\u9700\u200b\u7684\u200b <code>dtype</code>\uff1a</p> <p><pre><code>model = T5ForConditionalGeneration.from_pretrained(\"t5\", torch_dtype=torch.float16)\n</code></pre> \u200b\u6216\u8005\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u5e0c\u671b\u200b\u6a21\u578b\u200b\u59cb\u7ec8\u200b\u4ee5\u200b\u6700\u4f18\u200b\u7684\u200b\u5185\u5b58\u200b\u6a21\u5f0f\u200b\u52a0\u8f7d\u200b\uff0c\u200b\u5219\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u7279\u6b8a\u200b\u503c\u200b <code>\"auto\"</code>\uff0c\u200b\u7136\u540e\u200b <code>dtype</code> \u200b\u5c06\u200b\u81ea\u52a8\u200b\u4ece\u200b\u6a21\u578b\u200b\u7684\u200b\u6743\u91cd\u200b\u4e2d\u200b\u63a8\u5bfc\u200b\u51fa\u200b\uff1a <pre><code>model = T5ForConditionalGeneration.from_pretrained(\"t5\", torch_dtype=\"auto\")\n</code></pre></p> <p>\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u544a\u77e5\u200b\u4ece\u5934\u5f00\u59cb\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u7684\u200b\u6a21\u578b\u200b\u8981\u200b\u4f7f\u7528\u200b\u54ea\u200b\u79cd\u200b <code>dtype</code>\uff1a</p> <pre><code>config = T5Config.from_pretrained(\"t5\")\nmodel = AutoModel.from_config(config)\n</code></pre> <p>\u200b\u7531\u4e8e\u200b PyTorch \u200b\u7684\u200b\u8bbe\u8ba1\u200b\uff0c\u200b\u6b64\u200b\u529f\u80fd\u200b\u4ec5\u200b\u9002\u7528\u200b\u4e8e\u200b\u6d6e\u70b9\u200b\u7c7b\u578b\u200b\u3002</p>"},{"location":"main_classes/model/#moduleutilsmixin","title":"ModuleUtilsMixin","text":"<p>[[autodoc]] modeling_utils.ModuleUtilsMixin</p> <p>TFPreTrainedModel [[autodoc]] TFPreTrainedModel - push_to_hub - all</p>"},{"location":"main_classes/model/#tfmodelutilsmixin","title":"TFModelUtilsMixin","text":"<p>[[autodoc]] modeling_tf_utils.TFModelUtilsMixin</p> <p>FlaxPreTrainedModel [[autodoc]] FlaxPreTrainedModel - push_to_hub - all</p>"},{"location":"main_classes/model/#hub","title":"\u63a8\u9001\u200b\u5230\u200b Hub","text":"<p>[[autodoc]] utils.PushToHubMixin</p>"},{"location":"main_classes/model/#_3","title":"\u5206\u7247\u200b\u68c0\u67e5\u70b9","text":"<p>[[autodoc]] modeling_utils.load_sharded_checkpoint</p>"},{"location":"main_classes/trainer/","title":"Trainer","text":""},{"location":"main_classes/trainer/#trainer","title":"Trainer","text":"<p>[<code>Trainer</code>] \u200b\u7c7b\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b PyTorch \u200b\u7684\u200b API\uff0c\u200b\u7528\u4e8e\u200b\u5904\u7406\u200b\u5927\u591a\u6570\u200b\u6807\u51c6\u200b\u7528\u4f8b\u200b\u7684\u200b\u5168\u529f\u80fd\u200b\u8bad\u7ec3\u200b\u3002\u200b\u5b83\u200b\u5728\u200b\u5927\u591a\u6570\u200b\u793a\u4f8b\u200b\u811a\u672c\u200b\u4e2d\u200b\u88ab\u200b\u4f7f\u7528\u200b\u3002</p> <p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u8981\u200b\u4f7f\u7528\u200b\u81ea\u200b\u56de\u5f52\u200b\u6280\u672f\u200b\u5728\u200b\u6587\u672c\u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u5fae\u8c03\u200b\u50cf\u200b Llama-2 \u200b\u6216\u200b Mistral \u200b\u8fd9\u6837\u200b\u7684\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u8003\u8651\u200b\u4f7f\u7528\u200b <code>trl</code> \u200b\u7684\u200b [<code>~trl.SFTTrainer</code>]\u3002[<code>~trl.SFTTrainer</code>] \u200b\u5c01\u88c5\u200b\u4e86\u200b [<code>Trainer</code>]\uff0c\u200b\u4e13\u95e8\u200b\u9488\u5bf9\u200b\u8fd9\u4e2a\u200b\u7279\u5b9a\u200b\u4efb\u52a1\u200b\u8fdb\u884c\u200b\u4e86\u200b\u4f18\u5316\u200b\uff0c\u200b\u5e76\u200b\u652f\u6301\u200b\u5e8f\u5217\u200b\u6253\u5305\u200b\u3001LoRA\u3001\u200b\u91cf\u5316\u200b\u548c\u200b DeepSpeed\uff0c\u200b\u4ee5\u200b\u6709\u6548\u200b\u6269\u5c55\u200b\u5230\u200b\u4efb\u4f55\u200b\u6a21\u578b\u200b\u5927\u5c0f\u200b\u3002\u200b\u53e6\u4e00\u65b9\u9762\u200b\uff0c[<code>Trainer</code>] \u200b\u662f\u200b\u4e00\u4e2a\u200b\u66f4\u200b\u901a\u7528\u200b\u7684\u200b\u9009\u9879\u200b\uff0c\u200b\u9002\u7528\u200b\u4e8e\u200b\u66f4\u200b\u5e7f\u6cdb\u200b\u7684\u200b\u4efb\u52a1\u200b\u3002</p> <p></p> <p>\u200b\u5728\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u4f60\u200b\u7684\u200b [<code>Trainer</code>] \u200b\u4e4b\u524d\u200b\uff0c\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b [<code>TrainingArguments</code>]\uff0c\u200b\u4ee5\u4fbf\u200b\u5728\u200b\u8bad\u7ec3\u200b\u671f\u95f4\u200b\u8bbf\u95ee\u200b\u6240\u6709\u200b\u5b9a\u5236\u200b\u70b9\u200b\u3002</p> <p>\u200b\u8fd9\u4e2a\u200b API \u200b\u652f\u6301\u200b\u5728\u200b\u591a\u4e2a\u200b GPU/TPU \u200b\u4e0a\u200b\u8fdb\u884c\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u652f\u6301\u200b NVIDIA Apex \u200b\u7684\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u548c\u200b PyTorch \u200b\u7684\u200b\u539f\u751f\u200b AMP\u3002</p> <p>[<code>Trainer</code>] \u200b\u5305\u542b\u200b\u57fa\u672c\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\uff0c\u200b\u652f\u6301\u200b\u4e0a\u8ff0\u200b\u529f\u80fd\u200b\u3002\u200b\u5982\u679c\u200b\u9700\u8981\u200b\u81ea\u5b9a\u4e49\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u7ee7\u627f\u200b <code>Trainer</code> \u200b\u5e76\u200b\u8986\u76d6\u200b\u4ee5\u4e0b\u200b\u65b9\u6cd5\u200b\uff1a</p> <ul> <li>get_train_dataloader -- \u200b\u521b\u5efa\u200b\u8bad\u7ec3\u200b DataLoader\u3002</li> <li>get_eval_dataloader -- \u200b\u521b\u5efa\u200b\u8bc4\u4f30\u200b DataLoader\u3002</li> <li>get_test_dataloader -- \u200b\u521b\u5efa\u200b\u6d4b\u8bd5\u200b DataLoader\u3002</li> <li>log -- \u200b\u8bb0\u5f55\u200b\u89c2\u5bdf\u200b\u8bad\u7ec3\u200b\u7684\u200b\u5404\u79cd\u200b\u5bf9\u8c61\u200b\u7684\u200b\u4fe1\u606f\u200b\u3002</li> <li>create_optimizer_and_scheduler -- \u200b\u5982\u679c\u200b\u5b83\u4eec\u200b\u6ca1\u6709\u200b\u5728\u200b\u521d\u59cb\u5316\u200b\u65f6\u200b\u4f20\u9012\u200b\uff0c\u200b\u8bf7\u200b\u8bbe\u7f6e\u200b\u4f18\u5316\u200b\u5668\u200b\u548c\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u5ea6\u200b\u5668\u200b\u3002\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u4f60\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u5355\u72ec\u200b\u7ee7\u627f\u200b\u6216\u200b\u8986\u76d6\u200b <code>create_optimizer</code> \u200b\u548c\u200b <code>create_scheduler</code> \u200b\u65b9\u6cd5\u200b\u3002</li> <li>create_optimizer -- \u200b\u5982\u679c\u200b\u5728\u200b\u521d\u59cb\u5316\u200b\u65f6\u200b\u6ca1\u6709\u200b\u4f20\u9012\u200b\uff0c\u200b\u5219\u200b\u8bbe\u7f6e\u200b\u4f18\u5316\u200b\u5668\u200b\u3002</li> <li>create_scheduler -- \u200b\u5982\u679c\u200b\u5728\u200b\u521d\u59cb\u5316\u200b\u65f6\u200b\u6ca1\u6709\u200b\u4f20\u9012\u200b\uff0c\u200b\u5219\u200b\u8bbe\u7f6e\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u5ea6\u200b\u5668\u200b\u3002</li> <li>compute_loss - \u200b\u8ba1\u7b97\u200b\u5355\u6279\u200b\u8bad\u7ec3\u200b\u8f93\u5165\u200b\u7684\u200b\u635f\u5931\u200b\u3002</li> <li>training_step -- \u200b\u6267\u884c\u200b\u4e00\u6b65\u200b\u8bad\u7ec3\u200b\u3002</li> <li>prediction_step -- \u200b\u6267\u884c\u200b\u4e00\u6b65\u200b\u8bc4\u4f30\u200b/\u200b\u6d4b\u8bd5\u200b\u3002</li> <li>evaluate -- \u200b\u8fd0\u884c\u200b\u8bc4\u4f30\u200b\u5faa\u73af\u200b\u5e76\u200b\u8fd4\u56de\u200b\u6307\u6807\u200b\u3002</li> <li>predict -- \u200b\u8fd4\u56de\u200b\u5728\u200b\u6d4b\u8bd5\u200b\u96c6\u4e0a\u200b\u7684\u200b\u9884\u6d4b\u200b\uff08\u200b\u5982\u679c\u200b\u6709\u200b\u6807\u7b7e\u200b\uff0c\u200b\u5219\u200b\u5305\u62ec\u200b\u6307\u6807\u200b\uff09\u3002</li> </ul> <p> <p>[<code>Trainer</code>] \u200b\u7c7b\u200b\u88ab\u200b\u4f18\u5316\u200b\u7528\u4e8e\u200b \ud83e\udd17 Transformers \u200b\u6a21\u578b\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u4f60\u200b\u5728\u200b\u5176\u4ed6\u200b\u6a21\u578b\u200b\u4e0a\u200b\u4f7f\u7528\u200b\u65f6\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u6709\u200b\u4e00\u4e9b\u200b\u4ee4\u4eba\u200b\u60ca\u8bb6\u200b\u7684\u200b\u7ed3\u679c\u200b\u3002\u200b\u5f53\u200b\u5728\u200b\u4f60\u200b\u81ea\u5df1\u200b\u7684\u200b\u6a21\u578b\u200b\u4e0a\u200b\u4f7f\u7528\u200b\u65f6\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200b\uff1a</p> <ul> <li>\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u59cb\u7ec8\u200b\u8fd4\u56de\u200b\u5143\u7ec4\u200b\u6216\u200b [<code>~utils.ModelOutput</code>] \u200b\u7684\u200b\u5b50\u7c7b\u200b\u3002</li> <li>\u200b\u5982\u679c\u200b\u63d0\u4f9b\u200b\u4e86\u200b <code>labels</code> \u200b\u53c2\u6570\u200b\uff0c\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u53ef\u4ee5\u200b\u8ba1\u7b97\u200b\u635f\u5931\u200b\uff0c\u200b\u5e76\u4e14\u200b\u635f\u5931\u200b\u4f5c\u4e3a\u200b\u5143\u7ec4\u200b\u7684\u200b\u7b2c\u4e00\u4e2a\u200b\u5143\u7d20\u200b\u8fd4\u56de\u200b\uff08\u200b\u5982\u679c\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u8fd4\u56de\u200b\u5143\u7ec4\u200b\uff09\u3002</li> <li>\u200b\u4f60\u200b\u7684\u200b\u6a21\u578b\u200b\u53ef\u4ee5\u200b\u63a5\u53d7\u200b\u591a\u4e2a\u200b\u6807\u7b7e\u200b\u53c2\u6570\u200b\uff08\u200b\u5728\u200b [<code>TrainingArguments</code>] \u200b\u4e2d\u200b\u4f7f\u7528\u200b <code>label_names</code> \u200b\u5c06\u200b\u5b83\u4eec\u200b\u7684\u200b\u540d\u79f0\u200b\u6307\u793a\u200b\u7ed9\u200b [<code>Trainer</code>]\uff09\uff0c\u200b\u4f46\u200b\u5b83\u4eec\u200b\u4e2d\u200b\u6ca1\u6709\u200b\u4e00\u4e2a\u200b\u5e94\u8be5\u200b\u88ab\u200b\u547d\u540d\u200b\u4e3a\u200b <code>\"label\"</code>\u3002</li> </ul> <p></p> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u5982\u4f55\u200b\u81ea\u5b9a\u4e49\u200b [<code>Trainer</code>] \u200b\u4ee5\u200b\u4f7f\u7528\u200b\u52a0\u6743\u200b\u635f\u5931\u200b\u7684\u200b\u793a\u4f8b\u200b\uff08\u200b\u5728\u200b\u8bad\u7ec3\u200b\u96c6\u200b\u4e0d\u200b\u5e73\u8861\u200b\u65f6\u200b\u5f88\u200b\u6709\u7528\u200b\uff09\uff1a</p> <pre><code>from torch import nn\nfrom transformers import Trainer\n\n\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        # forward pass\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n        # compute custom loss (suppose one has 3 labels with different weights)\n        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 3.0], device=model.device))\n        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n        return (loss, outputs) if return_outputs else loss\n</code></pre> <p>\u200b\u5728\u200b PyTorch [<code>Trainer</code>] \u200b\u4e2d\u200b\u81ea\u5b9a\u4e49\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u884c\u4e3a\u200b\u7684\u200b\u53e6\u200b\u4e00\u79cd\u200b\u65b9\u6cd5\u200b\u662f\u200b\u4f7f\u7528\u200b callbacks\uff0c\u200b\u8fd9\u4e9b\u200b\u56de\u8c03\u200b\u53ef\u4ee5\u200b\u68c0\u67e5\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u72b6\u6001\u200b\uff08\u200b\u7528\u4e8e\u200b\u8fdb\u5ea6\u200b\u62a5\u544a\u200b\u3001\u200b\u5728\u200b TensorBoard \u200b\u6216\u200b\u5176\u4ed6\u200b ML \u200b\u5e73\u53f0\u200b\u4e0a\u200b\u8bb0\u5f55\u200b\u65e5\u5fd7\u200b\u7b49\u200b\uff09\u200b\u5e76\u200b\u505a\u51fa\u200b\u51b3\u7b56\u200b\uff08\u200b\u6bd4\u5982\u200b\u63d0\u524d\u200b\u505c\u6b62\u200b\uff09\u3002</p>"},{"location":"main_classes/trainer/#trainer_1","title":"Trainer","text":"<p>[[autodoc]] Trainer - all</p>"},{"location":"main_classes/trainer/#seq2seqtrainer","title":"Seq2SeqTrainer","text":"<p>[[autodoc]] Seq2SeqTrainer - evaluate - predict</p>"},{"location":"main_classes/trainer/#trainingarguments","title":"TrainingArguments","text":"<p>[[autodoc]] TrainingArguments - all</p>"},{"location":"main_classes/trainer/#seq2seqtrainingarguments","title":"Seq2SeqTrainingArguments","text":"<p>[[autodoc]] Seq2SeqTrainingArguments - all</p>"},{"location":"main_classes/trainer/#checkpoints","title":"Checkpoints","text":"<p>\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c[<code>Trainer</code>] \u200b\u4f1a\u200b\u5c06\u200b\u6240\u6709\u200bcheckpoints\u200b\u4fdd\u5b58\u200b\u5728\u200b\u4f60\u200b\u4f7f\u7528\u200b\u7684\u200b [<code>TrainingArguments</code>] \u200b\u4e2d\u200b\u8bbe\u7f6e\u200b\u7684\u200b <code>output_dir</code> \u200b\u4e2d\u200b\u3002\u200b\u8fd9\u4e9b\u200bcheckpoints\u200b\u5c06\u200b\u4f4d\u4e8e\u200b\u540d\u4e3a\u200b <code>checkpoint-xxx</code> \u200b\u7684\u200b\u5b50\u200b\u6587\u4ef6\u5939\u200b\u4e2d\u200b\uff0cxxx \u200b\u662f\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6b65\u9aa4\u200b\u3002</p> <p>\u200b\u4ece\u200bcheckpoints\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200b [<code>Trainer.train</code>] \u200b\u65f6\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u4efb\u4e00\u200b\u65b9\u5f0f\u200b\u8fdb\u884c\u200b\uff1a</p> <ul> <li><code>resume_from_checkpoint=True</code>\uff0c\u200b\u8fd9\u200b\u5c06\u200b\u4ece\u200b\u6700\u65b0\u200b\u7684\u200bcheckpoint\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\u3002</li> <li><code>resume_from_checkpoint=checkpoint_dir</code>\uff0c\u200b\u8fd9\u200b\u5c06\u200b\u4ece\u200b\u6307\u5b9a\u200b\u76ee\u5f55\u200b\u4e2d\u200b\u7684\u200b\u7279\u5b9a\u200bcheckpoint\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\u3002</li> </ul> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u5f53\u200b\u4f7f\u7528\u200b <code>push_to_hub=True</code> \u200b\u65f6\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u5c06\u200bcheckpoints\u200b\u4fdd\u5b58\u200b\u5728\u200b Model Hub \u200b\u4e2d\u200b\u3002\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u4fdd\u5b58\u200b\u5728\u200b\u8bad\u7ec3\u200b\u4e2d\u95f4\u200b\u8fc7\u7a0b\u200b\u7684\u200bcheckpoints\u200b\u4e2d\u200b\u7684\u200b\u6240\u6709\u200b\u6a21\u578b\u200b\u90fd\u200b\u4fdd\u5b58\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200b\u63d0\u4ea4\u200b\u4e2d\u200b\uff0c\u200b\u4f46\u200b\u4e0d\u200b\u5305\u62ec\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u6839\u636e\u200b\u9700\u8981\u200b\u8c03\u6574\u200b [<code>TrainingArguments</code>] \u200b\u7684\u200b <code>hub-strategy</code> \u200b\u503c\u200b\uff1a</p> <ul> <li><code>\"checkpoint\"</code>: \u200b\u6700\u65b0\u200b\u7684\u200bcheckpoint\u200b\u4e5f\u200b\u88ab\u200b\u63a8\u9001\u200b\u5230\u200b\u4e00\u4e2a\u200b\u540d\u4e3a\u200b last-checkpoint \u200b\u7684\u200b\u5b50\u200b\u6587\u4ef6\u5939\u200b\u4e2d\u200b\uff0c\u200b\u8ba9\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b <code>trainer.train(resume_from_checkpoint=\"output_dir/last-checkpoint\")</code> \u200b\u8f7b\u677e\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\u3002</li> <li><code>\"all_checkpoints\"</code>: \u200b\u6240\u6709\u200bcheckpoints\u200b\u90fd\u200b\u50cf\u200b\u5b83\u4eec\u200b\u51fa\u73b0\u200b\u5728\u200b\u8f93\u51fa\u200b\u6587\u4ef6\u5939\u200b\u4e2d\u200b\u4e00\u6837\u200b\u88ab\u200b\u63a8\u9001\u200b\uff08\u200b\u56e0\u6b64\u200b\u4f60\u200b\u5c06\u200b\u5728\u200b\u6700\u7ec8\u200b\u5b58\u50a8\u200b\u5e93\u4e2d\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u6587\u4ef6\u5939\u200b\u4e2d\u200b\u83b7\u5f97\u200b\u4e00\u4e2a\u200bcheckpoint\u200b\u6587\u4ef6\u5939\u200b\uff09\u3002</li> </ul>"},{"location":"main_classes/trainer/#logging","title":"Logging","text":"<p>\u200b\u9ed8\u8ba4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c[<code>Trainer</code>] \u200b\u5c06\u200b\u5bf9\u4e3b\u200b\u8fdb\u7a0b\u200b\u4f7f\u7528\u200b <code>logging.INFO</code>\uff0c\u200b\u5bf9\u200b\u526f\u672c\u200b\uff08\u200b\u5982\u679c\u200b\u6709\u200b\u7684\u8bdd\u200b\uff09\u200b\u4f7f\u7528\u200b <code>logging.WARNING</code>\u3002</p> <p>\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b [<code>TrainingArguments</code>] \u200b\u7684\u200b\u53c2\u6570\u200b\u8986\u76d6\u200b\u8fd9\u4e9b\u200b\u9ed8\u8ba4\u8bbe\u7f6e\u200b\uff0c\u200b\u4f7f\u7528\u200b\u5176\u4e2d\u200b\u7684\u200b 5 \u200b\u4e2a\u200b <code>logging</code> \u200b\u7ea7\u522b\u200b\uff1a</p> <ul> <li><code>log_level</code> - \u200b\u7528\u4e8e\u200b\u4e3b\u200b\u8fdb\u7a0b\u200b</li> <li><code>log_level_replica</code> - \u200b\u7528\u4e8e\u200b\u526f\u672c\u200b</li> </ul> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u5982\u679c\u200b [<code>TrainingArguments</code>] \u200b\u7684\u200b <code>log_on_each_node</code> \u200b\u8bbe\u7f6e\u200b\u4e3a\u200b <code>False</code>\uff0c\u200b\u5219\u200b\u53ea\u6709\u200b\u4e3b\u200b\u8282\u70b9\u200b\u5c06\u200b\u4f7f\u7528\u200b\u5176\u4e3b\u200b\u8fdb\u7a0b\u200b\u7684\u200b\u65e5\u5fd7\u200b\u7ea7\u522b\u200b\u8bbe\u7f6e\u200b\uff0c\u200b\u6240\u6709\u200b\u5176\u4ed6\u200b\u8282\u70b9\u200b\u5c06\u200b\u4f7f\u7528\u200b\u526f\u672c\u200b\u7684\u200b\u65e5\u5fd7\u200b\u7ea7\u522b\u200b\u8bbe\u7f6e\u200b\u3002</p> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c[<code>Trainer</code>] \u200b\u5c06\u200b\u5728\u200b\u5176\u200b [<code>Trainer.__init__</code>] \u200b\u4e2d\u200b\u5206\u522b\u200b\u4e3a\u200b\u6bcf\u4e2a\u200b\u8282\u70b9\u200b\u8bbe\u7f6e\u200b <code>transformers</code> \u200b\u7684\u200b\u65e5\u5fd7\u200b\u7ea7\u522b\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u5728\u200b\u521b\u5efa\u200b [<code>Trainer</code>] \u200b\u5bf9\u8c61\u200b\u4e4b\u524d\u200b\u8981\u200b\u8c03\u7528\u200b\u5176\u4ed6\u200b <code>transformers</code> \u200b\u529f\u80fd\u200b\uff0c\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u66f4\u200b\u65e9\u200b\u5730\u200b\u8bbe\u7f6e\u200b\u8fd9\u200b\u4e00\u70b9\u200b\uff08\u200b\u8bf7\u200b\u53c2\u89c1\u200b\u4e0b\u9762\u200b\u7684\u200b\u793a\u4f8b\u200b\uff09\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u5982\u4f55\u200b\u5728\u200b\u5e94\u7528\u7a0b\u5e8f\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u7684\u200b\u793a\u4f8b\u200b\uff1a</p> <pre><code>[...]\nlogger = logging.getLogger(__name__)\n\n# Setup logging\nlogging.basicConfig(\n    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n    datefmt=\"%m/%d/%Y %H:%M:%S\",\n    handlers=[logging.StreamHandler(sys.stdout)],\n)\n\n# set the main code and the modules it uses to the same log-level according to the node\nlog_level = training_args.get_process_log_level()\nlogger.setLevel(log_level)\ndatasets.utils.logging.set_verbosity(log_level)\ntransformers.utils.logging.set_verbosity(log_level)\n\ntrainer = Trainer(...)\n</code></pre> <p>\u200b\u7136\u540e\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u53ea\u200b\u60f3\u200b\u5728\u200b\u4e3b\u200b\u8282\u70b9\u200b\u4e0a\u200b\u770b\u5230\u200b\u8b66\u544a\u200b\uff0c\u200b\u5e76\u4e14\u200b\u6240\u6709\u200b\u5176\u4ed6\u200b\u8282\u70b9\u200b\u4e0d\u200b\u6253\u5370\u200b\u4efb\u4f55\u200b\u53ef\u80fd\u200b\u91cd\u590d\u200b\u7684\u200b\u8b66\u544a\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u8fd9\u6837\u200b\u8fd0\u884c\u200b\uff1a</p> <pre><code>my_app.py ... --log_level warning --log_level_replica error\n</code></pre> <p>\u200b\u5728\u200b\u591a\u200b\u8282\u70b9\u200b\u73af\u5883\u200b\u4e2d\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u4e5f\u200b\u4e0d\u200b\u5e0c\u671b\u200b\u6bcf\u4e2a\u200b\u8282\u70b9\u200b\u7684\u200b\u4e3b\u200b\u8fdb\u7a0b\u200b\u7684\u200b\u65e5\u5fd7\u200b\u91cd\u590d\u200b\u8f93\u51fa\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u5c06\u200b\u4e0a\u9762\u200b\u7684\u200b\u4ee3\u7801\u200b\u66f4\u200b\u6539\u4e3a\u200b\uff1a</p> <pre><code>my_app.py ... --log_level warning --log_level_replica error --log_on_each_node 0\n</code></pre> <p>\u200b\u7136\u540e\u200b\uff0c\u200b\u53ea\u6709\u200b\u7b2c\u4e00\u4e2a\u200b\u8282\u70b9\u200b\u7684\u200b\u4e3b\u200b\u8fdb\u7a0b\u200b\u5c06\u200b\u4ee5\u200b \"warning\" \u200b\u7ea7\u522b\u200b\u8bb0\u5f55\u200b\u65e5\u5fd7\u200b\uff0c\u200b\u4e3b\u200b\u8282\u70b9\u200b\u4e0a\u200b\u7684\u200b\u6240\u6709\u200b\u5176\u4ed6\u200b\u8fdb\u7a0b\u200b\u548c\u200b\u5176\u4ed6\u200b\u8282\u70b9\u200b\u4e0a\u200b\u7684\u200b\u6240\u6709\u200b\u8fdb\u7a0b\u200b\u5c06\u200b\u4ee5\u200b \"error\" \u200b\u7ea7\u522b\u200b\u8bb0\u5f55\u200b\u65e5\u5fd7\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u5e0c\u671b\u200b\u5e94\u7528\u7a0b\u5e8f\u200b\u5c3d\u53ef\u80fd\u200b\u201d\u200b\u5b89\u9759\u200b\u201c\uff0c\u200b\u53ef\u4ee5\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\uff1a</p> <pre><code>my_app.py ... --log_level error --log_level_replica error --log_on_each_node 0\n</code></pre> <p>(\u200b\u5982\u679c\u200b\u5728\u200b\u591a\u200b\u8282\u70b9\u200b\u73af\u5883\u200b\uff0c\u200b\u6dfb\u52a0\u200b <code>--log_on_each_node 0</code>)</p>"},{"location":"main_classes/trainer/#_1","title":"\u968f\u673a\u6027","text":"<p>\u200b\u5f53\u200b\u4ece\u200b [<code>Trainer</code>] \u200b\u751f\u6210\u200b\u7684\u200bcheckpoint\u200b\u6062\u590d\u200b\u8bad\u7ec3\u200b\u65f6\u200b\uff0c\u200b\u7a0b\u5e8f\u200b\u4f1a\u200b\u5c3d\u200b\u4e00\u5207\u200b\u52aa\u529b\u200b\u5c06\u200b python\u3001numpy \u200b\u548c\u200b pytorch \u200b\u7684\u200b RNG\uff08\u200b\u968f\u673a\u6570\u200b\u751f\u6210\u5668\u200b\uff09\u200b\u72b6\u6001\u200b\u6062\u590d\u200b\u4e3a\u200b\u4fdd\u5b58\u200b\u68c0\u67e5\u70b9\u200b\u65f6\u200b\u7684\u200b\u72b6\u6001\u200b\uff0c\u200b\u8fd9\u6837\u200b\u53ef\u4ee5\u200b\u4f7f\u200b\u201c\u200b\u505c\u6b62\u200b\u548c\u200b\u6062\u590d\u200b\u201d\u200b\u5f0f\u200b\u8bad\u7ec3\u200b\u5c3d\u53ef\u80fd\u200b\u63a5\u8fd1\u200b\u201c\u200b\u975e\u200b\u505c\u6b62\u200b\u5f0f\u200b\u201d\u200b\u8bad\u7ec3\u200b\u3002</p> <p>\u200b\u7136\u800c\u200b\uff0c\u200b\u7531\u4e8e\u200b\u5404\u79cd\u200b\u9ed8\u8ba4\u200b\u7684\u200b\u975e\u200b\u786e\u5b9a\u6027\u200b PyTorch \u200b\u8bbe\u7f6e\u200b\uff0c\u200b\u8fd9\u200b\u53ef\u80fd\u200b\u65e0\u6cd5\u200b\u5b8c\u5168\u200b\u5b9e\u73b0\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u60f3\u8981\u200b\u5b8c\u5168\u200b\u786e\u5b9a\u6027\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u63a7\u5236\u200b\u968f\u673a\u200b\u6e90\u200b\u3002\u200b\u6b63\u5982\u200b\u6587\u6863\u200b\u4e2d\u200b\u6240\u200b\u89e3\u91ca\u200b\u7684\u200b\u90a3\u6837\u200b\uff0c\u200b\u4f7f\u200b\u4e8b\u7269\u200b\u53d8\u5f97\u200b\u786e\u5b9a\u200b\u7684\u200b\u4e00\u4e9b\u200b\u8bbe\u7f6e\u200b\uff08\u200b\u4f8b\u5982\u200b <code>torch.backends.cudnn.deterministic</code>\uff09\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u51cf\u6162\u200b\u901f\u5ea6\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4e0d\u80fd\u200b\u9ed8\u8ba4\u200b\u6267\u884c\u200b\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u9700\u8981\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u81ea\u884c\u200b\u542f\u7528\u200b\u8fd9\u4e9b\u200b\u8bbe\u7f6e\u200b\u3002</p>"},{"location":"main_classes/trainer/#gpu","title":"\u7279\u5b9a\u200bGPU\u200b\u9009\u62e9","text":"<p>\u200b\u8ba9\u200b\u6211\u4eec\u200b\u8ba8\u8bba\u4e00\u4e0b\u200b\u5982\u4f55\u200b\u544a\u8bc9\u200b\u4f60\u200b\u7684\u200b\u7a0b\u5e8f\u200b\u5e94\u8be5\u200b\u4f7f\u7528\u200b\u54ea\u4e9b\u200b GPU \u200b\u4ee5\u53ca\u200b\u4f7f\u7528\u200b\u7684\u200b\u987a\u5e8f\u200b\u3002</p> <p>\u200b\u5f53\u200b\u4f7f\u7528\u200b <code>DistributedDataParallel</code> \u200b\u4e14\u200b\u4ec5\u200b\u4f7f\u7528\u200b\u90e8\u5206\u200b GPU \u200b\u65f6\u200b\uff0c\u200b\u4f60\u200b\u53ea\u200b\u9700\u200b\u6307\u5b9a\u200b\u8981\u200b\u4f7f\u7528\u200b\u7684\u200b GPU \u200b\u6570\u91cf\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u6709\u200b 4 \u200b\u4e2a\u200b GPU\uff0c\u200b\u4f46\u200b\u53ea\u200b\u60f3\u200b\u4f7f\u7528\u200b\u524d\u200b 2 \u200b\u4e2a\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\uff1a</p> <pre><code>python -m torch.distributed.launch --nproc_per_node=2  trainer-program.py ...\n</code></pre> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u5b89\u88c5\u200b\u4e86\u200b <code>accelerate</code> \u200b\u6216\u200b <code>deepspeed</code>\uff0c\u200b\u4f60\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u4efb\u4e00\u200b\u65b9\u6cd5\u200b\u5b9e\u73b0\u200b\u76f8\u540c\u200b\u7684\u200b\u6548\u679c\u200b\uff1a</p> <pre><code>accelerate launch --num_processes 2 trainer-program.py ...\n</code></pre> <pre><code>deepspeed --num_gpus 2 trainer-program.py ...\n</code></pre> <p>\u200b\u4f60\u200b\u4e0d\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b Accelerate \u200b\u6216\u200b Deepspeed \u200b\u96c6\u6210\u200b \u200b\u529f\u80fd\u200b\u6765\u200b\u4f7f\u7528\u200b\u8fd9\u4e9b\u200b\u542f\u52a8\u5668\u200b\u3002</p> <p>\u200b\u5230\u200b\u76ee\u524d\u4e3a\u6b62\u200b\uff0c\u200b\u4f60\u200b\u5df2\u7ecf\u200b\u80fd\u591f\u200b\u544a\u8bc9\u200b\u7a0b\u5e8f\u200b\u8981\u200b\u4f7f\u7528\u200b\u591a\u5c11\u200b\u4e2a\u200b GPU\u3002\u200b\u73b0\u5728\u200b\u8ba9\u200b\u6211\u4eec\u200b\u8ba8\u8bba\u200b\u5982\u4f55\u200b\u9009\u62e9\u200b\u7279\u5b9a\u200b\u7684\u200b GPU \u200b\u5e76\u200b\u63a7\u5236\u200b\u5b83\u4eec\u200b\u7684\u200b\u987a\u5e8f\u200b\u3002</p> <p>\u200b\u4ee5\u4e0b\u200b\u73af\u5883\u53d8\u91cf\u200b\u53ef\u200b\u5e2e\u52a9\u200b\u4f60\u200b\u63a7\u5236\u200b\u4f7f\u7528\u200b\u54ea\u4e9b\u200b GPU \u200b\u4ee5\u53ca\u200b\u5b83\u4eec\u200b\u7684\u200b\u987a\u5e8f\u200b\u3002</p> <p><code>CUDA_VISIBLE_DEVICES</code></p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u6709\u200b\u591a\u4e2a\u200b GPU\uff0c\u200b\u60f3\u8981\u200b\u4ec5\u200b\u4f7f\u7528\u200b\u5176\u4e2d\u200b\u7684\u200b\u4e00\u4e2a\u200b\u6216\u200b\u51e0\u4e2a\u200b GPU\uff0c\u200b\u8bf7\u200b\u5c06\u200b\u73af\u5883\u53d8\u91cf\u200b <code>CUDA_VISIBLE_DEVICES</code> \u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\u8981\u200b\u4f7f\u7528\u200b\u7684\u200b GPU \u200b\u5217\u8868\u200b\u3002</p> <p>\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5047\u8bbe\u200b\u4f60\u200b\u6709\u200b 4 \u200b\u4e2a\u200b GPU\uff1a0\u30011\u30012 \u200b\u548c\u200b 3\u3002\u200b\u8981\u200b\u4ec5\u200b\u5728\u200b\u7269\u7406\u200b GPU 0 \u200b\u548c\u200b 2 \u200b\u4e0a\u200b\u8fd0\u884c\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\uff1a</p> <pre><code>CUDA_VISIBLE_DEVICES=0,2 python -m torch.distributed.launch trainer-program.py ...\n</code></pre> <p>\u200b\u73b0\u5728\u200b\uff0cPyTorch \u200b\u5c06\u200b\u53ea\u200b\u770b\u5230\u200b 2 \u200b\u4e2a\u200b GPU\uff0c\u200b\u5176\u4e2d\u200b\u4f60\u200b\u7684\u200b\u7269\u7406\u200b GPU 0 \u200b\u548c\u200b 2 \u200b\u5206\u522b\u200b\u6620\u5c04\u200b\u5230\u200b <code>cuda:0</code> \u200b\u548c\u200b <code>cuda:1</code>\u3002</p> <p>\u200b\u4f60\u200b\u751a\u81f3\u200b\u53ef\u4ee5\u200b\u6539\u53d8\u200b\u5b83\u4eec\u200b\u7684\u200b\u987a\u5e8f\u200b\uff1a</p> <pre><code>CUDA_VISIBLE_DEVICES=2,0 python -m torch.distributed.launch trainer-program.py ...\n</code></pre> <p>\u200b\u8fd9\u91cc\u200b\uff0c\u200b\u4f60\u200b\u7684\u200b\u7269\u7406\u200b GPU 0 \u200b\u548c\u200b 2 \u200b\u5206\u522b\u200b\u6620\u5c04\u200b\u5230\u200b <code>cuda:1</code> \u200b\u548c\u200b <code>cuda:0</code>\u3002</p> <p>\u200b\u4e0a\u9762\u200b\u7684\u200b\u4f8b\u5b50\u200b\u90fd\u200b\u662f\u200b\u9488\u5bf9\u200b <code>DistributedDataParallel</code> \u200b\u4f7f\u7528\u200b\u6a21\u5f0f\u200b\u7684\u200b\uff0c\u200b\u4f46\u200b\u540c\u6837\u200b\u7684\u200b\u65b9\u6cd5\u200b\u4e5f\u200b\u9002\u7528\u200b\u4e8e\u200b <code>DataParallel</code>\uff1a</p> <pre><code>CUDA_VISIBLE_DEVICES=2,0 python trainer-program.py ...\n</code></pre> <p>\u200b\u4e3a\u4e86\u200b\u6a21\u62df\u200b\u6ca1\u6709\u200b GPU \u200b\u7684\u200b\u73af\u5883\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u5c06\u200b\u6b64\u200b\u73af\u5883\u53d8\u91cf\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\u7a7a\u503c\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>CUDA_VISIBLE_DEVICES= python trainer-program.py ...\n</code></pre> <p>\u200b\u4e0e\u200b\u4efb\u4f55\u200b\u73af\u5883\u53d8\u91cf\u200b\u4e00\u6837\u200b\uff0c\u200b\u4f60\u200b\u5f53\u7136\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u5176\u200bexport\u200b\u5230\u200b\u73af\u5883\u53d8\u91cf\u200b\u800c\u200b\u4e0d\u662f\u200b\u5c06\u200b\u5176\u200b\u6dfb\u52a0\u200b\u5230\u200b\u547d\u4ee4\u884c\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>export CUDA_VISIBLE_DEVICES=0,2\npython -m torch.distributed.launch trainer-program.py ...\n</code></pre> <p>\u200b\u8fd9\u79cd\u200b\u65b9\u6cd5\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u4ee4\u4eba\u56f0\u60d1\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u4f60\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5fd8\u8bb0\u200b\u4e4b\u524d\u200b\u8bbe\u7f6e\u200b\u4e86\u200b\u73af\u5883\u53d8\u91cf\u200b\uff0c\u200b\u8fdb\u800c\u200b\u4e0d\u200b\u660e\u767d\u200b\u4e3a\u4ec0\u4e48\u200b\u4f1a\u200b\u4f7f\u7528\u200b\u9519\u8bef\u200b\u7684\u200b GPU\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5728\u200b\u540c\u4e00\u200b\u547d\u4ee4\u884c\u200b\u4e2d\u4ec5\u200b\u4e3a\u200b\u7279\u5b9a\u200b\u8fd0\u884c\u200b\u8bbe\u7f6e\u200b\u73af\u5883\u53d8\u91cf\u200b\u662f\u200b\u4e00\u79cd\u200b\u5e38\u89c1\u200b\u505a\u6cd5\u200b\uff0c\u200b\u6b63\u5982\u200b\u672c\u200b\u8282\u200b\u5927\u591a\u6570\u200b\u793a\u4f8b\u200b\u6240\u793a\u200b\u3002</p> <p><code>CUDA_DEVICE_ORDER</code></p> <p>\u200b\u8fd8\u6709\u200b\u4e00\u4e2a\u200b\u989d\u5916\u200b\u7684\u200b\u73af\u5883\u53d8\u91cf\u200b <code>CUDA_DEVICE_ORDER</code>\uff0c\u200b\u7528\u4e8e\u200b\u63a7\u5236\u200b\u7269\u7406\u200b\u8bbe\u5907\u200b\u7684\u200b\u6392\u5e8f\u200b\u65b9\u5f0f\u200b\u3002\u200b\u6709\u200b\u4e24\u4e2a\u200b\u9009\u62e9\u200b\uff1a</p> <ol> <li>\u200b\u6309\u200b PCIe \u200b\u603b\u7ebf\u200b ID \u200b\u6392\u5e8f\u200b\uff08\u200b\u4e0e\u200b nvidia-smi \u200b\u7684\u200b\u987a\u5e8f\u200b\u76f8\u5339\u914d\u200b\uff09- \u200b\u8fd9\u662f\u200b\u9ed8\u8ba4\u200b\u9009\u9879\u200b\u3002</li> </ol> <pre><code>export CUDA_DEVICE_ORDER=PCI_BUS_ID\n</code></pre> <ol> <li>\u200b\u6309\u200b GPU \u200b\u8ba1\u7b97\u80fd\u529b\u200b\u6392\u5e8f\u200b\u3002</li> </ol> <pre><code>export CUDA_DEVICE_ORDER=FASTEST_FIRST\n</code></pre> <p>\u200b\u5927\u591a\u6570\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u4f60\u200b\u4e0d\u200b\u9700\u8981\u200b\u5173\u5fc3\u200b\u8fd9\u4e2a\u200b\u73af\u5883\u53d8\u91cf\u200b\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u4f60\u200b\u7684\u200b\u8bbe\u7f6e\u200b\u4e0d\u200b\u5747\u5300\u200b\uff0c\u200b\u90a3\u4e48\u200b\u8fd9\u200b\u5c06\u200b\u975e\u5e38\u200b\u6709\u7528\u200b\uff0c\u200b\u4f8b\u5982\u200b\uff0c\u200b\u60a8\u200b\u7684\u200b\u65e7\u200b GPU \u200b\u548c\u200b\u65b0\u200b GPU \u200b\u7269\u7406\u200b\u4e0a\u200b\u5b89\u88c5\u200b\u5728\u200b\u4e00\u8d77\u200b\uff0c\u200b\u4f46\u200b\u8ba9\u200b\u901f\u5ea6\u200b\u8f83\u6162\u200b\u7684\u200b\u65e7\u5361\u200b\u6392\u200b\u5728\u200b\u8fd0\u884c\u200b\u7684\u200b\u7b2c\u4e00\u4f4d\u200b\u3002\u200b\u89e3\u51b3\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\u7684\u200b\u4e00\u79cd\u200b\u65b9\u6cd5\u200b\u662f\u200b\u4ea4\u6362\u200b\u5361\u200b\u7684\u200b\u4f4d\u7f6e\u200b\u3002\u200b\u4f46\u200b\u5982\u679c\u200b\u4e0d\u80fd\u200b\u4ea4\u6362\u200b\u5361\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u8bbe\u5907\u200b\u7684\u200b\u6563\u70ed\u200b\u53d7\u5230\u200b\u5f71\u54cd\u200b\uff09\uff0c\u200b\u90a3\u4e48\u200b\u8bbe\u7f6e\u200b <code>CUDA_DEVICE_ORDER=FASTEST_FIRST</code> \u200b\u5c06\u200b\u59cb\u7ec8\u200b\u5c06\u200b\u8f83\u200b\u65b0\u200b\u3001\u200b\u66f4\u5feb\u200b\u7684\u200b\u5361\u200b\u653e\u5728\u200b\u7b2c\u4e00\u4f4d\u200b\u3002\u200b\u4f46\u200b\u8fd9\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u6709\u70b9\u200b\u6df7\u4e71\u200b\uff0c\u200b\u56e0\u4e3a\u200b <code>nvidia-smi</code> \u200b\u4ecd\u7136\u200b\u4f1a\u200b\u6309\u7167\u200b PCIe \u200b\u987a\u5e8f\u200b\u62a5\u544a\u200b\u5b83\u4eec\u200b\u3002</p> <p>\u200b\u4ea4\u6362\u200b\u5361\u200b\u7684\u200b\u987a\u5e8f\u200b\u7684\u200b\u53e6\u200b\u4e00\u79cd\u200b\u65b9\u6cd5\u200b\u662f\u200b\u4f7f\u7528\u200b\uff1a</p> <pre><code>export CUDA_VISIBLE_DEVICES=1,0\n</code></pre> <p>\u200b\u5728\u200b\u6b64\u200b\u793a\u4f8b\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ea\u200b\u4f7f\u7528\u200b\u4e86\u200b 2 \u200b\u4e2a\u200b GPU\uff0c\u200b\u4f46\u662f\u200b\u5f53\u7136\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u8ba1\u7b97\u673a\u200b\u4e0a\u200b\u6709\u200b\u7684\u200b\u4efb\u4f55\u200b\u6570\u91cf\u200b\u7684\u200b GPU\uff0c\u200b\u90fd\u200b\u9002\u7528\u200b\u76f8\u540c\u200b\u7684\u200b\u65b9\u6cd5\u200b\u3002</p> <p>\u200b\u6b64\u5916\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u8bbe\u7f6e\u200b\u4e86\u200b\u8fd9\u4e2a\u200b\u73af\u5883\u53d8\u91cf\u200b\uff0c\u200b\u6700\u597d\u200b\u5c06\u200b\u5176\u200b\u8bbe\u7f6e\u200b\u5728\u200b <code>~/.bashrc</code> \u200b\u6587\u4ef6\u200b\u6216\u200b\u5176\u4ed6\u200b\u542f\u52a8\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\uff0c\u200b\u7136\u540e\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u5fd8\u8bb0\u200b\u5b83\u200b\u4e86\u200b\u3002</p>"},{"location":"main_classes/trainer/#trainer_2","title":"Trainer\u200b\u96c6\u6210","text":"<p>[<code>Trainer</code>] \u200b\u5df2\u7ecf\u200b\u88ab\u200b\u6269\u5c55\u200b\uff0c\u200b\u4ee5\u200b\u652f\u6301\u200b\u53ef\u80fd\u200b\u663e\u8457\u200b\u63d0\u9ad8\u200b\u8bad\u7ec3\u200b\u65f6\u95f4\u200b\u5e76\u200b\u9002\u5e94\u200b\u66f4\u5927\u200b\u6a21\u578b\u200b\u7684\u200b\u5e93\u200b\u3002</p> <p>\u200b\u76ee\u524d\u200b\uff0c\u200b\u5b83\u200b\u652f\u6301\u200b\u7b2c\u4e09\u65b9\u200b\u89e3\u51b3\u65b9\u6848\u200b DeepSpeed \u200b\u548c\u200b PyTorch FSDP\uff0c\u200b\u5b83\u4eec\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u8bba\u6587\u200b ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, by Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, Yuxiong He \u200b\u7684\u200b\u90e8\u5206\u200b\u5185\u5bb9\u200b\u3002</p> <p>\u200b\u622a\u81f3\u200b\u64b0\u5199\u200b\u672c\u6587\u200b\uff0c\u200b\u6b64\u200b\u63d0\u4f9b\u200b\u7684\u200b\u652f\u6301\u200b\u662f\u200b\u65b0\u200b\u7684\u200b\u4e14\u200b\u5b9e\u9a8c\u6027\u200b\u7684\u200b\u3002\u200b\u5c3d\u7ba1\u200b\u6211\u4eec\u200b\u6b22\u8fce\u200b\u56f4\u7ed5\u200b DeepSpeed \u200b\u548c\u200b PyTorch FSDP \u200b\u7684\u200bissues\uff0c\u200b\u4f46\u200b\u6211\u4eec\u200b\u4e0d\u518d\u200b\u652f\u6301\u200b FairScale \u200b\u96c6\u6210\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u5df2\u7ecf\u200b\u96c6\u6210\u200b\u5230\u200b\u4e86\u200b PyTorch \u200b\u4e3b\u7ebf\u200b\uff08\u200b\u53c2\u89c1\u200b PyTorch FSDP \u200b\u96c6\u6210\u200b\uff09\u3002</p> <p></p>"},{"location":"main_classes/trainer/#cuda","title":"CUDA\u200b\u62d3\u5c55\u200b\u5b89\u88c5\u200b\u6ce8\u610f\u4e8b\u9879","text":"<p>\u200b\u64b0\u5199\u200b\u65f6\u200b\uff0cDeepspeed \u200b\u9700\u8981\u200b\u5728\u200b\u4f7f\u7528\u200b\u4e4b\u524d\u200b\u7f16\u8bd1\u200b CUDA C++ \u200b\u4ee3\u7801\u200b\u3002</p> <p>\u200b\u867d\u7136\u200b\u6240\u6709\u200b\u5b89\u88c5\u200b\u95ee\u9898\u200b\u90fd\u200b\u5e94\u200b\u901a\u8fc7\u200b Deepspeed \u200b\u7684\u200b GitHub Issues\u200b\u5904\u7406\u200b\uff0c\u200b\u4f46\u200b\u5728\u200b\u6784\u5efa\u200b\u4f9d\u8d56\u200bCUDA \u200b\u6269\u5c55\u200b\u7684\u200b\u4efb\u4f55\u200b PyTorch \u200b\u6269\u5c55\u200b\u65f6\u200b\uff0c\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u9047\u5230\u200b\u4e00\u4e9b\u200b\u5e38\u89c1\u95ee\u9898\u200b\u3002</p> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5982\u679c\u200b\u5728\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\u65f6\u200b\u9047\u5230\u200b\u4e0e\u200b CUDA \u200b\u76f8\u5173\u200b\u7684\u200b\u6784\u5efa\u200b\u95ee\u9898\u200b\uff1a</p> <pre><code>pip install deepspeed\n</code></pre> <p>\u200b\u8bf7\u200b\u9996\u5148\u200b\u9605\u8bfb\u200b\u4ee5\u4e0b\u200b\u8bf4\u660e\u200b\u3002</p> <p>\u200b\u5728\u200b\u8fd9\u4e9b\u200b\u8bf4\u660e\u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u5728\u200b <code>pytorch</code> \u200b\u4f7f\u7528\u200b CUDA <code>10.2</code> \u200b\u6784\u5efa\u200b\u65f6\u5e94\u200b\u91c7\u53d6\u200b\u7684\u200b\u64cd\u4f5c\u200b\u793a\u4f8b\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u7684\u200b\u60c5\u51b5\u200b\u6709\u6240\u4e0d\u540c\u200b\uff0c\u200b\u8bf7\u200b\u8bb0\u5f97\u200b\u5c06\u200b\u7248\u672c\u53f7\u200b\u8c03\u6574\u200b\u4e3a\u200b\u60a8\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u7248\u672c\u200b\u3002</p>"},{"location":"main_classes/trainer/#1","title":"\u53ef\u80fd\u200b\u7684\u200b\u95ee\u9898\u200b #1","text":"<p>\u200b\u5c3d\u7ba1\u200b PyTorch \u200b\u81ea\u5e26\u200b\u4e86\u200b\u5176\u200b\u81ea\u5df1\u200b\u7684\u200b CUDA \u200b\u5de5\u5177\u5305\u200b\uff0c\u200b\u4f46\u200b\u8981\u200b\u6784\u5efa\u200b\u8fd9\u200b\u4e24\u4e2a\u200b\u9879\u76ee\u200b\uff0c\u200b\u4f60\u200b\u5fc5\u987b\u200b\u5728\u200b\u6574\u4e2a\u200b\u7cfb\u7edf\u200b\u4e0a\u200b\u5b89\u88c5\u200b\u76f8\u540c\u200b\u7248\u672c\u200b\u7684\u200b CUDA\u3002</p> <p>\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u5728\u200b Python \u200b\u73af\u5883\u200b\u4e2d\u200b\u4f7f\u7528\u200b <code>cudatoolkit==10.2</code> \u200b\u5b89\u88c5\u200b\u4e86\u200b <code>pytorch</code>\uff0c\u200b\u4f60\u200b\u8fd8\u200b\u9700\u8981\u200b\u5728\u200b\u6574\u4e2a\u200b\u7cfb\u7edf\u200b\u4e0a\u200b\u5b89\u88c5\u200b CUDA <code>10.2</code>\u3002</p> <p>\u200b\u786e\u5207\u200b\u7684\u200b\u4f4d\u7f6e\u200b\u53ef\u80fd\u200b\u56e0\u200b\u7cfb\u7edf\u200b\u800c\u5f02\u200b\uff0c\u200b\u4f46\u200b\u5728\u200b\u8bb8\u591a\u200b Unix \u200b\u7cfb\u7edf\u200b\u4e0a\u200b\uff0c<code>/usr/local/cuda-10.2</code> \u200b\u662f\u200b\u6700\u200b\u5e38\u89c1\u200b\u7684\u200b\u4f4d\u7f6e\u200b\u3002\u200b\u5f53\u200b CUDA \u200b\u6b63\u786e\u200b\u8bbe\u7f6e\u200b\u5e76\u200b\u6dfb\u52a0\u200b\u5230\u200b <code>PATH</code> \u200b\u73af\u5883\u53d8\u91cf\u200b\u65f6\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u6267\u884c\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u627e\u5230\u200b\u5b89\u88c5\u200b\u4f4d\u7f6e\u200b\uff1a</p> <pre><code>which nvcc\n</code></pre> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u5c1a\u672a\u200b\u5728\u200b\u6574\u4e2a\u200b\u7cfb\u7edf\u200b\u4e0a\u200b\u5b89\u88c5\u200b CUDA\uff0c\u200b\u8bf7\u200b\u9996\u5148\u200b\u5b89\u88c5\u200b\u3002\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4f60\u200b\u559c\u6b22\u200b\u7684\u200b\u641c\u7d22\u5f15\u64ce\u200b\u67e5\u627e\u200b\u8bf4\u660e\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u4f60\u200b\u4f7f\u7528\u200b\u7684\u200b\u662f\u200b Ubuntu\uff0c\u200b\u4f60\u200b\u53ef\u80fd\u200b\u60f3\u200b\u641c\u7d22\u200b\uff1aubuntu cuda 10.2 install\u3002</p>"},{"location":"main_classes/trainer/#2","title":"\u53ef\u80fd\u200b\u7684\u200b\u95ee\u9898\u200b #2","text":"<p>\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u53ef\u80fd\u200b\u7684\u200b\u5e38\u89c1\u95ee\u9898\u200b\u662f\u200b\u4f60\u200b\u53ef\u80fd\u200b\u5728\u200b\u6574\u4e2a\u200b\u7cfb\u7edf\u200b\u4e0a\u200b\u5b89\u88c5\u200b\u4e86\u200b\u591a\u4e2a\u200b CUDA \u200b\u5de5\u5177\u5305\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4f60\u200b\u53ef\u80fd\u200b\u6709\u200b\uff1a</p> <pre><code>/usr/local/cuda-10.2\n/usr/local/cuda-11.0\n</code></pre> <p>\u200b\u5728\u200b\u8fd9\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u786e\u4fdd\u200b <code>PATH</code> \u200b\u548c\u200b <code>LD_LIBRARY_PATH</code> \u200b\u73af\u5883\u53d8\u91cf\u200b\u5305\u542b\u200b\u6240\u200b\u9700\u200b CUDA \u200b\u7248\u672c\u200b\u7684\u200b\u6b63\u786e\u200b\u8def\u5f84\u200b\u3002\u200b\u901a\u5e38\u200b\uff0c\u200b\u8f6f\u4ef6\u5305\u200b\u5b89\u88c5\u7a0b\u5e8f\u200b\u5c06\u200b\u8bbe\u7f6e\u200b\u8fd9\u4e9b\u200b\u53d8\u91cf\u200b\u4ee5\u200b\u5305\u542b\u200b\u6700\u65b0\u200b\u5b89\u88c5\u200b\u7684\u200b\u7248\u672c\u200b\u3002\u200b\u5982\u679c\u200b\u9047\u5230\u200b\u6784\u5efa\u200b\u5931\u8d25\u200b\u7684\u200b\u95ee\u9898\u200b\uff0c\u200b\u4e14\u200b\u662f\u56e0\u4e3a\u200b\u5728\u200b\u6574\u4e2a\u200b\u7cfb\u7edf\u200b\u5b89\u88c5\u200b\u4f46\u200b\u8f6f\u4ef6\u200b\u4ecd\u200b\u627e\u200b\u4e0d\u5230\u200b\u6b63\u786e\u200b\u7684\u200b CUDA \u200b\u7248\u672c\u200b\uff0c\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u4f60\u200b\u9700\u8981\u200b\u8c03\u6574\u200b\u8fd9\u200b\u4e24\u4e2a\u200b\u73af\u5883\u53d8\u91cf\u200b\u3002</p> <p>\u200b\u9996\u5148\u200b\uff0c\u200b\u4f60\u200b\u4ee5\u200b\u67e5\u770b\u200b\u5b83\u4eec\u200b\u7684\u200b\u5185\u5bb9\u200b\uff1a</p> <pre><code>echo $PATH\necho $LD_LIBRARY_PATH\n</code></pre> <p>\u200b\u56e0\u6b64\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4e86\u89e3\u200b\u5176\u4e2d\u200b\u7684\u200b\u5185\u5bb9\u200b\u3002</p> <p><code>LD_LIBRARY_PATH</code> \u200b\u53ef\u80fd\u200b\u662f\u200b\u7a7a\u200b\u7684\u200b\u3002</p> <p><code>PATH</code> \u200b\u5217\u51fa\u200b\u4e86\u200b\u53ef\u4ee5\u200b\u627e\u5230\u200b\u53ef\u6267\u884c\u6587\u4ef6\u200b\u7684\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u800c\u200b <code>LD_LIBRARY_PATH</code> \u200b\u7528\u4e8e\u200b\u67e5\u627e\u200b\u5171\u4eab\u200b\u5e93\u200b\u3002\u200b\u5728\u200b\u8fd9\u200b\u4e24\u79cd\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u8f83\u200b\u65e9\u200b\u7684\u200b\u6761\u76ee\u200b\u4f18\u5148\u200b\u4e8e\u200b\u8f83\u200b\u540e\u200b\u7684\u200b\u6761\u76ee\u200b\u3002 <code>:</code> \u200b\u7528\u4e8e\u200b\u5206\u9694\u200b\u591a\u4e2a\u200b\u6761\u76ee\u200b\u3002</p> <p>\u200b\u73b0\u5728\u200b\uff0c\u200b\u4e3a\u4e86\u200b\u544a\u8bc9\u200b\u6784\u5efa\u200b\u7a0b\u5e8f\u200b\u5728\u200b\u54ea\u91cc\u200b\u627e\u5230\u200b\u7279\u5b9a\u200b\u7684\u200b CUDA \u200b\u5de5\u5177\u5305\u200b\uff0c\u200b\u8bf7\u200b\u63d2\u5165\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u8def\u5f84\u200b\uff0c\u200b\u8ba9\u200b\u5176\u200b\u9996\u5148\u200b\u5217\u51fa\u200b\uff1a</p> <pre><code>export PATH=/usr/local/cuda-10.2/bin:$PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH\n</code></pre> <p>\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u6211\u4eec\u200b\u6ca1\u6709\u200b\u8986\u76d6\u200b\u73b0\u6709\u200b\u503c\u200b\uff0c\u200b\u800c\u662f\u200b\u5728\u200b\u524d\u9762\u200b\u6dfb\u52a0\u200b\u65b0\u200b\u7684\u200b\u503c\u200b\u3002</p> <p>\u200b\u5f53\u7136\u200b\uff0c\u200b\u6839\u636e\u200b\u9700\u8981\u200b\u8c03\u6574\u200b\u7248\u672c\u53f7\u200b\u548c\u200b\u5b8c\u6574\u200b\u8def\u5f84\u200b\u3002\u200b\u68c0\u67e5\u200b\u4f60\u200b\u5206\u914d\u200b\u7684\u200b\u76ee\u5f55\u200b\u662f\u5426\u200b\u5b9e\u9645\u200b\u5b58\u5728\u200b\u3002<code>lib64</code> \u200b\u5b50\u76ee\u5f55\u200b\u662f\u200b\u5404\u79cd\u200b CUDA <code>.so</code> \u200b\u5bf9\u8c61\u200b\uff08\u200b\u5982\u200b <code>libcudart.so</code>\uff09\u200b\u7684\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u540d\u5b57\u200b\u53ef\u80fd\u200b\u5728\u200b\u4f60\u200b\u7684\u200b\u7cfb\u7edf\u200b\u4e2d\u662f\u200b\u4e0d\u540c\u200b\u7684\u200b\uff0c\u200b\u5982\u679c\u200b\u662f\u200b\uff0c\u200b\u8bf7\u200b\u8c03\u6574\u200b\u4ee5\u200b\u53cd\u6620\u200b\u5b9e\u9645\u200b\u60c5\u51b5\u200b\u3002</p>"},{"location":"main_classes/trainer/#3","title":"\u53ef\u80fd\u200b\u7684\u200b\u95ee\u9898\u200b #3","text":"<p>\u200b\u4e00\u4e9b\u200b\u8f83\u200b\u65e7\u200b\u7684\u200b CUDA \u200b\u7248\u672c\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u62d2\u7edd\u200b\u4f7f\u7528\u200b\u66f4\u65b0\u200b\u7684\u200b\u7f16\u8bd1\u5668\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4f60\u200b\u53ef\u80fd\u200b\u6709\u200b <code>gcc-9</code>\uff0c\u200b\u4f46\u200b CUDA \u200b\u53ef\u80fd\u200b\u9700\u8981\u200b <code>gcc-7</code>\u3002</p> <p>\u200b\u6709\u200b\u5404\u79cd\u200b\u65b9\u6cd5\u200b\u53ef\u4ee5\u200b\u89e3\u51b3\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\u3002</p> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5b89\u88c5\u200b\u6700\u65b0\u200b\u7684\u200b CUDA \u200b\u5de5\u5177\u5305\u200b\uff0c\u200b\u901a\u5e38\u200b\u5b83\u200b\u5e94\u8be5\u200b\u652f\u6301\u200b\u66f4\u65b0\u200b\u7684\u200b\u7f16\u8bd1\u5668\u200b\u3002</p> <p>\u200b\u6216\u8005\u200b\uff0c\u200b\u4f60\u200b\u53ef\u4ee5\u200b\u5728\u200b\u5df2\u7ecf\u200b\u62e5\u6709\u200b\u7684\u200b\u7f16\u8bd1\u5668\u200b\u7248\u672c\u200b\u4e4b\u5916\u200b\u5b89\u88c5\u200b\u8f83\u200b\u4f4e\u7248\u672c\u200b\uff0c\u200b\u6216\u8005\u200b\u4f60\u200b\u53ef\u80fd\u200b\u5df2\u7ecf\u200b\u5b89\u88c5\u200b\u4e86\u200b\u5b83\u200b\u4f46\u200b\u5b83\u200b\u4e0d\u662f\u200b\u9ed8\u8ba4\u200b\u7684\u200b\u7f16\u8bd1\u5668\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6784\u5efa\u200b\u7cfb\u7edf\u200b\u65e0\u6cd5\u200b\u627e\u5230\u200b\u5b83\u200b\u3002\u200b\u5982\u679c\u200b\u4f60\u200b\u5df2\u7ecf\u200b\u5b89\u88c5\u200b\u4e86\u200b <code>gcc-7</code> \u200b\u4f46\u200b\u6784\u5efa\u200b\u7cfb\u7edf\u200b\u627e\u200b\u4e0d\u5230\u200b\u5b83\u200b\uff0c\u200b\u4ee5\u4e0b\u200b\u64cd\u4f5c\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u89e3\u51b3\u95ee\u9898\u200b\uff1a</p> <pre><code>sudo ln -s /usr/bin/gcc-7  /usr/local/cuda-10.2/bin/gcc\nsudo ln -s /usr/bin/g++-7  /usr/local/cuda-10.2/bin/g++\n</code></pre> <p>\u200b\u8fd9\u91cc\u200b\uff0c\u200b\u6211\u4eec\u200b\u6b63\u5728\u200b\u4ece\u200b <code>/usr/local/cuda-10.2/bin/gcc</code> \u200b\u521b\u5efa\u200b\u5230\u200b <code>gcc-7</code> \u200b\u7684\u200b\u8f6f\u200b\u94fe\u63a5\u200b\uff0c\u200b\u7531\u4e8e\u200b <code>/usr/local/cuda-10.2/bin/</code> \u200b\u5e94\u8be5\u200b\u5728\u200b <code>PATH</code> \u200b\u73af\u5883\u53d8\u91cf\u200b\u4e2d\u200b\uff08\u200b\u53c2\u89c1\u200b\u524d\u200b\u4e00\u4e2a\u200b\u95ee\u9898\u200b\u7684\u200b\u89e3\u51b3\u65b9\u6848\u200b\uff09\uff0c\u200b\u5b83\u200b\u5e94\u8be5\u200b\u80fd\u591f\u200b\u627e\u5230\u200b <code>gcc-7</code>\uff08\u200b\u548c\u200b <code>g++7</code>\uff09\uff0c\u200b\u7136\u540e\u200b\u6784\u5efa\u200b\u5c06\u200b\u6210\u529f\u200b\u3002</p> <p>\u200b\u4e0e\u200b\u5f80\u5e38\u200b\u4e00\u6837\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200b\u7f16\u8f91\u200b\u793a\u4f8b\u200b\u4e2d\u200b\u7684\u200b\u8def\u5f84\u200b\u4ee5\u200b\u5339\u914d\u200b\u4f60\u200b\u7684\u200b\u60c5\u51b5\u200b\u3002</p>"},{"location":"main_classes/trainer/#pytorchfsdp","title":"PyTorch\u200b\u5b8c\u5168\u200b\u5206\u7247\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\uff08FSDP)","text":"<p>\u200b\u4e3a\u4e86\u200b\u52a0\u901f\u200b\u5728\u200b\u66f4\u200b\u5927\u200b\u6279\u6b21\u200b\u5927\u5c0f\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u5e9e\u5927\u200b\u6a21\u578b\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u5b8c\u5168\u200b\u5206\u7247\u200b\u7684\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u6a21\u578b\u200b\u3002\u200b\u8fd9\u79cd\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u8303\u4f8b\u200b\u901a\u8fc7\u200b\u5bf9\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u3001\u200b\u68af\u5ea6\u200b\u548c\u200b\u53c2\u6570\u200b\u8fdb\u884c\u200b\u5206\u7247\u200b\uff0c\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u5728\u200b\u66f4\u200b\u591a\u200b\u6570\u636e\u200b\u548c\u200b\u66f4\u200b\u5927\u200b\u6a21\u578b\u200b\u4e0a\u200b\u7684\u200b\u8bad\u7ec3\u200b\u3002\u200b\u8981\u200b\u4e86\u89e3\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\u4ee5\u53ca\u200b\u5176\u200b\u4f18\u52bf\u200b\uff0c\u200b\u8bf7\u200b\u67e5\u770b\u200b\u5b8c\u5168\u200b\u5206\u7247\u200b\u7684\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u535a\u5ba2\u200b\u3002\u200b\u6211\u4eec\u200b\u5df2\u7ecf\u200b\u96c6\u6210\u200b\u4e86\u200b\u6700\u65b0\u200b\u7684\u200bPyTorch\u200b\u5b8c\u5168\u200b\u5206\u7247\u200b\u7684\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\uff08FSDP\uff09\u200b\u8bad\u7ec3\u200b\u529f\u80fd\u200b\u3002\u200b\u60a8\u200b\u53ea\u200b\u9700\u200b\u901a\u8fc7\u200b\u914d\u7f6e\u200b\u542f\u7528\u200b\u5b83\u200b\u3002</p> <p>FSDP\u200b\u652f\u6301\u200b\u6240\u200b\u9700\u200b\u7684\u200bPyTorch\u200b\u7248\u672c\u200b: PyTorch Nightly\uff08\u200b\u6216\u8005\u200b\u5982\u679c\u200b\u4f60\u200b\u5728\u200b\u53d1\u5e03\u200b\u540e\u200b\u9605\u8bfb\u200b\u8fd9\u4e2a\u200b\uff0c\u200b\u4f7f\u7528\u200b1.12.0\u200b\u7248\u672c\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5e26\u6709\u200b\u6fc0\u6d3b\u200b\u7684\u200bFSDP\u200b\u7684\u200b\u6a21\u578b\u200b\u4fdd\u5b58\u200b\u4ec5\u200b\u5728\u200b\u6700\u8fd1\u200b\u7684\u200b\u4fee\u590d\u200b\u4e2d\u200b\u53ef\u7528\u200b\u3002</p> <p>\u200b\u7528\u6cd5\u200b:</p> <ul> <li> <p>\u200b\u5982\u679c\u200b\u4f60\u200b\u5c1a\u672a\u200b\u4f7f\u7528\u200b\u8fc7\u200b\u5206\u5e03\u5f0f\u200b\u542f\u52a8\u5668\u200b\uff0c\u200b\u786e\u4fdd\u200b\u4f60\u200b\u5df2\u7ecf\u200b\u6dfb\u52a0\u200b\u4e86\u200b\u5b83\u200b <code>-m torch.distributed.launch --nproc_per_node=NUMBER_OF_GPUS_YOU_HAVE</code>\u3002</p> </li> <li> <p>\u200b\u5206\u7247\u200b\u7b56\u7565\u200b\uff1a</p> </li> <li>FULL_SHARD\uff1a\u200b\u5728\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u7ebf\u7a0b\u200b/GPU\u200b\u4e4b\u95f4\u200b\uff0c\u200b\u5bf9\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u3001\u200b\u68af\u5ea6\u200b\u548c\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u8fdb\u884c\u200b\u5206\u7247\u200b\u3002     \u200b\u4e3a\u6b64\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u4e2d\u200b\u6dfb\u52a0\u200b <code>--fsdp full_shard</code>\u3002</li> <li>SHARD_GRAD_OP\uff1a\u200b\u5728\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u7ebf\u7a0b\u200b/GPU\u200b\u4e4b\u95f4\u200b\u5bf9\u200b\u4f18\u5316\u200b\u5668\u200b\u72b6\u6001\u200b\u548c\u200b\u68af\u5ea6\u200b\u8fdb\u884c\u200b\u5206\u7247\u200b\u3002     \u200b\u4e3a\u6b64\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u4e2d\u200b\u6dfb\u52a0\u200b <code>--fsdp shard_grad_op</code>\u3002</li> <li>NO_SHARD\uff1a\u200b\u4e0d\u200b\u8fdb\u884c\u200b\u5206\u7247\u200b\u3002\u200b\u4e3a\u6b64\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u4e2d\u200b\u6dfb\u52a0\u200b <code>--fsdp no_shard</code>\u3002</li> <li>\u200b\u8981\u200b\u5c06\u200b\u53c2\u6570\u200b\u548c\u200b\u68af\u5ea6\u200b\u5378\u8f7d\u200b\u5230\u200bCPU\uff0c\u200b\u6dfb\u52a0\u200b <code>--fsdp \"full_shard offload\"</code> \u200b\u6216\u200b <code>--fsdp \"shard_grad_op offload\"</code> \u200b\u5230\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u4e2d\u200b\u3002</li> <li>\u200b\u8981\u200b\u4f7f\u7528\u200b <code>default_auto_wrap_policy</code> \u200b\u81ea\u52a8\u200b\u9012\u5f52\u200b\u5730\u7528\u200bFSDP\u200b\u5305\u88c5\u200b\u5c42\u200b\uff0c\u200b\u8bf7\u200b\u6dfb\u52a0\u200b <code>--fsdp \"full_shard auto_wrap\"</code> \u200b\u6216\u200b <code>--fsdp \"shard_grad_op auto_wrap\"</code> \u200b\u5230\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u4e2d\u200b\u3002</li> <li>\u200b\u8981\u200b\u540c\u65f6\u200b\u542f\u7528\u200bCPU\u200b\u5378\u8f7d\u200b\u548c\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u5c42\u200b\u5de5\u5177\u200b\uff0c\u200b\u8bf7\u200b\u6dfb\u52a0\u200b <code>--fsdp \"full_shard offload auto_wrap\"</code> \u200b\u6216\u200b <code>--fsdp \"shard_grad_op offload auto_wrap\"</code> \u200b\u5230\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b\u4e2d\u200b\u3002</li> <li>\u200b\u5176\u4f59\u200b\u7684\u200bFSDP\u200b\u914d\u7f6e\u200b\u901a\u8fc7\u200b <code>--fsdp_config &lt;path_to_fsdp_config.json&gt;</code> \u200b\u4f20\u9012\u200b\u3002\u200b\u5b83\u200b\u53ef\u4ee5\u200b\u662f\u200bFSDP json\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u7684\u200b\u4f4d\u7f6e\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c<code>fsdp_config.json</code>\uff09\u200b\u6216\u200b\u5df2\u200b\u52a0\u8f7d\u200b\u7684\u200bjson\u200b\u6587\u4ef6\u200b\u4f5c\u4e3a\u200b <code>dict</code>\u3002</li> <li>\u200b\u5982\u679c\u200b\u542f\u7528\u200b\u4e86\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u57fa\u4e8e\u200btransformer\u200b\u7684\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7b56\u7565\u200b\u6216\u200b\u57fa\u4e8e\u200b\u5927\u5c0f\u200b\u7684\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7b56\u7565\u200b\u3002<ul> <li>\u200b\u5bf9\u4e8e\u200b\u57fa\u4e8e\u200btransformer\u200b\u7684\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7b56\u7565\u200b\uff0c\u200b\u5efa\u8bae\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u6307\u5b9a\u200b <code>fsdp_transformer_layer_cls_to_wrap</code>\u3002\u200b\u5982\u679c\u200b\u672a\u6307\u5b9a\u200b\uff0c\u200b\u5219\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b <code>model._no_split_modules</code>\uff08\u200b\u5982\u679c\u200b\u53ef\u7528\u200b\uff09\u3002\u200b\u8fd9\u200b\u5c06\u200b\u6307\u5b9a\u200b\u8981\u200b\u5305\u88c5\u200b\u7684\u200btransformer\u200b\u5c42\u7c7b\u200b\u540d\u200b\uff08\u200b\u533a\u5206\u200b\u5927\u5c0f\u5199\u200b\uff09\uff0c\u200b\u4f8b\u5982\u200b [<code>BertLayer</code>]\u3001[<code>GPTJBlock</code>]\u3001[<code>T5Block</code>] \u200b\u7b49\u200b\u3002\u200b\u8fd9\u200b\u5f88\u200b\u91cd\u8981\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5171\u4eab\u200b\u6743\u91cd\u200b\u7684\u200b\u5b50\u200b\u6a21\u5757\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0cembedding\u200b\u5c42\u200b\uff09\u200b\u4e0d\u200b\u5e94\u200b\u6700\u7ec8\u200b\u51fa\u73b0\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200bFSDP\u200b\u5305\u88c5\u200b\u5355\u5143\u200b\u4e2d\u200b\u3002\u200b\u4f7f\u7528\u200b\u6b64\u200b\u7b56\u7565\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u5305\u88c5\u200b\u7684\u200b\u5757\u200b\u5c06\u200b\u5305\u542b\u200b\u591a\u5934\u200b\u6ce8\u610f\u529b\u200b\u548c\u200b\u540e\u9762\u200b\u7684\u200b\u51e0\u4e2a\u200bMLP\u200b\u5c42\u200b\u3002\u200b\u5269\u4f59\u200b\u7684\u200b\u5c42\u200b\uff0c\u200b\u5305\u62ec\u200b\u5171\u4eab\u200b\u7684\u200bembedding\u200b\u5c42\u200b\uff0c\u200b\u90fd\u200b\u5c06\u200b\u88ab\u200b\u65b9\u4fbf\u200b\u5730\u200b\u5305\u88c5\u200b\u5728\u200b\u540c\u4e00\u4e2a\u200b\u6700\u200b\u5916\u5c42\u200b\u7684\u200bFSDP\u200b\u5355\u5143\u200b\u4e2d\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u57fa\u4e8e\u200btransformer\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u8bf7\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200b\u65b9\u6cd5\u200b\u3002</li> <li>\u200b\u5bf9\u4e8e\u200b\u57fa\u4e8e\u200b\u5927\u5c0f\u200b\u7684\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7b56\u7565\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u6dfb\u52a0\u200b <code>fsdp_min_num_params</code>\u3002\u200b\u5b83\u200b\u6307\u5b9a\u200b\u4e86\u200bFSDP\u200b\u8fdb\u884c\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7684\u200b\u6700\u5c0f\u200b\u53c2\u6570\u200b\u6570\u91cf\u200b\u3002</li> </ul> </li> <li>\u200b\u53ef\u4ee5\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u6307\u5b9a\u200b <code>fsdp_backward_prefetch</code>\u3002\u200b\u5b83\u200b\u63a7\u5236\u200b\u4f55\u65f6\u200b\u9884\u53d6\u200b\u4e0b\u200b\u4e00\u7ec4\u200b\u53c2\u6570\u200b\u3002<code>backward_pre</code> \u200b\u548c\u200b <code>backward_pos</code> \u200b\u662f\u200b\u53ef\u7528\u200b\u7684\u200b\u9009\u9879\u200b\u3002\u200b\u6709\u5173\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b <code>torch.distributed.fsdp.fully_sharded_data_parallel.BackwardPrefetch</code></li> <li>\u200b\u53ef\u4ee5\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u6307\u5b9a\u200b <code>fsdp_forward_prefetch</code>\u3002\u200b\u5b83\u200b\u63a7\u5236\u200b\u4f55\u65f6\u200b\u9884\u53d6\u200b\u4e0b\u200b\u4e00\u7ec4\u200b\u53c2\u6570\u200b\u3002\u200b\u5982\u679c\u200b\u662f\u200b<code>\"True\"</code>\uff0c\u200b\u5728\u200b\u6267\u884c\u200b\u524d\u5411\u200b\u4f20\u9012\u200b\u65f6\u200b\uff0cFSDP\u200b\u660e\u786e\u200b\u5730\u200b\u9884\u53d6\u200b\u4e0b\u200b\u4e00\u6b21\u200b\u5373\u5c06\u200b\u53d1\u751f\u200b\u7684\u200b\u5168\u5c40\u200b\u805a\u96c6\u200b\u3002</li> <li>\u200b\u53ef\u4ee5\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u6307\u5b9a\u200b <code>limit_all_gathers</code>\u3002\u200b\u5982\u679c\u200b\u662f\u200b<code>\"True\"</code>\uff0cFSDP\u200b\u660e\u786e\u200b\u5730\u200b\u540c\u6b65\u200bCPU\u200b\u7ebf\u7a0b\u200b\uff0c\u200b\u4ee5\u200b\u9632\u6b62\u200b\u592a\u591a\u200b\u7684\u200b\u8fdb\u884c\u200b\u4e2d\u200b\u7684\u200b\u5168\u5c40\u200b\u805a\u96c6\u200b\u3002</li> <li>\u200b\u53ef\u4ee5\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u6307\u5b9a\u200b <code>activation_checkpointing</code>\u3002\u200b\u5982\u679c\u200b\u662f\u200b<code>\"True\"</code>\uff0cFSDP activation checkpoint\u200b\u662f\u200b\u4e00\u79cd\u200b\u901a\u8fc7\u200b\u6e05\u9664\u200b\u67d0\u4e9b\u200b\u5c42\u200b\u7684\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u5e76\u200b\u5728\u200b\u53cd\u5411\u200b\u4f20\u9012\u200b\u671f\u95f4\u200b\u91cd\u65b0\u200b\u8ba1\u7b97\u200b\u5b83\u4eec\u200b\u6765\u200b\u51cf\u5c11\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u7684\u200b\u6280\u672f\u200b\u3002\u200b\u5b9e\u9645\u4e0a\u200b\uff0c\u200b\u8fd9\u4ee5\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u8ba1\u7b97\u200b\u65f6\u95f4\u200b\u4e3a\u200b\u4ee3\u4ef7\u200b\u51cf\u5c11\u200b\u4e86\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u3002</li> </ul> <p>\u200b\u9700\u8981\u200b\u6ce8\u610f\u200b\u51e0\u4e2a\u200b\u6ce8\u610f\u4e8b\u9879\u200b - \u200b\u5b83\u200b\u4e0e\u200b <code>generate</code> \u200b\u4e0d\u200b\u517c\u5bb9\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4e0e\u200b\u6240\u6709\u200bseq2seq/clm\u200b\u811a\u672c\u200b\uff08\u200b\u7ffb\u8bd1\u200b/\u200b\u6458\u8981\u200b/clm\u200b\u7b49\u200b\uff09\u200b\u4e2d\u200b\u7684\u200b <code>--predict_with_generate</code> \u200b\u4e0d\u200b\u517c\u5bb9\u200b\u3002\u200b\u8bf7\u53c2\u9605\u200bissue#21667\u3002</p>"},{"location":"main_classes/trainer/#pytorchxla","title":"PyTorch/XLA \u200b\u5b8c\u5168\u200b\u5206\u7247\u200b\u6570\u636e\u200b\u5e76\u884c","text":"<p>\u200b\u5bf9\u4e8e\u200b\u6240\u6709\u200bTPU\u200b\u7528\u6237\u200b\uff0c\u200b\u6709\u4e2a\u200b\u597d\u6d88\u606f\u200b\uff01PyTorch/XLA\u200b\u73b0\u5728\u200b\u652f\u6301\u200bFSDP\u3002\u200b\u6240\u6709\u200b\u6700\u65b0\u200b\u7684\u200b\u5b8c\u5168\u200b\u5206\u7247\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\uff08FSDP\uff09\u200b\u8bad\u7ec3\u200b\u90fd\u200b\u53d7\u200b\u652f\u6301\u200b\u3002\u200b\u6709\u5173\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u5728\u200b\u4e91\u7aef\u200bTPU\u200b\u4e0a\u200b\u4f7f\u7528\u200bFSDP\u200b\u6269\u5c55\u200bPyTorch\u200b\u6a21\u578b\u200b\u548c\u200bPyTorch/XLA FSDP\u200b\u7684\u200b\u5b9e\u73b0\u200b\u3002\u200b\u4f7f\u7528\u200b\u5b83\u200b\u53ea\u200b\u9700\u200b\u901a\u8fc7\u200b\u914d\u7f6e\u200b\u542f\u7528\u200b\u3002</p> <p>\u200b\u9700\u8981\u200b\u7684\u200b PyTorch/XLA \u200b\u7248\u672c\u200b\u4ee5\u200b\u652f\u6301\u200b FSDP\uff1a&gt;=2.0</p> <p>\u200b\u7528\u6cd5\u200b\uff1a</p> <p>\u200b\u4f20\u9012\u200b <code>--fsdp \"full shard\"</code>\uff0c\u200b\u540c\u65f6\u200b\u5bf9\u200b <code>--fsdp_config &lt;path_to_fsdp_config.json&gt;</code> \u200b\u8fdb\u884c\u200b\u4ee5\u4e0b\u200b\u66f4\u6539\u200b\uff1a - <code>xla</code> \u200b\u5e94\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b <code>True</code> \u200b\u4ee5\u200b\u542f\u7528\u200b PyTorch/XLA FSDP\u3002 - <code>xla_fsdp_settings</code> \u200b\u7684\u200b\u503c\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5b57\u5178\u200b\uff0c\u200b\u5b58\u50a8\u200b XLA FSDP \u200b\u5c01\u88c5\u200b\u53c2\u6570\u200b\u3002\u200b\u5b8c\u6574\u200b\u7684\u200b\u9009\u9879\u200b\u5217\u8868\u200b\uff0c\u200b\u8bf7\u200b\u53c2\u89c1\u200b\u6b64\u5904\u200b\u3002 - <code>xla_fsdp_grad_ckpt</code>\u3002\u200b\u5f53\u200b <code>True</code> \u200b\u65f6\u200b\uff0c\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u5d4c\u5957\u200b\u7684\u200b XLA FSDP \u200b\u5c01\u88c5\u200b\u5c42\u4e0a\u200b\u4f7f\u7528\u200b\u68af\u5ea6\u200bcheckpoint\u3002\u200b\u8be5\u200b\u8bbe\u7f6e\u200b\u53ea\u80fd\u200b\u5728\u200b\u5c06\u200b xla \u200b\u6807\u5fd7\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b true\uff0c\u200b\u5e76\u200b\u901a\u8fc7\u200b <code>fsdp_min_num_params</code> \u200b\u6216\u200b <code>fsdp_transformer_layer_cls_to_wrap</code> \u200b\u6307\u5b9a\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7b56\u7565\u200b\u65f6\u200b\u4f7f\u7528\u200b\u3002 - \u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u57fa\u4e8e\u200btransformer\u200b\u7684\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7b56\u7565\u200b\u6216\u200b\u57fa\u4e8e\u200b\u5927\u5c0f\u200b\u7684\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7b56\u7565\u200b\u3002   - \u200b\u5bf9\u4e8e\u200b\u57fa\u4e8e\u200btransformer\u200b\u7684\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7b56\u7565\u200b\uff0c\u200b\u5efa\u8bae\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u6307\u5b9a\u200b <code>fsdp_transformer_layer_cls_to_wrap</code>\u3002\u200b\u5982\u679c\u200b\u672a\u6307\u5b9a\u200b\uff0c\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b <code>model._no_split_modules</code>\uff08\u200b\u5982\u679c\u200b\u53ef\u7528\u200b\uff09\u3002\u200b\u8fd9\u200b\u6307\u5b9a\u200b\u4e86\u200b\u8981\u200b\u5305\u88c5\u200b\u7684\u200btransformer\u200b\u5c42\u7c7b\u200b\u540d\u200b\u5217\u8868\u200b\uff08\u200b\u533a\u5206\u200b\u5927\u5c0f\u5199\u200b\uff09\uff0c\u200b\u4f8b\u5982\u200b [<code>BertLayer</code>]\u3001[<code>GPTJBlock</code>]\u3001[<code>T5Block</code>] \u200b\u7b49\u200b\u3002\u200b\u8fd9\u200b\u5f88\u200b\u91cd\u8981\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u5171\u4eab\u200b\u6743\u91cd\u200b\u7684\u200b\u5b50\u200b\u6a21\u5757\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0cembedding\u200b\u5c42\u200b\uff09\u200b\u4e0d\u200b\u5e94\u200b\u6700\u7ec8\u200b\u51fa\u73b0\u200b\u5728\u200b\u4e0d\u540c\u200b\u7684\u200bFSDP\u200b\u5305\u88c5\u200b\u5355\u5143\u200b\u4e2d\u200b\u3002\u200b\u4f7f\u7528\u200b\u6b64\u200b\u7b56\u7565\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u5305\u88c5\u200b\u7684\u200b\u5757\u200b\u5c06\u200b\u5305\u542b\u200b\u591a\u5934\u200b\u6ce8\u610f\u529b\u200b\u548c\u200b\u540e\u9762\u200b\u7684\u200b\u51e0\u4e2a\u200bMLP\u200b\u5c42\u200b\u3002\u200b\u5269\u4f59\u200b\u7684\u200b\u5c42\u200b\uff0c\u200b\u5305\u62ec\u200b\u5171\u4eab\u200b\u7684\u200bembedding\u200b\u5c42\u200b\uff0c\u200b\u90fd\u200b\u5c06\u200b\u88ab\u200b\u65b9\u4fbf\u200b\u5730\u200b\u5305\u88c5\u200b\u5728\u200b\u540c\u4e00\u4e2a\u200b\u6700\u200b\u5916\u5c42\u200b\u7684\u200bFSDP\u200b\u5355\u5143\u200b\u4e2d\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u57fa\u4e8e\u200btransformer\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u8bf7\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200b\u65b9\u6cd5\u200b\u3002   - \u200b\u5bf9\u4e8e\u200b\u57fa\u4e8e\u200b\u5927\u5c0f\u200b\u7684\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7b56\u7565\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u4e2d\u200b\u6dfb\u52a0\u200b <code>fsdp_min_num_params</code>\u3002\u200b\u5b83\u200b\u6307\u5b9a\u200b\u4e86\u200b\u81ea\u52a8\u200b\u5305\u88c5\u200b\u7684\u200b FSDP \u200b\u7684\u200b\u6700\u5c0f\u200b\u53c2\u6570\u200b\u6570\u91cf\u200b\u3002</p>"},{"location":"main_classes/trainer/#mac-trainer-pytorch","title":"\u5728\u200b Mac \u200b\u4e0a\u200b\u4f7f\u7528\u200b Trainer \u200b\u8fdb\u884c\u200b\u52a0\u901f\u200b\u7684\u200b PyTorch \u200b\u8bad\u7ec3","text":"<p>\u200b\u968f\u7740\u200b PyTorch v1.12 \u200b\u7248\u672c\u200b\u7684\u200b\u53d1\u5e03\u200b\uff0c\u200b\u5f00\u53d1\u4eba\u5458\u200b\u548c\u200b\u7814\u7a76\u200b\u4eba\u5458\u200b\u53ef\u4ee5\u200b\u5229\u7528\u200b Apple Silicon GPU \u200b\u8fdb\u884c\u200b\u663e\u8457\u200b\u66f4\u5feb\u200b\u7684\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u3002\u200b\u8fd9\u200b\u4f7f\u5f97\u200b\u53ef\u4ee5\u200b\u5728\u200b Mac \u200b\u4e0a\u200b\u672c\u5730\u200b\u6267\u884c\u200b\u539f\u578b\u200b\u8bbe\u8ba1\u200b\u548c\u200b\u5fae\u8c03\u200b\u7b49\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u5de5\u4f5c\u200b\u6d41\u7a0b\u200b\u3002Apple \u200b\u7684\u200b Metal Performance Shaders\uff08MPS\uff09\u200b\u4f5c\u4e3a\u200b PyTorch \u200b\u7684\u200b\u540e\u200b\u7aef\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u8fd9\u200b\u4e00\u70b9\u200b\uff0c\u200b\u5e76\u4e14\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u65b0\u200b\u7684\u200b <code>\"mps\"</code> \u200b\u8bbe\u5907\u200b\u6765\u200b\u4f7f\u7528\u200b\u3002 \u200b\u8fd9\u200b\u5c06\u200b\u5728\u200b MPS \u200b\u56fe\u5f62\u200b\u6846\u67b6\u200b\u4e0a\u200b\u6620\u5c04\u200b\u8ba1\u7b97\u200b\u56fe\u200b\u548c\u200b\u795e\u7ecf\u200b\u56fe\u200b\u5143\u200b\uff0c\u200b\u5e76\u200b\u4f7f\u7528\u200b MPS \u200b\u63d0\u4f9b\u200b\u7684\u200b\u4f18\u5316\u200b\u5185\u6838\u200b\u3002\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u5b98\u65b9\u200b\u6587\u6863\u200b Introducing Accelerated PyTorch Training on Mac \u200b\u548c\u200b MPS BACKEND\u3002</p> <p> <p>\u200b\u6211\u4eec\u200b\u5f3a\u70c8\u5efa\u8bae\u200b\u5728\u200b\u4f60\u200b\u7684\u200b MacOS \u200b\u673a\u5668\u200b\u4e0a\u200b\u5b89\u88c5\u200b PyTorch &gt;= 1.13\uff08\u200b\u5728\u200b\u64b0\u5199\u200b\u672c\u6587\u200b\u65f6\u4e3a\u200b\u6700\u65b0\u200b\u7248\u672c\u200b\uff09\u3002\u200b\u5bf9\u4e8e\u200b\u57fa\u4e8e\u200b transformer \u200b\u7684\u200b\u6a21\u578b\u200b\uff0c \u200b\u5b83\u200b\u63d0\u4f9b\u200b\u4e0e\u200b\u6a21\u578b\u200b\u6b63\u786e\u6027\u200b\u548c\u200b\u6027\u80fd\u200b\u6539\u8fdb\u200b\u76f8\u5173\u200b\u7684\u200b\u91cd\u5927\u200b\u4fee\u590d\u200b\u3002\u200b\u6709\u5173\u200b\u66f4\u200b\u591a\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200bpytorch/pytorch#82707\u3002</p> <p></p> <p>\u200b\u4f7f\u7528\u200b Apple Silicon \u200b\u82af\u7247\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u548c\u200b\u63a8\u7406\u200b\u7684\u200b\u597d\u5904\u200b</p> <ol> <li>\u200b\u4f7f\u200b\u7528\u6237\u200b\u80fd\u591f\u200b\u5728\u200b\u672c\u5730\u200b\u8bad\u7ec3\u200b\u66f4\u5927\u200b\u7684\u200b\u7f51\u7edc\u200b\u6216\u200b\u6279\u91cf\u200b\u6570\u636e\u200b\u3002</li> <li>\u200b\u7531\u4e8e\u200b\u7edf\u4e00\u200b\u5185\u5b58\u200b\u67b6\u6784\u200b\uff0c\u200b\u51cf\u5c11\u200b\u6570\u636e\u68c0\u7d22\u200b\u5ef6\u8fdf\u200b\uff0c\u200b\u5e76\u200b\u4e3a\u200b GPU \u200b\u63d0\u4f9b\u200b\u5bf9\u200b\u5b8c\u6574\u200b\u5185\u5b58\u200b\u5b58\u50a8\u200b\u7684\u200b\u76f4\u63a5\u200b\u8bbf\u95ee\u200b\u3002\u200b\u4ece\u800c\u200b\u63d0\u9ad8\u200b\u7aef\u5230\u200b\u7aef\u200b\u6027\u80fd\u200b\u3002</li> <li>\u200b\u964d\u4f4e\u200b\u4e0e\u200b\u57fa\u4e8e\u200b\u4e91\u200b\u7684\u200b\u5f00\u53d1\u200b\u6216\u200b\u9700\u8981\u200b\u989d\u5916\u200b\u672c\u5730\u200b GPU \u200b\u7684\u200b\u6210\u672c\u200b\u3002</li> </ol> <p>\u200b\u5148\u51b3\u6761\u4ef6\u200b\uff1a\u200b\u8981\u200b\u5b89\u88c5\u200b\u5e26\u6709\u200b mps \u200b\u652f\u6301\u200b\u7684\u200b torch\uff0c\u200b\u8bf7\u200b\u6309\u7167\u200b\u8fd9\u7bc7\u200b\u7cbe\u5f69\u200b\u7684\u200b Medium \u200b\u6587\u7ae0\u200b\u64cd\u4f5c\u200b GPU-Acceleration Comes to PyTorch on M1 Macs\u3002</p> <p>\u200b\u7528\u6cd5\u200b\uff1a \u200b\u5982\u679c\u200b\u53ef\u7528\u200b\uff0c<code>mps</code> \u200b\u8bbe\u5907\u200b\u5c06\u200b\u9ed8\u8ba4\u200b\u4f7f\u7528\u200b\uff0c\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u4f7f\u7528\u200b <code>cuda</code> \u200b\u8bbe\u5907\u200b\u7684\u200b\u65b9\u5f0f\u200b\u3002\u200b\u56e0\u6b64\u200b\uff0c\u200b\u7528\u6237\u200b\u65e0\u9700\u200b\u91c7\u53d6\u4efb\u4f55\u200b\u64cd\u4f5c\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u5728\u200b Apple Silicon GPU \u200b\u4e0a\u200b\u8fd0\u884c\u200b\u5b98\u65b9\u200b\u7684\u200b Glue \u200b\u6587\u672c\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b\uff08\u200b\u4ece\u6839\u200b\u6587\u4ef6\u5939\u200b\u8fd0\u884c\u200b\uff09\uff1a</p> <pre><code>export TASK_NAME=mrpc\n\npython examples/pytorch/text-classification/run_glue.py \\\n  --model_name_or_path bert-base-cased \\\n  --task_name $TASK_NAME \\\n  --do_train \\\n  --do_eval \\\n  --max_seq_length 128 \\\n  --per_device_train_batch_size 32 \\\n  --learning_rate 2e-5 \\\n  --num_train_epochs 3 \\\n  --output_dir /tmp/$TASK_NAME/ \\\n  --overwrite_output_dir\n</code></pre> <p>\u200b\u9700\u8981\u200b\u6ce8\u610f\u200b\u7684\u200b\u4e00\u4e9b\u200b\u6ce8\u610f\u4e8b\u9879\u200b</p> <ol> <li>\u200b\u4e00\u4e9b\u200b PyTorch \u200b\u64cd\u4f5c\u200b\u5c1a\u672a\u200b\u5728\u200b mps \u200b\u4e2d\u200b\u5b9e\u73b0\u200b\uff0c\u200b\u5c06\u200b\u5f15\u53d1\u200b\u9519\u8bef\u200b\u3002\u200b\u89e3\u51b3\u200b\u6b64\u200b\u95ee\u9898\u200b\u7684\u200b\u4e00\u79cd\u200b\u65b9\u6cd5\u200b\u662f\u200b\u8bbe\u7f6e\u200b\u73af\u5883\u53d8\u91cf\u200b <code>PYTORCH_ENABLE_MPS_FALLBACK=1</code>\uff0c\u200b\u5b83\u200b\u5c06\u200b\u628a\u200b\u8fd9\u4e9b\u200b\u64cd\u4f5c\u200b\u56de\u9000\u200b\u5230\u200b CPU \u200b\u8fdb\u884c\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u5b83\u200b\u4ecd\u7136\u200b\u4f1a\u200b\u629b\u51fa\u200b UserWarning \u200b\u4fe1\u606f\u200b\u3002</li> <li>\u200b\u5206\u5e03\u5f0f\u200b\u8bbe\u7f6e\u200b <code>gloo</code> \u200b\u548c\u200b <code>nccl</code> \u200b\u5728\u200b <code>mps</code> \u200b\u8bbe\u5907\u200b\u4e0a\u200b\u4e0d\u8d77\u4f5c\u7528\u200b\u3002\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u5f53\u524d\u200b\u53ea\u80fd\u200b\u4f7f\u7528\u200b <code>mps</code> \u200b\u8bbe\u5907\u200b\u7c7b\u578b\u200b\u7684\u200b\u5355\u4e2a\u200b GPU\u3002</li> </ol> <p>\u200b\u6700\u540e\u200b\uff0c\u200b\u8bf7\u200b\u8bb0\u4f4f\u200b\uff0c\ud83e\udd17 <code>Trainer</code> \u200b\u4ec5\u200b\u96c6\u6210\u200b\u4e86\u200b MPS \u200b\u540e\u200b\u7aef\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5982\u679c\u200b\u4f60\u200b\u5728\u200b\u4f7f\u7528\u200b MPS \u200b\u540e\u7aef\u200b\u65f6\u200b\u9047\u5230\u200b\u4efb\u4f55\u200b\u95ee\u9898\u200b\u6216\u200b\u6709\u200b\u7591\u95ee\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b PyTorch GitHub \u200b\u4e0a\u200b\u63d0\u4ea4\u200b\u95ee\u9898\u200b\u3002</p>"},{"location":"main_classes/trainer/#accelerate-launcher-trainer","title":"\u901a\u8fc7\u200b Accelerate Launcher \u200b\u4f7f\u7528\u200b Trainer","text":"<p>Accelerate \u200b\u73b0\u5728\u200b\u652f\u6301\u200b Trainer\u3002\u200b\u7528\u6237\u200b\u53ef\u4ee5\u200b\u671f\u5f85\u200b\u4ee5\u4e0b\u5185\u5bb9\u200b\uff1a - \u200b\u4ed6\u4eec\u200b\u53ef\u4ee5\u200b\u7ee7\u7eed\u200b\u4f7f\u7528\u200b Trainer \u200b\u7684\u200b\u8fed\u4ee3\u200b\uff0c\u200b\u5982\u200b FSDP\u3001DeepSpeed \u200b\u7b49\u200b\uff0c\u200b\u800c\u200b\u65e0\u9700\u200b\u505a\u200b\u4efb\u4f55\u200b\u66f4\u6539\u200b\u3002 - \u200b\u73b0\u5728\u200b\u53ef\u4ee5\u200b\u5728\u200b Trainer \u200b\u4e2d\u200b\u4f7f\u7528\u200b Accelerate Launcher\uff08\u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200b\uff09\u3002</p> <p>\u200b\u901a\u8fc7\u200b Accelerate Launcher \u200b\u4f7f\u7528\u200b Trainer \u200b\u7684\u200b\u6b65\u9aa4\u200b\uff1a 1. \u200b\u786e\u4fdd\u200b\u5df2\u200b\u5b89\u88c5\u200b \ud83e\udd17 Accelerate\uff0c\u200b\u65e0\u8bba\u5982\u4f55\u200b\uff0c\u200b\u5982\u679c\u200b\u6ca1\u6709\u200b\u5b83\u200b\uff0c\u200b\u4f60\u200b\u65e0\u6cd5\u200b\u4f7f\u7528\u200b <code>Trainer</code>\u3002\u200b\u5982\u679c\u200b\u6ca1\u6709\u200b\uff0c\u200b\u8bf7\u200b\u6267\u884c\u200b <code>pip install accelerate</code>\u3002\u200b\u4f60\u200b\u53ef\u80fd\u200b\u8fd8\u200b\u9700\u8981\u200b\u66f4\u65b0\u200b Accelerate \u200b\u7684\u200b\u7248\u672c\u200b\uff1a<code>pip install accelerate --upgrade</code>\u3002 2. \u200b\u8fd0\u884c\u200b <code>accelerate config</code> \u200b\u5e76\u200b\u586b\u5199\u200b\u95ee\u9898\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u4e00\u4e9b\u200b\u52a0\u901f\u200b\u914d\u7f6e\u200b\u7684\u200b\u793a\u4f8b\u200b\uff1a</p> <p>a. DDP \u200b\u591a\u200b\u8282\u70b9\u200b\u591a\u200b GPU \u200b\u914d\u7f6e\u200b\uff1a</p> <pre><code>```yaml\ncompute_environment: LOCAL_MACHINE                                                                                             \ndistributed_type: MULTI_GPU                                                                                                    \ndowncast_bf16: 'no'\ngpu_ids: all\nmachine_rank: 0 #change rank as per the node\nmain_process_ip: 192.168.20.1\nmain_process_port: 9898\nmain_training_function: main\nmixed_precision: fp16\nnum_machines: 2\nnum_processes: 8\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false\n```\n</code></pre> <p>b. FSDP \u200b\u914d\u7f6e\u200b\uff1a</p> <pre><code>```yaml\ncompute_environment: LOCAL_MACHINE\ndistributed_type: FSDP\ndowncast_bf16: 'no'\nfsdp_config:\n  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP\n  fsdp_backward_prefetch_policy: BACKWARD_PRE\n  fsdp_forward_prefetch: true\n  fsdp_offload_params: false\n  fsdp_sharding_strategy: 1\n  fsdp_state_dict_type: FULL_STATE_DICT\n  fsdp_sync_module_states: true\n  fsdp_transformer_layer_cls_to_wrap: BertLayer\n  fsdp_use_orig_params: true\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: bf16\nnum_machines: 1\nnum_processes: 2\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false\n```\n</code></pre> <p>c. \u200b\u6307\u5411\u200b\u6587\u4ef6\u200b\u7684\u200b DeepSpeed \u200b\u914d\u7f6e\u200b\uff1a</p> <pre><code>```yaml\ncompute_environment: LOCAL_MACHINE\ndeepspeed_config:\n  deepspeed_config_file: /home/user/configs/ds_zero3_config.json\n  zero3_init_flag: true\ndistributed_type: DEEPSPEED\ndowncast_bf16: 'no'\nmachine_rank: 0\nmain_training_function: main\nnum_machines: 1\nnum_processes: 4\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false\n```\n</code></pre> <p>d. \u200b\u4f7f\u7528\u200b accelerate \u200b\u63d2\u4ef6\u200b\u7684\u200b DeepSpeed \u200b\u914d\u7f6e\u200b\uff1a</p> <pre><code>```yaml\ncompute_environment: LOCAL_MACHINE                                                                                             \ndeepspeed_config:                                                                                                              \n  gradient_accumulation_steps: 1\n  gradient_clipping: 0.7\n  offload_optimizer_device: cpu\n  offload_param_device: cpu\n  zero3_init_flag: true\n  zero_stage: 2\ndistributed_type: DEEPSPEED\ndowncast_bf16: 'no'\nmachine_rank: 0\nmain_training_function: main\nmixed_precision: bf16\nnum_machines: 1\nnum_processes: 4\nrdzv_backend: static\nsame_network: true\ntpu_env: []\ntpu_use_cluster: false\ntpu_use_sudo: false\nuse_cpu: false\n```\n</code></pre> <ol> <li>\u200b\u4f7f\u7528\u200baccelerate\u200b\u914d\u7f6e\u6587\u4ef6\u200b\u53c2\u6570\u200b\u6216\u200b\u542f\u52a8\u5668\u200b\u53c2\u6570\u200b\u4ee5\u5916\u200b\u7684\u200b\u53c2\u6570\u200b\u8fd0\u884c\u200bTrainer\u200b\u811a\u672c\u200b\u3002\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u4e00\u4e2a\u200b\u4f7f\u7528\u200b\u4e0a\u8ff0\u200bFSDP\u200b\u914d\u7f6e\u200b\u4ece\u200baccelerate\u200b\u542f\u52a8\u5668\u200b\u8fd0\u884c\u200b<code>run_glue.py</code>\u200b\u7684\u200b\u793a\u4f8b\u200b\u3002</li> </ol> <pre><code>cd transformers\n\naccelerate launch \\\n./examples/pytorch/text-classification/run_glue.py \\\n--model_name_or_path bert-base-cased \\\n--task_name $TASK_NAME \\\n--do_train \\\n--do_eval \\\n--max_seq_length 128 \\\n--per_device_train_batch_size 16 \\\n--learning_rate 5e-5 \\\n--num_train_epochs 3 \\\n--output_dir /tmp/$TASK_NAME/ \\\n--overwrite_output_dir\n</code></pre> <ol> <li>\u200b\u4f60\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u4f7f\u7528\u200b<code>accelerate launch</code>\u200b\u7684\u200bcmd\u200b\u53c2\u6570\u200b\u3002\u200b\u4e0a\u9762\u200b\u7684\u200b\u793a\u4f8b\u200b\u5c06\u200b\u6620\u5c04\u200b\u5230\u200b\uff1a</li> </ol> <pre><code>cd transformers\n\naccelerate launch --num_processes=2 \\\n--use_fsdp \\\n--mixed_precision=bf16 \\\n--fsdp_auto_wrap_policy=TRANSFORMER_BASED_WRAP  \\\n--fsdp_transformer_layer_cls_to_wrap=\"BertLayer\" \\\n--fsdp_sharding_strategy=1 \\\n--fsdp_state_dict_type=FULL_STATE_DICT \\\n./examples/pytorch/text-classification/run_glue.py\n--model_name_or_path bert-base-cased \\\n--task_name $TASK_NAME \\\n--do_train \\\n--do_eval \\\n--max_seq_length 128 \\\n--per_device_train_batch_size 16 \\\n--learning_rate 5e-5 \\\n--num_train_epochs 3 \\\n--output_dir /tmp/$TASK_NAME/ \\\n--overwrite_output_dir\n</code></pre> <p>\u200b\u6709\u5173\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b \ud83e\udd17 Accelerate CLI \u200b\u6307\u5357\u200b\uff1a\u200b\u542f\u52a8\u200b\u60a8\u200b\u7684\u200b \ud83e\udd17 Accelerate \u200b\u811a\u672c\u200b\u3002</p> <p>\u200b\u5df2\u200b\u79fb\u52a8\u200b\u7684\u200b\u90e8\u5206\u200b\uff1a</p> <p>[ DeepSpeed | Installation | Deployment with multiple GPUs | Deployment with one GPU | Deployment in Notebooks | Configuration | Passing Configuration | Shared Configuration | ZeRO | ZeRO-2 Config | ZeRO-3 Config | NVMe Support | ZeRO-2 vs ZeRO-3 Performance | ZeRO-2 Example | ZeRO-3 Example | Optimizer | Scheduler | fp32 Precision | Automatic Mixed Precision | Batch Size | Gradient Accumulation | Gradient Clipping | Getting The Model Weights Out]</p>"},{"location":"main_classes/trainer/#neftune","title":"\u901a\u8fc7\u200b NEFTune \u200b\u63d0\u5347\u200b\u5fae\u8c03\u200b\u6027\u80fd","text":"<p>NEFTune \u200b\u662f\u200b\u4e00\u79cd\u200b\u63d0\u5347\u200b\u804a\u5929\u200b\u6a21\u578b\u200b\u6027\u80fd\u200b\u7684\u200b\u6280\u672f\u200b\uff0c\u200b\u7531\u200b Jain \u200b\u7b49\u200b\u4eba\u200b\u5728\u200b\u8bba\u6587\u200b\u201cNEFTune: Noisy Embeddings Improve Instruction Finetuning\u201d \u200b\u4e2d\u200b\u5f15\u5165\u200b\u3002\u200b\u8be5\u200b\u6280\u672f\u200b\u5728\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u5411\u200bembedding\u200b\u5411\u91cf\u200b\u6dfb\u52a0\u200b\u566a\u97f3\u200b\u3002\u200b\u6839\u636e\u200b\u8bba\u6587\u200b\u6458\u8981\u200b\uff1a</p> <p>\u200b\u4f7f\u7528\u200b Alpaca \u200b\u5bf9\u200b LLaMA-2-7B \u200b\u8fdb\u884c\u200b\u6807\u51c6\u200b\u5fae\u8c03\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5728\u200b AlpacaEval \u200b\u4e0a\u200b\u8fbe\u5230\u200b 29.79%\uff0c\u200b\u800c\u200b\u4f7f\u7528\u200b\u5e26\u6709\u200b\u566a\u97f3\u200bembedding\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u6027\u80fd\u200b\u63d0\u9ad8\u200b\u81f3\u200b 64.69%\u3002NEFTune \u200b\u8fd8\u200b\u5728\u200bmodern instruction\u200b\u6570\u636e\u200b\u96c6\u4e0a\u200b\u5927\u5927\u200b\u4f18\u4e8e\u200b\u57fa\u7ebf\u200b\u3002Evol-Instruct \u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u8868\u73b0\u200b\u63d0\u9ad8\u200b\u4e86\u200b 10%\uff0cShareGPT \u200b\u63d0\u9ad8\u200b\u4e86\u200b 8%\uff0cOpenPlatypus \u200b\u63d0\u9ad8\u200b\u4e86\u200b 8%\u3002\u200b\u5373\u4f7f\u200b\u50cf\u200b LLaMA-2-Chat \u200b\u8fd9\u6837\u200b\u901a\u8fc7\u200b RLHF \u200b\u8fdb\u4e00\u6b65\u200b\u7ec6\u5316\u200b\u7684\u200b\u5f3a\u5927\u200b\u6a21\u578b\u200b\uff0c\u200b\u901a\u8fc7\u200b NEFTune \u200b\u7684\u200b\u989d\u5916\u200b\u8bad\u7ec3\u200b\u4e5f\u200b\u80fd\u200b\u53d7\u76ca\u200b\u3002</p> <p>\u200b\u8981\u200b\u5728\u200b <code>Trainer</code> \u200b\u4e2d\u200b\u4f7f\u7528\u200b\u5b83\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u5728\u200b\u521b\u5efa\u200b <code>TrainingArguments</code> \u200b\u5b9e\u4f8b\u200b\u65f6\u200b\u4f20\u9012\u200b <code>neftune_noise_alpha</code>\u3002\u200b\u8bf7\u200b\u6ce8\u610f\u200b\uff0c\u200b\u4e3a\u4e86\u200b\u907f\u514d\u200b\u4efb\u4f55\u200b\u610f\u5916\u200b\u884c\u4e3a\u200b\uff0cNEFTune\u200b\u5728\u200b\u8bad\u7ec3\u200b\u540e\u200b\u88ab\u200b\u7981\u6b62\u200b\uff0c\u200b\u4ee5\u6b64\u200b\u6062\u590d\u200b\u539f\u59cb\u200b\u7684\u200bembedding\u200b\u5c42\u200b\u3002</p> <pre><code>from transformers import Trainer, TrainingArguments\n\nargs = TrainingArguments(..., neftune_noise_alpha=0.1)\ntrainer = Trainer(..., args=args)\n\n...\n\ntrainer.train()\n</code></pre>"}]}