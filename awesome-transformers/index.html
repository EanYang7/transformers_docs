
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="transformers_docs">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/transformers_docs/awesome-transformers/">
      
      
        <link rel="prev" href="../autoclass_tutorial/">
      
      
        <link rel="next" href="../big_models/">
      
      
      <link rel="icon" href="../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>Awesome projects built with Transformers - Transformers 文档</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#awesome-projects-built-with-transformers" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="Transformers 文档" class="md-header__button md-logo" aria-label="Transformers 文档" data-md-component="logo">
      
  <img src="../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Transformers 文档
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Awesome projects built with Transformers
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/transformers_docs" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Transformers 文档" class="md-nav__button md-logo" aria-label="Transformers 文档" data-md-component="logo">
      
  <img src="../assets/logo.jpg" alt="logo">

    </a>
    Transformers 文档
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/transformers_docs" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../autoclass_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autoclass tutorial
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Awesome projects built with Transformers
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Awesome projects built with Transformers
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#gpt4all" class="md-nav__link">
    <span class="md-ellipsis">
      gpt4all
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recommenders" class="md-nav__link">
    <span class="md-ellipsis">
      recommenders
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lama-cleaner" class="md-nav__link">
    <span class="md-ellipsis">
      lama-cleaner
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flair" class="md-nav__link">
    <span class="md-ellipsis">
      flair
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindsdb" class="md-nav__link">
    <span class="md-ellipsis">
      mindsdb
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langchain" class="md-nav__link">
    <span class="md-ellipsis">
      langchain
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llamaindex" class="md-nav__link">
    <span class="md-ellipsis">
      LlamaIndex
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parlai" class="md-nav__link">
    <span class="md-ellipsis">
      ParlAI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentence-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      sentence-transformers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ludwig" class="md-nav__link">
    <span class="md-ellipsis">
      ludwig
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#invokeai" class="md-nav__link">
    <span class="md-ellipsis">
      InvokeAI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#paddlenlp" class="md-nav__link">
    <span class="md-ellipsis">
      PaddleNLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stanza" class="md-nav__link">
    <span class="md-ellipsis">
      stanza
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deeppavlov" class="md-nav__link">
    <span class="md-ellipsis">
      DeepPavlov
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alpaca-lora" class="md-nav__link">
    <span class="md-ellipsis">
      alpaca-lora
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#imagen-pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      imagen-pytorch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adapter-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      adapter-transformers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nemo" class="md-nav__link">
    <span class="md-ellipsis">
      NeMo
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#runhouse" class="md-nav__link">
    <span class="md-ellipsis">
      Runhouse
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#monai" class="md-nav__link">
    <span class="md-ellipsis">
      MONAI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simpletransformers" class="md-nav__link">
    <span class="md-ellipsis">
      simpletransformers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jarvis" class="md-nav__link">
    <span class="md-ellipsis">
      JARVIS
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformersjs" class="md-nav__link">
    <span class="md-ellipsis">
      transformers.js
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bumblebee" class="md-nav__link">
    <span class="md-ellipsis">
      bumblebee
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#argilla" class="md-nav__link">
    <span class="md-ellipsis">
      argilla
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#haystack" class="md-nav__link">
    <span class="md-ellipsis">
      haystack
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spacy" class="md-nav__link">
    <span class="md-ellipsis">
      spaCy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speechbrain" class="md-nav__link">
    <span class="md-ellipsis">
      speechbrain
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skorch" class="md-nav__link">
    <span class="md-ellipsis">
      skorch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertviz" class="md-nav__link">
    <span class="md-ellipsis">
      bertviz
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mesh-transformer-jax" class="md-nav__link">
    <span class="md-ellipsis">
      mesh-transformer-jax
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deepchem" class="md-nav__link">
    <span class="md-ellipsis">
      deepchem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#opennre" class="md-nav__link">
    <span class="md-ellipsis">
      OpenNRE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pycorrector" class="md-nav__link">
    <span class="md-ellipsis">
      pycorrector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nlpaug" class="md-nav__link">
    <span class="md-ellipsis">
      nlpaug
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dream-textures" class="md-nav__link">
    <span class="md-ellipsis">
      dream-textures
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seldon-core" class="md-nav__link">
    <span class="md-ellipsis">
      seldon-core
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#open_model_zoo" class="md-nav__link">
    <span class="md-ellipsis">
      open_model_zoo
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ml-stable-diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      ml-stable-diffusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stable-dreamfusion" class="md-nav__link">
    <span class="md-ellipsis">
      stable-dreamfusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai" class="md-nav__link">
    <span class="md-ellipsis">
      txtai
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#djl" class="md-nav__link">
    <span class="md-ellipsis">
      djl
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm-evaluation-harness" class="md-nav__link">
    <span class="md-ellipsis">
      lm-evaluation-harness
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpt-neox" class="md-nav__link">
    <span class="md-ellipsis">
      gpt-neox
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#muzic" class="md-nav__link">
    <span class="md-ellipsis">
      muzic
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dalle-flow" class="md-nav__link">
    <span class="md-ellipsis">
      dalle-flow
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lightseq" class="md-nav__link">
    <span class="md-ellipsis">
      lightseq
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latex-ocr" class="md-nav__link">
    <span class="md-ellipsis">
      LaTeX-OCR
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#open_clip" class="md-nav__link">
    <span class="md-ellipsis">
      open_clip
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dalle-playground" class="md-nav__link">
    <span class="md-ellipsis">
      dalle-playground
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fedml" class="md-nav__link">
    <span class="md-ellipsis">
      FedML
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpt-code-clippy" class="md-nav__link">
    <span class="md-ellipsis">
      gpt-code-clippy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#textattack" class="md-nav__link">
    <span class="md-ellipsis">
      TextAttack
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openprompt" class="md-nav__link">
    <span class="md-ellipsis">
      OpenPrompt
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-generation-webui" class="md-nav__link">
    <span class="md-ellipsis">
      text-generation-webui
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#libra" class="md-nav__link">
    <span class="md-ellipsis">
      libra
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alibi" class="md-nav__link">
    <span class="md-ellipsis">
      alibi
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tortoise-tts" class="md-nav__link">
    <span class="md-ellipsis">
      tortoise-tts
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flower" class="md-nav__link">
    <span class="md-ellipsis">
      flower
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fast-bert" class="md-nav__link">
    <span class="md-ellipsis">
      fast-bert
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#towhee" class="md-nav__link">
    <span class="md-ellipsis">
      towhee
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alibi-detect" class="md-nav__link">
    <span class="md-ellipsis">
      alibi-detect
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#farm" class="md-nav__link">
    <span class="md-ellipsis">
      FARM
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aitextgen" class="md-nav__link">
    <span class="md-ellipsis">
      aitextgen
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#diffgram" class="md-nav__link">
    <span class="md-ellipsis">
      diffgram
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ecco" class="md-nav__link">
    <span class="md-ellipsis">
      ecco
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#s3prl" class="md-nav__link">
    <span class="md-ellipsis">
      s3prl
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ru-dalle" class="md-nav__link">
    <span class="md-ellipsis">
      ru-dalle
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deepke" class="md-nav__link">
    <span class="md-ellipsis">
      DeepKE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nebuly" class="md-nav__link">
    <span class="md-ellipsis">
      Nebuly
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#imaginairy" class="md-nav__link">
    <span class="md-ellipsis">
      imaginAIry
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparseml" class="md-nav__link">
    <span class="md-ellipsis">
      sparseml
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#opacus" class="md-nav__link">
    <span class="md-ellipsis">
      opacus
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lavis" class="md-nav__link">
    <span class="md-ellipsis">
      LAVIS
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#buzz" class="md-nav__link">
    <span class="md-ellipsis">
      buzz
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rust-bert" class="md-nav__link">
    <span class="md-ellipsis">
      rust-bert
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#easynlp" class="md-nav__link">
    <span class="md-ellipsis">
      EasyNLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#turbotransformers" class="md-nav__link">
    <span class="md-ellipsis">
      TurboTransformers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hivemind" class="md-nav__link">
    <span class="md-ellipsis">
      hivemind
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#docquery" class="md-nav__link">
    <span class="md-ellipsis">
      docquery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#codegeex" class="md-nav__link">
    <span class="md-ellipsis">
      CodeGeeX
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ktrain" class="md-nav__link">
    <span class="md-ellipsis">
      ktrain
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fastdeploy" class="md-nav__link">
    <span class="md-ellipsis">
      FastDeploy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#underthesea" class="md-nav__link">
    <span class="md-ellipsis">
      underthesea
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hasktorch" class="md-nav__link">
    <span class="md-ellipsis">
      hasktorch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#donut" class="md-nav__link">
    <span class="md-ellipsis">
      donut
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformers-interpret" class="md-nav__link">
    <span class="md-ellipsis">
      transformers-interpret
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mlrun" class="md-nav__link">
    <span class="md-ellipsis">
      mlrun
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#federatedscope" class="md-nav__link">
    <span class="md-ellipsis">
      FederatedScope
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pythainlp" class="md-nav__link">
    <span class="md-ellipsis">
      pythainlp
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flagai" class="md-nav__link">
    <span class="md-ellipsis">
      FlagAI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pyserini" class="md-nav__link">
    <span class="md-ellipsis">
      pyserini
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baal" class="md-nav__link">
    <span class="md-ellipsis">
      baal
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cleanlab" class="md-nav__link">
    <span class="md-ellipsis">
      cleanlab
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bentoml" class="md-nav__link">
    <span class="md-ellipsis">
      BentoML
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-efficient-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      LLaMA-Efficient-Tuning
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../big_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Big models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../debugging/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Debugging
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../hpo_train/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hpo train
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../llm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llm tutorial
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../model_sharing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model sharing
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Peft
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../perf_hardware/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Perf hardware
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../perf_torch_compile/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Perf torch compile
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../performance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Performance
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../run_scripts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Run scripts
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../tf_xla/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tf xla
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../tokenizer_summary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tokenizer summary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    1 开始使用
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../2-%E6%95%99%E7%A8%8B/accelerate/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    2 教程
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    3 开发者指南
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    4 概念指南
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../main_classes/deepspeed/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Main classes
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#gpt4all" class="md-nav__link">
    <span class="md-ellipsis">
      gpt4all
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recommenders" class="md-nav__link">
    <span class="md-ellipsis">
      recommenders
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lama-cleaner" class="md-nav__link">
    <span class="md-ellipsis">
      lama-cleaner
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flair" class="md-nav__link">
    <span class="md-ellipsis">
      flair
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindsdb" class="md-nav__link">
    <span class="md-ellipsis">
      mindsdb
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#langchain" class="md-nav__link">
    <span class="md-ellipsis">
      langchain
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llamaindex" class="md-nav__link">
    <span class="md-ellipsis">
      LlamaIndex
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#parlai" class="md-nav__link">
    <span class="md-ellipsis">
      ParlAI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sentence-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      sentence-transformers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ludwig" class="md-nav__link">
    <span class="md-ellipsis">
      ludwig
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#invokeai" class="md-nav__link">
    <span class="md-ellipsis">
      InvokeAI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#paddlenlp" class="md-nav__link">
    <span class="md-ellipsis">
      PaddleNLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stanza" class="md-nav__link">
    <span class="md-ellipsis">
      stanza
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deeppavlov" class="md-nav__link">
    <span class="md-ellipsis">
      DeepPavlov
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alpaca-lora" class="md-nav__link">
    <span class="md-ellipsis">
      alpaca-lora
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#imagen-pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      imagen-pytorch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adapter-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      adapter-transformers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nemo" class="md-nav__link">
    <span class="md-ellipsis">
      NeMo
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#runhouse" class="md-nav__link">
    <span class="md-ellipsis">
      Runhouse
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#monai" class="md-nav__link">
    <span class="md-ellipsis">
      MONAI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simpletransformers" class="md-nav__link">
    <span class="md-ellipsis">
      simpletransformers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jarvis" class="md-nav__link">
    <span class="md-ellipsis">
      JARVIS
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformersjs" class="md-nav__link">
    <span class="md-ellipsis">
      transformers.js
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bumblebee" class="md-nav__link">
    <span class="md-ellipsis">
      bumblebee
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#argilla" class="md-nav__link">
    <span class="md-ellipsis">
      argilla
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#haystack" class="md-nav__link">
    <span class="md-ellipsis">
      haystack
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spacy" class="md-nav__link">
    <span class="md-ellipsis">
      spaCy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speechbrain" class="md-nav__link">
    <span class="md-ellipsis">
      speechbrain
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skorch" class="md-nav__link">
    <span class="md-ellipsis">
      skorch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertviz" class="md-nav__link">
    <span class="md-ellipsis">
      bertviz
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mesh-transformer-jax" class="md-nav__link">
    <span class="md-ellipsis">
      mesh-transformer-jax
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deepchem" class="md-nav__link">
    <span class="md-ellipsis">
      deepchem
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#opennre" class="md-nav__link">
    <span class="md-ellipsis">
      OpenNRE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pycorrector" class="md-nav__link">
    <span class="md-ellipsis">
      pycorrector
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nlpaug" class="md-nav__link">
    <span class="md-ellipsis">
      nlpaug
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dream-textures" class="md-nav__link">
    <span class="md-ellipsis">
      dream-textures
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seldon-core" class="md-nav__link">
    <span class="md-ellipsis">
      seldon-core
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#open_model_zoo" class="md-nav__link">
    <span class="md-ellipsis">
      open_model_zoo
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ml-stable-diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      ml-stable-diffusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stable-dreamfusion" class="md-nav__link">
    <span class="md-ellipsis">
      stable-dreamfusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#txtai" class="md-nav__link">
    <span class="md-ellipsis">
      txtai
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#djl" class="md-nav__link">
    <span class="md-ellipsis">
      djl
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lm-evaluation-harness" class="md-nav__link">
    <span class="md-ellipsis">
      lm-evaluation-harness
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpt-neox" class="md-nav__link">
    <span class="md-ellipsis">
      gpt-neox
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#muzic" class="md-nav__link">
    <span class="md-ellipsis">
      muzic
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dalle-flow" class="md-nav__link">
    <span class="md-ellipsis">
      dalle-flow
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lightseq" class="md-nav__link">
    <span class="md-ellipsis">
      lightseq
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latex-ocr" class="md-nav__link">
    <span class="md-ellipsis">
      LaTeX-OCR
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#open_clip" class="md-nav__link">
    <span class="md-ellipsis">
      open_clip
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dalle-playground" class="md-nav__link">
    <span class="md-ellipsis">
      dalle-playground
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fedml" class="md-nav__link">
    <span class="md-ellipsis">
      FedML
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpt-code-clippy" class="md-nav__link">
    <span class="md-ellipsis">
      gpt-code-clippy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#textattack" class="md-nav__link">
    <span class="md-ellipsis">
      TextAttack
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openprompt" class="md-nav__link">
    <span class="md-ellipsis">
      OpenPrompt
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-generation-webui" class="md-nav__link">
    <span class="md-ellipsis">
      text-generation-webui
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#libra" class="md-nav__link">
    <span class="md-ellipsis">
      libra
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alibi" class="md-nav__link">
    <span class="md-ellipsis">
      alibi
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tortoise-tts" class="md-nav__link">
    <span class="md-ellipsis">
      tortoise-tts
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flower" class="md-nav__link">
    <span class="md-ellipsis">
      flower
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fast-bert" class="md-nav__link">
    <span class="md-ellipsis">
      fast-bert
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#towhee" class="md-nav__link">
    <span class="md-ellipsis">
      towhee
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alibi-detect" class="md-nav__link">
    <span class="md-ellipsis">
      alibi-detect
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#farm" class="md-nav__link">
    <span class="md-ellipsis">
      FARM
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#aitextgen" class="md-nav__link">
    <span class="md-ellipsis">
      aitextgen
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#diffgram" class="md-nav__link">
    <span class="md-ellipsis">
      diffgram
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ecco" class="md-nav__link">
    <span class="md-ellipsis">
      ecco
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#s3prl" class="md-nav__link">
    <span class="md-ellipsis">
      s3prl
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ru-dalle" class="md-nav__link">
    <span class="md-ellipsis">
      ru-dalle
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deepke" class="md-nav__link">
    <span class="md-ellipsis">
      DeepKE
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nebuly" class="md-nav__link">
    <span class="md-ellipsis">
      Nebuly
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#imaginairy" class="md-nav__link">
    <span class="md-ellipsis">
      imaginAIry
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sparseml" class="md-nav__link">
    <span class="md-ellipsis">
      sparseml
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#opacus" class="md-nav__link">
    <span class="md-ellipsis">
      opacus
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lavis" class="md-nav__link">
    <span class="md-ellipsis">
      LAVIS
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#buzz" class="md-nav__link">
    <span class="md-ellipsis">
      buzz
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rust-bert" class="md-nav__link">
    <span class="md-ellipsis">
      rust-bert
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#easynlp" class="md-nav__link">
    <span class="md-ellipsis">
      EasyNLP
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#turbotransformers" class="md-nav__link">
    <span class="md-ellipsis">
      TurboTransformers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hivemind" class="md-nav__link">
    <span class="md-ellipsis">
      hivemind
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#docquery" class="md-nav__link">
    <span class="md-ellipsis">
      docquery
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#codegeex" class="md-nav__link">
    <span class="md-ellipsis">
      CodeGeeX
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ktrain" class="md-nav__link">
    <span class="md-ellipsis">
      ktrain
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fastdeploy" class="md-nav__link">
    <span class="md-ellipsis">
      FastDeploy
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#underthesea" class="md-nav__link">
    <span class="md-ellipsis">
      underthesea
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hasktorch" class="md-nav__link">
    <span class="md-ellipsis">
      hasktorch
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#donut" class="md-nav__link">
    <span class="md-ellipsis">
      donut
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformers-interpret" class="md-nav__link">
    <span class="md-ellipsis">
      transformers-interpret
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mlrun" class="md-nav__link">
    <span class="md-ellipsis">
      mlrun
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#federatedscope" class="md-nav__link">
    <span class="md-ellipsis">
      FederatedScope
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pythainlp" class="md-nav__link">
    <span class="md-ellipsis">
      pythainlp
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#flagai" class="md-nav__link">
    <span class="md-ellipsis">
      FlagAI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pyserini" class="md-nav__link">
    <span class="md-ellipsis">
      pyserini
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#baal" class="md-nav__link">
    <span class="md-ellipsis">
      baal
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cleanlab" class="md-nav__link">
    <span class="md-ellipsis">
      cleanlab
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bentoml" class="md-nav__link">
    <span class="md-ellipsis">
      BentoML
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#llama-efficient-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      LLaMA-Efficient-Tuning
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/transformers_docs/tree/main/docs/awesome-transformers.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/transformers_docs/tree/main/docs/awesome-transformers.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="awesome-projects-built-with-transformers">Awesome projects built with Transformers<a class="headerlink" href="#awesome-projects-built-with-transformers" title="Permanent link">⚓︎</a></h1>
<p>This page lists awesome projects built on top of Transformers. Transformers is more than a toolkit to use pretrained
models: it's a community of projects built around it and the Hugging Face Hub. We want Transformers to enable
developers, researchers, students, professors, engineers, and anyone else to build their dream projects.</p>
<p>In this list, we showcase incredibly impactful and novel projects that have pushed the field forward. We celebrate
100 of these projects as we reach the milestone of 100k stars as a community; but we're very open to pull requests
adding other projects to the list. If you believe a project should be here and it's not, then please, open a PR 
to add it.</p>
<h2 id="gpt4all"><a href="https://github.com/nomic-ai/gpt4all">gpt4all</a><a class="headerlink" href="#gpt4all" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/nomic-ai/gpt4all">gpt4all</a> is an ecosystem of open-source chatbots trained on massive collections of clean assistant data including code, stories and dialogue. It offers open-source, large language models such as LLaMA and GPT-J trained in an assistant-style.</p>
<p>Keywords: Open-source, LLaMa, GPT-J, instruction, assistant</p>
<h2 id="recommenders"><a href="https://github.com/microsoft/recommenders">recommenders</a><a class="headerlink" href="#recommenders" title="Permanent link">⚓︎</a></h2>
<p>This repository contains examples and best practices for building recommendation systems, provided as Jupyter notebooks. It goes over several aspects required to build efficient recommendation systems: data preparation, modeling, evaluation, model selection &amp; optimization, as well as operationalization</p>
<p>Keywords: Recommender systems, AzureML</p>
<h2 id="lama-cleaner"><a href="https://github.com/Sanster/lama-cleaner">lama-cleaner</a><a class="headerlink" href="#lama-cleaner" title="Permanent link">⚓︎</a></h2>
<p>Image inpainting tool powered by Stable Diffusion. Remove any unwanted object, defect, people from your pictures or erase and replace anything on your pictures.</p>
<p>Keywords: inpainting, SD, Stable Diffusion</p>
<h2 id="flair"><a href="https://github.com/flairNLP/flair">flair</a><a class="headerlink" href="#flair" title="Permanent link">⚓︎</a></h2>
<p>FLAIR is a powerful PyTorch NLP framework, convering several important tasks: NER, sentiment-analysis, part-of-speech tagging, text and document embeddings, among other things.</p>
<p>Keywords: NLP, text embedding, document embedding, biomedical, NER, PoS, sentiment-analysis</p>
<h2 id="mindsdb"><a href="https://github.com/mindsdb/mindsdb">mindsdb</a><a class="headerlink" href="#mindsdb" title="Permanent link">⚓︎</a></h2>
<p>MindsDB is a low-code ML platform, which automates and integrates several ML frameworks into the data stack as "AI Tables" to streamline the integration of AI into applications, making it accessible to developers of all skill levels.</p>
<p>Keywords: Database, low-code, AI table</p>
<h2 id="langchain"><a href="https://github.com/hwchase17/langchain">langchain</a><a class="headerlink" href="#langchain" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/hwchase17/langchain">langchain</a> is aimed at assisting in the development of apps merging both LLMs and other sources of knowledge. The library allows chaining calls to applications, creating a sequence across many tools.</p>
<p>Keywords: LLMs, Large Language Models, Agents, Chains</p>
<h2 id="llamaindex"><a href="https://github.com/jerryjliu/llama_index">LlamaIndex</a><a class="headerlink" href="#llamaindex" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/jerryjliu/llama_index">LlamaIndex</a> is a project that provides a central interface to connect your LLM's with external data. It provides various kinds of indices and retreival mechanisms to perform different LLM tasks and obtain knowledge-augmented results.</p>
<p>Keywords: LLMs, Large Language Models, Data Retrieval, Indices, Knowledge Augmentation </p>
<h2 id="parlai"><a href="https://github.com/facebookresearch/ParlAI">ParlAI</a><a class="headerlink" href="#parlai" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/facebookresearch/ParlAI">ParlAI</a> is a python framework for sharing, training and testing dialogue models, from open-domain chitchat, to task-oriented dialogue, to visual question answering. It provides more than 100 datasets under the same API, a large zoo of pretrained models, a set of agents, and has several integrations.</p>
<p>Keywords: Dialogue, Chatbots, VQA, Datasets, Agents</p>
<h2 id="sentence-transformers"><a href="https://github.com/UKPLab/sentence-transformers">sentence-transformers</a><a class="headerlink" href="#sentence-transformers" title="Permanent link">⚓︎</a></h2>
<p>This framework provides an easy method to compute dense vector representations for sentences, paragraphs, and images. The models are based on transformer networks like BERT / RoBERTa / XLM-RoBERTa etc. and achieve state-of-the-art performance in various task. Text is embedding in vector space such that similar text is close and can efficiently be found using cosine similarity.</p>
<p>Keywords: Dense vector representations, Text embeddings, Sentence embeddings</p>
<h2 id="ludwig"><a href="https://github.com/ludwig-ai/ludwig">ludwig</a><a class="headerlink" href="#ludwig" title="Permanent link">⚓︎</a></h2>
<p>Ludwig is a declarative machine learning framework that makes it easy to define machine learning pipelines using a simple and flexible data-driven configuration system. Ludwig is targeted at a wide variety of AI tasks. It provides a data-driven configuration system, training, prediction, and evaluation scripts, as well as a programmatic API.</p>
<p>Keywords: Declarative, Data-driven, ML Framework</p>
<h2 id="invokeai"><a href="https://github.com/invoke-ai/InvokeAI">InvokeAI</a><a class="headerlink" href="#invokeai" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/invoke-ai/InvokeAI">InvokeAI</a> is an engine for Stable Diffusion models, aimed at professionals, artists, and enthusiasts. It leverages the latest AI-driven technologies through CLI as well as a WebUI.</p>
<p>Keywords: Stable-Diffusion, WebUI, CLI</p>
<h2 id="paddlenlp"><a href="https://github.com/PaddlePaddle/PaddleNLP">PaddleNLP</a><a class="headerlink" href="#paddlenlp" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/PaddlePaddle/PaddleNLP">PaddleNLP</a> is an easy-to-use and powerful NLP library particularly targeted at the Chinese languages. It has support for multiple pre-trained model zoos, and supports a wide-range of NLP tasks from research to industrial applications.</p>
<p>Keywords: NLP, Chinese, Research, Industry</p>
<h2 id="stanza"><a href="https://github.com/stanfordnlp/stanza">stanza</a><a class="headerlink" href="#stanza" title="Permanent link">⚓︎</a></h2>
<p>The Stanford NLP Group's official Python NLP library. It contains support for running various accurate natural language processing tools on 60+ languages and for accessing the Java Stanford CoreNLP software from Python.</p>
<p>Keywords: NLP, Multilingual, CoreNLP</p>
<h2 id="deeppavlov"><a href="https://github.com/deeppavlov/DeepPavlov">DeepPavlov</a><a class="headerlink" href="#deeppavlov" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/deeppavlov/DeepPavlov">DeepPavlov</a> is an open-source conversational AI library. It is designed for the development of production ready chat-bots and complex conversational systems, as well as research in the area of NLP and, particularly, of dialog systems.</p>
<p>Keywords: Conversational, Chatbot, Dialog</p>
<h2 id="alpaca-lora"><a href="https://github.com/tloen/alpaca-lora">alpaca-lora</a><a class="headerlink" href="#alpaca-lora" title="Permanent link">⚓︎</a></h2>
<p>Alpaca-lora contains code for reproducing the Stanford Alpaca results using low-rank adaptation (LoRA). The repository provides training (fine-tuning) as well as generation scripts.</p>
<p>Keywords: LoRA, Parameter-efficient fine-tuning</p>
<h2 id="imagen-pytorch"><a href="https://github.com/lucidrains/imagen-pytorch">imagen-pytorch</a><a class="headerlink" href="#imagen-pytorch" title="Permanent link">⚓︎</a></h2>
<p>An open-source Implementation of Imagen, Google's closed-source Text-to-Image Neural Network that beats DALL-E2. As of release, it is the new SOTA for text-to-image synthesis.</p>
<p>Keywords: Imagen, Text-to-image</p>
<h2 id="adapter-transformers"><a href="https://github.com/adapter-hub/adapter-transformers">adapter-transformers</a><a class="headerlink" href="#adapter-transformers" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/adapter-hub/adapter-transformers">adapter-transformers</a> is an extension of HuggingFace's Transformers library, integrating adapters into state-of-the-art language models by incorporating AdapterHub, a central repository for pre-trained adapter modules. It is a drop-in replacement for transformers, which is regularly updated to stay up-to-date with the developments of transformers.</p>
<p>Keywords: Adapters, LoRA, Parameter-efficient fine-tuning, Hub</p>
<h2 id="nemo"><a href="https://github.com/NVIDIA/NeMo">NeMo</a><a class="headerlink" href="#nemo" title="Permanent link">⚓︎</a></h2>
<p>NVIDIA <a href="https://github.com/NVIDIA/NeMo">NeMo</a> is a conversational AI toolkit built for researchers working on automatic speech recognition (ASR), text-to-speech synthesis (TTS), large language models (LLMs), and natural language processing (NLP). The primary objective of <a href="https://github.com/NVIDIA/NeMo">NeMo</a> is to help researchers from industry and academia to reuse prior work (code and pretrained models) and make it easier to create new https://developer.nvidia.com/conversational-ai#started.</p>
<p>Keywords: Conversational, ASR, TTS, LLMs, NLP</p>
<h2 id="runhouse"><a href="https://github.com/run-house/runhouse">Runhouse</a><a class="headerlink" href="#runhouse" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/run-house/runhouse">Runhouse</a> allows to send code and data to any of your compute or data infra, all in Python, and continue to interact with them normally from your existing code and environment. Runhouse developers mention:</p>
<blockquote>
<p>Think of it as an expansion pack to your Python interpreter that lets it take detours to remote machines or manipulate remote data.</p>
</blockquote>
<p>Keywords: MLOps, Infrastructure, Data storage, Modeling</p>
<h2 id="monai"><a href="https://github.com/Project-MONAI/MONAI">MONAI</a><a class="headerlink" href="#monai" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/Project-MONAI/MONAI">MONAI</a> is a PyTorch-based, open-source framework for deep learning in healthcare imaging, part of PyTorch Ecosystem. Its ambitions are:
- developing a community of academic, industrial and clinical researchers collaborating on a common foundation;
- creating state-of-the-art, end-to-end training workflows for healthcare imaging;
- providing researchers with the optimized and standardized way to create and evaluate deep learning models.</p>
<p>Keywords: Healthcare imaging, Training, Evaluation</p>
<h2 id="simpletransformers"><a href="https://github.com/ThilinaRajapakse/simpletransformers">simpletransformers</a><a class="headerlink" href="#simpletransformers" title="Permanent link">⚓︎</a></h2>
<p>Simple Transformers lets you quickly train and evaluate Transformer models. Only 3 lines of code are needed to initialize, train, and evaluate a model. It supports a wide variety of NLP tasks.</p>
<p>Keywords: Framework, simplicity, NLP</p>
<h2 id="jarvis"><a href="https://github.com/microsoft/JARVIS">JARVIS</a><a class="headerlink" href="#jarvis" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/microsoft/JARVIS">JARVIS</a> is a system attempting to merge LLMs such as GPT-4 with the rest of the open-source ML community: leveraging up to 60 downstream models in order to perform tasks identified by the LLM.</p>
<p>Keywords: LLM, Agents, HF Hub</p>
<h2 id="transformersjs"><a href="https://xenova.github.io/transformers.js/">transformers.js</a><a class="headerlink" href="#transformersjs" title="Permanent link">⚓︎</a></h2>
<p><a href="https://xenova.github.io/transformers.js/">transformers.js</a> is a JavaScript library targeted at running models from transformers directly within the browser.</p>
<p>Keywords: Transformers, JavaScript, browser</p>
<h2 id="bumblebee"><a href="https://github.com/elixir-nx/bumblebee">bumblebee</a><a class="headerlink" href="#bumblebee" title="Permanent link">⚓︎</a></h2>
<p>Bumblebee provides pre-trained Neural Network models on top of Axon, a neural networks library for the Elixir language. It includes integration with 🤗 Models, allowing anyone to download and perform Machine Learning tasks with few lines of code.</p>
<p>Keywords: Elixir, Axon</p>
<h2 id="argilla"><a href="https://github.com/argilla-io/argilla">argilla</a><a class="headerlink" href="#argilla" title="Permanent link">⚓︎</a></h2>
<p>Argilla is an open-source platform providing advanced NLP labeling, monitoring, and workspaces. It is compatible with many open source ecosystems such as Hugging Face, Stanza, FLAIR, and others.</p>
<p>Keywords: NLP, Labeling, Monitoring, Workspaces</p>
<h2 id="haystack"><a href="https://github.com/deepset-ai/haystack">haystack</a><a class="headerlink" href="#haystack" title="Permanent link">⚓︎</a></h2>
<p>Haystack is an open source NLP framework to interact with your data using Transformer models and LLMs. It offers production-ready tools to quickly build complex decision making, question answering, semantic search, text generation applications, and more.</p>
<p>Keywords: NLP, Framework, LLM</p>
<h2 id="spacy"><a href="https://github.com/explosion/spaCy">spaCy</a><a class="headerlink" href="#spacy" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/explosion/spaCy">spaCy</a> is a library for advanced Natural Language Processing in Python and Cython. It's built on the very latest research, and was designed from day one to be used in real products. It offers support for transformers models through its third party package, spacy-transformers.</p>
<p>Keywords: NLP, Framework</p>
<h2 id="speechbrain"><a href="https://github.com/speechbrain/speechbrain">speechbrain</a><a class="headerlink" href="#speechbrain" title="Permanent link">⚓︎</a></h2>
<p>SpeechBrain is an open-source and all-in-one conversational AI toolkit based on PyTorch.
The goal is to create a single, flexible, and user-friendly toolkit that can be used to easily develop state-of-the-art speech technologies, including systems for speech recognition, speaker recognition, speech enhancement, speech separation, language identification, multi-microphone signal processing, and many others.</p>
<p>Keywords: Conversational, Speech</p>
<h2 id="skorch"><a href="https://github.com/skorch-dev/skorch">skorch</a><a class="headerlink" href="#skorch" title="Permanent link">⚓︎</a></h2>
<p>Skorch is a scikit-learn compatible neural network library that wraps PyTorch. It has support for models within transformers, and tokenizers from tokenizers.</p>
<p>Keywords: Scikit-Learn, PyTorch</p>
<h2 id="bertviz"><a href="https://github.com/jessevig/bertviz">bertviz</a><a class="headerlink" href="#bertviz" title="Permanent link">⚓︎</a></h2>
<p>BertViz is an interactive tool for visualizing attention in Transformer language models such as BERT, GPT2, or T5. It can be run inside a Jupyter or Colab notebook through a simple Python API that supports most Huggingface models.</p>
<p>Keywords: Visualization, Transformers</p>
<h2 id="mesh-transformer-jax"><a href="https://github.com/kingoflolz/mesh-transformer-jax">mesh-transformer-jax</a><a class="headerlink" href="#mesh-transformer-jax" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/kingoflolz/mesh-transformer-jax">mesh-transformer-jax</a> is a haiku library using the xmap/pjit operators in JAX for model parallelism of transformers. This library is designed for scalability up to approximately 40B parameters on TPUv3s. It was the library used to train the GPT-J model.</p>
<p>Keywords: Haiku, Model parallelism, LLM, TPU</p>
<h2 id="deepchem"><a href="https://github.com/deepchem/deepchem">deepchem</a><a class="headerlink" href="#deepchem" title="Permanent link">⚓︎</a></h2>
<p>DeepChem aims to provide a high quality open-source toolchain that democratizes the use of deep-learning in drug discovery, materials science, quantum chemistry, and biology.</p>
<p>Keywords: Drug discovery, Materials Science, Quantum Chemistry, Biology</p>
<h2 id="opennre"><a href="https://github.com/thunlp/OpenNRE">OpenNRE</a><a class="headerlink" href="#opennre" title="Permanent link">⚓︎</a></h2>
<p>An Open-Source Package for Neural Relation Extraction (NRE). It is targeted at a wide range of users, from newcomers to relation extraction, to developers, researchers, or students.</p>
<p>Keywords: Neural Relation Extraction, Framework</p>
<h2 id="pycorrector"><a href="https://github.com/shibing624/pycorrector">pycorrector</a><a class="headerlink" href="#pycorrector" title="Permanent link">⚓︎</a></h2>
<p>PyCorrector is a Chinese Text Error Correction Tool. It uses a language model to detect errors, pinyin feature and shape feature to correct Chinese text errors. it can be used for Chinese Pinyin and stroke input method.</p>
<p>Keywords: Chinese, Error correction tool, Language model, Pinyin</p>
<h2 id="nlpaug"><a href="https://github.com/makcedward/nlpaug">nlpaug</a><a class="headerlink" href="#nlpaug" title="Permanent link">⚓︎</a></h2>
<p>This python library helps you with augmenting nlp for machine learning projects. It is a lightweight library featuring synthetic data generation for improving model performance, support for audio and text, and compatibility with several ecosystems (scikit-learn, pytorch, tensorflow).</p>
<p>Keywords: Data augmentation, Synthetic data generation, Audio, NLP</p>
<h2 id="dream-textures"><a href="https://github.com/carson-katri/dream-textures">dream-textures</a><a class="headerlink" href="#dream-textures" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/carson-katri/dream-textures">dream-textures</a> is a library targeted at bringing stable-diffusion support within Blender. It supports several use-cases, such as image generation, texture projection, inpainting/outpainting, ControlNet, and upscaling.</p>
<p>Keywords: Stable-Diffusion, Blender</p>
<h2 id="seldon-core"><a href="https://github.com/SeldonIO/seldon-core">seldon-core</a><a class="headerlink" href="#seldon-core" title="Permanent link">⚓︎</a></h2>
<p>Seldon core converts your ML models (Tensorflow, Pytorch, H2o, etc.) or language wrappers (Python, Java, etc.) into production REST/GRPC microservices.
Seldon handles scaling to thousands of production machine learning models and provides advanced machine learning capabilities out of the box including Advanced Metrics, Request Logging, Explainers, Outlier Detectors, A/B Tests, Canaries and more.</p>
<p>Keywords: Microservices, Modeling, Language wrappers</p>
<h2 id="open_model_zoo"><a href="https://github.com/openvinotoolkit/open_model_zoo">open_model_zoo</a><a class="headerlink" href="#open_model_zoo" title="Permanent link">⚓︎</a></h2>
<p>This repository includes optimized deep learning models and a set of demos to expedite development of high-performance deep learning inference applications. Use these free pre-trained models instead of training your own models to speed-up the development and production deployment process.</p>
<p>Keywords: Optimized models, Demos</p>
<h2 id="ml-stable-diffusion"><a href="https://github.com/apple/ml-stable-diffusion">ml-stable-diffusion</a><a class="headerlink" href="#ml-stable-diffusion" title="Permanent link">⚓︎</a></h2>
<p>ML-Stable-Diffusion is a repository by Apple bringing Stable Diffusion support to Core ML, on Apple Silicon devices. It supports stable diffusion checkpoints hosted on the Hugging Face Hub.</p>
<p>Keywords: Stable Diffusion, Apple Silicon, Core ML</p>
<h2 id="stable-dreamfusion"><a href="https://github.com/ashawkey/stable-dreamfusion">stable-dreamfusion</a><a class="headerlink" href="#stable-dreamfusion" title="Permanent link">⚓︎</a></h2>
<p>Stable-Dreamfusion is a pytorch implementation of the text-to-3D model Dreamfusion, powered by the Stable Diffusion text-to-2D model.</p>
<p>Keywords: Text-to-3D, Stable Diffusion</p>
<h2 id="txtai"><a href="https://github.com/neuml/txtai">txtai</a><a class="headerlink" href="#txtai" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/neuml/txtai">txtai</a> is an open-source platform for semantic search and workflows powered by language models. txtai builds embeddings databases, which are a union of vector indexes and relational databases enabling similarity search with SQL. Semantic workflows connect language models together into unified applications.</p>
<p>Keywords: Semantic search, LLM</p>
<h2 id="djl"><a href="https://github.com/deepjavalibrary/djl">djl</a><a class="headerlink" href="#djl" title="Permanent link">⚓︎</a></h2>
<p>Deep Java Library (DJL) is an open-source, high-level, engine-agnostic Java framework for deep learning. DJL is designed to be easy to get started with and simple to use for developers. DJL provides a native Java development experience and functions like any other regular Java library. DJL offers <a href="https://github.com/deepjavalibrary/djl/tree/master/extensions/tokenizers">a Java binding</a> for HuggingFace Tokenizers and easy conversion toolkit for HuggingFace model to deploy in Java.</p>
<p>Keywords: Java, Framework</p>
<h2 id="lm-evaluation-harness"><a href="https://github.com/EleutherAI/lm-evaluation-harness/">lm-evaluation-harness</a><a class="headerlink" href="#lm-evaluation-harness" title="Permanent link">⚓︎</a></h2>
<p>This project provides a unified framework to test generative language models on a large number of different evaluation tasks. It has support for more than 200 tasks, and supports different ecosystems: HF Transformers, GPT-NeoX, DeepSpeed, as well as the OpenAI API.</p>
<p>Keywords: LLM, Evaluation, Few-shot</p>
<h2 id="gpt-neox"><a href="https://github.com/EleutherAI/gpt-neox">gpt-neox</a><a class="headerlink" href="#gpt-neox" title="Permanent link">⚓︎</a></h2>
<p>This repository records EleutherAI's library for training large-scale language models on GPUs. The framework is based on NVIDIA's Megatron Language Model and has been augmented with techniques from DeepSpeed as well as some novel optimizations. It is focused on training multi-billion-parameter models.</p>
<p>Keywords: Training, LLM, Megatron, DeepSpeed</p>
<h2 id="muzic"><a href="https://github.com/microsoft/muzic">muzic</a><a class="headerlink" href="#muzic" title="Permanent link">⚓︎</a></h2>
<p>Muzic is a research project on AI music that empowers music understanding and generation with deep learning and artificial intelligence. Muzic was created by researchers from Microsoft Research Asia.</p>
<p>Keywords: Music understanding, Music generation</p>
<h2 id="dalle-flow"><a href="https://github.com/jina-ai/dalle-flow">dalle-flow</a><a class="headerlink" href="#dalle-flow" title="Permanent link">⚓︎</a></h2>
<p>DALL·E Flow is an interactive workflow for generating high-definition images from a text prompt. Itt leverages DALL·E-Mega, GLID-3 XL, and Stable Diffusion to generate image candidates, and then calls CLIP-as-service to rank the candidates w.r.t. the prompt.
The preferred candidate is fed to GLID-3 XL for diffusion, which often enriches the texture and background. Finally, the candidate is upscaled to 1024x1024 via SwinIR.</p>
<p>Keywords: High-definition image generation, Stable Diffusion, DALL-E Mega, GLID-3 XL, CLIP, SwinIR</p>
<h2 id="lightseq"><a href="https://github.com/bytedance/lightseq">lightseq</a><a class="headerlink" href="#lightseq" title="Permanent link">⚓︎</a></h2>
<p>LightSeq is a high performance training and inference library for sequence processing and generation implemented in CUDA. It enables highly efficient computation of modern NLP and CV models such as BERT, GPT, Transformer, etc. It is therefore best useful for machine translation, text generation, image classification, and other sequence related tasks.</p>
<p>Keywords: Training, Inference, Sequence Processing, Sequence Generation</p>
<h2 id="latex-ocr"><a href="https://github.com/lukas-blecher/LaTeX-OCR">LaTeX-OCR</a><a class="headerlink" href="#latex-ocr" title="Permanent link">⚓︎</a></h2>
<p>The goal of this project is to create a learning based system that takes an image of a math formula and returns corresponding LaTeX code.</p>
<p>Keywords: OCR, LaTeX, Math formula</p>
<h2 id="open_clip"><a href="https://github.com/mlfoundations/open_clip">open_clip</a><a class="headerlink" href="#open_clip" title="Permanent link">⚓︎</a></h2>
<p>OpenCLIP is an open source implementation of OpenAI's CLIP.</p>
<p>The goal of this repository is to enable training models with contrastive image-text supervision, and to investigate their properties such as robustness to distribution shift. 
The starting point is an implementation of CLIP that matches the accuracy of the original CLIP models when trained on the same dataset. </p>
<p>Specifically, a ResNet-50 model trained with this codebase on OpenAI's 15 million image subset of YFCC achieves 32.7% top-1 accuracy on ImageNet.</p>
<p>Keywords: CLIP, Open-source, Contrastive, Image-text</p>
<h2 id="dalle-playground"><a href="https://github.com/saharmor/dalle-playground">dalle-playground</a><a class="headerlink" href="#dalle-playground" title="Permanent link">⚓︎</a></h2>
<p>A playground to generate images from any text prompt using Stable Diffusion and Dall-E mini.</p>
<p>Keywords: WebUI, Stable Diffusion, Dall-E mini</p>
<h2 id="fedml"><a href="https://github.com/FedML-AI/FedML">FedML</a><a class="headerlink" href="#fedml" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/FedML-AI/FedML">FedML</a> is a federated learning and analytics library enabling secure and collaborative machine learning on decentralized data anywhere at any scale.</p>
<p>It supports large-scale cross-silo federated learning, and cross-device federated learning on smartphones/IoTs, and research simulation.</p>
<p>Keywords: Federated Learning, Analytics, Collaborative ML, Decentralized</p>
<h2 id="gpt-code-clippy"><a href="https://github.com/CodedotAl/gpt-code-clippy">gpt-code-clippy</a><a class="headerlink" href="#gpt-code-clippy" title="Permanent link">⚓︎</a></h2>
<p>GPT-Code-Clippy (GPT-CC) is an open source version of GitHub Copilot, a language model -- based on GPT-3, called GPT-Codex -- that is fine-tuned on publicly available code from GitHub.</p>
<p>Keywords: LLM, Code</p>
<h2 id="textattack"><a href="https://github.com/QData/TextAttack">TextAttack</a><a class="headerlink" href="#textattack" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/QData/TextAttack">TextAttack</a> 🐙 is a Python framework for adversarial attacks, data augmentation, and model training in NLP.</p>
<p>Keywords: Adversarial attacks, Data augmentation, NLP</p>
<h2 id="openprompt"><a href="https://github.com/thunlp/OpenPrompt">OpenPrompt</a><a class="headerlink" href="#openprompt" title="Permanent link">⚓︎</a></h2>
<p>Prompt-learning is a paradigm to adapt pre-trained language models (PLMs) to downstream NLP tasks, which modify the input text with a textual template and directly uses PLMs to conduct pre-trained tasks. This library provides a standard, flexible and extensible framework to deploy the prompt-learning pipeline. <a href="https://github.com/thunlp/OpenPrompt">OpenPrompt</a> supports loading PLMs directly from https://github.com/huggingface/transformers.</p>
<h2 id="text-generation-webui"><a href="https://github.com/oobabooga/text-generation-webui/">text-generation-webui</a><a class="headerlink" href="#text-generation-webui" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/oobabooga/text-generation-webui/">text-generation-webui</a> is a Gradio Web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.</p>
<p>Keywords: LLM, WebUI</p>
<h2 id="libra"><a href="https://github.com/Palashio/libra">libra</a><a class="headerlink" href="#libra" title="Permanent link">⚓︎</a></h2>
<p>An ergonomic machine learning <a href="https://github.com/Palashio/libra">libra</a>ry for non-technical users. It focuses on ergonomics and on ensuring that training a model is as simple as it can be.</p>
<p>Keywords: Ergonomic, Non-technical</p>
<h2 id="alibi"><a href="https://github.com/SeldonIO/alibi">alibi</a><a class="headerlink" href="#alibi" title="Permanent link">⚓︎</a></h2>
<p>Alibi is an open source Python library aimed at machine learning model inspection and interpretation. The focus of the library is to provide high-quality implementations of black-box, white-box, local and global explanation methods for classification and regression models.</p>
<p>Keywords: Model inspection, Model interpretation, Black-box, White-box</p>
<h2 id="tortoise-tts"><a href="https://github.com/neonbjb/tortoise-tts">tortoise-tts</a><a class="headerlink" href="#tortoise-tts" title="Permanent link">⚓︎</a></h2>
<p>Tortoise is a text-to-speech program built with the following priorities: strong multi-voice capabilities, and highly realistic prosody and intonation.</p>
<p>Keywords: Text-to-speech</p>
<h2 id="flower"><a href="https://github.com/adap/flower">flower</a><a class="headerlink" href="#flower" title="Permanent link">⚓︎</a></h2>
<p>Flower (flwr) is a framework for building federated learning systems. The design of Flower is based on a few guiding principles: customizability, extendability, framework agnosticity, and ease-of-use.</p>
<p>Keywords: Federated learning systems, Customizable, Extendable, Framework-agnostic, Simplicity</p>
<h2 id="fast-bert"><a href="https://github.com/utterworks/fast-bert">fast-bert</a><a class="headerlink" href="#fast-bert" title="Permanent link">⚓︎</a></h2>
<p>Fast-Bert is a deep learning library that allows developers and data scientists to train and deploy BERT and XLNet based models for natural language processing tasks beginning with Text Classification. It is aimed at simplicity.</p>
<p>Keywords: Deployment, BERT, XLNet</p>
<h2 id="towhee"><a href="https://github.com/towhee-io/towhee">towhee</a><a class="headerlink" href="#towhee" title="Permanent link">⚓︎</a></h2>
<p>Towhee makes it easy to build neural data processing pipelines for AI applications. We provide hundreds of models, algorithms, and transformations that can be used as standard pipeline building blocks. Users can use Towhee's Pythonic API to build a prototype of their pipeline and automatically optimize it for production-ready environments.</p>
<p>Keywords: Data processing pipeline, Optimization</p>
<h2 id="alibi-detect"><a href="https://github.com/SeldonIO/alibi-detect">alibi-detect</a><a class="headerlink" href="#alibi-detect" title="Permanent link">⚓︎</a></h2>
<p>Alibi Detect is an open source Python library focused on outlier, adversarial and drift detection. The package aims to cover both online and offline detectors for tabular data, text, images and time series. Both TensorFlow and PyTorch backends are supported for drift detection.</p>
<p>Keywords: Adversarial, Outlier, Drift detection</p>
<h2 id="farm"><a href="https://github.com/deepset-ai/FARM">FARM</a><a class="headerlink" href="#farm" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/deepset-ai/FARM">FARM</a> makes Transfer Learning with BERT &amp; Co simple, fast and enterprise-ready. It's built upon transformers and provides additional features to simplify the life of developers: Parallelized preprocessing, highly modular design, multi-task learning, experiment tracking, easy debugging and close integration with AWS SageMaker.</p>
<p>Keywords: Transfer Learning, Modular design, Multi-task learning, Experiment tracking</p>
<h2 id="aitextgen"><a href="https://github.com/minimaxir/aitextgen">aitextgen</a><a class="headerlink" href="#aitextgen" title="Permanent link">⚓︎</a></h2>
<p>A robust Python tool for text-based AI training and generation using OpenAI's GPT-2 and EleutherAI's GPT Neo/GPT-3 architecture.
<a href="https://github.com/minimaxir/aitextgen">aitextgen</a> is a Python package that leverages PyTorch, Hugging Face Transformers and pytorch-lightning with specific optimizations for text generation using GPT-2, plus many added features.</p>
<p>Keywords: Training, Generation</p>
<h2 id="diffgram"><a href="https://github.com/diffgram/diffgram">diffgram</a><a class="headerlink" href="#diffgram" title="Permanent link">⚓︎</a></h2>
<p>Diffgram aims to integrate human supervision into platforms. We support your team programmatically changing the UI (Schema, layout, etc.) like in Streamlit. This means that you can collect and annotate timely data from users. In other words, we are the platform behind your platform, an integrated part of your application, to ship new &amp; better AI products faster.</p>
<p>Keywords: Human supervision, Platform</p>
<h2 id="ecco"><a href="https://github.com/jalammar/ecco">ecco</a><a class="headerlink" href="#ecco" title="Permanent link">⚓︎</a></h2>
<p>Explain, analyze, and visualize NLP language models. Ecco creates interactive visualizations directly in Jupyter notebooks explaining the behavior of Transformer-based language models (like GPT2, BERT, RoBERTA, T5, and T0).</p>
<p>Keywords: Model explainability</p>
<h2 id="s3prl"><a href="https://github.com/s3prl/s3prl">s3prl</a><a class="headerlink" href="#s3prl" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/s3prl/s3prl">s3prl</a> stands for Self-Supervised Speech Pre-training and Representation Learning. Self-supervised speech pre-trained models are called upstream in this toolkit, and are utilized in various downstream tasks.</p>
<p>Keywords: Speech, Training</p>
<h2 id="ru-dalle"><a href="https://github.com/ai-forever/ru-dalle">ru-dalle</a><a class="headerlink" href="#ru-dalle" title="Permanent link">⚓︎</a></h2>
<p>RuDALL-E aims to be similar to DALL-E, targeted to Russian.</p>
<p>Keywords: DALL-E, Russian</p>
<h2 id="deepke"><a href="https://github.com/zjunlp/DeepKE">DeepKE</a><a class="headerlink" href="#deepke" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/zjunlp/DeepKE">DeepKE</a> is a knowledge extraction toolkit for knowledge graph construction supporting cnSchema，low-resource, document-level and multimodal scenarios for entity, relation and attribute extraction.</p>
<p>Keywords: Knowledge Extraction, Knowledge Graphs</p>
<h2 id="nebuly"><a href="https://github.com/nebuly-ai/nebuly">Nebuly</a><a class="headerlink" href="#nebuly" title="Permanent link">⚓︎</a></h2>
<p>Nebuly is the next-generation platform to monitor and optimize your AI costs in one place. The platform connects to all your AI cost sources (compute, API providers, AI software licenses, etc) and centralizes them in one place to give you full visibility on a model basis. The platform also provides optimization recommendations and a co-pilot model that can guide during the optimization process. The platform builds on top of the open-source tools allowing you to optimize the different steps of your AI stack to squeeze out the best possible cost performances.</p>
<p>Keywords: Optimization, Performance, Monitoring</p>
<h2 id="imaginairy"><a href="https://github.com/brycedrennan/imaginAIry">imaginAIry</a><a class="headerlink" href="#imaginairy" title="Permanent link">⚓︎</a></h2>
<p>Offers a CLI and a Python API to generate images with Stable Diffusion. It has support for many tools, like image structure control (controlnet), instruction-based image edits (InstructPix2Pix), prompt-based masking (clipseg), among others.</p>
<p>Keywords: Stable Diffusion, CLI, Python API</p>
<h2 id="sparseml"><a href="https://github.com/neuralmagic/sparseml">sparseml</a><a class="headerlink" href="#sparseml" title="Permanent link">⚓︎</a></h2>
<p>SparseML is an open-source model optimization toolkit that enables you to create inference-optimized sparse models using pruning, quantization, and distillation algorithms. Models optimized with SparseML can then be exported to the ONNX and deployed with DeepSparse for GPU-class performance on CPU hardware.</p>
<p>Keywords: Model optimization, Pruning, Quantization, Distillation</p>
<h2 id="opacus"><a href="https://github.com/pytorch/opacus">opacus</a><a class="headerlink" href="#opacus" title="Permanent link">⚓︎</a></h2>
<p>Opacus is a library that enables training PyTorch models with differential privacy. It supports training with minimal code changes required on the client, has little impact on training performance, and allows the client to online track the privacy budget expended at any given moment.</p>
<p>Keywords: Differential privacy</p>
<h2 id="lavis"><a href="https://github.com/salesforce/LAVIS">LAVIS</a><a class="headerlink" href="#lavis" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/salesforce/LAVIS">LAVIS</a> is a Python deep learning library for LAnguage-and-VISion intelligence research and applications. This library aims to provide engineers and researchers with a one-stop solution to rapidly develop models for their specific multimodal scenarios, and benchmark them across standard and customized datasets. It features a unified interface design to access</p>
<p>Keywords: Multimodal, NLP, Vision</p>
<h2 id="buzz"><a href="https://github.com/chidiwilliams/buzz">buzz</a><a class="headerlink" href="#buzz" title="Permanent link">⚓︎</a></h2>
<p>Buzz transcribes and translates audio offline on your personal computer. Powered by OpenAI's Whisper.</p>
<p>Keywords: Audio transcription, Translation</p>
<h2 id="rust-bert"><a href="https://github.com/guillaume-be/rust-bert">rust-bert</a><a class="headerlink" href="#rust-bert" title="Permanent link">⚓︎</a></h2>
<p>Rust-native state-of-the-art Natural Language Processing models and pipelines. Port of Hugging Face's Transformers library, using the tch-rs crate and pre-processing from rust-tokenizers. Supports multi-threaded tokenization and GPU inference. This repository exposes the model base architecture, task-specific heads and ready-to-use pipelines.</p>
<p>Keywords: Rust, BERT, Inference</p>
<h2 id="easynlp"><a href="https://github.com/alibaba/EasyNLP">EasyNLP</a><a class="headerlink" href="#easynlp" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/alibaba/EasyNLP">EasyNLP</a> is an easy-to-use NLP development and application toolkit in PyTorch, first released inside Alibaba in 2021. It is built with scalable distributed training strategies and supports a comprehensive suite of NLP algorithms for various NLP applications. <a href="https://github.com/alibaba/EasyNLP">EasyNLP</a> integrates knowledge distillation and few-shot learning for landing large pre-trained models, together with various popular multi-modality pre-trained models. It provides a unified framework of model training, inference, and deployment for real-world applications.</p>
<p>Keywords: NLP, Knowledge distillation, Few-shot learning, Multi-modality, Training, Inference, Deployment</p>
<h2 id="turbotransformers"><a href="https://github.com/Tencent/TurboTransformers">TurboTransformers</a><a class="headerlink" href="#turbotransformers" title="Permanent link">⚓︎</a></h2>
<p>A fast and user-friendly runtime for transformer inference (Bert, Albert, GPT2, Decoders, etc) on CPU and GPU.</p>
<p>Keywords: Optimization, Performance</p>
<h2 id="hivemind"><a href="https://github.com/learning-at-home/hivemind">hivemind</a><a class="headerlink" href="#hivemind" title="Permanent link">⚓︎</a></h2>
<p>Hivemind is a PyTorch library for decentralized deep learning across the Internet. Its intended usage is training one large model on hundreds of computers from different universities, companies, and volunteers.</p>
<p>Keywords: Decentralized training</p>
<h2 id="docquery"><a href="https://github.com/impira/docquery">docquery</a><a class="headerlink" href="#docquery" title="Permanent link">⚓︎</a></h2>
<p>DocQuery is a library and command-line tool that makes it easy to analyze semi-structured and unstructured documents (PDFs, scanned images, etc.) using large language models (LLMs). You simply point DocQuery at one or more documents and specify a question you want to ask. DocQuery is created by the team at Impira.</p>
<p>Keywords: Semi-structured documents, Unstructured documents, LLM, Document Question Answering</p>
<h2 id="codegeex"><a href="https://github.com/THUDM/CodeGeeX">CodeGeeX</a><a class="headerlink" href="#codegeex" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/THUDM/CodeGeeX">CodeGeeX</a> is a large-scale multilingual code generation model with 13 billion parameters, pre-trained on a large code corpus of more than 20 programming languages. It has several unique features:
- Multilingual code generation
- Crosslingual code translation
- Is a customizable programming assistant</p>
<p>Keywords: Code Generation Model</p>
<h2 id="ktrain"><a href="https://github.com/amaiya/ktrain">ktrain</a><a class="headerlink" href="#ktrain" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/amaiya/ktrain">ktrain</a> is a lightweight wrapper for the deep learning library TensorFlow Keras (and other libraries) to help build, train, and deploy neural networks and other machine learning models. Inspired by ML framework extensions like fastai and ludwig, <a href="https://github.com/amaiya/ktrain">ktrain</a> is designed to make deep learning and AI more accessible and easier to apply for both newcomers and experienced practitioners.</p>
<p>Keywords: Keras wrapper, Model building, Training, Deployment</p>
<h2 id="fastdeploy"><a href="https://github.com/PaddlePaddle/FastDeploy">FastDeploy</a><a class="headerlink" href="#fastdeploy" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/PaddlePaddle/FastDeploy">FastDeploy</a> is an Easy-to-use and High Performance AI model deployment toolkit for Cloud, Mobile and Edge with packageout-of-the-box and unified experience, endend-to-end optimization for over fire160+ Text, Vision, Speech and Cross-modal AI models. Including image classification, object detection, OCR, face detection, matting, pp-tracking, NLP, stable diffusion, TTS and other tasks to meet developers' industrial deployment needs for multi-scenario, multi-hardware and multi-platform.</p>
<p>Keywords: Model deployment, CLoud, Mobile, Edge</p>
<h2 id="underthesea"><a href="https://github.com/undertheseanlp/underthesea">underthesea</a><a class="headerlink" href="#underthesea" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/undertheseanlp/underthesea">underthesea</a> is a Vietnamese NLP toolkit. Underthesea is a suite of open source Python modules data sets and tutorials supporting research and development in Vietnamese Natural Language Processing. We provides extremely easy API to quickly apply pretrained NLP models to your Vietnamese text, such as word segmentation, part-of-speech tagging (PoS), named entity recognition (NER), text classification and dependency parsing.</p>
<p>Keywords: Vietnamese, NLP</p>
<h2 id="hasktorch"><a href="https://github.com/hasktorch/hasktorch">hasktorch</a><a class="headerlink" href="#hasktorch" title="Permanent link">⚓︎</a></h2>
<p>Hasktorch is a library for tensors and neural networks in Haskell. It is an independent open source community project which leverages the core C++ libraries shared by PyTorch.</p>
<p>Keywords: Haskell, Neural Networks</p>
<h2 id="donut"><a href="https://github.com/clovaai/donut">donut</a><a class="headerlink" href="#donut" title="Permanent link">⚓︎</a></h2>
<p>Donut, or Document understanding transformer, is a new method of document understanding that utilizes an OCR-free end-to-end Transformer model.</p>
<p>Donut does not require off-the-shelf OCR engines/APIs, yet it shows state-of-the-art performances on various visual document understanding tasks, such as visual document classification or information extraction (a.k.a. document parsing).</p>
<p>Keywords: Document Understanding</p>
<h2 id="transformers-interpret"><a href="https://github.com/cdpierse/transformers-interpret">transformers-interpret</a><a class="headerlink" href="#transformers-interpret" title="Permanent link">⚓︎</a></h2>
<p>Transformers Interpret is a model explainability tool designed to work exclusively with the transformers package.</p>
<p>In line with the philosophy of the Transformers package Transformers Interpret allows any transformers model to be explained in just two lines. Explainers are available for both text and computer vision models. Visualizations are also available in notebooks and as savable png and html files</p>
<p>Keywords: Model interpretation, Visualization</p>
<h2 id="mlrun"><a href="https://github.com/mlrun/mlrun">mlrun</a><a class="headerlink" href="#mlrun" title="Permanent link">⚓︎</a></h2>
<p>MLRun is an open MLOps platform for quickly building and managing continuous ML applications across their lifecycle. MLRun integrates into your development and CI/CD environment and automates the delivery of production data, ML pipelines, and online applications, significantly reducing engineering efforts, time to production, and computation resources. With MLRun, you can choose any IDE on your local machine or on the cloud. MLRun breaks the silos between data, ML, software, and DevOps/MLOps teams, enabling collaboration and fast continuous improvements.</p>
<p>Keywords: MLOps</p>
<h2 id="federatedscope"><a href="https://github.com/alibaba/FederatedScope">FederatedScope</a><a class="headerlink" href="#federatedscope" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/alibaba/FederatedScope">FederatedScope</a> is a comprehensive federated learning platform that provides convenient usage and flexible customization for various federated learning tasks in both academia and industry. Based on an event-driven architecture, <a href="https://github.com/alibaba/FederatedScope">FederatedScope</a> integrates rich collections of functionalities to satisfy the burgeoning demands from federated learning, and aims to build up an easy-to-use platform for promoting learning safely and effectively.</p>
<p>Keywords: Federated learning, Event-driven</p>
<h2 id="pythainlp"><a href="https://github.com/PyThaiNLP/pythainlp">pythainlp</a><a class="headerlink" href="#pythainlp" title="Permanent link">⚓︎</a></h2>
<p>PyThaiNLP is a Python package for text processing and linguistic analysis, similar to NLTK with focus on Thai language.</p>
<p>Keywords: Thai, NLP, NLTK</p>
<h2 id="flagai"><a href="https://github.com/FlagAI-Open/FlagAI">FlagAI</a><a class="headerlink" href="#flagai" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/FlagAI-Open/FlagAI">FlagAI</a> (Fast LArge-scale General AI models) is a fast, easy-to-use and extensible toolkit for large-scale model. Our goal is to support training, fine-tuning, and deployment of large-scale models on various downstream tasks with multi-modality.</p>
<p>Keywords: Large models, Training, Fine-tuning, Deployment, Multi-modal</p>
<h2 id="pyserini"><a href="https://github.com/castorini/pyserini">pyserini</a><a class="headerlink" href="#pyserini" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/castorini/pyserini">pyserini</a> is a Python toolkit for reproducible information retrieval research with sparse and dense representations. Retrieval using sparse representations is provided via integration with the group's Anserini IR toolkit. Retrieval using dense representations is provided via integration with Facebook's Faiss library.</p>
<p>Keywords: IR, Information Retrieval, Dense, Sparse</p>
<h2 id="baal"><a href="https://github.com/baal-org/baal">baal</a><a class="headerlink" href="#baal" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/baal-org/baal">baal</a> is an active learning library that supports both industrial applications and research usecases. <a href="https://github.com/baal-org/baal">baal</a> currently supports Monte-Carlo Dropout, MCDropConnect, deep ensembles, and semi-supervised learning.</p>
<p>Keywords: Active Learning, Research, Labeling</p>
<h2 id="cleanlab"><a href="https://github.com/cleanlab/cleanlab">cleanlab</a><a class="headerlink" href="#cleanlab" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/cleanlab/cleanlab">cleanlab</a> is the standard data-centric AI package for data quality and machine learning with messy, real-world data and labels. For text, image, tabular, audio (among others) datasets, you can use cleanlab to automatically: detect data issues (outliers, label errors, near duplicates, etc), train robust ML models, infer consensus + annotator-quality for multi-annotator data, suggest data to (re)label next (active learning).</p>
<p>Keywords: Data-Centric AI, Data Quality, Noisy Labels, Outlier Detection, Active Learning  </p>
<h2 id="bentoml"><a href="https://github.com/bentoml/BentoML">BentoML</a><a class="headerlink" href="#bentoml" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/bentoml">BentoML</a> is the unified framework for for building, shipping, and scaling production-ready AI applications incorporating traditional ML, pre-trained AI models, Generative and Large Language Models. 
All Hugging Face models and pipelines can be seamlessly integrated into BentoML applications, enabling the running of models on the most suitable hardware and independent scaling based on usage.</p>
<p>Keywords: BentoML, Framework, Deployment, AI Applications</p>
<h2 id="llama-efficient-tuning"><a href="https://github.com/hiyouga/LLaMA-Efficient-Tuning">LLaMA-Efficient-Tuning</a><a class="headerlink" href="#llama-efficient-tuning" title="Permanent link">⚓︎</a></h2>
<p><a href="https://github.com/hiyouga/LLaMA-Efficient-Tuning">LLaMA-Efficient-Tuning</a> offers a user-friendly fine-tuning framework that incorporates PEFT. The repository includes training(fine-tuning) and inference examples for LLaMA-2, BLOOM, Falcon, Baichuan, Qwen, and other LLMs. A ChatGLM version is also available in <a href="https://github.com/hiyouga/ChatGLM-Efficient-Tuning">ChatGLM-Efficient-Tuning</a>.</p>
<p>Keywords: PEFT, fine-tuning, LLaMA-2, ChatGLM, Qwen</p>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../autoclass_tutorial/" class="md-footer__link md-footer__link--prev" aria-label="上一页: Autoclass tutorial">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                Autoclass tutorial
              </div>
            </div>
          </a>
        
        
          
          <a href="../big_models/" class="md-footer__link md-footer__link--next" aria-label="下一页: Big models">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                Big models
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="b站主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="个人主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>