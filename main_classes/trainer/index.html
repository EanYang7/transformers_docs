
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="transformers_docs">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/transformers_docs/main_classes/trainer/">
      
      
        <link rel="prev" href="../model/">
      
      
      
      <link rel="icon" href="../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>Trainer - Transformers æ–‡æ¡£</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#trainer" class="md-skip">
          è·³è½¬è‡³
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="é¡µçœ‰">
    <a href="../.." title="Transformers æ–‡æ¡£" class="md-header__button md-logo" aria-label="Transformers æ–‡æ¡£" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Transformers æ–‡æ¡£
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Trainer
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="åˆ‡æ¢ä¸ºæš—é»‘æ¨¡å¼"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="åˆ‡æ¢ä¸ºæš—é»‘æ¨¡å¼" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="åˆ‡æ¢ä¸ºæµ…è‰²æ¨¡å¼"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="åˆ‡æ¢ä¸ºæµ…è‰²æ¨¡å¼" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="æœç´¢" placeholder="æœç´¢" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="æŸ¥æ‰¾">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="åˆ†äº«" aria-label="åˆ†äº«" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="æ¸…ç©ºå½“å‰å†…å®¹" aria-label="æ¸…ç©ºå½“å‰å†…å®¹" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            æ­£åœ¨åˆå§‹åŒ–æœç´¢å¼•æ“
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/transformers_docs" title="å‰å¾€ä»“åº“" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    githubä»“åº“
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="å¯¼èˆªæ " data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Transformers æ–‡æ¡£" class="md-nav__button md-logo" aria-label="Transformers æ–‡æ¡£" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    Transformers æ–‡æ¡£
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/transformers_docs" title="å‰å¾€ä»“åº“" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    githubä»“åº“
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../autoclass_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autoclass tutorial
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../awesome-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Awesome projects built with Transformers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../big_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Big models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../debugging/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Debugging
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../hpo_train/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hpo train
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../llm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llm tutorial
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../model_sharing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model sharing
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Peft
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../perf_hardware/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Perf hardware
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../perf_torch_compile/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Perf torch compile
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../performance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Performance
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../run_scripts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Run scripts
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../tf_xla/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tf xla
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer_summary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tokenizer summary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    1 å¼€å§‹ä½¿ç”¨
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../2-%E6%95%99%E7%A8%8B/accelerate/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    2 æ•™ç¨‹
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    3 å¼€å‘è€…æŒ‡å—
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    4 æ¦‚å¿µæŒ‡å—
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_20" checked>
        
          
          <label class="md-nav__link" for="__nav_20" id="__nav_20_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Main classes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_20_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_20">
            <span class="md-nav__icon md-icon"></span>
            Main classes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../deepspeed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Deepspeed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Trainer
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Trainer
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="ç›®å½•">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      ç›®å½•
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#trainer_1" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seq2seqtrainer" class="md-nav__link">
    <span class="md-ellipsis">
      Seq2SeqTrainer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainingarguments" class="md-nav__link">
    <span class="md-ellipsis">
      TrainingArguments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seq2seqtrainingarguments" class="md-nav__link">
    <span class="md-ellipsis">
      Seq2SeqTrainingArguments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#checkpoints" class="md-nav__link">
    <span class="md-ellipsis">
      Checkpoints
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logging" class="md-nav__link">
    <span class="md-ellipsis">
      Logging
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      éšæœºæ€§
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu" class="md-nav__link">
    <span class="md-ellipsis">
      ç‰¹å®šGPUé€‰æ‹©
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer_2" class="md-nav__link">
    <span class="md-ellipsis">
      Traineré›†æˆ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Traineré›†æˆ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda" class="md-nav__link">
    <span class="md-ellipsis">
      CUDAæ‹“å±•å®‰è£…æ³¨æ„äº‹é¡¹
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDAæ‹“å±•å®‰è£…æ³¨æ„äº‹é¡¹">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      å¯èƒ½çš„é—®é¢˜ #1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      å¯èƒ½çš„é—®é¢˜ #2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      å¯èƒ½çš„é—®é¢˜ #3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorchfsdp" class="md-nav__link">
    <span class="md-ellipsis">
      PyTorchå®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œï¼ˆFSDP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorchxla" class="md-nav__link">
    <span class="md-ellipsis">
      PyTorch/XLA å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mac-trainer-pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      åœ¨ Mac ä¸Šä½¿ç”¨ Trainer è¿›è¡ŒåŠ é€Ÿçš„ PyTorch è®­ç»ƒ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#accelerate-launcher-trainer" class="md-nav__link">
    <span class="md-ellipsis">
      é€šè¿‡ Accelerate Launcher ä½¿ç”¨ Trainer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neftune" class="md-nav__link">
    <span class="md-ellipsis">
      é€šè¿‡ NEFTune æå‡å¾®è°ƒæ€§èƒ½
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="ç›®å½•">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      ç›®å½•
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#trainer_1" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seq2seqtrainer" class="md-nav__link">
    <span class="md-ellipsis">
      Seq2SeqTrainer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainingarguments" class="md-nav__link">
    <span class="md-ellipsis">
      TrainingArguments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seq2seqtrainingarguments" class="md-nav__link">
    <span class="md-ellipsis">
      Seq2SeqTrainingArguments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#checkpoints" class="md-nav__link">
    <span class="md-ellipsis">
      Checkpoints
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logging" class="md-nav__link">
    <span class="md-ellipsis">
      Logging
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      éšæœºæ€§
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu" class="md-nav__link">
    <span class="md-ellipsis">
      ç‰¹å®šGPUé€‰æ‹©
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer_2" class="md-nav__link">
    <span class="md-ellipsis">
      Traineré›†æˆ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Traineré›†æˆ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cuda" class="md-nav__link">
    <span class="md-ellipsis">
      CUDAæ‹“å±•å®‰è£…æ³¨æ„äº‹é¡¹
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CUDAæ‹“å±•å®‰è£…æ³¨æ„äº‹é¡¹">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      å¯èƒ½çš„é—®é¢˜ #1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      å¯èƒ½çš„é—®é¢˜ #2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      å¯èƒ½çš„é—®é¢˜ #3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorchfsdp" class="md-nav__link">
    <span class="md-ellipsis">
      PyTorchå®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œï¼ˆFSDP)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pytorchxla" class="md-nav__link">
    <span class="md-ellipsis">
      PyTorch/XLA å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mac-trainer-pytorch" class="md-nav__link">
    <span class="md-ellipsis">
      åœ¨ Mac ä¸Šä½¿ç”¨ Trainer è¿›è¡ŒåŠ é€Ÿçš„ PyTorch è®­ç»ƒ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#accelerate-launcher-trainer" class="md-nav__link">
    <span class="md-ellipsis">
      é€šè¿‡ Accelerate Launcher ä½¿ç”¨ Trainer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neftune" class="md-nav__link">
    <span class="md-ellipsis">
      é€šè¿‡ NEFTune æå‡å¾®è°ƒæ€§èƒ½
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/transformers_docs/tree/main/docs/main_classes/trainer.md" title="ç¼–è¾‘æ­¤é¡µ" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/transformers_docs/tree/main/docs/main_classes/trainer.md" title="æŸ¥çœ‹æœ¬é¡µçš„æºä»£ç " class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

<h1 id="trainer">Trainer<a class="headerlink" href="#trainer" title="Permanent link">âš“ï¸</a></h1>
<p>[<code>Trainer</code>] ç±»æä¾›äº†ä¸€ä¸ª PyTorch çš„ APIï¼Œç”¨äºå¤„ç†å¤§å¤šæ•°æ ‡å‡†ç”¨ä¾‹çš„å…¨åŠŸèƒ½è®­ç»ƒã€‚å®ƒåœ¨å¤§å¤šæ•°<a href="https://github.com/huggingface/transformers/tree/main/examples">ç¤ºä¾‹è„šæœ¬</a>ä¸­è¢«ä½¿ç”¨ã€‚</p>
<p><Tip></p>
<p>å¦‚æœä½ æƒ³è¦ä½¿ç”¨è‡ªå›å½’æŠ€æœ¯åœ¨æ–‡æœ¬æ•°æ®é›†ä¸Šå¾®è°ƒåƒ Llama-2 æˆ– Mistral è¿™æ ·çš„è¯­è¨€æ¨¡å‹ï¼Œè€ƒè™‘ä½¿ç”¨ <a href="https://github.com/huggingface/trl"><code>trl</code></a> çš„ [<code>~trl.SFTTrainer</code>]ã€‚[<code>~trl.SFTTrainer</code>] å°è£…äº† [<code>Trainer</code>]ï¼Œä¸“é—¨é’ˆå¯¹è¿™ä¸ªç‰¹å®šä»»åŠ¡è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¹¶æ”¯æŒåºåˆ—æ‰“åŒ…ã€LoRAã€é‡åŒ–å’Œ DeepSpeedï¼Œä»¥æœ‰æ•ˆæ‰©å±•åˆ°ä»»ä½•æ¨¡å‹å¤§å°ã€‚å¦ä¸€æ–¹é¢ï¼Œ[<code>Trainer</code>] æ˜¯ä¸€ä¸ªæ›´é€šç”¨çš„é€‰é¡¹ï¼Œé€‚ç”¨äºæ›´å¹¿æ³›çš„ä»»åŠ¡ã€‚</p>
<p></Tip></p>
<p>åœ¨å®ä¾‹åŒ–ä½ çš„ [<code>Trainer</code>] ä¹‹å‰ï¼Œåˆ›å»ºä¸€ä¸ª [<code>TrainingArguments</code>]ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒæœŸé—´è®¿é—®æ‰€æœ‰å®šåˆ¶ç‚¹ã€‚</p>
<p>è¿™ä¸ª API æ”¯æŒåœ¨å¤šä¸ª GPU/TPU ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œæ”¯æŒ <a href="https://github.com/NVIDIA/apex">NVIDIA Apex</a> çš„æ··åˆç²¾åº¦å’Œ PyTorch çš„åŸç”Ÿ AMPã€‚</p>
<p>[<code>Trainer</code>] åŒ…å«åŸºæœ¬çš„è®­ç»ƒå¾ªç¯ï¼Œæ”¯æŒä¸Šè¿°åŠŸèƒ½ã€‚å¦‚æœéœ€è¦è‡ªå®šä¹‰è®­ç»ƒï¼Œä½ å¯ä»¥ç»§æ‰¿ <code>Trainer</code> å¹¶è¦†ç›–ä»¥ä¸‹æ–¹æ³•ï¼š</p>
<ul>
<li><strong>get_train_dataloader</strong> -- åˆ›å»ºè®­ç»ƒ DataLoaderã€‚</li>
<li><strong>get_eval_dataloader</strong> -- åˆ›å»ºè¯„ä¼° DataLoaderã€‚</li>
<li><strong>get_test_dataloader</strong> -- åˆ›å»ºæµ‹è¯• DataLoaderã€‚</li>
<li><strong>log</strong> -- è®°å½•è§‚å¯Ÿè®­ç»ƒçš„å„ç§å¯¹è±¡çš„ä¿¡æ¯ã€‚</li>
<li><strong>create_optimizer_and_scheduler</strong> -- å¦‚æœå®ƒä»¬æ²¡æœ‰åœ¨åˆå§‹åŒ–æ—¶ä¼ é€’ï¼Œè¯·è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚è¯·æ³¨æ„ï¼Œä½ è¿˜å¯ä»¥å•ç‹¬ç»§æ‰¿æˆ–è¦†ç›– <code>create_optimizer</code> å’Œ <code>create_scheduler</code> æ–¹æ³•ã€‚</li>
<li><strong>create_optimizer</strong> -- å¦‚æœåœ¨åˆå§‹åŒ–æ—¶æ²¡æœ‰ä¼ é€’ï¼Œåˆ™è®¾ç½®ä¼˜åŒ–å™¨ã€‚</li>
<li><strong>create_scheduler</strong> -- å¦‚æœåœ¨åˆå§‹åŒ–æ—¶æ²¡æœ‰ä¼ é€’ï¼Œåˆ™è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚</li>
<li><strong>compute_loss</strong> - è®¡ç®—å•æ‰¹è®­ç»ƒè¾“å…¥çš„æŸå¤±ã€‚</li>
<li><strong>training_step</strong> -- æ‰§è¡Œä¸€æ­¥è®­ç»ƒã€‚</li>
<li><strong>prediction_step</strong> -- æ‰§è¡Œä¸€æ­¥è¯„ä¼°/æµ‹è¯•ã€‚</li>
<li><strong>evaluate</strong> -- è¿è¡Œè¯„ä¼°å¾ªç¯å¹¶è¿”å›æŒ‡æ ‡ã€‚</li>
<li><strong>predict</strong> -- è¿”å›åœ¨æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹ï¼ˆå¦‚æœæœ‰æ ‡ç­¾ï¼Œåˆ™åŒ…æ‹¬æŒ‡æ ‡ï¼‰ã€‚</li>
</ul>
<p><Tip warning={true}></p>
<p>[<code>Trainer</code>] ç±»è¢«ä¼˜åŒ–ç”¨äº ğŸ¤— Transformers æ¨¡å‹ï¼Œå¹¶åœ¨ä½ åœ¨å…¶ä»–æ¨¡å‹ä¸Šä½¿ç”¨æ—¶å¯èƒ½ä¼šæœ‰ä¸€äº›ä»¤äººæƒŠè®¶çš„ç»“æœã€‚å½“åœ¨ä½ è‡ªå·±çš„æ¨¡å‹ä¸Šä½¿ç”¨æ—¶ï¼Œè¯·ç¡®ä¿ï¼š</p>
<ul>
<li>ä½ çš„æ¨¡å‹å§‹ç»ˆè¿”å›å…ƒç»„æˆ– [<code>~utils.ModelOutput</code>] çš„å­ç±»ã€‚</li>
<li>å¦‚æœæä¾›äº† <code>labels</code> å‚æ•°ï¼Œä½ çš„æ¨¡å‹å¯ä»¥è®¡ç®—æŸå¤±ï¼Œå¹¶ä¸”æŸå¤±ä½œä¸ºå…ƒç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ è¿”å›ï¼ˆå¦‚æœä½ çš„æ¨¡å‹è¿”å›å…ƒç»„ï¼‰ã€‚</li>
<li>ä½ çš„æ¨¡å‹å¯ä»¥æ¥å—å¤šä¸ªæ ‡ç­¾å‚æ•°ï¼ˆåœ¨ [<code>TrainingArguments</code>] ä¸­ä½¿ç”¨ <code>label_names</code> å°†å®ƒä»¬çš„åç§°æŒ‡ç¤ºç»™ [<code>Trainer</code>]ï¼‰ï¼Œä½†å®ƒä»¬ä¸­æ²¡æœ‰ä¸€ä¸ªåº”è¯¥è¢«å‘½åä¸º <code>"label"</code>ã€‚</li>
</ul>
<p></Tip></p>
<p>ä»¥ä¸‹æ˜¯å¦‚ä½•è‡ªå®šä¹‰ [<code>Trainer</code>] ä»¥ä½¿ç”¨åŠ æƒæŸå¤±çš„ç¤ºä¾‹ï¼ˆåœ¨è®­ç»ƒé›†ä¸å¹³è¡¡æ—¶å¾ˆæœ‰ç”¨ï¼‰ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>


<span class="k">class</span> <span class="nc">CustomTrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">return_outputs</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">)</span>
        <span class="c1"># forward pass</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>
        <span class="c1"># compute custom loss (suppose one has 3 labels with different weights)</span>
        <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_labels</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_outputs</span> <span class="k">else</span> <span class="n">loss</span>
</code></pre></div>
<p>åœ¨ PyTorch [<code>Trainer</code>] ä¸­è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯è¡Œä¸ºçš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ <a href="callback">callbacks</a>ï¼Œè¿™äº›å›è°ƒå¯ä»¥æ£€æŸ¥è®­ç»ƒå¾ªç¯çŠ¶æ€ï¼ˆç”¨äºè¿›åº¦æŠ¥å‘Šã€åœ¨ TensorBoard æˆ–å…¶ä»– ML å¹³å°ä¸Šè®°å½•æ—¥å¿—ç­‰ï¼‰å¹¶åšå‡ºå†³ç­–ï¼ˆæ¯”å¦‚æå‰åœæ­¢ï¼‰ã€‚</p>
<h2 id="trainer_1">Trainer<a class="headerlink" href="#trainer_1" title="Permanent link">âš“ï¸</a></h2>
<p>[[autodoc]] Trainer - all</p>
<h2 id="seq2seqtrainer">Seq2SeqTrainer<a class="headerlink" href="#seq2seqtrainer" title="Permanent link">âš“ï¸</a></h2>
<p>[[autodoc]] Seq2SeqTrainer - evaluate - predict</p>
<h2 id="trainingarguments">TrainingArguments<a class="headerlink" href="#trainingarguments" title="Permanent link">âš“ï¸</a></h2>
<p>[[autodoc]] TrainingArguments - all</p>
<h2 id="seq2seqtrainingarguments">Seq2SeqTrainingArguments<a class="headerlink" href="#seq2seqtrainingarguments" title="Permanent link">âš“ï¸</a></h2>
<p>[[autodoc]] Seq2SeqTrainingArguments - all</p>
<h2 id="checkpoints">Checkpoints<a class="headerlink" href="#checkpoints" title="Permanent link">âš“ï¸</a></h2>
<p>é»˜è®¤æƒ…å†µä¸‹ï¼Œ[<code>Trainer</code>] ä¼šå°†æ‰€æœ‰checkpointsä¿å­˜åœ¨ä½ ä½¿ç”¨çš„ [<code>TrainingArguments</code>] ä¸­è®¾ç½®çš„ <code>output_dir</code> ä¸­ã€‚è¿™äº›checkpointså°†ä½äºåä¸º <code>checkpoint-xxx</code> çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œxxx æ˜¯è®­ç»ƒçš„æ­¥éª¤ã€‚</p>
<p>ä»checkpointsæ¢å¤è®­ç»ƒå¯ä»¥é€šè¿‡è°ƒç”¨ [<code>Trainer.train</code>] æ—¶ä½¿ç”¨ä»¥ä¸‹ä»»ä¸€æ–¹å¼è¿›è¡Œï¼š</p>
<ul>
<li><code>resume_from_checkpoint=True</code>ï¼Œè¿™å°†ä»æœ€æ–°çš„checkpointæ¢å¤è®­ç»ƒã€‚</li>
<li><code>resume_from_checkpoint=checkpoint_dir</code>ï¼Œè¿™å°†ä»æŒ‡å®šç›®å½•ä¸­çš„ç‰¹å®šcheckpointæ¢å¤è®­ç»ƒã€‚</li>
</ul>
<p>æ­¤å¤–ï¼Œå½“ä½¿ç”¨ <code>push_to_hub=True</code> æ—¶ï¼Œä½ å¯ä»¥è½»æ¾å°†checkpointsä¿å­˜åœ¨ Model Hub ä¸­ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä¿å­˜åœ¨è®­ç»ƒä¸­é—´è¿‡ç¨‹çš„checkpointsä¸­çš„æ‰€æœ‰æ¨¡å‹éƒ½ä¿å­˜åœ¨ä¸åŒçš„æäº¤ä¸­ï¼Œä½†ä¸åŒ…æ‹¬ä¼˜åŒ–å™¨çŠ¶æ€ã€‚ä½ å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ [<code>TrainingArguments</code>] çš„ <code>hub-strategy</code> å€¼ï¼š</p>
<ul>
<li><code>"checkpoint"</code>: æœ€æ–°çš„checkpointä¹Ÿè¢«æ¨é€åˆ°ä¸€ä¸ªåä¸º last-checkpoint çš„å­æ–‡ä»¶å¤¹ä¸­ï¼Œè®©ä½ å¯ä»¥é€šè¿‡ <code>trainer.train(resume_from_checkpoint="output_dir/last-checkpoint")</code> è½»æ¾æ¢å¤è®­ç»ƒã€‚</li>
<li><code>"all_checkpoints"</code>: æ‰€æœ‰checkpointséƒ½åƒå®ƒä»¬å‡ºç°åœ¨è¾“å‡ºæ–‡ä»¶å¤¹ä¸­ä¸€æ ·è¢«æ¨é€ï¼ˆå› æ­¤ä½ å°†åœ¨æœ€ç»ˆå­˜å‚¨åº“ä¸­çš„æ¯ä¸ªæ–‡ä»¶å¤¹ä¸­è·å¾—ä¸€ä¸ªcheckpointæ–‡ä»¶å¤¹ï¼‰ã€‚</li>
</ul>
<h2 id="logging">Logging<a class="headerlink" href="#logging" title="Permanent link">âš“ï¸</a></h2>
<p>é»˜è®¤æƒ…å†µä¸‹ï¼Œ[<code>Trainer</code>] å°†å¯¹ä¸»è¿›ç¨‹ä½¿ç”¨ <code>logging.INFO</code>ï¼Œå¯¹å‰¯æœ¬ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ä½¿ç”¨ <code>logging.WARNING</code>ã€‚</p>
<p>å¯ä»¥é€šè¿‡ [<code>TrainingArguments</code>] çš„å‚æ•°è¦†ç›–è¿™äº›é»˜è®¤è®¾ç½®ï¼Œä½¿ç”¨å…¶ä¸­çš„ 5 ä¸ª <code>logging</code> çº§åˆ«ï¼š</p>
<ul>
<li><code>log_level</code> - ç”¨äºä¸»è¿›ç¨‹</li>
<li><code>log_level_replica</code> - ç”¨äºå‰¯æœ¬</li>
</ul>
<p>æ­¤å¤–ï¼Œå¦‚æœ [<code>TrainingArguments</code>] çš„ <code>log_on_each_node</code> è®¾ç½®ä¸º <code>False</code>ï¼Œåˆ™åªæœ‰ä¸»èŠ‚ç‚¹å°†ä½¿ç”¨å…¶ä¸»è¿›ç¨‹çš„æ—¥å¿—çº§åˆ«è®¾ç½®ï¼Œæ‰€æœ‰å…¶ä»–èŠ‚ç‚¹å°†ä½¿ç”¨å‰¯æœ¬çš„æ—¥å¿—çº§åˆ«è®¾ç½®ã€‚</p>
<p>è¯·æ³¨æ„ï¼Œ[<code>Trainer</code>] å°†åœ¨å…¶ [<code>Trainer.__init__</code>] ä¸­åˆ†åˆ«ä¸ºæ¯ä¸ªèŠ‚ç‚¹è®¾ç½® <code>transformers</code> çš„æ—¥å¿—çº§åˆ«ã€‚å› æ­¤ï¼Œå¦‚æœåœ¨åˆ›å»º [<code>Trainer</code>] å¯¹è±¡ä¹‹å‰è¦è°ƒç”¨å…¶ä»– <code>transformers</code> åŠŸèƒ½ï¼Œå¯èƒ½éœ€è¦æ›´æ—©åœ°è®¾ç½®è¿™ä¸€ç‚¹ï¼ˆè¯·å‚è§ä¸‹é¢çš„ç¤ºä¾‹ï¼‰ã€‚</p>
<p>ä»¥ä¸‹æ˜¯å¦‚ä½•åœ¨åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨çš„ç¤ºä¾‹ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">[</span><span class="o">...</span><span class="p">]</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="c1"># Setup logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span>
    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%(asctime)s</span><span class="s2"> - </span><span class="si">%(levelname)s</span><span class="s2"> - </span><span class="si">%(name)s</span><span class="s2"> - </span><span class="si">%(message)s</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">datefmt</span><span class="o">=</span><span class="s2">&quot;%m/</span><span class="si">%d</span><span class="s2">/%Y %H:%M:%S&quot;</span><span class="p">,</span>
    <span class="n">handlers</span><span class="o">=</span><span class="p">[</span><span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">)],</span>
<span class="p">)</span>

<span class="c1"># set the main code and the modules it uses to the same log-level according to the node</span>
<span class="n">log_level</span> <span class="o">=</span> <span class="n">training_args</span><span class="o">.</span><span class="n">get_process_log_level</span><span class="p">()</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>
<span class="n">transformers</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</code></pre></div>
<p>ç„¶åï¼Œå¦‚æœä½ åªæƒ³åœ¨ä¸»èŠ‚ç‚¹ä¸Šçœ‹åˆ°è­¦å‘Šï¼Œå¹¶ä¸”æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹ä¸æ‰“å°ä»»ä½•å¯èƒ½é‡å¤çš„è­¦å‘Šï¼Œå¯ä»¥è¿™æ ·è¿è¡Œï¼š</p>
<div class="highlight"><pre><span></span><code>my_app.py<span class="w"> </span>...<span class="w"> </span>--log_level<span class="w"> </span>warning<span class="w"> </span>--log_level_replica<span class="w"> </span>error
</code></pre></div>
<p>åœ¨å¤šèŠ‚ç‚¹ç¯å¢ƒä¸­ï¼Œå¦‚æœä½ ä¹Ÿä¸å¸Œæœ›æ¯ä¸ªèŠ‚ç‚¹çš„ä¸»è¿›ç¨‹çš„æ—¥å¿—é‡å¤è¾“å‡ºï¼Œä½ éœ€è¦å°†ä¸Šé¢çš„ä»£ç æ›´æ”¹ä¸ºï¼š</p>
<div class="highlight"><pre><span></span><code>my_app.py<span class="w"> </span>...<span class="w"> </span>--log_level<span class="w"> </span>warning<span class="w"> </span>--log_level_replica<span class="w"> </span>error<span class="w"> </span>--log_on_each_node<span class="w"> </span><span class="m">0</span>
</code></pre></div>
<p>ç„¶åï¼Œåªæœ‰ç¬¬ä¸€ä¸ªèŠ‚ç‚¹çš„ä¸»è¿›ç¨‹å°†ä»¥ "warning" çº§åˆ«è®°å½•æ—¥å¿—ï¼Œä¸»èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰å…¶ä»–è¿›ç¨‹å’Œå…¶ä»–èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰è¿›ç¨‹å°†ä»¥ "error" çº§åˆ«è®°å½•æ—¥å¿—ã€‚</p>
<p>å¦‚æœä½ å¸Œæœ›åº”ç”¨ç¨‹åºå°½å¯èƒ½â€å®‰é™â€œï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š</p>
<div class="highlight"><pre><span></span><code>my_app.py<span class="w"> </span>...<span class="w"> </span>--log_level<span class="w"> </span>error<span class="w"> </span>--log_level_replica<span class="w"> </span>error<span class="w"> </span>--log_on_each_node<span class="w"> </span><span class="m">0</span>
</code></pre></div>
<p>(å¦‚æœåœ¨å¤šèŠ‚ç‚¹ç¯å¢ƒï¼Œæ·»åŠ  <code>--log_on_each_node 0</code>)</p>
<h2 id="_1">éšæœºæ€§<a class="headerlink" href="#_1" title="Permanent link">âš“ï¸</a></h2>
<p>å½“ä» [<code>Trainer</code>] ç”Ÿæˆçš„checkpointæ¢å¤è®­ç»ƒæ—¶ï¼Œç¨‹åºä¼šå°½ä¸€åˆ‡åŠªåŠ›å°† <em>python</em>ã€<em>numpy</em> å’Œ <em>pytorch</em> çš„ RNGï¼ˆéšæœºæ•°ç”Ÿæˆå™¨ï¼‰çŠ¶æ€æ¢å¤ä¸ºä¿å­˜æ£€æŸ¥ç‚¹æ—¶çš„çŠ¶æ€ï¼Œè¿™æ ·å¯ä»¥ä½¿â€œåœæ­¢å’Œæ¢å¤â€å¼è®­ç»ƒå°½å¯èƒ½æ¥è¿‘â€œéåœæ­¢å¼â€è®­ç»ƒã€‚</p>
<p>ç„¶è€Œï¼Œç”±äºå„ç§é»˜è®¤çš„éç¡®å®šæ€§ PyTorch è®¾ç½®ï¼Œè¿™å¯èƒ½æ— æ³•å®Œå…¨å®ç°ã€‚å¦‚æœä½ æƒ³è¦å®Œå…¨ç¡®å®šæ€§ï¼Œè¯·å‚é˜…<a href="https://pytorch.org/docs/stable/notes/randomness">æ§åˆ¶éšæœºæº</a>ã€‚æ­£å¦‚æ–‡æ¡£ä¸­æ‰€è§£é‡Šçš„é‚£æ ·ï¼Œä½¿äº‹ç‰©å˜å¾—ç¡®å®šçš„ä¸€äº›è®¾ç½®ï¼ˆä¾‹å¦‚ <code>torch.backends.cudnn.deterministic</code>ï¼‰å¯èƒ½ä¼šå‡æ…¢é€Ÿåº¦ï¼Œå› æ­¤ä¸èƒ½é»˜è®¤æ‰§è¡Œï¼Œä½†å¦‚æœéœ€è¦ï¼Œä½ å¯ä»¥è‡ªè¡Œå¯ç”¨è¿™äº›è®¾ç½®ã€‚</p>
<h2 id="gpu">ç‰¹å®šGPUé€‰æ‹©<a class="headerlink" href="#gpu" title="Permanent link">âš“ï¸</a></h2>
<p>è®©æˆ‘ä»¬è®¨è®ºä¸€ä¸‹å¦‚ä½•å‘Šè¯‰ä½ çš„ç¨‹åºåº”è¯¥ä½¿ç”¨å“ªäº› GPU ä»¥åŠä½¿ç”¨çš„é¡ºåºã€‚</p>
<p>å½“ä½¿ç”¨ <a href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html"><code>DistributedDataParallel</code></a> ä¸”ä»…ä½¿ç”¨éƒ¨åˆ† GPU æ—¶ï¼Œä½ åªéœ€æŒ‡å®šè¦ä½¿ç”¨çš„ GPU æ•°é‡ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰ 4 ä¸ª GPUï¼Œä½†åªæƒ³ä½¿ç”¨å‰ 2 ä¸ªï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š</p>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>-m<span class="w"> </span>torch.distributed.launch<span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="m">2</span><span class="w">  </span>trainer-program.py<span class="w"> </span>...
</code></pre></div>
<p>å¦‚æœä½ å®‰è£…äº† <a href="https://github.com/huggingface/accelerate"><code>accelerate</code></a> æˆ– <a href="https://github.com/microsoft/DeepSpeed"><code>deepspeed</code></a>ï¼Œä½ è¿˜å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»»ä¸€æ–¹æ³•å®ç°ç›¸åŒçš„æ•ˆæœï¼š</p>
<div class="highlight"><pre><span></span><code>accelerate<span class="w"> </span>launch<span class="w"> </span>--num_processes<span class="w"> </span><span class="m">2</span><span class="w"> </span>trainer-program.py<span class="w"> </span>...
</code></pre></div>
<div class="highlight"><pre><span></span><code>deepspeed<span class="w"> </span>--num_gpus<span class="w"> </span><span class="m">2</span><span class="w"> </span>trainer-program.py<span class="w"> </span>...
</code></pre></div>
<p>ä½ ä¸éœ€è¦ä½¿ç”¨ Accelerate æˆ– <a href="Deepspeed">Deepspeed é›†æˆ</a> åŠŸèƒ½æ¥ä½¿ç”¨è¿™äº›å¯åŠ¨å™¨ã€‚</p>
<p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½ å·²ç»èƒ½å¤Ÿå‘Šè¯‰ç¨‹åºè¦ä½¿ç”¨å¤šå°‘ä¸ª GPUã€‚ç°åœ¨è®©æˆ‘ä»¬è®¨è®ºå¦‚ä½•é€‰æ‹©ç‰¹å®šçš„ GPU å¹¶æ§åˆ¶å®ƒä»¬çš„é¡ºåºã€‚</p>
<p>ä»¥ä¸‹ç¯å¢ƒå˜é‡å¯å¸®åŠ©ä½ æ§åˆ¶ä½¿ç”¨å“ªäº› GPU ä»¥åŠå®ƒä»¬çš„é¡ºåºã€‚</p>
<p><strong><code>CUDA_VISIBLE_DEVICES</code></strong></p>
<p>å¦‚æœä½ æœ‰å¤šä¸ª GPUï¼Œæƒ³è¦ä»…ä½¿ç”¨å…¶ä¸­çš„ä¸€ä¸ªæˆ–å‡ ä¸ª GPUï¼Œè¯·å°†ç¯å¢ƒå˜é‡ <code>CUDA_VISIBLE_DEVICES</code> è®¾ç½®ä¸ºè¦ä½¿ç”¨çš„ GPU åˆ—è¡¨ã€‚</p>
<p>ä¾‹å¦‚ï¼Œå‡è®¾ä½ æœ‰ 4 ä¸ª GPUï¼š0ã€1ã€2 å’Œ 3ã€‚è¦ä»…åœ¨ç‰©ç† GPU 0 å’Œ 2 ä¸Šè¿è¡Œï¼Œä½ å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,2<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>torch.distributed.launch<span class="w"> </span>trainer-program.py<span class="w"> </span>...
</code></pre></div>
<p>ç°åœ¨ï¼ŒPyTorch å°†åªçœ‹åˆ° 2 ä¸ª GPUï¼Œå…¶ä¸­ä½ çš„ç‰©ç† GPU 0 å’Œ 2 åˆ†åˆ«æ˜ å°„åˆ° <code>cuda:0</code> å’Œ <code>cuda:1</code>ã€‚</p>
<p>ä½ ç”šè‡³å¯ä»¥æ”¹å˜å®ƒä»¬çš„é¡ºåºï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">2</span>,0<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>torch.distributed.launch<span class="w"> </span>trainer-program.py<span class="w"> </span>...
</code></pre></div>
<p>è¿™é‡Œï¼Œä½ çš„ç‰©ç† GPU 0 å’Œ 2 åˆ†åˆ«æ˜ å°„åˆ° <code>cuda:1</code> å’Œ <code>cuda:0</code>ã€‚</p>
<p>ä¸Šé¢çš„ä¾‹å­éƒ½æ˜¯é’ˆå¯¹ <code>DistributedDataParallel</code> ä½¿ç”¨æ¨¡å¼çš„ï¼Œä½†åŒæ ·çš„æ–¹æ³•ä¹Ÿé€‚ç”¨äº <a href="https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html"><code>DataParallel</code></a>ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">2</span>,0<span class="w"> </span>python<span class="w"> </span>trainer-program.py<span class="w"> </span>...
</code></pre></div>
<p>ä¸ºäº†æ¨¡æ‹Ÿæ²¡æœ‰ GPU çš„ç¯å¢ƒï¼Œåªéœ€å°†æ­¤ç¯å¢ƒå˜é‡è®¾ç½®ä¸ºç©ºå€¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="w"> </span>python<span class="w"> </span>trainer-program.py<span class="w"> </span>...
</code></pre></div>
<p>ä¸ä»»ä½•ç¯å¢ƒå˜é‡ä¸€æ ·ï¼Œä½ å½“ç„¶å¯ä»¥å°†å…¶exportåˆ°ç¯å¢ƒå˜é‡è€Œä¸æ˜¯å°†å…¶æ·»åŠ åˆ°å‘½ä»¤è¡Œï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,2
python<span class="w"> </span>-m<span class="w"> </span>torch.distributed.launch<span class="w"> </span>trainer-program.py<span class="w"> </span>...
</code></pre></div>
<p>è¿™ç§æ–¹æ³•å¯èƒ½ä¼šä»¤äººå›°æƒ‘ï¼Œå› ä¸ºä½ å¯èƒ½ä¼šå¿˜è®°ä¹‹å‰è®¾ç½®äº†ç¯å¢ƒå˜é‡ï¼Œè¿›è€Œä¸æ˜ç™½ä¸ºä»€ä¹ˆä¼šä½¿ç”¨é”™è¯¯çš„ GPUã€‚å› æ­¤ï¼Œåœ¨åŒä¸€å‘½ä»¤è¡Œä¸­ä»…ä¸ºç‰¹å®šè¿è¡Œè®¾ç½®ç¯å¢ƒå˜é‡æ˜¯ä¸€ç§å¸¸è§åšæ³•ï¼Œæ­£å¦‚æœ¬èŠ‚å¤§å¤šæ•°ç¤ºä¾‹æ‰€ç¤ºã€‚</p>
<p><strong><code>CUDA_DEVICE_ORDER</code></strong></p>
<p>è¿˜æœ‰ä¸€ä¸ªé¢å¤–çš„ç¯å¢ƒå˜é‡ <code>CUDA_DEVICE_ORDER</code>ï¼Œç”¨äºæ§åˆ¶ç‰©ç†è®¾å¤‡çš„æ’åºæ–¹å¼ã€‚æœ‰ä¸¤ä¸ªé€‰æ‹©ï¼š</p>
<ol>
<li>æŒ‰ PCIe æ€»çº¿ ID æ’åºï¼ˆä¸ nvidia-smi çš„é¡ºåºç›¸åŒ¹é…ï¼‰- è¿™æ˜¯é»˜è®¤é€‰é¡¹ã€‚</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_DEVICE_ORDER</span><span class="o">=</span>PCI_BUS_ID
</code></pre></div>
<ol>
<li>æŒ‰ GPU è®¡ç®—èƒ½åŠ›æ’åºã€‚</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_DEVICE_ORDER</span><span class="o">=</span>FASTEST_FIRST
</code></pre></div>
<p>å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä½ ä¸éœ€è¦å…³å¿ƒè¿™ä¸ªç¯å¢ƒå˜é‡ï¼Œä½†å¦‚æœä½ çš„è®¾ç½®ä¸å‡åŒ€ï¼Œé‚£ä¹ˆè¿™å°†éå¸¸æœ‰ç”¨ï¼Œä¾‹å¦‚ï¼Œæ‚¨çš„æ—§ GPU å’Œæ–° GPU ç‰©ç†ä¸Šå®‰è£…åœ¨ä¸€èµ·ï¼Œä½†è®©é€Ÿåº¦è¾ƒæ…¢çš„æ—§å¡æ’åœ¨è¿è¡Œçš„ç¬¬ä¸€ä½ã€‚è§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯äº¤æ¢å¡çš„ä½ç½®ã€‚ä½†å¦‚æœä¸èƒ½äº¤æ¢å¡ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœè®¾å¤‡çš„æ•£çƒ­å—åˆ°å½±å“ï¼‰ï¼Œé‚£ä¹ˆè®¾ç½® <code>CUDA_DEVICE_ORDER=FASTEST_FIRST</code> å°†å§‹ç»ˆå°†è¾ƒæ–°ã€æ›´å¿«çš„å¡æ”¾åœ¨ç¬¬ä¸€ä½ã€‚ä½†è¿™å¯èƒ½ä¼šæœ‰ç‚¹æ··ä¹±ï¼Œå› ä¸º <code>nvidia-smi</code> ä»ç„¶ä¼šæŒ‰ç…§ PCIe é¡ºåºæŠ¥å‘Šå®ƒä»¬ã€‚</p>
<p>äº¤æ¢å¡çš„é¡ºåºçš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">1</span>,0
</code></pre></div>
<p>åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬åªä½¿ç”¨äº† 2 ä¸ª GPUï¼Œä½†æ˜¯å½“ç„¶ï¼Œå¯¹äºè®¡ç®—æœºä¸Šæœ‰çš„ä»»ä½•æ•°é‡çš„ GPUï¼Œéƒ½é€‚ç”¨ç›¸åŒçš„æ–¹æ³•ã€‚</p>
<p>æ­¤å¤–ï¼Œå¦‚æœä½ è®¾ç½®äº†è¿™ä¸ªç¯å¢ƒå˜é‡ï¼Œæœ€å¥½å°†å…¶è®¾ç½®åœ¨ <code>~/.bashrc</code> æ–‡ä»¶æˆ–å…¶ä»–å¯åŠ¨é…ç½®æ–‡ä»¶ä¸­ï¼Œç„¶åå°±å¯ä»¥å¿˜è®°å®ƒäº†ã€‚</p>
<h2 id="trainer_2">Traineré›†æˆ<a class="headerlink" href="#trainer_2" title="Permanent link">âš“ï¸</a></h2>
<p>[<code>Trainer</code>] å·²ç»è¢«æ‰©å±•ï¼Œä»¥æ”¯æŒå¯èƒ½æ˜¾è‘—æé«˜è®­ç»ƒæ—¶é—´å¹¶é€‚åº”æ›´å¤§æ¨¡å‹çš„åº“ã€‚</p>
<p>ç›®å‰ï¼Œå®ƒæ”¯æŒç¬¬ä¸‰æ–¹è§£å†³æ–¹æ¡ˆ <a href="https://github.com/microsoft/DeepSpeed">DeepSpeed</a> å’Œ <a href="https://pytorch.org/docs/stable/fsdp.html">PyTorch FSDP</a>ï¼Œå®ƒä»¬å®ç°äº†è®ºæ–‡ <a href="https://arxiv.org/abs/1910.02054">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models, by Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, Yuxiong He</a> çš„éƒ¨åˆ†å†…å®¹ã€‚</p>
<p>æˆªè‡³æ’°å†™æœ¬æ–‡ï¼Œæ­¤æä¾›çš„æ”¯æŒæ˜¯æ–°çš„ä¸”å®éªŒæ€§çš„ã€‚å°½ç®¡æˆ‘ä»¬æ¬¢è¿å›´ç»• DeepSpeed å’Œ PyTorch FSDP çš„issuesï¼Œä½†æˆ‘ä»¬ä¸å†æ”¯æŒ FairScale é›†æˆï¼Œå› ä¸ºå®ƒå·²ç»é›†æˆåˆ°äº† PyTorch ä¸»çº¿ï¼ˆå‚è§ <a href="#pytorch-fully-sharded-data-parallel">PyTorch FSDP é›†æˆ</a>ï¼‰ã€‚</p>
<p><a id='zero-install-notes'></a></p>
<h3 id="cuda">CUDAæ‹“å±•å®‰è£…æ³¨æ„äº‹é¡¹<a class="headerlink" href="#cuda" title="Permanent link">âš“ï¸</a></h3>
<p>æ’°å†™æ—¶ï¼ŒDeepspeed éœ€è¦åœ¨ä½¿ç”¨ä¹‹å‰ç¼–è¯‘ CUDA C++ ä»£ç ã€‚</p>
<p>è™½ç„¶æ‰€æœ‰å®‰è£…é—®é¢˜éƒ½åº”é€šè¿‡ <a href="https://github.com/microsoft/DeepSpeed/issues">Deepspeed</a> çš„ GitHub Issueså¤„ç†ï¼Œä½†åœ¨æ„å»ºä¾èµ–CUDA æ‰©å±•çš„ä»»ä½• PyTorch æ‰©å±•æ—¶ï¼Œå¯èƒ½ä¼šé‡åˆ°ä¸€äº›å¸¸è§é—®é¢˜ã€‚</p>
<p>å› æ­¤ï¼Œå¦‚æœåœ¨æ‰§è¡Œä»¥ä¸‹æ“ä½œæ—¶é‡åˆ°ä¸ CUDA ç›¸å…³çš„æ„å»ºé—®é¢˜ï¼š</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>deepspeed
</code></pre></div>
<p>è¯·é¦–å…ˆé˜…è¯»ä»¥ä¸‹è¯´æ˜ã€‚</p>
<p>åœ¨è¿™äº›è¯´æ˜ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†åœ¨ <code>pytorch</code> ä½¿ç”¨ CUDA <code>10.2</code> æ„å»ºæ—¶åº”é‡‡å–çš„æ“ä½œç¤ºä¾‹ã€‚å¦‚æœä½ çš„æƒ…å†µæœ‰æ‰€ä¸åŒï¼Œè¯·è®°å¾—å°†ç‰ˆæœ¬å·è°ƒæ•´ä¸ºæ‚¨æ‰€éœ€çš„ç‰ˆæœ¬ã€‚</p>
<h4 id="1">å¯èƒ½çš„é—®é¢˜ #1<a class="headerlink" href="#1" title="Permanent link">âš“ï¸</a></h4>
<p>å°½ç®¡ PyTorch è‡ªå¸¦äº†å…¶è‡ªå·±çš„ CUDA å·¥å…·åŒ…ï¼Œä½†è¦æ„å»ºè¿™ä¸¤ä¸ªé¡¹ç›®ï¼Œä½ å¿…é¡»åœ¨æ•´ä¸ªç³»ç»Ÿä¸Šå®‰è£…ç›¸åŒç‰ˆæœ¬çš„ CUDAã€‚</p>
<p>ä¾‹å¦‚ï¼Œå¦‚æœä½ åœ¨ Python ç¯å¢ƒä¸­ä½¿ç”¨ <code>cudatoolkit==10.2</code> å®‰è£…äº† <code>pytorch</code>ï¼Œä½ è¿˜éœ€è¦åœ¨æ•´ä¸ªç³»ç»Ÿä¸Šå®‰è£… CUDA <code>10.2</code>ã€‚</p>
<p>ç¡®åˆ‡çš„ä½ç½®å¯èƒ½å› ç³»ç»Ÿè€Œå¼‚ï¼Œä½†åœ¨è®¸å¤š Unix ç³»ç»Ÿä¸Šï¼Œ<code>/usr/local/cuda-10.2</code> æ˜¯æœ€å¸¸è§çš„ä½ç½®ã€‚å½“ CUDA æ­£ç¡®è®¾ç½®å¹¶æ·»åŠ åˆ° <code>PATH</code> ç¯å¢ƒå˜é‡æ—¶ï¼Œå¯ä»¥é€šè¿‡æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ‰¾åˆ°å®‰è£…ä½ç½®ï¼š</p>
<div class="highlight"><pre><span></span><code>which<span class="w"> </span>nvcc
</code></pre></div>
<p>å¦‚æœä½ å°šæœªåœ¨æ•´ä¸ªç³»ç»Ÿä¸Šå®‰è£… CUDAï¼Œè¯·é¦–å…ˆå®‰è£…ã€‚ä½ å¯ä»¥ä½¿ç”¨ä½ å–œæ¬¢çš„æœç´¢å¼•æ“æŸ¥æ‰¾è¯´æ˜ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ ä½¿ç”¨çš„æ˜¯ Ubuntuï¼Œä½ å¯èƒ½æƒ³æœç´¢ï¼š<a href="https://www.google.com/search?q=ubuntu+cuda+10.2+install">ubuntu cuda 10.2 install</a>ã€‚</p>
<h4 id="2">å¯èƒ½çš„é—®é¢˜ #2<a class="headerlink" href="#2" title="Permanent link">âš“ï¸</a></h4>
<p>å¦ä¸€ä¸ªå¯èƒ½çš„å¸¸è§é—®é¢˜æ˜¯ä½ å¯èƒ½åœ¨æ•´ä¸ªç³»ç»Ÿä¸Šå®‰è£…äº†å¤šä¸ª CUDA å·¥å…·åŒ…ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½æœ‰ï¼š</p>
<div class="highlight"><pre><span></span><code>/usr/local/cuda-10.2
/usr/local/cuda-11.0
</code></pre></div>
<p>åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ éœ€è¦ç¡®ä¿ <code>PATH</code> å’Œ <code>LD_LIBRARY_PATH</code> ç¯å¢ƒå˜é‡åŒ…å«æ‰€éœ€ CUDA ç‰ˆæœ¬çš„æ­£ç¡®è·¯å¾„ã€‚é€šå¸¸ï¼Œè½¯ä»¶åŒ…å®‰è£…ç¨‹åºå°†è®¾ç½®è¿™äº›å˜é‡ä»¥åŒ…å«æœ€æ–°å®‰è£…çš„ç‰ˆæœ¬ã€‚å¦‚æœé‡åˆ°æ„å»ºå¤±è´¥çš„é—®é¢˜ï¼Œä¸”æ˜¯å› ä¸ºåœ¨æ•´ä¸ªç³»ç»Ÿå®‰è£…ä½†è½¯ä»¶ä»æ‰¾ä¸åˆ°æ­£ç¡®çš„ CUDA ç‰ˆæœ¬ï¼Œè¿™æ„å‘³ç€ä½ éœ€è¦è°ƒæ•´è¿™ä¸¤ä¸ªç¯å¢ƒå˜é‡ã€‚</p>
<p>é¦–å…ˆï¼Œä½ ä»¥æŸ¥çœ‹å®ƒä»¬çš„å†…å®¹ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nb">echo</span><span class="w"> </span><span class="nv">$PATH</span>
<span class="nb">echo</span><span class="w"> </span><span class="nv">$LD_LIBRARY_PATH</span>
</code></pre></div>
<p>å› æ­¤ï¼Œæ‚¨å¯ä»¥äº†è§£å…¶ä¸­çš„å†…å®¹ã€‚</p>
<p><code>LD_LIBRARY_PATH</code> å¯èƒ½æ˜¯ç©ºçš„ã€‚</p>
<p><code>PATH</code> åˆ—å‡ºäº†å¯ä»¥æ‰¾åˆ°å¯æ‰§è¡Œæ–‡ä»¶çš„ä½ç½®ï¼Œè€Œ <code>LD_LIBRARY_PATH</code> ç”¨äºæŸ¥æ‰¾å…±äº«åº“ã€‚åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œè¾ƒæ—©çš„æ¡ç›®ä¼˜å…ˆäºè¾ƒåçš„æ¡ç›®ã€‚ <code>:</code> ç”¨äºåˆ†éš”å¤šä¸ªæ¡ç›®ã€‚</p>
<p>ç°åœ¨ï¼Œä¸ºäº†å‘Šè¯‰æ„å»ºç¨‹åºåœ¨å“ªé‡Œæ‰¾åˆ°ç‰¹å®šçš„ CUDA å·¥å…·åŒ…ï¼Œè¯·æ’å…¥æ‰€éœ€çš„è·¯å¾„ï¼Œè®©å…¶é¦–å…ˆåˆ—å‡ºï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">PATH</span><span class="o">=</span>/usr/local/cuda-10.2/bin:<span class="nv">$PATH</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span>/usr/local/cuda-10.2/lib64:<span class="nv">$LD_LIBRARY_PATH</span>
</code></pre></div>
<p>è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ²¡æœ‰è¦†ç›–ç°æœ‰å€¼ï¼Œè€Œæ˜¯åœ¨å‰é¢æ·»åŠ æ–°çš„å€¼ã€‚</p>
<p>å½“ç„¶ï¼Œæ ¹æ®éœ€è¦è°ƒæ•´ç‰ˆæœ¬å·å’Œå®Œæ•´è·¯å¾„ã€‚æ£€æŸ¥ä½ åˆ†é…çš„ç›®å½•æ˜¯å¦å®é™…å­˜åœ¨ã€‚<code>lib64</code> å­ç›®å½•æ˜¯å„ç§ CUDA <code>.so</code> å¯¹è±¡ï¼ˆå¦‚ <code>libcudart.so</code>ï¼‰çš„ä½ç½®ï¼Œè¿™ä¸ªåå­—å¯èƒ½åœ¨ä½ çš„ç³»ç»Ÿä¸­æ˜¯ä¸åŒçš„ï¼Œå¦‚æœæ˜¯ï¼Œè¯·è°ƒæ•´ä»¥åæ˜ å®é™…æƒ…å†µã€‚</p>
<h4 id="3">å¯èƒ½çš„é—®é¢˜ #3<a class="headerlink" href="#3" title="Permanent link">âš“ï¸</a></h4>
<p>ä¸€äº›è¾ƒæ—§çš„ CUDA ç‰ˆæœ¬å¯èƒ½ä¼šæ‹’ç»ä½¿ç”¨æ›´æ–°çš„ç¼–è¯‘å™¨ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½æœ‰ <code>gcc-9</code>ï¼Œä½† CUDA å¯èƒ½éœ€è¦ <code>gcc-7</code>ã€‚</p>
<p>æœ‰å„ç§æ–¹æ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</p>
<p>å¦‚æœä½ å¯ä»¥å®‰è£…æœ€æ–°çš„ CUDA å·¥å…·åŒ…ï¼Œé€šå¸¸å®ƒåº”è¯¥æ”¯æŒæ›´æ–°çš„ç¼–è¯‘å™¨ã€‚</p>
<p>æˆ–è€…ï¼Œä½ å¯ä»¥åœ¨å·²ç»æ‹¥æœ‰çš„ç¼–è¯‘å™¨ç‰ˆæœ¬ä¹‹å¤–å®‰è£…è¾ƒä½ç‰ˆæœ¬ï¼Œæˆ–è€…ä½ å¯èƒ½å·²ç»å®‰è£…äº†å®ƒä½†å®ƒä¸æ˜¯é»˜è®¤çš„ç¼–è¯‘å™¨ï¼Œå› æ­¤æ„å»ºç³»ç»Ÿæ— æ³•æ‰¾åˆ°å®ƒã€‚å¦‚æœä½ å·²ç»å®‰è£…äº† <code>gcc-7</code> ä½†æ„å»ºç³»ç»Ÿæ‰¾ä¸åˆ°å®ƒï¼Œä»¥ä¸‹æ“ä½œå¯èƒ½ä¼šè§£å†³é—®é¢˜ï¼š</p>
<div class="highlight"><pre><span></span><code>sudo<span class="w"> </span>ln<span class="w"> </span>-s<span class="w"> </span>/usr/bin/gcc-7<span class="w">  </span>/usr/local/cuda-10.2/bin/gcc
sudo<span class="w"> </span>ln<span class="w"> </span>-s<span class="w"> </span>/usr/bin/g++-7<span class="w">  </span>/usr/local/cuda-10.2/bin/g++
</code></pre></div>
<p>è¿™é‡Œï¼Œæˆ‘ä»¬æ­£åœ¨ä» <code>/usr/local/cuda-10.2/bin/gcc</code> åˆ›å»ºåˆ° <code>gcc-7</code> çš„è½¯é“¾æ¥ï¼Œç”±äº <code>/usr/local/cuda-10.2/bin/</code> åº”è¯¥åœ¨ <code>PATH</code> ç¯å¢ƒå˜é‡ä¸­ï¼ˆå‚è§å‰ä¸€ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼‰ï¼Œå®ƒåº”è¯¥èƒ½å¤Ÿæ‰¾åˆ° <code>gcc-7</code>ï¼ˆå’Œ <code>g++7</code>ï¼‰ï¼Œç„¶åæ„å»ºå°†æˆåŠŸã€‚</p>
<p>ä¸å¾€å¸¸ä¸€æ ·ï¼Œè¯·ç¡®ä¿ç¼–è¾‘ç¤ºä¾‹ä¸­çš„è·¯å¾„ä»¥åŒ¹é…ä½ çš„æƒ…å†µã€‚</p>
<h3 id="pytorchfsdp">PyTorchå®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œï¼ˆFSDP)<a class="headerlink" href="#pytorchfsdp" title="Permanent link">âš“ï¸</a></h3>
<p>ä¸ºäº†åŠ é€Ÿåœ¨æ›´å¤§æ‰¹æ¬¡å¤§å°ä¸Šè®­ç»ƒåºå¤§æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®Œå…¨åˆ†ç‰‡çš„æ•°æ®å¹¶è¡Œæ¨¡å‹ã€‚è¿™ç§æ•°æ®å¹¶è¡ŒèŒƒä¾‹é€šè¿‡å¯¹ä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦å’Œå‚æ•°è¿›è¡Œåˆ†ç‰‡ï¼Œå®ç°äº†åœ¨æ›´å¤šæ•°æ®å’Œæ›´å¤§æ¨¡å‹ä¸Šçš„è®­ç»ƒã€‚è¦äº†è§£æ›´å¤šä¿¡æ¯ä»¥åŠå…¶ä¼˜åŠ¿ï¼Œè¯·æŸ¥çœ‹<a href="https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/">å®Œå…¨åˆ†ç‰‡çš„æ•°æ®å¹¶è¡Œåšå®¢</a>ã€‚æˆ‘ä»¬å·²ç»é›†æˆäº†æœ€æ–°çš„PyTorchå®Œå…¨åˆ†ç‰‡çš„æ•°æ®å¹¶è¡Œï¼ˆFSDPï¼‰è®­ç»ƒåŠŸèƒ½ã€‚æ‚¨åªéœ€é€šè¿‡é…ç½®å¯ç”¨å®ƒã€‚</p>
<p><strong>FSDPæ”¯æŒæ‰€éœ€çš„PyTorchç‰ˆæœ¬</strong>: PyTorch Nightlyï¼ˆæˆ–è€…å¦‚æœä½ åœ¨å‘å¸ƒåé˜…è¯»è¿™ä¸ªï¼Œä½¿ç”¨1.12.0ç‰ˆæœ¬ï¼Œå› ä¸ºå¸¦æœ‰æ¿€æ´»çš„FSDPçš„æ¨¡å‹ä¿å­˜ä»…åœ¨æœ€è¿‘çš„ä¿®å¤ä¸­å¯ç”¨ã€‚</p>
<p><strong>ç”¨æ³•</strong>:</p>
<ul>
<li>
<p>å¦‚æœä½ å°šæœªä½¿ç”¨è¿‡åˆ†å¸ƒå¼å¯åŠ¨å™¨ï¼Œç¡®ä¿ä½ å·²ç»æ·»åŠ äº†å®ƒ <code>-m torch.distributed.launch --nproc_per_node=NUMBER_OF_GPUS_YOU_HAVE</code>ã€‚</p>
</li>
<li>
<p><strong>åˆ†ç‰‡ç­–ç•¥</strong>ï¼š</p>
</li>
<li>FULL_SHARDï¼šåœ¨æ•°æ®å¹¶è¡Œçº¿ç¨‹/GPUä¹‹é—´ï¼Œå¯¹ä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦å’Œæ¨¡å‹å‚æ•°è¿›è¡Œåˆ†ç‰‡ã€‚
    ä¸ºæ­¤ï¼Œè¯·åœ¨å‘½ä»¤è¡Œå‚æ•°ä¸­æ·»åŠ  <code>--fsdp full_shard</code>ã€‚</li>
<li>SHARD_GRAD_OPï¼šåœ¨æ•°æ®å¹¶è¡Œçº¿ç¨‹/GPUä¹‹é—´å¯¹ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦è¿›è¡Œåˆ†ç‰‡ã€‚
    ä¸ºæ­¤ï¼Œè¯·åœ¨å‘½ä»¤è¡Œå‚æ•°ä¸­æ·»åŠ  <code>--fsdp shard_grad_op</code>ã€‚</li>
<li>NO_SHARDï¼šä¸è¿›è¡Œåˆ†ç‰‡ã€‚ä¸ºæ­¤ï¼Œè¯·åœ¨å‘½ä»¤è¡Œå‚æ•°ä¸­æ·»åŠ  <code>--fsdp no_shard</code>ã€‚</li>
<li>è¦å°†å‚æ•°å’Œæ¢¯åº¦å¸è½½åˆ°CPUï¼Œæ·»åŠ  <code>--fsdp "full_shard offload"</code> æˆ– <code>--fsdp "shard_grad_op offload"</code> åˆ°å‘½ä»¤è¡Œå‚æ•°ä¸­ã€‚</li>
<li>è¦ä½¿ç”¨ <code>default_auto_wrap_policy</code> è‡ªåŠ¨é€’å½’åœ°ç”¨FSDPåŒ…è£…å±‚ï¼Œè¯·æ·»åŠ  <code>--fsdp "full_shard auto_wrap"</code> æˆ– <code>--fsdp "shard_grad_op auto_wrap"</code> åˆ°å‘½ä»¤è¡Œå‚æ•°ä¸­ã€‚</li>
<li>è¦åŒæ—¶å¯ç”¨CPUå¸è½½å’Œè‡ªåŠ¨åŒ…è£…å±‚å·¥å…·ï¼Œè¯·æ·»åŠ  <code>--fsdp "full_shard offload auto_wrap"</code> æˆ– <code>--fsdp "shard_grad_op offload auto_wrap"</code> åˆ°å‘½ä»¤è¡Œå‚æ•°ä¸­ã€‚</li>
<li>å…¶ä½™çš„FSDPé…ç½®é€šè¿‡ <code>--fsdp_config &lt;path_to_fsdp_config.json&gt;</code> ä¼ é€’ã€‚å®ƒå¯ä»¥æ˜¯FSDP jsoné…ç½®æ–‡ä»¶çš„ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œ<code>fsdp_config.json</code>ï¼‰æˆ–å·²åŠ è½½çš„jsonæ–‡ä»¶ä½œä¸º <code>dict</code>ã€‚</li>
<li>å¦‚æœå¯ç”¨äº†è‡ªåŠ¨åŒ…è£…ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨åŸºäºtransformerçš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥æˆ–åŸºäºå¤§å°çš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ã€‚<ul>
<li>å¯¹äºåŸºäºtransformerçš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ï¼Œå»ºè®®åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š <code>fsdp_transformer_layer_cls_to_wrap</code>ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™é»˜è®¤å€¼ä¸º <code>model._no_split_modules</code>ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚è¿™å°†æŒ‡å®šè¦åŒ…è£…çš„transformerå±‚ç±»åï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼Œä¾‹å¦‚ [<code>BertLayer</code>]ã€[<code>GPTJBlock</code>]ã€[<code>T5Block</code>] ç­‰ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºå…±äº«æƒé‡çš„å­æ¨¡å—ï¼ˆä¾‹å¦‚ï¼Œembeddingå±‚ï¼‰ä¸åº”æœ€ç»ˆå‡ºç°åœ¨ä¸åŒçš„FSDPåŒ…è£…å•å…ƒä¸­ã€‚ä½¿ç”¨æ­¤ç­–ç•¥ï¼Œæ¯ä¸ªåŒ…è£…çš„å—å°†åŒ…å«å¤šå¤´æ³¨æ„åŠ›å’Œåé¢çš„å‡ ä¸ªMLPå±‚ã€‚å‰©ä½™çš„å±‚ï¼ŒåŒ…æ‹¬å…±äº«çš„embeddingå±‚ï¼Œéƒ½å°†è¢«æ–¹ä¾¿åœ°åŒ…è£…åœ¨åŒä¸€ä¸ªæœ€å¤–å±‚çš„FSDPå•å…ƒä¸­ã€‚å› æ­¤ï¼Œå¯¹äºåŸºäºtransformerçš„æ¨¡å‹ï¼Œè¯·ä½¿ç”¨è¿™ä¸ªæ–¹æ³•ã€‚</li>
<li>å¯¹äºåŸºäºå¤§å°çš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ  <code>fsdp_min_num_params</code>ã€‚å®ƒæŒ‡å®šäº†FSDPè¿›è¡Œè‡ªåŠ¨åŒ…è£…çš„æœ€å°å‚æ•°æ•°é‡ã€‚</li>
</ul>
</li>
<li>å¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š <code>fsdp_backward_prefetch</code>ã€‚å®ƒæ§åˆ¶ä½•æ—¶é¢„å–ä¸‹ä¸€ç»„å‚æ•°ã€‚<code>backward_pre</code> å’Œ <code>backward_pos</code> æ˜¯å¯ç”¨çš„é€‰é¡¹ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… <code>torch.distributed.fsdp.fully_sharded_data_parallel.BackwardPrefetch</code></li>
<li>å¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š <code>fsdp_forward_prefetch</code>ã€‚å®ƒæ§åˆ¶ä½•æ—¶é¢„å–ä¸‹ä¸€ç»„å‚æ•°ã€‚å¦‚æœæ˜¯<code>"True"</code>ï¼Œåœ¨æ‰§è¡Œå‰å‘ä¼ é€’æ—¶ï¼ŒFSDPæ˜ç¡®åœ°é¢„å–ä¸‹ä¸€æ¬¡å³å°†å‘ç”Ÿçš„å…¨å±€èšé›†ã€‚</li>
<li>å¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š <code>limit_all_gathers</code>ã€‚å¦‚æœæ˜¯<code>"True"</code>ï¼ŒFSDPæ˜ç¡®åœ°åŒæ­¥CPUçº¿ç¨‹ï¼Œä»¥é˜²æ­¢å¤ªå¤šçš„è¿›è¡Œä¸­çš„å…¨å±€èšé›†ã€‚</li>
<li>å¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š <code>activation_checkpointing</code>ã€‚å¦‚æœæ˜¯<code>"True"</code>ï¼ŒFSDP activation checkpointæ˜¯ä¸€ç§é€šè¿‡æ¸…é™¤æŸäº›å±‚çš„æ¿€æ´»å€¼å¹¶åœ¨åå‘ä¼ é€’æœŸé—´é‡æ–°è®¡ç®—å®ƒä»¬æ¥å‡å°‘å†…å­˜ä½¿ç”¨çš„æŠ€æœ¯ã€‚å®é™…ä¸Šï¼Œè¿™ä»¥æ›´å¤šçš„è®¡ç®—æ—¶é—´ä¸ºä»£ä»·å‡å°‘äº†å†…å­˜ä½¿ç”¨ã€‚</li>
</ul>
<p><strong>éœ€è¦æ³¨æ„å‡ ä¸ªæ³¨æ„äº‹é¡¹</strong>
- å®ƒä¸ <code>generate</code> ä¸å…¼å®¹ï¼Œå› æ­¤ä¸æ‰€æœ‰seq2seq/clmè„šæœ¬ï¼ˆç¿»è¯‘/æ‘˜è¦/clmç­‰ï¼‰ä¸­çš„ <code>--predict_with_generate</code> ä¸å…¼å®¹ã€‚è¯·å‚é˜…issue<a href="https://github.com/huggingface/transformers/issues/21667">#21667</a>ã€‚</p>
<h3 id="pytorchxla">PyTorch/XLA å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œ<a class="headerlink" href="#pytorchxla" title="Permanent link">âš“ï¸</a></h3>
<p>å¯¹äºæ‰€æœ‰TPUç”¨æˆ·ï¼Œæœ‰ä¸ªå¥½æ¶ˆæ¯ï¼PyTorch/XLAç°åœ¨æ”¯æŒFSDPã€‚æ‰€æœ‰æœ€æ–°çš„å®Œå…¨åˆ†ç‰‡æ•°æ®å¹¶è¡Œï¼ˆFSDPï¼‰è®­ç»ƒéƒ½å—æ”¯æŒã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…<a href="https://pytorch.org/blog/scaling-pytorch-models-on-cloud-tpus-with-fsdp/">åœ¨äº‘ç«¯TPUä¸Šä½¿ç”¨FSDPæ‰©å±•PyTorchæ¨¡å‹</a>å’Œ<a href="https://github.com/pytorch/xla/tree/master/torch_xla/distributed/fsdp">PyTorch/XLA FSDPçš„å®ç°</a>ã€‚ä½¿ç”¨å®ƒåªéœ€é€šè¿‡é…ç½®å¯ç”¨ã€‚</p>
<p><strong>éœ€è¦çš„ PyTorch/XLA ç‰ˆæœ¬ä»¥æ”¯æŒ FSDP</strong>ï¼š&gt;=2.0</p>
<p><strong>ç”¨æ³•</strong>ï¼š</p>
<p>ä¼ é€’ <code>--fsdp "full shard"</code>ï¼ŒåŒæ—¶å¯¹ <code>--fsdp_config &lt;path_to_fsdp_config.json&gt;</code> è¿›è¡Œä»¥ä¸‹æ›´æ”¹ï¼š
- <code>xla</code> åº”è®¾ç½®ä¸º <code>True</code> ä»¥å¯ç”¨ PyTorch/XLA FSDPã€‚
- <code>xla_fsdp_settings</code> çš„å€¼æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå­˜å‚¨ XLA FSDP å°è£…å‚æ•°ã€‚å®Œæ•´çš„é€‰é¡¹åˆ—è¡¨ï¼Œè¯·å‚è§<a href="https://github.com/pytorch/xla/blob/master/torch_xla/distributed/fsdp/xla_fully_sharded_data_parallel.py">æ­¤å¤„</a>ã€‚
- <code>xla_fsdp_grad_ckpt</code>ã€‚å½“ <code>True</code> æ—¶ï¼Œåœ¨æ¯ä¸ªåµŒå¥—çš„ XLA FSDP å°è£…å±‚ä¸Šä½¿ç”¨æ¢¯åº¦checkpointã€‚è¯¥è®¾ç½®åªèƒ½åœ¨å°† xla æ ‡å¿—è®¾ç½®ä¸º trueï¼Œå¹¶é€šè¿‡ <code>fsdp_min_num_params</code> æˆ– <code>fsdp_transformer_layer_cls_to_wrap</code> æŒ‡å®šè‡ªåŠ¨åŒ…è£…ç­–ç•¥æ—¶ä½¿ç”¨ã€‚
- æ‚¨å¯ä»¥ä½¿ç”¨åŸºäºtransformerçš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥æˆ–åŸºäºå¤§å°çš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ã€‚
  - å¯¹äºåŸºäºtransformerçš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ï¼Œå»ºè®®åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®š <code>fsdp_transformer_layer_cls_to_wrap</code>ã€‚å¦‚æœæœªæŒ‡å®šï¼Œé»˜è®¤å€¼ä¸º <code>model._no_split_modules</code>ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚è¿™æŒ‡å®šäº†è¦åŒ…è£…çš„transformerå±‚ç±»ååˆ—è¡¨ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰ï¼Œä¾‹å¦‚ [<code>BertLayer</code>]ã€[<code>GPTJBlock</code>]ã€[<code>T5Block</code>] ç­‰ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºå…±äº«æƒé‡çš„å­æ¨¡å—ï¼ˆä¾‹å¦‚ï¼Œembeddingå±‚ï¼‰ä¸åº”æœ€ç»ˆå‡ºç°åœ¨ä¸åŒçš„FSDPåŒ…è£…å•å…ƒä¸­ã€‚ä½¿ç”¨æ­¤ç­–ç•¥ï¼Œæ¯ä¸ªåŒ…è£…çš„å—å°†åŒ…å«å¤šå¤´æ³¨æ„åŠ›å’Œåé¢çš„å‡ ä¸ªMLPå±‚ã€‚å‰©ä½™çš„å±‚ï¼ŒåŒ…æ‹¬å…±äº«çš„embeddingå±‚ï¼Œéƒ½å°†è¢«æ–¹ä¾¿åœ°åŒ…è£…åœ¨åŒä¸€ä¸ªæœ€å¤–å±‚çš„FSDPå•å…ƒä¸­ã€‚å› æ­¤ï¼Œå¯¹äºåŸºäºtransformerçš„æ¨¡å‹ï¼Œè¯·ä½¿ç”¨è¿™ä¸ªæ–¹æ³•ã€‚
  - å¯¹äºåŸºäºå¤§å°çš„è‡ªåŠ¨åŒ…è£…ç­–ç•¥ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ  <code>fsdp_min_num_params</code>ã€‚å®ƒæŒ‡å®šäº†è‡ªåŠ¨åŒ…è£…çš„ FSDP çš„æœ€å°å‚æ•°æ•°é‡ã€‚</p>
<h3 id="mac-trainer-pytorch">åœ¨ Mac ä¸Šä½¿ç”¨ Trainer è¿›è¡ŒåŠ é€Ÿçš„ PyTorch è®­ç»ƒ<a class="headerlink" href="#mac-trainer-pytorch" title="Permanent link">âš“ï¸</a></h3>
<p>éšç€ PyTorch v1.12 ç‰ˆæœ¬çš„å‘å¸ƒï¼Œå¼€å‘äººå‘˜å’Œç ”ç©¶äººå‘˜å¯ä»¥åˆ©ç”¨ Apple Silicon GPU è¿›è¡Œæ˜¾è‘—æ›´å¿«çš„æ¨¡å‹è®­ç»ƒã€‚è¿™ä½¿å¾—å¯ä»¥åœ¨ Mac ä¸Šæœ¬åœ°æ‰§è¡ŒåŸå‹è®¾è®¡å’Œå¾®è°ƒç­‰æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ã€‚Apple çš„ Metal Performance Shadersï¼ˆMPSï¼‰ä½œä¸º PyTorch çš„åç«¯å®ç°äº†è¿™ä¸€ç‚¹ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡æ–°çš„ <code>"mps"</code> è®¾å¤‡æ¥ä½¿ç”¨ã€‚
è¿™å°†åœ¨ MPS å›¾å½¢æ¡†æ¶ä¸Šæ˜ å°„è®¡ç®—å›¾å’Œç¥ç»å›¾å…ƒï¼Œå¹¶ä½¿ç”¨ MPS æä¾›çš„ä¼˜åŒ–å†…æ ¸ã€‚æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…å®˜æ–¹æ–‡æ¡£ <a href="https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/">Introducing Accelerated PyTorch Training on Mac</a> å’Œ <a href="https://pytorch.org/docs/stable/notes/mps.html">MPS BACKEND</a>ã€‚</p>
<p><Tip warning={false}></p>
<p>æˆ‘ä»¬å¼ºçƒˆå»ºè®®åœ¨ä½ çš„ MacOS æœºå™¨ä¸Šå®‰è£… PyTorch &gt;= 1.13ï¼ˆåœ¨æ’°å†™æœ¬æ–‡æ—¶ä¸ºæœ€æ–°ç‰ˆæœ¬ï¼‰ã€‚å¯¹äºåŸºäº transformer çš„æ¨¡å‹ï¼Œ å®ƒæä¾›ä¸æ¨¡å‹æ­£ç¡®æ€§å’Œæ€§èƒ½æ”¹è¿›ç›¸å…³çš„é‡å¤§ä¿®å¤ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…<a href="https://github.com/pytorch/pytorch/issues/82707">pytorch/pytorch#82707</a>ã€‚</p>
<p></Tip></p>
<p><strong>ä½¿ç”¨ Apple Silicon èŠ¯ç‰‡è¿›è¡Œè®­ç»ƒå’Œæ¨ç†çš„å¥½å¤„</strong></p>
<ol>
<li>ä½¿ç”¨æˆ·èƒ½å¤Ÿåœ¨æœ¬åœ°è®­ç»ƒæ›´å¤§çš„ç½‘ç»œæˆ–æ‰¹é‡æ•°æ®ã€‚</li>
<li>ç”±äºç»Ÿä¸€å†…å­˜æ¶æ„ï¼Œå‡å°‘æ•°æ®æ£€ç´¢å»¶è¿Ÿï¼Œå¹¶ä¸º GPU æä¾›å¯¹å®Œæ•´å†…å­˜å­˜å‚¨çš„ç›´æ¥è®¿é—®ã€‚ä»è€Œæé«˜ç«¯åˆ°ç«¯æ€§èƒ½ã€‚</li>
<li>é™ä½ä¸åŸºäºäº‘çš„å¼€å‘æˆ–éœ€è¦é¢å¤–æœ¬åœ° GPU çš„æˆæœ¬ã€‚</li>
</ol>
<p><strong>å…ˆå†³æ¡ä»¶</strong>ï¼šè¦å®‰è£…å¸¦æœ‰ mps æ”¯æŒçš„ torchï¼Œè¯·æŒ‰ç…§è¿™ç¯‡ç²¾å½©çš„ Medium æ–‡ç« æ“ä½œ <a href="https://medium.com/towards-data-science/gpu-acceleration-comes-to-pytorch-on-m1-macs-195c399efcc1">GPU-Acceleration Comes to PyTorch on M1 Macs</a>ã€‚</p>
<p><strong>ç”¨æ³•</strong>ï¼š
å¦‚æœå¯ç”¨ï¼Œ<code>mps</code> è®¾å¤‡å°†é»˜è®¤ä½¿ç”¨ï¼Œç±»ä¼¼äºä½¿ç”¨ <code>cuda</code> è®¾å¤‡çš„æ–¹å¼ã€‚å› æ­¤ï¼Œç”¨æˆ·æ— éœ€é‡‡å–ä»»ä½•æ“ä½œã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åœ¨ Apple Silicon GPU ä¸Šè¿è¡Œå®˜æ–¹çš„ Glue æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼ˆä»æ ¹æ–‡ä»¶å¤¹è¿è¡Œï¼‰ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">TASK_NAME</span><span class="o">=</span>mrpc

python<span class="w"> </span>examples/pytorch/text-classification/run_glue.py<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--model_name_or_path<span class="w"> </span>bert-base-cased<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--task_name<span class="w"> </span><span class="nv">$TASK_NAME</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--do_train<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--do_eval<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--max_seq_length<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--per_device_train_batch_size<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--learning_rate<span class="w"> </span>2e-5<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--num_train_epochs<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--output_dir<span class="w"> </span>/tmp/<span class="nv">$TASK_NAME</span>/<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--overwrite_output_dir
</code></pre></div>
<p><strong>éœ€è¦æ³¨æ„çš„ä¸€äº›æ³¨æ„äº‹é¡¹</strong></p>
<ol>
<li>ä¸€äº› PyTorch æ“ä½œå°šæœªåœ¨ mps ä¸­å®ç°ï¼Œå°†å¼•å‘é”™è¯¯ã€‚è§£å†³æ­¤é—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯è®¾ç½®ç¯å¢ƒå˜é‡ <code>PYTORCH_ENABLE_MPS_FALLBACK=1</code>ï¼Œå®ƒå°†æŠŠè¿™äº›æ“ä½œå›é€€åˆ° CPU è¿›è¡Œã€‚ç„¶è€Œï¼Œå®ƒä»ç„¶ä¼šæŠ›å‡º UserWarning ä¿¡æ¯ã€‚</li>
<li>åˆ†å¸ƒå¼è®¾ç½® <code>gloo</code> å’Œ <code>nccl</code> åœ¨ <code>mps</code> è®¾å¤‡ä¸Šä¸èµ·ä½œç”¨ã€‚è¿™æ„å‘³ç€å½“å‰åªèƒ½ä½¿ç”¨ <code>mps</code> è®¾å¤‡ç±»å‹çš„å•ä¸ª GPUã€‚</li>
</ol>
<p>æœ€åï¼Œè¯·è®°ä½ï¼ŒğŸ¤— <code>Trainer</code> ä»…é›†æˆäº† MPS åç«¯ï¼Œå› æ­¤å¦‚æœä½ åœ¨ä½¿ç”¨ MPS åç«¯æ—¶é‡åˆ°ä»»ä½•é—®é¢˜æˆ–æœ‰ç–‘é—®ï¼Œè¯·åœ¨ <a href="https://github.com/pytorch/pytorch/issues">PyTorch GitHub</a> ä¸Šæäº¤é—®é¢˜ã€‚</p>
<h2 id="accelerate-launcher-trainer">é€šè¿‡ Accelerate Launcher ä½¿ç”¨ Trainer<a class="headerlink" href="#accelerate-launcher-trainer" title="Permanent link">âš“ï¸</a></h2>
<p>Accelerate ç°åœ¨æ”¯æŒ Trainerã€‚ç”¨æˆ·å¯ä»¥æœŸå¾…ä»¥ä¸‹å†…å®¹ï¼š
- ä»–ä»¬å¯ä»¥ç»§ç»­ä½¿ç”¨ Trainer çš„è¿­ä»£ï¼Œå¦‚ FSDPã€DeepSpeed ç­‰ï¼Œè€Œæ— éœ€åšä»»ä½•æ›´æ”¹ã€‚
- ç°åœ¨å¯ä»¥åœ¨ Trainer ä¸­ä½¿ç”¨ Accelerate Launcherï¼ˆå»ºè®®ä½¿ç”¨ï¼‰ã€‚</p>
<p>é€šè¿‡ Accelerate Launcher ä½¿ç”¨ Trainer çš„æ­¥éª¤ï¼š
1. ç¡®ä¿å·²å®‰è£… ğŸ¤— Accelerateï¼Œæ— è®ºå¦‚ä½•ï¼Œå¦‚æœæ²¡æœ‰å®ƒï¼Œä½ æ— æ³•ä½¿ç”¨ <code>Trainer</code>ã€‚å¦‚æœæ²¡æœ‰ï¼Œè¯·æ‰§è¡Œ <code>pip install accelerate</code>ã€‚ä½ å¯èƒ½è¿˜éœ€è¦æ›´æ–° Accelerate çš„ç‰ˆæœ¬ï¼š<code>pip install accelerate --upgrade</code>ã€‚
2. è¿è¡Œ <code>accelerate config</code> å¹¶å¡«å†™é—®é¢˜ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›åŠ é€Ÿé…ç½®çš„ç¤ºä¾‹ï¼š</p>
<p>a. DDP å¤šèŠ‚ç‚¹å¤š GPU é…ç½®ï¼š</p>
<div class="highlight"><pre><span></span><code>```yaml
compute_environment: LOCAL_MACHINE                                                                                             
distributed_type: MULTI_GPU                                                                                                    
downcast_bf16: &#39;no&#39;
gpu_ids: all
machine_rank: 0 #change rank as per the node
main_process_ip: 192.168.20.1
main_process_port: 9898
main_training_function: main
mixed_precision: fp16
num_machines: 2
num_processes: 8
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```
</code></pre></div>
<p>b. FSDP é…ç½®ï¼š</p>
<div class="highlight"><pre><span></span><code>```yaml
compute_environment: LOCAL_MACHINE
distributed_type: FSDP
downcast_bf16: &#39;no&#39;
fsdp_config:
  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP
  fsdp_backward_prefetch_policy: BACKWARD_PRE
  fsdp_forward_prefetch: true
  fsdp_offload_params: false
  fsdp_sharding_strategy: 1
  fsdp_state_dict_type: FULL_STATE_DICT
  fsdp_sync_module_states: true
  fsdp_transformer_layer_cls_to_wrap: BertLayer
  fsdp_use_orig_params: true
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 2
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```
</code></pre></div>
<p>c. æŒ‡å‘æ–‡ä»¶çš„ DeepSpeed é…ç½®ï¼š</p>
<div class="highlight"><pre><span></span><code>```yaml
compute_environment: LOCAL_MACHINE
deepspeed_config:
  deepspeed_config_file: /home/user/configs/ds_zero3_config.json
  zero3_init_flag: true
distributed_type: DEEPSPEED
downcast_bf16: &#39;no&#39;
machine_rank: 0
main_training_function: main
num_machines: 1
num_processes: 4
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```
</code></pre></div>
<p>d. ä½¿ç”¨ accelerate æ’ä»¶çš„ DeepSpeed é…ç½®ï¼š</p>
<div class="highlight"><pre><span></span><code>```yaml
compute_environment: LOCAL_MACHINE                                                                                             
deepspeed_config:                                                                                                              
  gradient_accumulation_steps: 1
  gradient_clipping: 0.7
  offload_optimizer_device: cpu
  offload_param_device: cpu
  zero3_init_flag: true
  zero_stage: 2
distributed_type: DEEPSPEED
downcast_bf16: &#39;no&#39;
machine_rank: 0
main_training_function: main
mixed_precision: bf16
num_machines: 1
num_processes: 4
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```
</code></pre></div>
<ol>
<li>ä½¿ç”¨accelerateé…ç½®æ–‡ä»¶å‚æ•°æˆ–å¯åŠ¨å™¨å‚æ•°ä»¥å¤–çš„å‚æ•°è¿è¡ŒTrainerè„šæœ¬ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨ä¸Šè¿°FSDPé…ç½®ä»accelerateå¯åŠ¨å™¨è¿è¡Œ<code>run_glue.py</code>çš„ç¤ºä¾‹ã€‚</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>transformers

accelerate<span class="w"> </span>launch<span class="w"> </span><span class="se">\</span>
./examples/pytorch/text-classification/run_glue.py<span class="w"> </span><span class="se">\</span>
--model_name_or_path<span class="w"> </span>bert-base-cased<span class="w"> </span><span class="se">\</span>
--task_name<span class="w"> </span><span class="nv">$TASK_NAME</span><span class="w"> </span><span class="se">\</span>
--do_train<span class="w"> </span><span class="se">\</span>
--do_eval<span class="w"> </span><span class="se">\</span>
--max_seq_length<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
--per_device_train_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
--learning_rate<span class="w"> </span>5e-5<span class="w"> </span><span class="se">\</span>
--num_train_epochs<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
--output_dir<span class="w"> </span>/tmp/<span class="nv">$TASK_NAME</span>/<span class="w"> </span><span class="se">\</span>
--overwrite_output_dir
</code></pre></div>
<ol>
<li>ä½ ä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨<code>accelerate launch</code>çš„cmdå‚æ•°ã€‚ä¸Šé¢çš„ç¤ºä¾‹å°†æ˜ å°„åˆ°ï¼š</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>transformers

accelerate<span class="w"> </span>launch<span class="w"> </span>--num_processes<span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
--use_fsdp<span class="w"> </span><span class="se">\</span>
--mixed_precision<span class="o">=</span>bf16<span class="w"> </span><span class="se">\</span>
--fsdp_auto_wrap_policy<span class="o">=</span>TRANSFORMER_BASED_WRAP<span class="w">  </span><span class="se">\</span>
--fsdp_transformer_layer_cls_to_wrap<span class="o">=</span><span class="s2">&quot;BertLayer&quot;</span><span class="w"> </span><span class="se">\</span>
--fsdp_sharding_strategy<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
--fsdp_state_dict_type<span class="o">=</span>FULL_STATE_DICT<span class="w"> </span><span class="se">\</span>
./examples/pytorch/text-classification/run_glue.py
--model_name_or_path<span class="w"> </span>bert-base-cased<span class="w"> </span><span class="se">\</span>
--task_name<span class="w"> </span><span class="nv">$TASK_NAME</span><span class="w"> </span><span class="se">\</span>
--do_train<span class="w"> </span><span class="se">\</span>
--do_eval<span class="w"> </span><span class="se">\</span>
--max_seq_length<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
--per_device_train_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
--learning_rate<span class="w"> </span>5e-5<span class="w"> </span><span class="se">\</span>
--num_train_epochs<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
--output_dir<span class="w"> </span>/tmp/<span class="nv">$TASK_NAME</span>/<span class="w"> </span><span class="se">\</span>
--overwrite_output_dir
</code></pre></div>
<p>æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… ğŸ¤— Accelerate CLI æŒ‡å—ï¼š<a href="https://huggingface.co/docs/accelerate/basic_tutorials/launch">å¯åŠ¨æ‚¨çš„ ğŸ¤— Accelerate è„šæœ¬</a>ã€‚</p>
<p>å·²ç§»åŠ¨çš„éƒ¨åˆ†ï¼š</p>
<p>[ <a href="./deepspeed#deepspeed-trainer-integration">DeepSpeed</a><a id="deepspeed"></a> | <a href="./deepspeed#deepspeed-installation">Installation</a><a id="installation"></a> | <a href="./deepspeed#deepspeed-multi-gpu">Deployment with multiple GPUs</a><a id="deployment-with-multiple-gpus"></a> | <a href="./deepspeed#deepspeed-one-gpu">Deployment with one GPU</a><a id="deployment-with-one-gpu"></a> | <a href="./deepspeed#deepspeed-notebook">Deployment in Notebooks</a><a id="deployment-in-notebooks"></a> | <a href="./deepspeed#deepspeed-config">Configuration</a><a id="configuration"></a> | <a href="./deepspeed#deepspeed-config-passing">Passing Configuration</a><a id="passing-configuration"></a> | <a href="./deepspeed#deepspeed-config-shared">Shared Configuration</a><a id="shared-configuration"></a> | <a href="./deepspeed#deepspeed-zero">ZeRO</a><a id="zero"></a> | <a href="./deepspeed#deepspeed-zero2-config">ZeRO-2 Config</a><a id="zero-2-config"></a> | <a href="./deepspeed#deepspeed-zero3-config">ZeRO-3 Config</a><a id="zero-3-config"></a> | <a href="./deepspeed#deepspeed-nvme">NVMe Support</a><a id="nvme-support"></a> | <a href="./deepspeed#deepspeed-zero2-zero3-performance">ZeRO-2 vs ZeRO-3 Performance</a><a id="zero-2-vs-zero-3-performance"></a> | <a href="./deepspeed#deepspeed-zero2-example">ZeRO-2 Example</a><a id="zero-2-example"></a> | <a href="./deepspeed#deepspeed-zero3-example">ZeRO-3 Example</a><a id="zero-3-example"></a> | <a href="./deepspeed#deepspeed-optimizer">Optimizer</a><a id="optimizer"></a> | <a href="./deepspeed#deepspeed-scheduler">Scheduler</a><a id="scheduler"></a> | <a href="./deepspeed#deepspeed-fp32">fp32 Precision</a><a id="fp32-precision"></a> | <a href="./deepspeed#deepspeed-amp">Automatic Mixed Precision</a><a id="automatic-mixed-precision"></a> | <a href="./deepspeed#deepspeed-bs">Batch Size</a><a id="batch-size"></a> | <a href="./deepspeed#deepspeed-grad-acc">Gradient Accumulation</a><a id="gradient-accumulation"></a> | <a href="./deepspeed#deepspeed-grad-clip">Gradient Clipping</a><a id="gradient-clipping"></a> | <a href="./deepspeed#deepspeed-weight-extraction">Getting The Model Weights Out</a><a id="getting-the-model-weights-out"></a>]</p>
<h2 id="neftune">é€šè¿‡ NEFTune æå‡å¾®è°ƒæ€§èƒ½<a class="headerlink" href="#neftune" title="Permanent link">âš“ï¸</a></h2>
<p>NEFTune æ˜¯ä¸€ç§æå‡èŠå¤©æ¨¡å‹æ€§èƒ½çš„æŠ€æœ¯ï¼Œç”± Jain ç­‰äººåœ¨è®ºæ–‡â€œNEFTune: Noisy Embeddings Improve Instruction Finetuningâ€ ä¸­å¼•å…¥ã€‚è¯¥æŠ€æœ¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‘embeddingå‘é‡æ·»åŠ å™ªéŸ³ã€‚æ ¹æ®è®ºæ–‡æ‘˜è¦ï¼š</p>
<blockquote>
<p>ä½¿ç”¨ Alpaca å¯¹ LLaMA-2-7B è¿›è¡Œæ ‡å‡†å¾®è°ƒï¼Œå¯ä»¥åœ¨ AlpacaEval ä¸Šè¾¾åˆ° 29.79%ï¼Œè€Œä½¿ç”¨å¸¦æœ‰å™ªéŸ³embeddingçš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½æé«˜è‡³ 64.69%ã€‚NEFTune è¿˜åœ¨modern instructionæ•°æ®é›†ä¸Šå¤§å¤§ä¼˜äºåŸºçº¿ã€‚Evol-Instruct è®­ç»ƒçš„æ¨¡å‹è¡¨ç°æé«˜äº† 10%ï¼ŒShareGPT æé«˜äº† 8%ï¼ŒOpenPlatypus æé«˜äº† 8%ã€‚å³ä½¿åƒ LLaMA-2-Chat è¿™æ ·é€šè¿‡ RLHF è¿›ä¸€æ­¥ç»†åŒ–çš„å¼ºå¤§æ¨¡å‹ï¼Œé€šè¿‡ NEFTune çš„é¢å¤–è®­ç»ƒä¹Ÿèƒ½å—ç›Šã€‚</p>
</blockquote>
<div style="text-align: center">
<img src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/neft-screenshot.png">
</div>

<p>è¦åœ¨ <code>Trainer</code> ä¸­ä½¿ç”¨å®ƒï¼Œåªéœ€åœ¨åˆ›å»º <code>TrainingArguments</code> å®ä¾‹æ—¶ä¼ é€’ <code>neftune_noise_alpha</code>ã€‚è¯·æ³¨æ„ï¼Œä¸ºäº†é¿å…ä»»ä½•æ„å¤–è¡Œä¸ºï¼ŒNEFTuneåœ¨è®­ç»ƒåè¢«ç¦æ­¢ï¼Œä»¥æ­¤æ¢å¤åŸå§‹çš„embeddingå±‚ã€‚</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">neftune_noise_alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>

<span class="o">...</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>

  <hr>
<div class="md-source-file">
  <small>
    
      æœ€åæ›´æ–°:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        åˆ›å»ºæ—¥æœŸ:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  å›åˆ°é¡µé¢é¡¶éƒ¨
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="é¡µè„š" >
        
          
          <a href="../model/" class="md-footer__link md-footer__link--prev" aria-label="ä¸Šä¸€é¡µ: Model">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                ä¸Šä¸€é¡µ
              </span>
              <div class="md-ellipsis">
                Model
              </div>
            </div>
          </a>
        
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="githubä¸»é¡µ" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="bç«™ä¸»é¡µ" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="ä¸ªäººä¸»é¡µ" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>