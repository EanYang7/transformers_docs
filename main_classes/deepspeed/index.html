
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="transformers_docs">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/transformers_docs/main_classes/deepspeed/">
      
      
        <link rel="prev" href="../../4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/">
      
      
        <link rel="next" href="../model/">
      
      
      <link rel="icon" href="../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>Deepspeed - Transformers æ–‡æ¡£</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#deepspeed" class="md-skip">
          è·³è½¬è‡³
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="é¡µçœ‰">
    <a href="../.." title="Transformers æ–‡æ¡£" class="md-header__button md-logo" aria-label="Transformers æ–‡æ¡£" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Transformers æ–‡æ¡£
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Deepspeed
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="åˆ‡æ¢ä¸ºæš—é»‘æ¨¡å¼"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="åˆ‡æ¢ä¸ºæš—é»‘æ¨¡å¼" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="åˆ‡æ¢ä¸ºæµ…è‰²æ¨¡å¼"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="åˆ‡æ¢ä¸ºæµ…è‰²æ¨¡å¼" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="æœç´¢" placeholder="æœç´¢" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="æŸ¥æ‰¾">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="åˆ†äº«" aria-label="åˆ†äº«" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="æ¸…ç©ºå½“å‰å†…å®¹" aria-label="æ¸…ç©ºå½“å‰å†…å®¹" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            æ­£åœ¨åˆå§‹åŒ–æœç´¢å¼•æ“
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/transformers_docs" title="å‰å¾€ä»“åº“" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    githubä»“åº“
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="å¯¼èˆªæ " data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Transformers æ–‡æ¡£" class="md-nav__button md-logo" aria-label="Transformers æ–‡æ¡£" data-md-component="logo">
      
  <img src="../../assets/logo.jpg" alt="logo">

    </a>
    Transformers æ–‡æ¡£
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/transformers_docs" title="å‰å¾€ä»“åº“" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    githubä»“åº“
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../autoclass_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autoclass tutorial
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../awesome-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Awesome projects built with Transformers
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../big_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Big models
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../debugging/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Debugging
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../hpo_train/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hpo train
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../llm_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llm tutorial
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../model_sharing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model sharing
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Peft
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../perf_hardware/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Perf hardware
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../perf_torch_compile/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Perf torch compile
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../performance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Performance
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../run_scripts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Run scripts
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../tf_xla/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tf xla
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer_summary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tokenizer summary
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../1-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    1 å¼€å§‹ä½¿ç”¨
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../2-%E6%95%99%E7%A8%8B/accelerate/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    2 æ•™ç¨‹
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../3-%E5%BC%80%E5%8F%91%E8%80%85%E6%8C%87%E5%8D%97/create_a_model/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    3 å¼€å‘è€…æŒ‡å—
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    4 æ¦‚å¿µæŒ‡å—
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_20" checked>
        
          
          <label class="md-nav__link" for="__nav_20" id="__nav_20_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Main classes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_20_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_20">
            <span class="md-nav__icon md-icon"></span>
            Main classes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Deepspeed
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Deepspeed
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="ç›®å½•">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      ç›®å½•
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#trainer-deepspeed" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer DeepSpeed é›†æˆ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Trainer DeepSpeed é›†æˆ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      å®‰è£…
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu" class="md-nav__link">
    <span class="md-ellipsis">
      å¤šGPUå¯ç”¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu_1" class="md-nav__link">
    <span class="md-ellipsis">
      å•GPUå¯ç”¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      å¤šèŠ‚ç‚¹å¯ç”¨
    </span>
  </a>
  
    <nav class="md-nav" aria-label="å¤šèŠ‚ç‚¹å¯ç”¨">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchdistributedrun" class="md-nav__link">
    <span class="md-ellipsis">
      torch.distributed.runå¯åŠ¨å™¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deepspeed_1" class="md-nav__link">
    <span class="md-ellipsis">
      deepspeedå¯åŠ¨å™¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slurm" class="md-nav__link">
    <span class="md-ellipsis">
      åœ¨ SLURM ç¯å¢ƒä¸­å¯åŠ¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      ä½¿ç”¨éå…±äº«æ–‡ä»¶ç³»ç»Ÿ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#notebooks" class="md-nav__link">
    <span class="md-ellipsis">
      åœ¨Notebookså¯ç”¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      ä¼ é€’é…ç½®
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      å…±äº«é…ç½®
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ZeRO">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zero-2" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-2 é…ç½®
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-3" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-3 é…ç½®
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-0" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-0 é…ç½®
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-1" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-1 é…ç½®
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nvme" class="md-nav__link">
    <span class="md-ellipsis">
      NVMe æ”¯æŒ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NVMe æ”¯æŒ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zero-2-zero-3" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-2 å’Œ ZeRO-3 æ€§èƒ½å¯¹æ¯”
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-2_1" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-2 ç¤ºä¾‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-3_1" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-3 ç¤ºä¾‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-stage-offloads" class="md-nav__link">
    <span class="md-ellipsis">
      å¦‚ä½•é€‰æ‹©æœ€ä½³æ€§èƒ½çš„ZeRO Stageå’Œ offloads
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-checkpointing-gradient-checkpointing" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Checkpointing æˆ– Gradient Checkpointing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optimizer-scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizer å’Œ Scheduler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Optimizer å’Œ Scheduler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#optimizer" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      Scheduler
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fp32" class="md-nav__link">
    <span class="md-ellipsis">
      fp32ç²¾åº¦
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      è‡ªåŠ¨æ··åˆç²¾åº¦
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fp16" class="md-nav__link">
    <span class="md-ellipsis">
      fp16
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bf16" class="md-nav__link">
    <span class="md-ellipsis">
      bf16
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nccl" class="md-nav__link">
    <span class="md-ellipsis">
      NCCLé›†åˆ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apex" class="md-nav__link">
    <span class="md-ellipsis">
      apex
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-accumulation" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Accumulation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-clipping" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Clipping
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      è·å–æ¨¡å‹æƒé‡
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-3-infinity-nuances" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-3 å’Œ Infinity Nuances
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ZeRO-3 å’Œ Infinity Nuances">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      æ„å»ºå¤§æ¨¡å‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      å‚æ•°æ”¶é›†
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero_1" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO æ¨ç†
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      å†…å­˜è¦æ±‚
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#issues" class="md-nav__link">
    <span class="md-ellipsis">
      å½’æ¡£Issues
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      Troubleshooting
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Troubleshooting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deepspeed_2" class="md-nav__link">
    <span class="md-ellipsis">
      å¯åŠ¨æ—¶deepspeedè¿›ç¨‹è¢«ç»ˆæ­¢ï¼Œæ²¡æœ‰å›æº¯
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lossnan" class="md-nav__link">
    <span class="md-ellipsis">
      è®­ç»ƒå’Œ/æˆ–è¯„ä¼°/é¢„æµ‹lossä¸ºNaN
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      æ³¨æ„äº‹é¡¹
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#non-trainer-deepspeed" class="md-nav__link">
    <span class="md-ellipsis">
      Non-Trainer Deepspeedé›†æˆ
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hfdeepspeedconfig" class="md-nav__link">
    <span class="md-ellipsis">
      HfDeepSpeedConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="HfDeepSpeedConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deepspeed-zero" class="md-nav__link">
    <span class="md-ellipsis">
      è‡ªå®šä¹‰DeepSpeed ZeROæ¨ç†
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate çš„å·®å¼‚
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deepspeed_3" class="md-nav__link">
    <span class="md-ellipsis">
      æµ‹è¯• DeepSpeed é›†æˆ
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deepspeed_4" class="md-nav__link">
    <span class="md-ellipsis">
      ä¸»è¦çš„DeepSpeedèµ„æº
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../trainer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Trainer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="ç›®å½•">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      ç›®å½•
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#trainer-deepspeed" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer DeepSpeed é›†æˆ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Trainer DeepSpeed é›†æˆ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      å®‰è£…
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu" class="md-nav__link">
    <span class="md-ellipsis">
      å¤šGPUå¯ç”¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu_1" class="md-nav__link">
    <span class="md-ellipsis">
      å•GPUå¯ç”¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      å¤šèŠ‚ç‚¹å¯ç”¨
    </span>
  </a>
  
    <nav class="md-nav" aria-label="å¤šèŠ‚ç‚¹å¯ç”¨">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#torchdistributedrun" class="md-nav__link">
    <span class="md-ellipsis">
      torch.distributed.runå¯åŠ¨å™¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deepspeed_1" class="md-nav__link">
    <span class="md-ellipsis">
      deepspeedå¯åŠ¨å™¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slurm" class="md-nav__link">
    <span class="md-ellipsis">
      åœ¨ SLURM ç¯å¢ƒä¸­å¯åŠ¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      ä½¿ç”¨éå…±äº«æ–‡ä»¶ç³»ç»Ÿ
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#notebooks" class="md-nav__link">
    <span class="md-ellipsis">
      åœ¨Notebookså¯ç”¨
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      ä¼ é€’é…ç½®
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      å…±äº«é…ç½®
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ZeRO">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zero-2" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-2 é…ç½®
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-3" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-3 é…ç½®
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-0" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-0 é…ç½®
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-1" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-1 é…ç½®
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nvme" class="md-nav__link">
    <span class="md-ellipsis">
      NVMe æ”¯æŒ
    </span>
  </a>
  
    <nav class="md-nav" aria-label="NVMe æ”¯æŒ">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zero-2-zero-3" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-2 å’Œ ZeRO-3 æ€§èƒ½å¯¹æ¯”
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-2_1" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-2 ç¤ºä¾‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-3_1" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-3 ç¤ºä¾‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-stage-offloads" class="md-nav__link">
    <span class="md-ellipsis">
      å¦‚ä½•é€‰æ‹©æœ€ä½³æ€§èƒ½çš„ZeRO Stageå’Œ offloads
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#activation-checkpointing-gradient-checkpointing" class="md-nav__link">
    <span class="md-ellipsis">
      Activation Checkpointing æˆ– Gradient Checkpointing
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optimizer-scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizer å’Œ Scheduler
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Optimizer å’Œ Scheduler">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#optimizer" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scheduler" class="md-nav__link">
    <span class="md-ellipsis">
      Scheduler
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fp32" class="md-nav__link">
    <span class="md-ellipsis">
      fp32ç²¾åº¦
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      è‡ªåŠ¨æ··åˆç²¾åº¦
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fp16" class="md-nav__link">
    <span class="md-ellipsis">
      fp16
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bf16" class="md-nav__link">
    <span class="md-ellipsis">
      bf16
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nccl" class="md-nav__link">
    <span class="md-ellipsis">
      NCCLé›†åˆ
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#apex" class="md-nav__link">
    <span class="md-ellipsis">
      apex
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-accumulation" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Accumulation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-clipping" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Clipping
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      è·å–æ¨¡å‹æƒé‡
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero-3-infinity-nuances" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO-3 å’Œ Infinity Nuances
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ZeRO-3 å’Œ Infinity Nuances">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      æ„å»ºå¤§æ¨¡å‹
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      å‚æ•°æ”¶é›†
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zero_1" class="md-nav__link">
    <span class="md-ellipsis">
      ZeRO æ¨ç†
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      å†…å­˜è¦æ±‚
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#issues" class="md-nav__link">
    <span class="md-ellipsis">
      å½’æ¡£Issues
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#troubleshooting" class="md-nav__link">
    <span class="md-ellipsis">
      Troubleshooting
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Troubleshooting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deepspeed_2" class="md-nav__link">
    <span class="md-ellipsis">
      å¯åŠ¨æ—¶deepspeedè¿›ç¨‹è¢«ç»ˆæ­¢ï¼Œæ²¡æœ‰å›æº¯
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lossnan" class="md-nav__link">
    <span class="md-ellipsis">
      è®­ç»ƒå’Œ/æˆ–è¯„ä¼°/é¢„æµ‹lossä¸ºNaN
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      æ³¨æ„äº‹é¡¹
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#non-trainer-deepspeed" class="md-nav__link">
    <span class="md-ellipsis">
      Non-Trainer Deepspeedé›†æˆ
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hfdeepspeedconfig" class="md-nav__link">
    <span class="md-ellipsis">
      HfDeepSpeedConfig
    </span>
  </a>
  
    <nav class="md-nav" aria-label="HfDeepSpeedConfig">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deepspeed-zero" class="md-nav__link">
    <span class="md-ellipsis">
      è‡ªå®šä¹‰DeepSpeed ZeROæ¨ç†
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate" class="md-nav__link">
    <span class="md-ellipsis">
      generate çš„å·®å¼‚
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deepspeed_3" class="md-nav__link">
    <span class="md-ellipsis">
      æµ‹è¯• DeepSpeed é›†æˆ
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deepspeed_4" class="md-nav__link">
    <span class="md-ellipsis">
      ä¸»è¦çš„DeepSpeedèµ„æº
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/transformers_docs/tree/main/docs/main_classes/deepspeed.md" title="ç¼–è¾‘æ­¤é¡µ" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/transformers_docs/tree/main/docs/main_classes/deepspeed.md" title="æŸ¥çœ‹æœ¬é¡µçš„æºä»£ç " class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

<h1 id="deepspeed">DeepSpeedé›†æˆ<a class="headerlink" href="#deepspeed" title="Permanent link">âš“ï¸</a></h1>
<p><a href="https://github.com/microsoft/DeepSpeed">DeepSpeed</a>å®ç°äº†<a href="https://arxiv.org/abs/1910.02054">ZeROè®ºæ–‡</a>ä¸­æè¿°çš„æ‰€æœ‰å†…å®¹ã€‚ç›®å‰ï¼Œå®ƒæä¾›å¯¹ä»¥ä¸‹åŠŸèƒ½çš„å…¨é¢æ”¯æŒï¼š</p>
<ol>
<li>ä¼˜åŒ–å™¨çŠ¶æ€åˆ†åŒºï¼ˆZeRO stage 1ï¼‰</li>
<li>æ¢¯åº¦åˆ†åŒºï¼ˆZeRO stage 2ï¼‰</li>
<li>å‚æ•°åˆ†åŒºï¼ˆZeRO stage 3ï¼‰</li>
<li>è‡ªå®šä¹‰æ··åˆç²¾åº¦è®­ç»ƒå¤„ç†</li>
<li>ä¸€ç³»åˆ—åŸºäºCUDAæ‰©å±•çš„å¿«é€Ÿä¼˜åŒ–å™¨</li>
<li>ZeRO-Offload åˆ° CPU å’Œ NVMe</li>
</ol>
<p>ZeRO-Offloadæœ‰å…¶è‡ªå·±çš„ä¸“é—¨è®ºæ–‡ï¼š<a href="https://arxiv.org/abs/2101.06840">ZeRO-Offload: Democratizing Billion-Scale Model Training</a>ã€‚è€ŒNVMeæ”¯æŒåœ¨è®ºæ–‡<a href="https://arxiv.org/abs/2104.07857">ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a>ä¸­è¿›è¡Œäº†æè¿°ã€‚</p>
<p>DeepSpeed ZeRO-2ä¸»è¦ç”¨äºè®­ç»ƒï¼Œå› ä¸ºå®ƒçš„ç‰¹æ€§å¯¹æ¨ç†æ²¡æœ‰ç”¨å¤„ã€‚</p>
<p>DeepSpeed ZeRO-3ä¹Ÿå¯ä»¥ç”¨äºæ¨ç†ï¼Œå› ä¸ºå®ƒå…è®¸å°†å•ä¸ªGPUæ— æ³•åŠ è½½çš„å¤§æ¨¡å‹åŠ è½½åˆ°å¤šä¸ªGPUä¸Šã€‚</p>
<p>ğŸ¤— Transformersé€šè¿‡ä»¥ä¸‹ä¸¤ç§æ–¹å¼é›†æˆäº†<a href="https://github.com/microsoft/DeepSpeed">DeepSpeed</a>ï¼š</p>
<ol>
<li>é€šè¿‡[<code>Trainer</code>]é›†æˆæ ¸å¿ƒçš„DeepSpeedåŠŸèƒ½ã€‚è¿™æ˜¯ä¸€ç§â€œä¸ºæ‚¨å®Œæˆä¸€åˆ‡â€å¼çš„é›†æˆ - æ‚¨åªéœ€æä¾›è‡ªå®šä¹‰é…ç½®æ–‡ä»¶æˆ–ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡æ¿é…ç½®æ–‡ä»¶ã€‚æœ¬æ–‡æ¡£çš„å¤§éƒ¨åˆ†å†…å®¹éƒ½é›†ä¸­åœ¨è¿™ä¸ªåŠŸèƒ½ä¸Šã€‚</li>
<li>å¦‚æœæ‚¨ä¸ä½¿ç”¨[<code>Trainer</code>]å¹¶å¸Œæœ›åœ¨è‡ªå·±çš„Trainerä¸­é›†æˆDeepSpeedï¼Œé‚£ä¹ˆåƒ<code>from_pretrained</code>å’Œ<code>from_config</code>è¿™æ ·çš„æ ¸å¿ƒåŠŸèƒ½å‡½æ•°å°†åŒ…æ‹¬ZeRO stage 3åŠä»¥ä¸Šçš„DeepSpeedçš„åŸºç¡€éƒ¨åˆ†ï¼Œå¦‚<code>zero.Init</code>ã€‚è¦åˆ©ç”¨æ­¤åŠŸèƒ½ï¼Œè¯·é˜…è¯»æœ‰å…³<a href="#nontrainer-deepspeed-integration">éTrainer DeepSpeedé›†æˆ</a>çš„æ–‡æ¡£ã€‚</li>
</ol>
<p>é›†æˆçš„å†…å®¹ï¼š</p>
<p>è®­ç»ƒï¼š</p>
<ol>
<li>DeepSpeed ZeROè®­ç»ƒæ”¯æŒå®Œæ•´çš„ZeRO stages 1ã€2å’Œ3ï¼Œä»¥åŠZeRO-Infinityï¼ˆCPUå’ŒNVMe offloadï¼‰ã€‚</li>
</ol>
<p>æ¨ç†ï¼š</p>
<ol>
<li>DeepSpeed ZeROæ¨ç†æ”¯æŒZeRO stage 3å’ŒZeRO-Infinityã€‚å®ƒä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„ZeROåè®®ï¼Œä½†ä¸ä½¿ç”¨ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåªæœ‰stage 3ä¸æ¨ç†ç›¸å…³ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚é˜…ï¼š<a href="#zero-inference">zero-inference</a>ã€‚</li>
</ol>
<p>æ­¤å¤–è¿˜æœ‰DeepSpeedæ¨ç† - è¿™æ˜¯ä¸€ç§å®Œå…¨ä¸åŒçš„æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨å¼ é‡å¹¶è¡Œè€Œä¸æ˜¯ZeROï¼ˆå³å°†æ¨å‡ºï¼‰ã€‚</p>
<p><a id='deepspeed-trainer-integration'></a></p>
<h2 id="trainer-deepspeed">Trainer DeepSpeed é›†æˆ<a class="headerlink" href="#trainer-deepspeed" title="Permanent link">âš“ï¸</a></h2>
<p><a id='deepspeed-installation'></a></p>
<h3 id="_1">å®‰è£…<a class="headerlink" href="#_1" title="Permanent link">âš“ï¸</a></h3>
<p>é€šè¿‡pypiå®‰è£…åº“ï¼š</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>deepspeed
</code></pre></div>
<p>æˆ–é€šè¿‡ <code>transformers</code> çš„ <code>extras</code>å®‰è£…ï¼š</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>transformers<span class="o">[</span>deepspeed<span class="o">]</span>
</code></pre></div>
<p>æˆ–åœ¨ <a href="https://github.com/microsoft/deepspeed#installation">DeepSpeed çš„ GitHub é¡µé¢</a> å’Œ
<a href="https://www.deepspeed.ai/tutorials/advanced-install/">é«˜çº§å®‰è£…</a> ä¸­æŸ¥æ‰¾æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚</p>
<p>å¦‚æœæ„å»ºè¿‡ç¨‹ä¸­ä»ç„¶é‡åˆ°é—®é¢˜ï¼Œè¯·é¦–å…ˆç¡®ä¿é˜…è¯» <a href="trainer#cuda-extension-installation-notes">CUDA æ‰©å±•å®‰è£…æ³¨æ„äº‹é¡¹</a>ã€‚</p>
<p>å¦‚æœæ‚¨æ²¡æœ‰é¢„å…ˆæ„å»ºæ‰©å±•è€Œæ˜¯åœ¨è¿è¡Œæ—¶æ„å»ºå®ƒä»¬ï¼Œè€Œä¸”æ‚¨å°è¯•äº†ä»¥ä¸Šæ‰€æœ‰è§£å†³æ–¹æ¡ˆéƒ½æ— æ•ˆï¼Œä¸‹ä¸€æ­¥å¯ä»¥å°è¯•åœ¨å®‰è£…ä¹‹å‰é¢„å…ˆæ„å»ºæ‰©å±•ã€‚</p>
<p>è¿›è¡Œ DeepSpeed çš„æœ¬åœ°æ„å»ºï¼š</p>
<div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/microsoft/DeepSpeed/
<span class="nb">cd</span><span class="w"> </span>DeepSpeed
rm<span class="w"> </span>-rf<span class="w"> </span>build
<span class="nv">TORCH_CUDA_ARCH_LIST</span><span class="o">=</span><span class="s2">&quot;8.6&quot;</span><span class="w"> </span><span class="nv">DS_BUILD_CPU_ADAM</span><span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="nv">DS_BUILD_UTILS</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>.<span class="w"> </span><span class="se">\</span>
--global-option<span class="o">=</span><span class="s2">&quot;build_ext&quot;</span><span class="w"> </span>--global-option<span class="o">=</span><span class="s2">&quot;-j8&quot;</span><span class="w"> </span>--no-cache<span class="w"> </span>-v<span class="w"> </span><span class="se">\</span>
--disable-pip-version-check<span class="w"> </span><span class="m">2</span>&gt;<span class="p">&amp;</span><span class="m">1</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>tee<span class="w"> </span>build.log
</code></pre></div>
<p>å¦‚æœæ‚¨æ‰“ç®—ä½¿ç”¨ NVMe offloadï¼Œæ‚¨è¿˜éœ€è¦åœ¨ä¸Šè¿°è¯´æ˜ä¸­æ·»åŠ  <code>DS_BUILD_AIO=1</code>ï¼ˆå¹¶ä¸”è¿˜éœ€è¦åœ¨ç³»ç»ŸèŒƒå›´å†…å®‰è£… <em>libaio-dev</em>ï¼‰ã€‚</p>
<p>ç¼–è¾‘ <code>TORCH_CUDA_ARCH_LIST</code> ä»¥æ’å…¥æ‚¨æ‰“ç®—ä½¿ç”¨çš„ GPU å¡çš„æ¶æ„ä»£ç ã€‚å‡è®¾æ‚¨çš„æ‰€æœ‰å¡éƒ½æ˜¯ç›¸åŒçš„ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–æ¶æ„ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import torch; print(torch.cuda.get_device_capability())&quot;</span>
</code></pre></div>
<p>å› æ­¤ï¼Œå¦‚æœæ‚¨å¾—åˆ° <code>8, 6</code>ï¼Œåˆ™ä½¿ç”¨ <code>TORCH_CUDA_ARCH_LIST="8.6"</code>ã€‚å¦‚æœæ‚¨æœ‰å¤šä¸ªä¸åŒçš„å¡ï¼Œæ‚¨å¯ä»¥åƒè¿™æ ·åˆ—å‡ºæ‰€æœ‰å¡ <code>TORCH_CUDA_ARCH_LIST="6.1;8.6"</code>ã€‚</p>
<p>å¦‚æœæ‚¨éœ€è¦åœ¨å¤šå°æœºå™¨ä¸Šä½¿ç”¨ç›¸åŒçš„è®¾ç½®ï¼Œè¯·åˆ›å»ºä¸€ä¸ªäºŒè¿›åˆ¶ wheelï¼š</p>
<div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/microsoft/DeepSpeed/
<span class="nb">cd</span><span class="w"> </span>DeepSpeed
rm<span class="w"> </span>-rf<span class="w"> </span>build
<span class="nv">TORCH_CUDA_ARCH_LIST</span><span class="o">=</span><span class="s2">&quot;8.6&quot;</span><span class="w"> </span><span class="nv">DS_BUILD_CPU_ADAM</span><span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="nv">DS_BUILD_UTILS</span><span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
python<span class="w"> </span>setup.py<span class="w"> </span>build_ext<span class="w"> </span>-j8<span class="w"> </span>bdist_wheel
</code></pre></div>
<p>å®ƒå°†ç”Ÿæˆç±»ä¼¼äº <code>dist/deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl</code> çš„æ–‡ä»¶ï¼Œç°åœ¨æ‚¨å¯ä»¥åœ¨æœ¬åœ°æˆ–ä»»ä½•å…¶ä»–æœºå™¨ä¸Šå®‰è£…å®ƒï¼Œå¦‚ <code>pip install deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl</code>ã€‚</p>
<p>å†æ¬¡æé†’ç¡®ä¿è°ƒæ•´ <code>TORCH_CUDA_ARCH_LIST</code> ä»¥åŒ¹é…ç›®æ ‡æ¶æ„ã€‚</p>
<p>æ‚¨å¯ä»¥åœ¨<a href="https://developer.nvidia.com/cuda-gpus">è¿™é‡Œ</a>æ‰¾åˆ°å®Œæ•´çš„ NVIDIA GPU åˆ—è¡¨åŠå…¶å¯¹åº”çš„ <strong>è®¡ç®—èƒ½åŠ›</strong>ï¼ˆä¸æ­¤ä¸Šä¸‹æ–‡ä¸­çš„æ¶æ„ç›¸åŒï¼‰ã€‚</p>
<p>æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ£€æŸ¥ PyTorch æ„å»ºæ—¶ä½¿ç”¨çš„æ¶æ„ï¼š</p>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import torch; print(torch.cuda.get_arch_list())&quot;</span>
</code></pre></div>
<p>ä»¥ä¸‹æ˜¯å¦‚ä½•æŸ¥æ‰¾å·²å®‰è£… GPU ä¸­çš„ä¸€å¼ å¡çš„æ¶æ„ã€‚ä¾‹å¦‚ï¼Œå¯¹äº GPU 0ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import torch; \</span>
<span class="s2">print(torch.cuda.get_device_properties(torch.device(&#39;cuda&#39;)))&quot;</span>
</code></pre></div>
<p>å¦‚æœè¾“å‡ºç»“æœå¦‚ä¸‹ï¼š</p>
<div class="highlight"><pre><span></span><code>_CudaDeviceProperties<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">&#39;GeForce RTX 3090&#39;</span>,<span class="w"> </span><span class="nv">major</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">minor</span><span class="o">=</span><span class="m">6</span>,<span class="w"> </span><span class="nv">total_memory</span><span class="o">=</span>24268MB,<span class="w"> </span><span class="nv">multi_processor_count</span><span class="o">=</span><span class="m">82</span><span class="o">)</span>
</code></pre></div>
<p>ç„¶åæ‚¨å°±çŸ¥é“è¿™å¼ å¡çš„æ¶æ„æ˜¯ <code>8.6</code>ã€‚</p>
<p>æ‚¨ä¹Ÿå¯ä»¥å®Œå…¨çœç•¥ <code>TORCH_CUDA_ARCH_LIST</code>ï¼Œç„¶åæ„å»ºç¨‹åºå°†è‡ªåŠ¨æŸ¥è¯¢æ„å»ºæ‰€åœ¨çš„ GPU çš„æ¶æ„ã€‚è¿™å¯èƒ½ä¸ç›®æ ‡æœºå™¨ä¸Šçš„ GPU ä¸åŒ¹é…ï¼Œå› æ­¤æœ€å¥½æ˜ç¡®æŒ‡å®šæ‰€éœ€çš„æ¶æ„ã€‚</p>
<p>å¦‚æœå°è¯•äº†æ‰€æœ‰å»ºè®®çš„æ–¹æ³•ä»ç„¶é‡åˆ°æ„å»ºé—®é¢˜ï¼Œè¯·ç»§ç»­åœ¨ <a href="https://github.com/microsoft/DeepSpeed/issues">Deepspeed</a>çš„ GitHub Issue ä¸Šæäº¤é—®é¢˜ã€‚</p>
<p><a id='deepspeed-multi-gpu'></a></p>
<h3 id="gpu">å¤šGPUå¯ç”¨<a class="headerlink" href="#gpu" title="Permanent link">âš“ï¸</a></h3>
<p>ä¸ºäº†å¯ç”¨DeepSpeed é›†æˆï¼Œè°ƒæ•´ [<code>Trainer</code>] çš„å‘½ä»¤è¡Œå‚æ•°ï¼Œæ·»åŠ ä¸€ä¸ªæ–°çš„å‚æ•° <code>--deepspeed ds_config.json</code>ï¼Œå…¶ä¸­ <code>ds_config.json</code> æ˜¯ DeepSpeed é…ç½®æ–‡ä»¶ï¼Œå¦‚æ–‡æ¡£ <a href="https://www.deepspeed.ai/docs/config-json/">è¿™é‡Œ</a> æ‰€è¿°ã€‚æ–‡ä»¶å‘½åç”±æ‚¨å†³å®šã€‚
å»ºè®®ä½¿ç”¨ DeepSpeed çš„ <code>add_config_arguments</code> ç¨‹åºå°†å¿…è¦çš„å‘½ä»¤è¡Œå‚æ•°æ·»åŠ åˆ°æ‚¨çš„ä»£ç ä¸­ã€‚
æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… <a href="https://deepspeed.readthedocs.io/en/latest/initialize.html#argument-parsing">DeepSpeed çš„å‚æ•°è§£æ</a> æ–‡æ¡£ã€‚</p>
<p>åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ‚¨å–œæ¬¢çš„å¯åŠ¨å™¨ã€‚æ‚¨å¯ä»¥ç»§ç»­ä½¿ç”¨ PyTorch å¯åŠ¨å™¨ï¼š</p>
<div class="highlight"><pre><span></span><code>torch.distributed.run<span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="m">2</span><span class="w"> </span>your_program.py<span class="w"> </span>&lt;normal<span class="w"> </span>cl<span class="w"> </span>args&gt;<span class="w"> </span>--deepspeed<span class="w"> </span>ds_config.json
</code></pre></div>
<p>æˆ–ä½¿ç”¨ç”± <code>deepspeed</code> æä¾›çš„å¯åŠ¨å™¨ï¼š</p>
<div class="highlight"><pre><span></span><code>deepspeed<span class="w"> </span>--num_gpus<span class="o">=</span><span class="m">2</span><span class="w"> </span>your_program.py<span class="w"> </span>&lt;normal<span class="w"> </span>cl<span class="w"> </span>args&gt;<span class="w"> </span>--deepspeed<span class="w"> </span>ds_config.json
</code></pre></div>
<p>æ­£å¦‚æ‚¨æ‰€è§ï¼Œè¿™ä¸¤ä¸ªå¯åŠ¨å™¨çš„å‚æ•°ä¸åŒï¼Œä½†å¯¹äºå¤§å¤šæ•°éœ€æ±‚ï¼Œä»»ä½•ä¸€ä¸ªéƒ½å¯ä»¥æ»¡è¶³å·¥ä½œéœ€æ±‚ã€‚æœ‰å…³å¦‚ä½•é…ç½®å„ä¸ªèŠ‚ç‚¹å’Œ GPU çš„å®Œæ•´è¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ <a href="https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node">æ­¤å¤„</a>ã€‚</p>
<p>å½“æ‚¨ä½¿ç”¨ <code>deepspeed</code> å¯åŠ¨å™¨å¹¶ä¸”å¸Œæœ›ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„ GPU æ—¶ï¼Œæ‚¨å¯ä»¥ç®€å•åœ°çœç•¥ <code>--num_gpus</code> æ ‡å¿—ã€‚</p>
<p>ä»¥ä¸‹æ˜¯åœ¨ DeepSpeed ä¸­å¯ç”¨ä½¿ç”¨æ‰€æœ‰å¯ç”¨ GPUæƒ…å†µä¸‹ï¼Œ è¿è¡Œ <code>run_translation.py</code> çš„ç¤ºä¾‹ï¼š</p>
<div class="highlight"><pre><span></span><code>deepspeed<span class="w"> </span>examples/pytorch/translation/run_translation.py<span class="w"> </span><span class="se">\</span>
--deepspeed<span class="w"> </span>tests/deepspeed/ds_config_zero3.json<span class="w"> </span><span class="se">\</span>
--model_name_or_path<span class="w"> </span>t5-small<span class="w"> </span>--per_device_train_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
--output_dir<span class="w"> </span>output_dir<span class="w"> </span>--overwrite_output_dir<span class="w"> </span>--fp16<span class="w"> </span><span class="se">\</span>
--do_train<span class="w"> </span>--max_train_samples<span class="w"> </span><span class="m">500</span><span class="w"> </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
--dataset_name<span class="w"> </span>wmt16<span class="w"> </span>--dataset_config<span class="w"> </span><span class="s2">&quot;ro-en&quot;</span><span class="w"> </span><span class="se">\</span>
--source_lang<span class="w"> </span>en<span class="w"> </span>--target_lang<span class="w"> </span>ro
</code></pre></div>
<p>è¯·æ³¨æ„ï¼Œåœ¨ DeepSpeed æ–‡æ¡£ä¸­ï¼Œæ‚¨å¯èƒ½ä¼šçœ‹åˆ° <code>--deepspeed --deepspeed_config ds_config.json</code> - å³ä¸¤ä¸ªä¸ DeepSpeed ç›¸å…³çš„å‚æ•°ï¼Œä½†ä¸ºç®€å•èµ·è§ï¼Œå¹¶ä¸”å› ä¸ºå·²ç»æœ‰å¾ˆå¤šå‚æ•°è¦å¤„ç†ï¼Œæˆ‘ä»¬å°†ä¸¤è€…åˆå¹¶ä¸ºä¸€ä¸ªå•ä¸€å‚æ•°ã€‚</p>
<p>æœ‰å…³ä¸€äº›å®é™…ä½¿ç”¨ç¤ºä¾‹ï¼Œè¯·å‚é˜… <a href="https://github.com/huggingface/transformers/issues/8771#issuecomment-759248400">æ­¤å¸–</a>ã€‚</p>
<p><a id='deepspeed-one-gpu'></a></p>
<h3 id="gpu_1">å•GPUå¯ç”¨<a class="headerlink" href="#gpu_1" title="Permanent link">âš“ï¸</a></h3>
<p>è¦ä½¿ç”¨ä¸€å¼  GPU å¯ç”¨ DeepSpeedï¼Œè°ƒæ•´ [<code>Trainer</code>] çš„å‘½ä»¤è¡Œå‚æ•°å¦‚ä¸‹ï¼š</p>
<div class="highlight"><pre><span></span><code>deepspeed<span class="w"> </span>--num_gpus<span class="o">=</span><span class="m">1</span><span class="w"> </span>examples/pytorch/translation/run_translation.py<span class="w"> </span><span class="se">\</span>
--deepspeed<span class="w"> </span>tests/deepspeed/ds_config_zero2.json<span class="w"> </span><span class="se">\</span>
--model_name_or_path<span class="w"> </span>t5-small<span class="w"> </span>--per_device_train_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
--output_dir<span class="w"> </span>output_dir<span class="w"> </span>--overwrite_output_dir<span class="w"> </span>--fp16<span class="w"> </span><span class="se">\</span>
--do_train<span class="w"> </span>--max_train_samples<span class="w"> </span><span class="m">500</span><span class="w"> </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
--dataset_name<span class="w"> </span>wmt16<span class="w"> </span>--dataset_config<span class="w"> </span><span class="s2">&quot;ro-en&quot;</span><span class="w"> </span><span class="se">\</span>
--source_lang<span class="w"> </span>en<span class="w"> </span>--target_lang<span class="w"> </span>ro
</code></pre></div>
<p>è¿™ä¸å¤š GPU çš„æƒ…å†µå‡ ä¹ç›¸åŒï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬é€šè¿‡ <code>--num_gpus=1</code> æ˜ç¡®å‘Šè¯‰ DeepSpeed ä»…ä½¿ç”¨ä¸€å¼  GPUã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒDeepSpeed å¯ç”¨ç»™å®šèŠ‚ç‚¹ä¸Šå¯ä»¥çœ‹åˆ°çš„æ‰€æœ‰ GPUã€‚å¦‚æœæ‚¨ä¸€å¼€å§‹åªæœ‰ä¸€å¼  GPUï¼Œé‚£ä¹ˆæ‚¨ä¸éœ€è¦è¿™ä¸ªå‚æ•°ã€‚ä»¥ä¸‹ <a href="https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node">æ–‡æ¡£</a> è®¨è®ºäº†å¯åŠ¨å™¨çš„é€‰é¡¹ã€‚</p>
<p>ä¸ºä»€ä¹ˆè¦åœ¨ä»…ä½¿ç”¨ä¸€å¼  GPU çš„æƒ…å†µä¸‹ä½¿ç”¨ DeepSpeed å‘¢ï¼Ÿ</p>
<ol>
<li>å®ƒå…·æœ‰ ZeRO-offload åŠŸèƒ½ï¼Œå¯ä»¥å°†ä¸€äº›è®¡ç®—å’Œå†…å­˜å§”æ‰˜ç»™ä¸»æœºçš„ CPU å’Œ å†…å­˜ï¼Œä»è€Œä¸ºæ¨¡å‹çš„éœ€æ±‚ä¿ç•™æ›´å¤š GPU èµ„æº - ä¾‹å¦‚æ›´å¤§çš„æ‰¹å¤„ç†å¤§å°ï¼Œæˆ–å¯ç”¨æ­£å¸¸æƒ…å†µä¸‹æ— æ³•å®¹çº³çš„éå¸¸å¤§æ¨¡å‹ã€‚</li>
<li>å®ƒæä¾›äº†æ™ºèƒ½çš„ GPU å†…å­˜ç®¡ç†ç³»ç»Ÿï¼Œæœ€å°åŒ–å†…å­˜ç¢ç‰‡ï¼Œè¿™å†æ¬¡å…è®¸æ‚¨å®¹çº³æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®æ‰¹æ¬¡ã€‚</li>
</ol>
<p>è™½ç„¶æ¥ä¸‹æ¥æˆ‘ä»¬å°†è¯¦ç»†è®¨è®ºé…ç½®ï¼Œä½†åœ¨å•ä¸ª GPU ä¸Šé€šè¿‡ DeepSpeed å®ç°å·¨å¤§æ€§èƒ½æå‡çš„å…³é”®æ˜¯åœ¨é…ç½®æ–‡ä»¶ä¸­è‡³å°‘æœ‰ä»¥ä¸‹é…ç½®ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;offload_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">         </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">         </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">     </span><span class="p">},</span>
<span class="w">     </span><span class="nt">&quot;allgather_partitions&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;allgather_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2e8</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;reduce_scatter&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;reduce_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2e8</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;overlap_comm&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;contiguous_gradients&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>è¿™ä¼šå¯ç”¨<code>optimizer offload</code>å’Œä¸€äº›å…¶ä»–é‡è¦åŠŸèƒ½ã€‚æ‚¨å¯ä»¥å°è¯•ä¸åŒçš„bufferå¤§å°ï¼Œæœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ä¸‹é¢çš„è®¨è®ºã€‚</p>
<p>å…³äºè¿™ç§å¯ç”¨ç±»å‹çš„å®é™…ä½¿ç”¨ç¤ºä¾‹ï¼Œè¯·å‚é˜… <a href="https://github.com/huggingface/transformers/issues/8771#issuecomment-759176685">æ­¤å¸–</a>ã€‚</p>
<p>æ‚¨è¿˜å¯ä»¥å°è¯•ä½¿ç”¨æœ¬æ–‡åé¢è¿›ä¸€æ­¥è§£é‡Šçš„æ”¯æŒ<code>CPU å’Œ NVMe offload</code>åŠŸèƒ½çš„ZeRO-3 ã€‚</p>
<!--- TODO: Benchmark whether we can get better performance out of ZeRO-3 vs. ZeRO-2 on a single GPU, and then
recommend ZeRO-3 config as starting one. -->

<p>æ³¨æ„ï¼š</p>
<ul>
<li>å¦‚æœæ‚¨éœ€è¦åœ¨ç‰¹å®šçš„ GPU ä¸Šè¿è¡Œï¼Œè€Œä¸æ˜¯ GPU 0ï¼Œåˆ™æ— æ³•ä½¿ç”¨ <code>CUDA_VISIBLE_DEVICES</code> æ¥é™åˆ¶å¯ç”¨ GPU çš„å¯è§èŒƒå›´ã€‚ç›¸åï¼Œæ‚¨å¿…é¡»ä½¿ç”¨ä»¥ä¸‹è¯­æ³•ï¼š</li>
</ul>
<div class="highlight"><pre><span></span><code>deepspeed<span class="w"> </span>--include<span class="w"> </span>localhost:1<span class="w"> </span>examples/pytorch/translation/run_translation.py<span class="w"> </span>...
</code></pre></div>
<p>åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å‘Šè¯‰ DeepSpeed ä½¿ç”¨ GPU 1ï¼ˆç¬¬äºŒä¸ª GPUï¼‰ã€‚</p>
<p><a id='deepspeed-multi-node'></a></p>
<h3 id="_2">å¤šèŠ‚ç‚¹å¯ç”¨<a class="headerlink" href="#_2" title="Permanent link">âš“ï¸</a></h3>
<p>è¿™ä¸€éƒ¨åˆ†çš„ä¿¡æ¯ä¸ä»…é€‚ç”¨äº DeepSpeed é›†æˆï¼Œä¹Ÿé€‚ç”¨äºä»»ä½•å¤šèŠ‚ç‚¹ç¨‹åºã€‚ä½† DeepSpeed æä¾›äº†ä¸€ä¸ªæ¯”å…¶ä»–å¯åŠ¨å™¨æ›´æ˜“äºä½¿ç”¨çš„ <code>deepspeed</code> å¯åŠ¨å™¨ï¼Œé™¤éæ‚¨åœ¨ SLURM ç¯å¢ƒä¸­ã€‚</p>
<p>åœ¨æœ¬èŠ‚ï¼Œè®©æˆ‘ä»¬å‡è®¾æ‚¨æœ‰ä¸¤ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹æœ‰ 8 å¼  GPUã€‚æ‚¨å¯ä»¥é€šè¿‡ <code>ssh hostname1</code> è®¿é—®ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼Œé€šè¿‡ <code>ssh hostname2</code> è®¿é—®ç¬¬äºŒä¸ªèŠ‚ç‚¹ï¼Œä¸¤è€…å¿…é¡»èƒ½å¤Ÿåœ¨æœ¬åœ°é€šè¿‡ ssh æ— å¯†ç æ–¹å¼ç›¸äº’è®¿é—®ã€‚å½“ç„¶ï¼Œæ‚¨éœ€è¦å°†è¿™äº›ä¸»æœºï¼ˆèŠ‚ç‚¹ï¼‰åç§°é‡å‘½åä¸ºæ‚¨å®é™…ä½¿ç”¨çš„ä¸»æœºåç§°ã€‚</p>
<h4 id="torchdistributedrun">torch.distributed.runå¯åŠ¨å™¨<a class="headerlink" href="#torchdistributedrun" title="Permanent link">âš“ï¸</a></h4>
<p>ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨ <code>torch.distributed.run</code>ï¼Œæ‚¨å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š</p>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>-m<span class="w"> </span>torch.distributed.run<span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="m">8</span><span class="w"> </span>--nnode<span class="o">=</span><span class="m">2</span><span class="w"> </span>--node_rank<span class="o">=</span><span class="m">0</span><span class="w"> </span>--master_addr<span class="o">=</span>hostname1<span class="w"> </span><span class="se">\</span>
--master_port<span class="o">=</span><span class="m">9901</span><span class="w"> </span>your_program.py<span class="w"> </span>&lt;normal<span class="w"> </span>cl<span class="w"> </span>args&gt;<span class="w"> </span>--deepspeed<span class="w"> </span>ds_config.json
</code></pre></div>
<p>æ‚¨å¿…é¡» ssh åˆ°æ¯ä¸ªèŠ‚ç‚¹ï¼Œå¹¶åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œç›¸åŒçš„å‘½ä»¤ï¼ä¸ç”¨æ‹…å¿ƒï¼Œå¯åŠ¨å™¨ä¼šç­‰å¾…ä¸¤ä¸ªèŠ‚ç‚¹åŒæ­¥å®Œæˆã€‚</p>
<p>æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… <a href="https://pytorch.org/docs/stable/elastic/run.html">torchrun</a>ã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œè¿™ä¹Ÿæ˜¯æ›¿ä»£äº†å‡ ä¸ª PyTorch ç‰ˆæœ¬å‰çš„ <code>torch.distributed.launch</code> çš„å¯åŠ¨å™¨ã€‚</p>
<h4 id="deepspeed_1">deepspeedå¯åŠ¨å™¨<a class="headerlink" href="#deepspeed_1" title="Permanent link">âš“ï¸</a></h4>
<p>è¦æ”¹ç”¨ <code>deepspeed</code> å¯åŠ¨å™¨ï¼Œé¦–å…ˆéœ€è¦åˆ›å»ºä¸€ä¸ª <code>hostfile</code> æ–‡ä»¶ï¼š</p>
<p><div class="highlight"><pre><span></span><code>hostname1 slots=8
hostname2 slots=8
</code></pre></div>
ç„¶åï¼Œæ‚¨å¯ä»¥è¿™æ ·å¯åŠ¨ï¼š</p>
<div class="highlight"><pre><span></span><code>deepspeed<span class="w"> </span>--num_gpus<span class="w"> </span><span class="m">8</span><span class="w"> </span>--num_nodes<span class="w"> </span><span class="m">2</span><span class="w"> </span>--hostfile<span class="w"> </span>hostfile<span class="w"> </span>--master_addr<span class="w"> </span>hostname1<span class="w"> </span>--master_port<span class="o">=</span><span class="m">9901</span><span class="w"> </span><span class="se">\</span>
your_program.py<span class="w"> </span>&lt;normal<span class="w"> </span>cl<span class="w"> </span>args&gt;<span class="w"> </span>--deepspeed<span class="w"> </span>ds_config.json
</code></pre></div>
<p>ä¸ <code>torch.distributed.run</code> å¯åŠ¨å™¨ä¸åŒï¼Œ<code>deepspeed</code> å°†è‡ªåŠ¨åœ¨ä¸¤ä¸ªèŠ‚ç‚¹ä¸Šå¯åŠ¨æ­¤å‘½ä»¤ï¼</p>
<p>æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…<a href="https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node">èµ„æºé…ç½®ï¼ˆå¤šèŠ‚ç‚¹ï¼‰</a>ã€‚</p>
<h4 id="slurm">åœ¨ SLURM ç¯å¢ƒä¸­å¯åŠ¨<a class="headerlink" href="#slurm" title="Permanent link">âš“ï¸</a></h4>
<p>åœ¨ SLURM ç¯å¢ƒä¸­ï¼Œå¯ä»¥é‡‡ç”¨ä»¥ä¸‹æ–¹æ³•ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ª SLURM è„šæœ¬ <code>launch.slurm</code>ï¼Œæ‚¨éœ€è¦æ ¹æ®æ‚¨çš„å…·ä½“ SLURM ç¯å¢ƒè¿›è¡Œè°ƒæ•´ã€‚</p>
<div class="highlight"><pre><span></span><code><span class="c1">#SBATCH --job-name=test-nodes        # name</span>
<span class="c1">#SBATCH --nodes=2                    # nodes</span>
<span class="c1">#SBATCH --ntasks-per-node=1          # crucial - only 1 task per dist per node!</span>
<span class="c1">#SBATCH --cpus-per-task=10           # number of cores per tasks</span>
<span class="c1">#SBATCH --gres=gpu:8                 # number of gpus</span>
<span class="c1">#SBATCH --time 20:00:00              # maximum execution time (HH:MM:SS)</span>
<span class="c1">#SBATCH --output=%x-%j.out           # output file name</span>

<span class="nb">export</span><span class="w"> </span><span class="nv">GPUS_PER_NODE</span><span class="o">=</span><span class="m">8</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">MASTER_ADDR</span><span class="o">=</span><span class="k">$(</span>scontrol<span class="w"> </span>show<span class="w"> </span>hostnames<span class="w"> </span><span class="nv">$SLURM_JOB_NODELIST</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="k">)</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">MASTER_PORT</span><span class="o">=</span><span class="m">9901</span>

srun<span class="w"> </span>--jobid<span class="w"> </span><span class="nv">$SLURM_JOBID</span><span class="w"> </span>bash<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;python -m torch.distributed.run \</span>
<span class="s1"> --nproc_per_node $GPUS_PER_NODE --nnodes $SLURM_NNODES --node_rank $SLURM_PROCID \</span>
<span class="s1"> --master_addr $MASTER_ADDR --master_port $MASTER_PORT \</span>
<span class="s1">your_program.py &lt;normal cl args&gt; --deepspeed ds_config.json&#39;</span>
</code></pre></div>
<p>å‰©ä¸‹çš„å°±æ˜¯è¿è¡Œå®ƒï¼š</p>
<div class="highlight"><pre><span></span><code>sbatch<span class="w"> </span>launch.slurm
</code></pre></div>
<p><code>srun</code> å°†è´Ÿè´£åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸ŠåŒæ—¶å¯åŠ¨ç¨‹åºã€‚</p>
<h4 id="_3">ä½¿ç”¨éå…±äº«æ–‡ä»¶ç³»ç»Ÿ<a class="headerlink" href="#_3" title="Permanent link">âš“ï¸</a></h4>
<p>é»˜è®¤æƒ…å†µä¸‹ï¼ŒDeepSpeed å‡å®šå¤šèŠ‚ç‚¹ç¯å¢ƒä½¿ç”¨å…±äº«å­˜å‚¨ã€‚å¦‚æœä¸æ˜¯è¿™ç§æƒ…å†µï¼Œæ¯ä¸ªèŠ‚ç‚¹åªèƒ½çœ‹åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼Œä½ éœ€è¦è°ƒæ•´é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«ä¸€ä¸ª <a href="https://www.deepspeed.ai/docs/config-json/#checkpoint-options"><code>checkpoint</code> éƒ¨åˆ†</a>å¹¶è®¾ç½®å¦‚ä¸‹é€‰é¡¹ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;checkpoint&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;use_node_local_storage&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>æˆ–è€…ï¼Œä½ è¿˜å¯ä»¥ä½¿ç”¨ [<code>Trainer</code>] çš„ <code>--save_on_each_node</code> å‚æ•°ï¼Œä¸Šè¿°é…ç½®å°†è‡ªåŠ¨æ·»åŠ ã€‚</p>
<p><a id='deepspeed-notebook'></a></p>
<h3 id="notebooks">åœ¨Notebookså¯ç”¨<a class="headerlink" href="#notebooks" title="Permanent link">âš“ï¸</a></h3>
<p>åœ¨å°†<code>notebook cells</code>ä½œä¸ºè„šæœ¬è¿è¡Œçš„æƒ…å†µä¸‹ï¼Œé—®é¢˜åœ¨äºæ²¡æœ‰æ­£å¸¸çš„ <code>deepspeed</code> å¯åŠ¨å™¨å¯ä¾èµ–ï¼Œå› æ­¤åœ¨æŸäº›è®¾ç½®ä¸‹ï¼Œæˆ‘ä»¬å¿…é¡»ä»¿çœŸè¿è¡Œå®ƒã€‚</p>
<p>å¦‚æœæ‚¨åªä½¿ç”¨ä¸€ä¸ª GPUï¼Œä»¥ä¸‹æ˜¯å¦‚ä½•è°ƒæ•´notebookä¸­çš„è®­ç»ƒä»£ç ä»¥ä½¿ç”¨ DeepSpeedã€‚</p>
<div class="highlight"><pre><span></span><code><span class="c1"># DeepSpeed requires a distributed environment even when only one process is used.</span>
<span class="c1"># This emulates a launcher in the notebook</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;localhost&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;9994&quot;</span>  <span class="c1"># modify if RuntimeError: Address already in use</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>

<span class="c1"># Now proceed as normal, plus pass the deepspeed config file</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">deepspeed</span><span class="o">=</span><span class="s2">&quot;ds_config_zero3.json&quot;</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>
<p>æ³¨æ„ï¼š<code>...</code> ä»£è¡¨æ‚¨ä¼ é€’ç»™å‡½æ•°çš„æ­£å¸¸å‚æ•°ã€‚</p>
<p>å¦‚æœè¦ä½¿ç”¨å¤šäºä¸€ä¸ª GPUï¼Œæ‚¨å¿…é¡»åœ¨ DeepSpeed ä¸­ä½¿ç”¨å¤šè¿›ç¨‹ç¯å¢ƒã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ‚¨å¿…é¡»ä½¿ç”¨ä¸“é—¨çš„å¯åŠ¨å™¨æ¥å®ç°è¿™ä¸€ç›®çš„ï¼Œè€Œä¸èƒ½é€šè¿‡ä»¿çœŸæœ¬èŠ‚å¼€å¤´å‘ˆç°çš„åˆ†å¸ƒå¼ç¯å¢ƒæ¥å®Œæˆã€‚</p>
<p>å¦‚æœæƒ³è¦åœ¨notebookä¸­åŠ¨æ€åˆ›å»ºé…ç½®æ–‡ä»¶å¹¶ä¿å­˜åœ¨å½“å‰ç›®å½•ï¼Œæ‚¨å¯ä»¥åœ¨ä¸€ä¸ªä¸“ç”¨çš„cellä¸­ä½¿ç”¨ï¼š</p>
<p>```python no-style
%%bash
cat &lt;&lt;'EOT' &gt; ds_config_zero3.json
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },</p>
<div class="highlight"><pre><span></span><code>&quot;optimizer&quot;: {
    &quot;type&quot;: &quot;AdamW&quot;,
    &quot;params&quot;: {
        &quot;lr&quot;: &quot;auto&quot;,
        &quot;betas&quot;: &quot;auto&quot;,
        &quot;eps&quot;: &quot;auto&quot;,
        &quot;weight_decay&quot;: &quot;auto&quot;
    }
},

&quot;scheduler&quot;: {
    &quot;type&quot;: &quot;WarmupLR&quot;,
    &quot;params&quot;: {
        &quot;warmup_min_lr&quot;: &quot;auto&quot;,
        &quot;warmup_max_lr&quot;: &quot;auto&quot;,
        &quot;warmup_num_steps&quot;: &quot;auto&quot;
    }
},

&quot;zero_optimization&quot;: {
    &quot;stage&quot;: 3,
    &quot;offload_optimizer&quot;: {
        &quot;device&quot;: &quot;cpu&quot;,
        &quot;pin_memory&quot;: true
    },
    &quot;offload_param&quot;: {
        &quot;device&quot;: &quot;cpu&quot;,
        &quot;pin_memory&quot;: true
    },
    &quot;overlap_comm&quot;: true,
    &quot;contiguous_gradients&quot;: true,
    &quot;sub_group_size&quot;: 1e9,
    &quot;reduce_bucket_size&quot;: &quot;auto&quot;,
    &quot;stage3_prefetch_bucket_size&quot;: &quot;auto&quot;,
    &quot;stage3_param_persistence_threshold&quot;: &quot;auto&quot;,
    &quot;stage3_max_live_parameters&quot;: 1e9,
    &quot;stage3_max_reuse_distance&quot;: 1e9,
    &quot;stage3_gather_16bit_weights_on_model_save&quot;: true
},

&quot;gradient_accumulation_steps&quot;: &quot;auto&quot;,
&quot;gradient_clipping&quot;: &quot;auto&quot;,
&quot;steps_per_print&quot;: 2000,
&quot;train_batch_size&quot;: &quot;auto&quot;,
&quot;train_micro_batch_size_per_gpu&quot;: &quot;auto&quot;,
&quot;wall_clock_breakdown&quot;: false
</code></pre></div>
<p>}
EOT
<code>å¦‚æœè®­ç»ƒè„šæœ¬åœ¨ä¸€ä¸ªæ™®é€šæ–‡ä»¶ä¸­è€Œä¸æ˜¯åœ¨notebook cellsä¸­ï¼Œæ‚¨å¯ä»¥é€šè¿‡ç¬”è®°æœ¬ä¸­çš„ shell æ­£å¸¸å¯åŠ¨ `deepspeed`ã€‚ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨ `run_translation.py`ï¼Œæ‚¨å¯ä»¥è¿™æ ·å¯åŠ¨ï¼š</code>python no-style
!git clone https://github.com/huggingface/transformers
!cd transformers; deepspeed examples/pytorch/translation/run_translation.py ...
```</p>
<p>æˆ–è€…ä½¿ç”¨ <code>%%bash</code> é­”æœ¯å‘½ä»¤ï¼Œæ‚¨å¯ä»¥ç¼–å†™å¤šè¡Œä»£ç ï¼Œç”¨äºè¿è¡Œ shell ç¨‹åºï¼š</p>
<p>```python no-style
%%bash</p>
<p>git clone https://github.com/huggingface/transformers
cd transformers
deepspeed examples/pytorch/translation/run_translation.py ...
<div class="highlight"><pre><span></span><code>åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨ä¸éœ€è¦æœ¬èŠ‚å¼€å¤´å‘ˆç°çš„ä»»ä½•ä»£ç ã€‚

æ³¨æ„ï¼šè™½ç„¶ `%%bash` é­”æœ¯å‘½ä»¤å¾ˆæ–¹ä¾¿ï¼Œä½†ç›®å‰å®ƒä¼šç¼“å†²è¾“å‡ºï¼Œå› æ­¤åœ¨è¿›ç¨‹å®Œæˆä¹‹å‰æ‚¨çœ‹ä¸åˆ°æ—¥å¿—ã€‚


&lt;a id=&#39;deepspeed-config&#39;&gt;&lt;/a&gt;

### é…ç½®

æœ‰å…³å¯ä»¥åœ¨ DeepSpeed é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨çš„å®Œæ•´é…ç½®é€‰é¡¹çš„è¯¦ç»†æŒ‡å—ï¼Œè¯·å‚é˜…[ä»¥ä¸‹æ–‡æ¡£](https://www.deepspeed.ai/docs/config-json/)ã€‚

æ‚¨å¯ä»¥åœ¨ [DeepSpeedExamples ä»“åº“](https://github.com/microsoft/DeepSpeedExamples)ä¸­æ‰¾åˆ°è§£å†³å„ç§å®é™…éœ€æ±‚çš„æ•°åä¸ª DeepSpeed é…ç½®ç¤ºä¾‹ã€‚

```bash
git clone https://github.com/microsoft/DeepSpeedExamples
cd DeepSpeedExamples
find . -name &#39;*json&#39;
</code></pre></div></p>
<p>å»¶ç»­ä¸Šé¢çš„ä»£ç ï¼Œå‡è®¾æ‚¨è¦é…ç½® Lamb ä¼˜åŒ–å™¨ã€‚é‚£ä¹ˆæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åœ¨ç¤ºä¾‹çš„ <code>.json</code> æ–‡ä»¶ä¸­è¿›è¡Œæœç´¢ï¼š</p>
<div class="highlight"><pre><span></span><code>grep<span class="w"> </span>-i<span class="w"> </span>Lamb<span class="w"> </span><span class="k">$(</span>find<span class="w"> </span>.<span class="w"> </span>-name<span class="w"> </span><span class="s1">&#39;*json&#39;</span><span class="k">)</span>
</code></pre></div>
<p>è¿˜å¯ä»¥åœ¨<a href="https://github.com/microsoft/DeepSpeed">ä¸»ä»“</a>ä¸­æ‰¾åˆ°æ›´å¤šç¤ºä¾‹ã€‚</p>
<p>åœ¨ä½¿ç”¨ DeepSpeed æ—¶ï¼Œæ‚¨æ€»æ˜¯éœ€è¦æä¾›ä¸€ä¸ª DeepSpeed é…ç½®æ–‡ä»¶ï¼Œä½†æ˜¯ä¸€äº›é…ç½®å‚æ•°å¿…é¡»é€šè¿‡å‘½ä»¤è¡Œè¿›è¡Œé…ç½®ã€‚æ‚¨å°†åœ¨æœ¬æŒ‡å—çš„å‰©ä½™ç« èŠ‚æ‰¾åˆ°è¿™äº›ç»†å¾®å·®åˆ«ã€‚</p>
<p>ä¸ºäº†äº†è§£ DeepSpeed é…ç½®æ–‡ä»¶ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªæ¿€æ´» ZeRO stage 2 åŠŸèƒ½çš„ç¤ºä¾‹ï¼ŒåŒ…æ‹¬ä¼˜åŒ–å™¨çŠ¶æ€çš„ CPU offloadï¼Œä½¿ç”¨ <code>AdamW</code> ä¼˜åŒ–å™¨å’Œ <code>WarmupLR</code>  è°ƒåº¦å™¨ï¼Œå¹¶ä¸”å¦‚æœä¼ é€’äº† <code>--fp16</code> å‚æ•°å°†å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;fp16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale_window&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;initial_scale_power&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;hysteresis&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;min_loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AdamW&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;betas&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;eps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;weight_decay&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;scheduler&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;WarmupLR&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;warmup_min_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;warmup_max_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;warmup_num_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;offload_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;allgather_partitions&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;allgather_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2e8</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;overlap_comm&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_scatter&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2e8</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;contiguous_gradients&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;gradient_clipping&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;train_batch_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div>
<p>å½“æ‚¨æ‰§è¡Œç¨‹åºæ—¶ï¼ŒDeepSpeed å°†æŠŠå®ƒä» [<code>Trainer</code>] æ”¶åˆ°çš„é…ç½®æ—¥å¿—è¾“å‡ºåˆ°consoleï¼Œå› æ­¤æ‚¨å¯ä»¥çœ‹åˆ°ä¼ é€’ç»™å®ƒçš„æœ€ç»ˆé…ç½®ã€‚</p>
<p><a id='deepspeed-config-passing'></a></p>
<h3 id="_4">ä¼ é€’é…ç½®<a class="headerlink" href="#_4" title="Permanent link">âš“ï¸</a></h3>
<p>æ­£å¦‚æœ¬æ–‡æ¡£è®¨è®ºçš„é‚£æ ·ï¼Œé€šå¸¸å°† DeepSpeed é…ç½®ä½œä¸ºæŒ‡å‘ JSON æ–‡ä»¶çš„è·¯å¾„ä¼ é€’ï¼Œä½†å¦‚æœæ‚¨æ²¡æœ‰ä½¿ç”¨å‘½ä»¤è¡Œç•Œé¢é…ç½®è®­ç»ƒï¼Œè€Œæ˜¯é€šè¿‡ [<code>TrainingArguments</code>] å®ä¾‹åŒ– [<code>Trainer</code>]ï¼Œé‚£ä¹ˆå¯¹äº <code>deepspeed</code> å‚æ•°ï¼Œä½ å¯ä»¥ä¼ é€’ä¸€ä¸ªåµŒå¥—çš„ <code>dict</code>ã€‚è¿™ä½¿æ‚¨èƒ½å¤Ÿå³æ—¶åˆ›å»ºé…ç½®ï¼Œè€Œæ— éœ€åœ¨å°†å…¶ä¼ é€’ç»™ [<code>TrainingArguments</code>] ä¹‹å‰å°†å…¶å†™å…¥æ–‡ä»¶ç³»ç»Ÿã€‚</p>
<p>æ€»ç»“èµ·æ¥ï¼Œæ‚¨å¯ä»¥è¿™æ ·åšï¼š</p>
<div class="highlight"><pre><span></span><code><span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">deepspeed</span><span class="o">=</span><span class="s2">&quot;/path/to/ds_config.json&quot;</span><span class="p">)</span>
</code></pre></div>
<p>æˆ–è€…:</p>
<div class="highlight"><pre><span></span><code><span class="n">ds_config_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler_params</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_params</span><span class="p">)</span>
<span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">deepspeed</span><span class="o">=</span><span class="n">ds_config_dict</span><span class="p">)</span>
</code></pre></div>
<p><a id='deepspeed-config-shared'></a></p>
<h3 id="_5">å…±äº«é…ç½®<a class="headerlink" href="#_5" title="Permanent link">âš“ï¸</a></h3>
<p><Tip warning={true}></p>
<p>è¿™ä¸€éƒ¨åˆ†æ˜¯å¿…è¯»çš„ã€‚</p>
<p></Tip></p>
<p>ä¸€äº›é…ç½®å€¼å¯¹äº [<code>Trainer</code>] å’Œ DeepSpeed æ­£å¸¸è¿è¡Œéƒ½æ˜¯å¿…éœ€çš„ï¼Œå› æ­¤ï¼Œä¸ºäº†é˜²æ­¢å®šä¹‰å†²çªåŠå¯¼è‡´çš„éš¾ä»¥æ£€æµ‹çš„é”™è¯¯ï¼Œæˆ‘ä»¬é€‰æ‹©é€šè¿‡ [<code>Trainer</code>] å‘½ä»¤è¡Œå‚æ•°é…ç½®è¿™äº›å€¼ã€‚</p>
<p>æ­¤å¤–ï¼Œä¸€äº›é…ç½®å€¼æ˜¯åŸºäºæ¨¡å‹çš„é…ç½®è‡ªåŠ¨æ´¾ç”Ÿçš„ï¼Œå› æ­¤ï¼Œä¸å…¶è®°ä½æ‰‹åŠ¨è°ƒæ•´å¤šä¸ªå€¼ï¼Œæœ€å¥½è®© [<code>Trainer</code>] ä¸ºæ‚¨åšå¤§éƒ¨åˆ†é…ç½®ã€‚</p>
<p>å› æ­¤ï¼Œåœ¨æœ¬æŒ‡å—çš„å…¶ä½™éƒ¨åˆ†ï¼Œæ‚¨å°†æ‰¾åˆ°ä¸€ä¸ªç‰¹æ®Šçš„é…ç½®å€¼ï¼š<code>auto</code>ï¼Œå½“è®¾ç½®æ—¶å°†è‡ªåŠ¨å°†å‚æ•°æ›¿æ¢ä¸ºæ­£ç¡®æˆ–æœ€æœ‰æ•ˆçš„å€¼ã€‚è¯·éšæ„é€‰æ‹©å¿½ç•¥æ­¤å»ºè®®æˆ–æ˜¾å¼è®¾ç½®è¯¥å€¼ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯·åŠ¡å¿…ç¡®ä¿ [<code>Trainer</code>] å‚æ•°å’Œ DeepSpeed é…ç½®ä¿æŒä¸€è‡´ã€‚ä¾‹å¦‚ï¼Œæ‚¨æ˜¯å¦ä½¿ç”¨ç›¸åŒçš„å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°æˆ–æ¢¯åº¦ç´¯ç§¯è®¾ç½®ï¼Ÿå¦‚æœè¿™äº›ä¸åŒ¹é…ï¼Œè®­ç»ƒå¯èƒ½ä»¥éå¸¸éš¾ä»¥æ£€æµ‹çš„æ–¹å¼å¤±è´¥ã€‚è¯·é‡è§†è¯¥è­¦å‘Šã€‚</p>
<p>è¿˜æœ‰ä¸€äº›å‚æ•°æ˜¯ä»…é€‚ç”¨äº DeepSpeed çš„ï¼Œå¹¶ä¸”è¿™äº›å‚æ•°å¿…é¡»æ‰‹åŠ¨è®¾ç½®ä»¥é€‚åº”æ‚¨çš„éœ€æ±‚ã€‚</p>
<p>åœ¨æ‚¨è‡ªå·±çš„ç¨‹åºä¸­ï¼Œå¦‚æœæ‚¨æƒ³è¦ä½œä¸ºä¸»åŠ¨ä¿®æ”¹ DeepSpeed é…ç½®å¹¶ä»¥æ­¤é…ç½® [<code>TrainingArguments</code>]ï¼Œæ‚¨è¿˜å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ã€‚æ­¥éª¤å¦‚ä¸‹ï¼š</p>
<ol>
<li>åˆ›å»ºæˆ–åŠ è½½è¦ç”¨ä½œä¸»é…ç½®çš„ DeepSpeed é…ç½®</li>
<li>æ ¹æ®è¿™äº›å‚æ•°å€¼åˆ›å»º [<code>TrainingArguments</code>] å¯¹è±¡</li>
</ol>
<p>è¯·æ³¨æ„ï¼Œä¸€äº›å€¼ï¼Œæ¯”å¦‚ <code>scheduler.params.total_num_steps</code>ï¼Œæ˜¯åœ¨ [<code>Trainer</code>] çš„ <code>train</code> è¿‡ç¨‹ä¸­è®¡ç®—çš„ï¼Œä½†å½“ç„¶æ‚¨ä¹Ÿå¯ä»¥è‡ªå·±è®¡ç®—è¿™äº›å€¼ã€‚</p>
<p><a id='deepspeed-zero'></a></p>
<h3 id="zero">ZeRO<a class="headerlink" href="#zero" title="Permanent link">âš“ï¸</a></h3>
<p><a href="https://www.deepspeed.ai/tutorials/zero/">Zero Redundancy Optimizer (ZeRO)</a> æ˜¯ DeepSpeed çš„å·¥ä½œæ ¸å¿ƒã€‚å®ƒæ”¯æŒ3ä¸ªä¸åŒçº§åˆ«ï¼ˆstagesï¼‰çš„ä¼˜åŒ–ã€‚Stage 1 å¯¹äºæ‰©å±•æ€§æ¥è¯´ä¸æ˜¯å¾ˆæœ‰è¶£ï¼Œå› æ­¤æœ¬æ–‡æ¡£é‡ç‚¹å…³æ³¨Stage 2å’ŒStage 3ã€‚Stage 3é€šè¿‡æœ€æ–°çš„ ZeRO-Infinity è¿›ä¸€æ­¥æ”¹è¿›ã€‚ä½ å¯ä»¥åœ¨ DeepSpeed æ–‡æ¡£ä¸­æ‰¾åˆ°æ›´è¯¦ç»†çš„ä¿¡æ¯ã€‚</p>
<p>é…ç½®æ–‡ä»¶çš„ <code>zero_optimization</code> éƒ¨åˆ†æ˜¯æœ€é‡è¦çš„éƒ¨åˆ†ï¼ˆ<a href="https://www.deepspeed.ai/docs/config-json/#zero-optimizations-for-fp16-training">æ–‡æ¡£</a>ï¼‰ï¼Œå› ä¸ºåœ¨è¿™é‡Œæ‚¨å®šä¹‰äº†è¦å¯ç”¨å“ªäº› ZeRO stages ä»¥åŠå¦‚ä½•é…ç½®å®ƒä»¬ã€‚æ‚¨å¯ä»¥åœ¨ DeepSpeed æ–‡æ¡£ä¸­æ‰¾åˆ°æ¯ä¸ªå‚æ•°çš„è§£é‡Šã€‚</p>
<p>è¿™ä¸€éƒ¨åˆ†å¿…é¡»é€šè¿‡ DeepSpeed é…ç½®æ–‡ä»¶å•ç‹¬é…ç½® - [<code>Trainer</code>] ä¸æä¾›ç›¸åº”çš„å‘½ä»¤è¡Œå‚æ•°ã€‚</p>
<p>æ³¨æ„ï¼šç›®å‰ DeepSpeed ä¸éªŒè¯å‚æ•°åç§°ï¼Œå› æ­¤å¦‚æœæ‚¨æ‹¼é”™äº†ä»»ä½•å‚æ•°ï¼Œå®ƒå°†ä½¿ç”¨æ‹¼å†™é”™è¯¯çš„å‚æ•°çš„é»˜è®¤è®¾ç½®ã€‚æ‚¨å¯ä»¥è§‚å¯Ÿ DeepSpeed å¼•æ“å¯åŠ¨æ—¥å¿—æ¶ˆæ¯ï¼Œçœ‹çœ‹å®ƒå°†ä½¿ç”¨å“ªäº›å€¼ã€‚</p>
<p><a id='deepspeed-zero2-config'></a></p>
<h4 id="zero-2">ZeRO-2 é…ç½®<a class="headerlink" href="#zero-2" title="Permanent link">âš“ï¸</a></h4>
<p>ä»¥ä¸‹æ˜¯ ZeRO stage 2 çš„é…ç½®ç¤ºä¾‹ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;offload_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;allgather_partitions&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;allgather_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">5e8</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;overlap_comm&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_scatter&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">5e8</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;contiguous_gradients&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p><strong>æ€§èƒ½è°ƒä¼˜ï¼š</strong></p>
<ul>
<li>å¯ç”¨ <code>offload_optimizer</code> åº”è¯¥å‡å°‘ GPU å†…å­˜ä½¿ç”¨ï¼ˆéœ€è¦ <code>"stage": 2</code>ï¼‰ã€‚</li>
<li><code>"overlap_comm": true</code> é€šè¿‡å¢åŠ  GPU å†…å­˜ä½¿ç”¨æ¥é™ä½all-reduce çš„å»¶è¿Ÿã€‚ <code>overlap_comm</code> ä½¿ç”¨äº† <code>allgather_bucket_size</code> å’Œ <code>reduce_bucket_size</code> å€¼çš„4.5å€ã€‚å› æ­¤ï¼Œå¦‚æœå®ƒä»¬è®¾ç½®ä¸º <code>5e8</code>ï¼Œè¿™å°†éœ€è¦ä¸€ä¸ª9GBçš„å†…å­˜å ç”¨ï¼ˆ<code>5e8 x 2Bytes x 2 x 4.5</code>ï¼‰ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨çš„ GPU å†…å­˜ä¸º8GBæˆ–æ›´å°ï¼Œä¸ºäº†é¿å…å‡ºç°OOMé”™è¯¯ï¼Œæ‚¨éœ€è¦å°†è¿™äº›å‚æ•°å‡å°åˆ°çº¦ <code>2e8</code>ï¼Œè¿™å°†éœ€è¦3.6GBã€‚å¦‚æœæ‚¨çš„ GPU å®¹é‡æ›´å¤§ï¼Œå½“æ‚¨å¼€å§‹é‡åˆ°OOMæ—¶ï¼Œä½ å¯èƒ½ä¹Ÿéœ€è¦è¿™æ ·åšã€‚</li>
<li>å½“å‡å°è¿™äº›buffersæ—¶ï¼Œæ‚¨ä»¥æ›´æ…¢çš„é€šä¿¡é€Ÿåº¦æ¥æ¢å–æ›´å¤šçš„ GPU å†…å­˜ã€‚bufferså¤§å°è¶Šå°ï¼Œé€šä¿¡é€Ÿåº¦è¶Šæ…¢ï¼ŒGPU å¯ç”¨äºå…¶ä»–ä»»åŠ¡çš„å†…å­˜å°±è¶Šå¤šã€‚å› æ­¤ï¼Œå¦‚æœæ›´å¤§çš„æ‰¹å¤„ç†å¤§å°å¾ˆé‡è¦ï¼Œé‚£ä¹ˆç¨å¾®å‡æ…¢è®­ç»ƒæ—¶é—´å¯èƒ½æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æƒè¡¡ã€‚</li>
</ul>
<p>æ­¤å¤–ï¼Œ<code>deepspeed==0.4.4</code> æ·»åŠ äº†ä¸€ä¸ªæ–°é€‰é¡¹ <code>round_robin_gradients</code>ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å¯ç”¨ï¼š</p>
<p><div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;round_robin_gradients&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
è¿™æ˜¯ä¸€ä¸ªç”¨äº CPU offloading çš„stage 2ä¼˜åŒ–ï¼Œé€šè¿‡ç»†ç²’åº¦æ¢¯åº¦åˆ†åŒºåœ¨ ranks ä¹‹é—´å¹¶è¡Œå¤åˆ¶åˆ° CPU å†…å­˜ï¼Œä»è€Œå®ç°äº†æ€§èƒ½çš„æå‡ã€‚æ€§èƒ½ä¼˜åŠ¿éšç€æ¢¯åº¦ç´¯ç§¯æ­¥éª¤ï¼ˆåœ¨ä¼˜åŒ–å™¨æ­¥éª¤ä¹‹é—´è¿›è¡Œæ›´å¤šå¤åˆ¶ï¼‰æˆ– GPU æ•°é‡ï¼ˆå¢åŠ å¹¶è¡Œæ€§ï¼‰å¢åŠ è€Œå¢åŠ ã€‚</p>
<p><a id='deepspeed-zero3-config'></a></p>
<h4 id="zero-3">ZeRO-3 é…ç½®<a class="headerlink" href="#zero-3" title="Permanent link">âš“ï¸</a></h4>
<p>ä»¥ä¸‹æ˜¯ ZeRO stage 3çš„é…ç½®ç¤ºä¾‹ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;offload_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;offload_param&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;overlap_comm&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;contiguous_gradients&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;sub_group_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_prefetch_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_param_persistence_threshold&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_max_live_parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_max_reuse_distance&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>å¦‚æœæ‚¨å› ä¸ºä½ çš„æ¨¡å‹æˆ–æ¿€æ´»å€¼è¶…è¿‡ GPU å†…å­˜è€Œé‡åˆ°OOMé—®é¢˜ï¼Œå¹¶ä¸”æ‚¨æœ‰æœªä½¿ç”¨çš„ CPU å†…å­˜ï¼Œå¯ä»¥é€šè‚¡ç¥¨ä½¿ç”¨ <code>"device": "cpu"</code> å°†ä¼˜åŒ–å™¨çŠ¶æ€å’Œå‚æ•°å¸è½½åˆ° CPU å†…å­˜ä¸­ï¼Œæ¥è§£å†³è¿™ä¸ªé™åˆ¶ã€‚å¦‚æœæ‚¨ä¸æƒ³å¸è½½åˆ° CPU å†…å­˜ï¼Œå¯ä»¥åœ¨ <code>device</code> æ¡ç›®ä¸­ä½¿ç”¨ <code>none</code> ä»£æ›¿ <code>cpu</code>ã€‚å°†ä¼˜åŒ–å™¨çŠ¶æ€å¸è½½åˆ° NVMe ä¸Šä¼šåœ¨åé¢è¿›ä¸€æ­¥è®¨è®ºã€‚</p>
<p>é€šè¿‡å°† <code>pin_memory</code> è®¾ç½®ä¸º <code>true</code> å¯ç”¨å›ºå®šå†…å­˜ã€‚æ­¤åŠŸèƒ½ä¼šä»¥å‡å°‘å¯ç”¨äºå…¶ä»–è¿›ç¨‹çš„å†…å­˜ä¸ºä»£ä»·æ¥æé«˜ååé‡ã€‚å›ºå®šå†…å­˜è¢«åˆ†é…ç»™ç‰¹å®šè¯·æ±‚å®ƒçš„è¿›ç¨‹ï¼Œé€šå¸¸æ¯”æ™®é€š CPU å†…å­˜è®¿é—®é€Ÿåº¦æ›´å¿«ã€‚</p>
<p><strong>æ€§èƒ½è°ƒä¼˜ï¼š</strong></p>
<ul>
<li><code>stage3_max_live_parameters</code>: <code>1e9</code></li>
<li><code>stage3_max_reuse_distance</code>: <code>1e9</code></li>
</ul>
<p>å¦‚æœé‡åˆ°OOMé—®é¢˜ï¼Œè¯·å‡å° <code>stage3_max_live_parameters</code> å’Œ <code>stage3_max_reuse_distance</code>ã€‚å®ƒä»¬å¯¹æ€§èƒ½çš„å½±å“åº”è¯¥å¾ˆå°ï¼Œé™¤éæ‚¨æ­£åœ¨è¿›è¡Œæ¿€æ´»å€¼checkpointingã€‚<code>1e9</code> å¤§çº¦ä¼šæ¶ˆè€— ~2GBã€‚å†…å­˜ç”± <code>stage3_max_live_parameters</code> å’Œ <code>stage3_max_reuse_distance</code> å…±äº«ï¼Œæ‰€ä»¥å®ƒä¸æ˜¯å åŠ çš„ï¼Œè€Œæ˜¯æ€»å…±2GBã€‚</p>
<p><code>stage3_max_live_parameters</code> æ˜¯åœ¨ä»»ä½•ç»™å®šæ—¶é—´è¦åœ¨ GPU ä¸Šä¿ç•™å¤šå°‘ä¸ªå®Œæ•´å‚æ•°çš„ä¸Šé™ã€‚"reuse distance" æ˜¯æˆ‘ä»¬ç”¨æ¥ç¡®å®šå‚æ•°åœ¨å°†æ¥ä½•æ—¶ä¼šå†æ¬¡ä½¿ç”¨çš„åº¦é‡æ ‡å‡†ï¼Œæˆ‘ä»¬ä½¿ç”¨ <code>stage3_max_reuse_distance</code> æ¥å†³å®šæ˜¯ä¸¢å¼ƒå‚æ•°è¿˜æ˜¯ä¿ç•™å‚æ•°ã€‚å¦‚æœä¸€ä¸ªå‚æ•°åœ¨ä¸ä¹…çš„å°†æ¥ï¼ˆå°äº <code>stage3_max_reuse_distance</code>ï¼‰å°†è¢«å†æ¬¡ä½¿ç”¨ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†å…¶ä¿ç•™ä»¥å‡å°‘é€šä¿¡å¼€é”€ã€‚è¿™åœ¨å¯ç”¨æ¿€æ´»å€¼checkpoingæ—¶éå¸¸æœ‰ç”¨ï¼Œå…¶ä¸­æˆ‘ä»¬ä»¥å•å±‚ç²’åº¦è¿›è¡Œå‰å‘é‡è®¡ç®—å’Œåå‘ä¼ æ’­ï¼Œå¹¶å¸Œæœ›åœ¨åå‘ä¼ æ’­æœŸé—´ä¿ç•™å‰å‘é‡è®¡ç®—ä¸­çš„å‚æ•°ã€‚</p>
<p>ä»¥ä¸‹é…ç½®å€¼å–å†³äºæ¨¡å‹çš„éšè—å¤§å°ï¼š</p>
<ul>
<li><code>reduce_bucket_size</code>: <code>hidden_size*hidden_size</code></li>
<li><code>stage3_prefetch_bucket_size</code>: <code>0.9 * hidden_size * hidden_size</code></li>
<li><code>stage3_param_persistence_threshold</code>: <code>10 * hidden_size</code></li>
</ul>
<p>å› æ­¤ï¼Œå°†è¿™äº›å€¼è®¾ç½®ä¸º <code>auto</code>ï¼Œ[<code>Trainer</code>] å°†è‡ªåŠ¨åˆ†é…æ¨èçš„å‚æ•°å€¼ã€‚å½“ç„¶ï¼Œå¦‚æœæ‚¨æ„¿æ„ï¼Œä¹Ÿå¯ä»¥æ˜¾å¼è®¾ç½®è¿™äº›å€¼ã€‚</p>
<p><code>stage3_gather_16bit_weights_on_model_save</code> åœ¨æ¨¡å‹ä¿å­˜æ—¶å¯ç”¨æ¨¡å‹çš„ fp16 æƒé‡æ•´åˆã€‚å¯¹äºå¤§æ¨¡å‹å’Œå¤šä¸ª GPUï¼Œæ— è®ºæ˜¯åœ¨å†…å­˜è¿˜æ˜¯é€Ÿåº¦æ–¹é¢ï¼Œè¿™éƒ½æ˜¯ä¸€é¡¹æ˜‚è´µçš„æ“ä½œã€‚ç›®å‰å¦‚æœè®¡åˆ’æ¢å¤è®­ç»ƒï¼Œè¿™æ˜¯å¿…éœ€çš„ã€‚è¯·æ³¨æ„æœªæ¥çš„æ›´æ–°å¯èƒ½ä¼šåˆ é™¤æ­¤é™åˆ¶å¹¶è®©ä½¿ç”¨æ›´åŠ çµæ´»ã€‚</p>
<p>å¦‚æœæ‚¨ä» ZeRO-2 é…ç½®è¿ç§»ï¼Œè¯·æ³¨æ„ <code>allgather_partitions</code>ã€<code>allgather_bucket_size</code> å’Œ <code>reduce_scatter</code> é…ç½®å‚æ•°åœ¨ ZeRO-3 ä¸­ä¸è¢«ä½¿ç”¨ã€‚å¦‚æœä¿ç•™è¿™äº›é…ç½®æ–‡ä»¶ï¼Œå®ƒä»¬å°†è¢«å¿½ç•¥ã€‚</p>
<ul>
<li><code>sub_group_size</code>: <code>1e9</code></li>
</ul>
<p><code>sub_group_size</code> æ§åˆ¶åœ¨ä¼˜åŒ–å™¨æ­¥éª¤æœŸé—´æ›´æ–°å‚æ•°çš„ç²’åº¦ã€‚å‚æ•°è¢«åˆ†ç»„åˆ°å¤§å°ä¸º <code>sub_group_size</code> çš„æ¡¶ä¸­ï¼Œæ¯ä¸ªæ¡¶é€ä¸ªæ›´æ–°ã€‚åœ¨ ZeRO-Infinity ä¸­ä¸ NVMe offloadä¸€èµ·ä½¿ç”¨æ—¶ï¼Œ<code>sub_group_size</code> æ§åˆ¶äº†åœ¨ä¼˜åŒ–å™¨æ­¥éª¤æœŸé—´åœ¨ NVMe å’Œ CPU å†…å­˜ä¹‹é—´ç§»åŠ¨æ¨¡å‹çŠ¶æ€çš„ç²’åº¦ã€‚è¿™å¯ä»¥é˜²æ­¢éå¸¸å¤§çš„æ¨¡å‹è€—å°½ CPU å†…å­˜ã€‚</p>
<p>å½“ä¸ä½¿ç”¨ NVMe offloadæ—¶ï¼Œå¯ä»¥å°† <code>sub_group_size</code> ä¿ç•™ä¸ºå…¶é»˜è®¤å€¼ <em>1e9</em>ã€‚åœ¨ä»¥ä¸‹æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½éœ€è¦æ›´æ”¹å…¶é»˜è®¤å€¼ï¼š</p>
<ol>
<li>åœ¨ä¼˜åŒ–å™¨æ­¥éª¤ä¸­é‡åˆ°OOMï¼šå‡å° <code>sub_group_size</code> ä»¥å‡å°‘ä¸´æ—¶buffersçš„å†…å­˜åˆ©ç”¨</li>
<li>ä¼˜åŒ–å™¨æ­¥éª¤èŠ±è´¹å¾ˆé•¿æ—¶é—´ï¼šå¢åŠ  <code>sub_group_size</code> ä»¥æé«˜ç”±äºå¢åŠ çš„æ•°æ®buffersè€Œå¯¼è‡´çš„å¸¦å®½åˆ©ç”¨ç‡ã€‚</li>
</ol>
<h4 id="zero-0">ZeRO-0 é…ç½®<a class="headerlink" href="#zero-0" title="Permanent link">âš“ï¸</a></h4>
<p>è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å°† Stage 0 å’Œ 1 æ”¾åœ¨æœ€åï¼Œå› ä¸ºå®ƒä»¬å¾ˆå°‘ä½¿ç”¨ã€‚</p>
<p>Stage 0 ç¦ç”¨äº†æ‰€æœ‰ç±»å‹çš„åˆ†ç‰‡ï¼Œåªæ˜¯å°† DeepSpeed ä½œä¸º DDP ä½¿ç”¨ã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å¯ç”¨ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>è¿™å°†å®è´¨ä¸Šç¦ç”¨ ZeROï¼Œè€Œæ— éœ€æ›´æ”¹å…¶ä»–ä»»ä½•å†…å®¹ã€‚</p>
<h4 id="zero-1">ZeRO-1 é…ç½®<a class="headerlink" href="#zero-1" title="Permanent link">âš“ï¸</a></h4>
<p>Stage 1 ç­‰åŒäº Stage 2 å‡å»æ¢¯åº¦åˆ†ç‰‡ã€‚æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨ä»¥ä¸‹é…ç½®ï¼Œä»…å¯¹ä¼˜åŒ–å™¨çŠ¶æ€è¿›è¡Œåˆ†ç‰‡ï¼Œä»¥ç¨å¾®åŠ é€Ÿï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p><a id='deepspeed-nvme'></a></p>
<h3 id="nvme">NVMe æ”¯æŒ<a class="headerlink" href="#nvme" title="Permanent link">âš“ï¸</a></h3>
<p>ZeRO-Infinity é€šè¿‡ä½¿ç”¨ NVMe å†…å­˜æ‰©å±• GPU å’Œ CPU å†…å­˜ï¼Œä»è€Œå…è®¸è®­ç»ƒéå¸¸å¤§çš„æ¨¡å‹ã€‚ç”±äºæ™ºèƒ½åˆ†åŒºå’Œå¹³é“ºç®—æ³•ï¼Œåœ¨offloadæœŸé—´æ¯ä¸ª GPU éœ€è¦å‘é€å’Œæ¥æ”¶éå¸¸å°é‡çš„æ•°æ®ï¼Œå› æ­¤ NVMe è¢«è¯æ˜é€‚ç”¨äºè®­ç»ƒè¿‡ç¨‹ä¸­æä¾›æ›´å¤§çš„æ€»å†…å­˜æ± ã€‚ZeRO-Infinity éœ€è¦å¯ç”¨ ZeRO-3ã€‚</p>
<p>ä»¥ä¸‹é…ç½®ç¤ºä¾‹å¯ç”¨ NVMe æ¥offloadä¼˜åŒ–å™¨çŠ¶æ€å’Œå‚æ•°ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;offload_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;nvme&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;nvme_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/local_nvme&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;buffer_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;fast_init&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;offload_param&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;nvme&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;nvme_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/local_nvme&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;buffer_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;buffer_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e8</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;max_in_cpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;aio&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;block_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">262144</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;queue_depth&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;thread_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;single_submit&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;overlap_events&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;overlap_comm&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;contiguous_gradients&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;sub_group_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_prefetch_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_param_persistence_threshold&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_max_live_parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_max_reuse_distance&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">},</span>
<span class="p">}</span>
</code></pre></div>
<p>æ‚¨å¯ä»¥é€‰æ‹©å°†ä¼˜åŒ–å™¨çŠ¶æ€å’Œå‚æ•°éƒ½å¸è½½åˆ° NVMeï¼Œä¹Ÿå¯ä»¥åªé€‰æ‹©å…¶ä¸­ä¸€ä¸ªï¼Œæˆ–è€…éƒ½ä¸é€‰æ‹©ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æœ‰å¤§é‡çš„ CPU å†…å­˜å¯ç”¨ï¼Œåªå¸è½½åˆ° CPU å†…å­˜è®­ç»ƒé€Ÿåº¦ä¼šæ›´å¿«ï¼ˆæç¤ºï¼š"device": "cpu"ï¼‰ã€‚</p>
<p>è¿™æ˜¯æœ‰å…³å¸è½½ <a href="https://www.deepspeed.ai/docs/config-json/#optimizer-offloading">ä¼˜åŒ–å™¨çŠ¶æ€</a> å’Œ <a href="https://www.deepspeed.ai/docs/config-json/#parameter-offloading">å‚æ•°</a> çš„å®Œæ•´æ–‡æ¡£ã€‚</p>
<p>ç¡®ä¿æ‚¨çš„ <code>nvme_path</code> å®é™…ä¸Šæ˜¯ä¸€ä¸ª NVMeï¼Œå› ä¸ºå®ƒä¸æ™®é€šç¡¬ç›˜æˆ– SSD ä¸€èµ·å·¥ä½œï¼Œä½†é€Ÿåº¦ä¼šæ…¢å¾—å¤šã€‚å¿«é€Ÿå¯æ‰©å±•çš„è®­ç»ƒæ˜¯æ ¹æ®ç°ä»£ NVMe ä¼ è¾“é€Ÿåº¦è®¾è®¡çš„ï¼ˆæˆªè‡³æœ¬æ–‡æ’°å†™æ—¶ï¼Œå¯ä»¥è¾¾åˆ° ~3.5GB/s è¯»å–ï¼Œ~3GB/s å†™å…¥çš„å³°å€¼é€Ÿåº¦ï¼‰ã€‚</p>
<p>ä¸ºäº†æ‰¾å‡ºæœ€ä½³çš„ <code>aio</code> é…ç½®å—ï¼Œæ‚¨å¿…é¡»åœ¨ç›®æ ‡è®¾ç½®ä¸Šè¿è¡Œä¸€ä¸ªåŸºå‡†æµ‹è¯•ï¼Œå…·ä½“æ“ä½œè¯·å‚è§<a href="https://github.com/microsoft/DeepSpeed/issues/998">è¯´æ˜</a>ã€‚</p>
<p><a id='deepspeed-zero2-zero3-performance'></a></p>
<h4 id="zero-2-zero-3">ZeRO-2 å’Œ ZeRO-3 æ€§èƒ½å¯¹æ¯”<a class="headerlink" href="#zero-2-zero-3" title="Permanent link">âš“ï¸</a></h4>
<p>å¦‚æœå…¶ä»–ä¸€åˆ‡éƒ½é…ç½®ç›¸åŒï¼ŒZeRO-3 å¯èƒ½æ¯” ZeRO-2 æ…¢ï¼Œå› ä¸ºå‰è€…é™¤äº† ZeRO-2 çš„æ“ä½œå¤–ï¼Œè¿˜å¿…é¡»æ”¶é›†æ¨¡å‹æƒé‡ã€‚å¦‚æœ ZeRO-2 æ»¡è¶³æ‚¨çš„éœ€æ±‚ï¼Œè€Œä¸”æ‚¨ä¸éœ€è¦æ‰©å±•åˆ°å‡ ä¸ª GPU ä»¥ä¸Šï¼Œé‚£ä¹ˆæ‚¨å¯ä»¥é€‰æ‹©ç»§ç»­ä½¿ç”¨å®ƒã€‚é‡è¦çš„æ˜¯è¦ç†è§£ï¼ŒZeRO-3 ä»¥é€Ÿåº¦ä¸ºä»£ä»·å®ç°äº†æ›´é«˜çš„å¯æ‰©å±•æ€§ã€‚</p>
<p>å¯ä»¥è°ƒæ•´ ZeRO-3 é…ç½®ä½¿å…¶æ€§èƒ½æ¥è¿‘ ZeRO-2ï¼š</p>
<ul>
<li>å°† <code>stage3_param_persistence_threshold</code> è®¾ç½®ä¸ºä¸€ä¸ªéå¸¸å¤§çš„æ•°å­— - å¤§äºæœ€å¤§çš„å‚æ•°ï¼Œä¾‹å¦‚ <code>6 * hidden_size * hidden_size</code>ã€‚è¿™å°†ä¿ç•™å‚æ•°åœ¨ GPU ä¸Šã€‚</li>
<li>å…³é—­ <code>offload_params</code>ï¼Œå› ä¸º ZeRO-2 æ²¡æœ‰è¿™ä¸ªé€‰é¡¹ã€‚</li>
</ul>
<p>å³ä½¿ä¸æ›´æ”¹ <code>stage3_param_persistence_threshold</code>ï¼Œä»…å°† <code>offload_params</code> å…³é—­ï¼Œæ€§èƒ½å¯èƒ½ä¼šæ˜¾è‘—æé«˜ã€‚å½“ç„¶ï¼Œè¿™äº›æ›´æ”¹å°†å½±å“æ‚¨å¯ä»¥è®­ç»ƒçš„æ¨¡å‹çš„å¤§å°ã€‚å› æ­¤ï¼Œè¿™äº›æ›´æ”¹å¯æ ¹æ®éœ€æ±‚å¸®åŠ©æ‚¨åœ¨å¯æ‰©å±•æ€§å’Œé€Ÿåº¦ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚</p>
<p><a id='deepspeed-zero2-example'></a></p>
<h4 id="zero-2_1">ZeRO-2 ç¤ºä¾‹<a class="headerlink" href="#zero-2_1" title="Permanent link">âš“ï¸</a></h4>
<p>è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ ZeRO-2 è‡ªåŠ¨é…ç½®æ–‡ä»¶ <code>ds_config_zero2.json</code>ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;fp16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale_window&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;initial_scale_power&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;hysteresis&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;min_loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AdamW&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;betas&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;eps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;weight_decay&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;scheduler&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;WarmupLR&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;warmup_min_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;warmup_max_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;warmup_num_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;offload_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;allgather_partitions&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;allgather_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2e8</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;overlap_comm&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_scatter&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2e8</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;contiguous_gradients&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;gradient_clipping&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;steps_per_print&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2000</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;train_batch_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;wall_clock_breakdown&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="p">}</span>
</code></pre></div>
<p>è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ‰‹åŠ¨è®¾ç½®çš„å¯ç”¨æ‰€æœ‰åŠŸèƒ½çš„ ZeRO-2 é…ç½®æ–‡ä»¶ã€‚ä¸»è¦æ˜¯ä¸ºäº†è®©æ‚¨çœ‹åˆ°å…¸å‹çš„å‚æ•°å€¼æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œä½†æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½¿ç”¨å…¶ä¸­åŒ…å«å¤šä¸ª <code>auto</code> è®¾ç½®çš„é…ç½®æ–‡ä»¶ã€‚</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;fp16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale_window&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;initial_scale_power&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;hysteresis&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;min_loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AdamW&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3e-5</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;betas&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span><span class="w"> </span><span class="mf">0.999</span><span class="p">],</span>
<span class="w">            </span><span class="nt">&quot;eps&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e-8</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;weight_decay&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3e-7</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;scheduler&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;WarmupLR&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;warmup_min_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;warmup_max_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3e-5</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;warmup_num_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">500</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;offload_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;allgather_partitions&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;allgather_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2e8</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;overlap_comm&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_scatter&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">2e8</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;contiguous_gradients&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;steps_per_print&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2000</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;wall_clock_breakdown&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="p">}</span>
</code></pre></div>
<p><a id='deepspeed-zero3-example'></a></p>
<h4 id="zero-3_1">ZeRO-3 ç¤ºä¾‹<a class="headerlink" href="#zero-3_1" title="Permanent link">âš“ï¸</a></h4>
<p>è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ ZeRO-3 è‡ªåŠ¨é…ç½®æ–‡ä»¶ <code>ds_config_zero3.json</code>ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;fp16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale_window&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;initial_scale_power&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;hysteresis&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;min_loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AdamW&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;betas&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;eps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;weight_decay&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;scheduler&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;WarmupLR&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;warmup_min_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;warmup_max_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;warmup_num_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;offload_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;offload_param&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;overlap_comm&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;contiguous_gradients&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;sub_group_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_prefetch_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_param_persistence_threshold&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_max_live_parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_max_reuse_distance&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;gradient_clipping&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;steps_per_print&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2000</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;train_batch_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;wall_clock_breakdown&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="p">}</span>
</code></pre></div>
<p>è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ æ‰‹åŠ¨è®¾ç½®çš„å¯ç”¨æ‰€æœ‰åŠŸèƒ½çš„ZeRO-3 é…ç½®æ–‡ä»¶ã€‚ä¸»è¦æ˜¯ä¸ºäº†è®©æ‚¨çœ‹åˆ°å…¸å‹çš„å‚æ•°å€¼æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œä½†æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½¿ç”¨å…¶ä¸­åŒ…å«å¤šä¸ª <code>auto</code> è®¾ç½®çš„é…ç½®æ–‡ä»¶ã€‚</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;fp16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale_window&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;initial_scale_power&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;hysteresis&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;min_loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AdamW&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3e-5</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;betas&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span><span class="w"> </span><span class="mf">0.999</span><span class="p">],</span>
<span class="w">            </span><span class="nt">&quot;eps&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e-8</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;weight_decay&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3e-7</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;scheduler&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;WarmupLR&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;warmup_min_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;warmup_max_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3e-5</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;warmup_num_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">500</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;offload_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;offload_param&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;device&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;pin_memory&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;overlap_comm&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;contiguous_gradients&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;sub_group_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;reduce_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e6</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_prefetch_bucket_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.94e6</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_param_persistence_threshold&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e4</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_max_live_parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_max_reuse_distance&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e9</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">},</span>

<span class="w">    </span><span class="nt">&quot;steps_per_print&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2000</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;wall_clock_breakdown&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="p">}</span>
</code></pre></div>
<h4 id="zero-stage-offloads">å¦‚ä½•é€‰æ‹©æœ€ä½³æ€§èƒ½çš„ZeRO Stageå’Œ offloads<a class="headerlink" href="#zero-stage-offloads" title="Permanent link">âš“ï¸</a></h4>
<p>äº†è§£äº†è¿™äº›ä¸åŒstagesåï¼Œç°åœ¨æ‚¨éœ€è¦å†³å®šä½¿ç”¨å“ªä¸ªstageã€‚æœ¬èŠ‚å°†å°è¯•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚</p>
<p>é€šå¸¸ï¼Œä»¥ä¸‹è§„åˆ™é€‚ç”¨ï¼š</p>
<ul>
<li>é€Ÿåº¦æ–¹é¢ï¼ˆå·¦è¾¹æ¯”å³è¾¹å¿«ï¼‰</li>
</ul>
<p>stage 0ï¼ˆDDPï¼‰ &gt; stage 1 &gt; stage 2 &gt; stage 2 + offload  &gt; stage 3 &gt; stage3 + offload</p>
<ul>
<li>GPUå†…å­˜ä½¿ç”¨æ–¹é¢ï¼ˆå³è¾¹æ¯”å·¦è¾¹æ›´èŠ‚çœGPUå†…å­˜ï¼‰</li>
</ul>
<p>stage 0ï¼ˆDDPï¼‰ &lt; stage 1 &lt; stage 2 &lt; stage 2 + offload &lt; stage 3 &lt; stage 3 + offload</p>
<p>æ‰€ä»¥ï¼Œå½“æ‚¨å¸Œæœ›åœ¨å°½é‡ä½¿ç”¨è¾ƒå°‘æ•°é‡çš„GPUçš„åŒæ—¶è·å¾—æœ€å¿«çš„æ‰§è¡Œé€Ÿåº¦æ—¶ï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œã€‚æˆ‘ä»¬ä»æœ€å¿«çš„æ–¹æ³•å¼€å§‹ï¼Œå¦‚æœé‡åˆ°GPUå†…å­˜æº¢å‡ºï¼Œç„¶ååˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªé€Ÿåº¦è¾ƒæ…¢ä½†ä½¿ç”¨çš„GPUå†…å­˜æ›´å°‘çš„æ–¹æ³•ã€‚ä»¥æ­¤ç±»æ¨ã€‚</p>
<p>é¦–å…ˆï¼Œå°†æ‰¹é‡å¤§å°è®¾ç½®ä¸º1ï¼ˆæ‚¨å§‹ç»ˆå¯ä»¥ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ¥è·å¾—ä»»ä½•æ‰€éœ€çš„æœ‰æ•ˆæ‰¹é‡å¤§å°ï¼‰ã€‚</p>
<ol>
<li>å¯ç”¨ <code>--gradient_checkpointing 1</code>ï¼ˆHF Trainerï¼‰æˆ–ç›´æ¥ <code>model.gradient_checkpointing_enable()</code> - å¦‚æœå‘ç”ŸOOMï¼ˆOut of Memoryï¼‰ï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚</li>
<li>é¦–å…ˆå°è¯• ZeRO stage 2ã€‚å¦‚æœå‘ç”ŸOOMï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚</li>
<li>å°è¯• ZeRO stage 2 + <code>offload_optimizer</code> - å¦‚æœå‘ç”ŸOOMï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚</li>
<li>åˆ‡æ¢åˆ° ZeRO stage 3 - å¦‚æœå‘ç”ŸOOMï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚</li>
<li>å¯ç”¨ <code>offload_param</code> åˆ° <code>cpu</code> - å¦‚æœå‘ç”ŸOOMï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚</li>
<li>å¯ç”¨ <code>offload_optimizer</code> åˆ° <code>cpu</code> - å¦‚æœå‘ç”ŸOOMï¼Œåˆ™æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚</li>
<li>å¦‚æœä»ç„¶æ— æ³•é€‚åº”æ‰¹é‡å¤§å°ä¸º1ï¼Œè¯·é¦–å…ˆæ£€æŸ¥å„ç§é»˜è®¤å€¼å¹¶å°½å¯èƒ½é™ä½å®ƒä»¬ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½¿ç”¨ <code>generate</code> å¹¶ä¸”ä¸ä½¿ç”¨å®½æœç´¢æŸï¼Œå°†å…¶ç¼©å°ï¼Œå› ä¸ºå®ƒä¼šå ç”¨å¤§é‡å†…å­˜ã€‚</li>
<li>ç»å¯¹è¦ä½¿ç”¨æ··åˆåŠç²¾åº¦è€Œéfp32 - åœ¨AmpereåŠæ›´é«˜çš„GPUä¸Šä½¿ç”¨bf16ï¼Œåœ¨æ—§çš„GPUä½“ç³»ç»“æ„ä¸Šä½¿ç”¨fp16ã€‚</li>
<li>å¦‚æœä»ç„¶å‘ç”ŸOOMï¼Œå¯ä»¥æ·»åŠ æ›´å¤šç¡¬ä»¶æˆ–å¯ç”¨ZeRO-Infinity - å³åˆ‡æ¢ <code>offload_param</code> å’Œ <code>offload_optimizer</code> åˆ° <code>nvme</code>ã€‚æ‚¨éœ€è¦ç¡®ä¿å®ƒæ˜¯éå¸¸å¿«çš„NVMeã€‚ä½œä¸ºè¶£é—»ï¼Œæˆ‘æ›¾ç»èƒ½å¤Ÿåœ¨ä¸€ä¸ªå°å‹GPUä¸Šä½¿ç”¨BLOOM-176Bè¿›è¡Œæ¨ç†ï¼Œä½¿ç”¨äº†ZeRO-Infinityï¼Œå°½ç®¡é€Ÿåº¦éå¸¸æ…¢ã€‚ä½†å®ƒå¥æ•ˆäº†ï¼</li>
</ol>
<p>å½“ç„¶ï¼Œæ‚¨ä¹Ÿå¯ä»¥æŒ‰ç›¸åçš„é¡ºåºè¿›è¡Œè¿™äº›æ­¥éª¤ï¼Œä»æœ€èŠ‚çœGPUå†…å­˜çš„é…ç½®å¼€å§‹ï¼Œç„¶åé€æ­¥åå‘è¿›è¡Œï¼Œæˆ–è€…å°è¯•è¿›è¡ŒäºŒåˆ†æ³•ã€‚</p>
<p>ä¸€æ—¦æ‚¨çš„æ‰¹é‡å¤§å°ä¸º1ä¸ä¼šå¯¼è‡´OOMï¼Œå°±æµ‹é‡æ‚¨çš„æœ‰æ•ˆååé‡ã€‚</p>
<p>æ¥ä¸‹æ¥å°è¯•å°†æ‰¹é‡å¤§å°å¢åŠ åˆ°å°½å¯èƒ½å¤§ï¼Œå› ä¸ºæ‰¹é‡å¤§å°è¶Šå¤§ï¼ŒGPUçš„æ•ˆç‡è¶Šé«˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å®ƒä»¬ä¹˜æ³•è¿ç®—çš„çŸ©é˜µå¾ˆå¤§æ—¶ã€‚</p>
<p>ç°åœ¨æ€§èƒ½ä¼˜åŒ–æ¸¸æˆå¼€å§‹äº†ã€‚æ‚¨å¯ä»¥å…³é—­ä¸€äº›offloadç‰¹æ€§ï¼Œæˆ–è€…é™ä½ZeRO stageï¼Œå¹¶å¢åŠ /å‡å°‘æ‰¹é‡å¤§å°ï¼Œå†æ¬¡æµ‹é‡æœ‰æ•ˆååé‡ã€‚åå¤å°è¯•ï¼Œç›´åˆ°æ»¡æ„ä¸ºæ­¢ã€‚</p>
<p>ä¸è¦èŠ±è´¹å¤ªå¤šæ—¶é—´ï¼Œä½†å¦‚æœæ‚¨å³å°†å¼€å§‹ä¸€ä¸ªä¸ºæœŸ3ä¸ªæœˆçš„è®­ç»ƒ - è¯·èŠ±å‡ å¤©æ—¶é—´æ‰¾åˆ°ååé‡æ–¹é¢æœ€æœ‰æ•ˆçš„è®¾ç½®ã€‚è¿™æ ·æ‚¨çš„è®­ç»ƒæˆæœ¬å°†æœ€ä½ï¼Œè€Œä¸”æ‚¨ä¼šæ›´å¿«åœ°å®Œæˆè®­ç»ƒã€‚åœ¨å½“å‰å¿«èŠ‚å¥çš„æœºå™¨å­¦ä¹ ä¸–ç•Œä¸­ï¼Œå¦‚æœæ‚¨èŠ±è´¹ä¸€ä¸ªé¢å¤–çš„æœˆä»½æ¥è®­ç»ƒæŸæ ·ä¸œè¥¿ï¼Œä½ å¾ˆå¯èƒ½ä¼šé”™è¿‡ä¸€ä¸ªé»„é‡‘æœºä¼šã€‚å½“ç„¶ï¼Œè¿™åªæ˜¯æˆ‘åˆ†äº«çš„ä¸€ç§è§‚å¯Ÿï¼Œæˆ‘å¹¶ä¸æ˜¯åœ¨å‚¬ä¿ƒä½ ã€‚åœ¨å¼€å§‹è®­ç»ƒBLOOM-176Bä¹‹å‰ï¼Œæˆ‘èŠ±äº†2å¤©æ—¶é—´è¿›è¡Œè¿™ä¸ªè¿‡ç¨‹ï¼ŒæˆåŠŸå°†ååé‡ä»90 TFLOPsæé«˜åˆ°150 TFLOPsï¼è¿™ä¸€åŠªåŠ›ä¸ºæˆ‘ä»¬èŠ‚çœäº†ä¸€ä¸ªå¤šæœˆçš„è®­ç»ƒæ—¶é—´ã€‚</p>
<p>è¿™äº›æ³¨é‡Šä¸»è¦æ˜¯ä¸ºè®­ç»ƒæ¨¡å¼ç¼–å†™çš„ï¼Œä½†å®ƒä»¬åœ¨æ¨ç†ä¸­ä¹Ÿåº”è¯¥å¤§éƒ¨åˆ†é€‚ç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨æ¨ç†ä¸­ï¼ŒGradient Checkpointing æ˜¯æ— ç”¨çš„ï¼Œå› ä¸ºå®ƒåªåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœ‰ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ï¼Œå¦‚æœä½ æ­£åœ¨è¿›è¡Œå¤šGPUæ¨ç†å¹¶ä¸”ä¸ä½¿ç”¨ <a href="https://www.deepspeed.ai/tutorials/inference-tutorial/">DeepSpeed-Inference</a>ï¼Œ<a href="https://huggingface.co/blog/bloom-inference-pytorch-scripts">Accelerate</a> åº”è¯¥æä¾›æ›´ä¼˜è¶Šçš„æ€§èƒ½ã€‚</p>
<p>å…¶ä»–ä¸æ€§èƒ½ç›¸å…³çš„å¿«é€Ÿæ³¨é‡Šï¼š
- å¦‚æœæ‚¨ä»å¤´å¼€å§‹è®­ç»ƒæŸä¸ªæ¨¡å‹ï¼Œè¯·å°½é‡ç¡®ä¿å¼ é‡çš„å½¢çŠ¶å¯ä»¥è¢«16æ•´é™¤ï¼ˆä¾‹å¦‚éšè—å±‚å¤§å°ï¼‰ã€‚å¯¹äºæ‰¹é‡å¤§å°ï¼Œè‡³å°‘å°è¯•å¯è¢«2æ•´é™¤ã€‚å¦‚æœæ‚¨æƒ³ä»GPUä¸­æŒ¤å–æ›´é«˜æ€§èƒ½ï¼Œè¿˜æœ‰ä¸€äº›ç¡¬ä»¶ç‰¹å®šçš„<a href="https://developer.nvidia.com/blog/optimizing-gpu-performance-tensor-cores/">waveå’Œtileé‡åŒ–</a>çš„å¯æ•´é™¤æ€§ã€‚</p>
<h3 id="activation-checkpointing-gradient-checkpointing">Activation Checkpointing æˆ– Gradient Checkpointing<a class="headerlink" href="#activation-checkpointing-gradient-checkpointing" title="Permanent link">âš“ï¸</a></h3>
<p>Activation Checkpointingå’ŒGradient Checkpointingæ˜¯æŒ‡ç›¸åŒæ–¹æ³•çš„ä¸¤ä¸ªä¸åŒæœ¯è¯­ã€‚è¿™ç¡®å®è®©äººæ„Ÿåˆ°å›°æƒ‘ï¼Œä½†äº‹å®å°±æ˜¯è¿™æ ·ã€‚</p>
<p>Gradient Checkpointingå…è®¸é€šè¿‡ç‰ºç‰²é€Ÿåº¦æ¥æ¢å–GPUå†…å­˜ï¼Œè¿™è¦ä¹ˆä½¿æ‚¨èƒ½å¤Ÿå…‹æœGPUå†…å­˜æº¢å‡ºï¼Œè¦ä¹ˆå¢åŠ æ‰¹é‡å¤§å°æ¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚</p>
<p>HF Transformers æ¨¡å‹å¯¹DeepSpeedçš„Activation Checkpointingä¸€æ— æ‰€çŸ¥ï¼Œå› æ­¤å¦‚æœå°è¯•åœ¨DeepSpeedé…ç½®æ–‡ä»¶ä¸­å¯ç”¨è¯¥åŠŸèƒ½ï¼Œä»€ä¹ˆéƒ½ä¸ä¼šå‘ç”Ÿã€‚</p>
<p>å› æ­¤ï¼Œæ‚¨æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥åˆ©ç”¨è¿™ä¸ªéå¸¸æœ‰ç›Šçš„åŠŸèƒ½ï¼š</p>
<ol>
<li>å¦‚æœæ‚¨æƒ³ä½¿ç”¨ HF Transformers æ¨¡å‹ï¼Œä½ å¯ä»¥ä½¿ç”¨ <code>model.gradient_checkpointing_enable()</code> æˆ–åœ¨ HF Trainer ä¸­ä½¿ç”¨ <code>--gradient_checkpointing</code>ï¼Œå®ƒä¼šè‡ªåŠ¨ä¸ºæ‚¨å¯ç”¨è¿™ä¸ªåŠŸèƒ½ã€‚åœ¨è¿™é‡Œä½¿ç”¨äº† <code>torch.utils.checkpoint</code>ã€‚</li>
<li>å¦‚æœæ‚¨ç¼–å†™è‡ªå·±çš„æ¨¡å‹å¹¶å¸Œæœ›ä½¿ç”¨DeepSpeedçš„Activation Checkpointingï¼Œå¯ä»¥ä½¿ç”¨<a href="https://deepspeed.readthedocs.io/en/latest/activation-checkpointing.html">è§„å®šçš„API</a>ã€‚æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ HF Transformers çš„æ¨¡å‹ä»£ç ï¼Œå°† <code>torch.utils.checkpoint</code> æ›¿æ¢ä¸º DeepSpeed çš„APIã€‚åè€…æ›´çµæ´»ï¼Œå› ä¸ºå®ƒå…è®¸æ‚¨å°†å‰å‘æ¿€æ´»å€¼å¸è½½åˆ°CPUå†…å­˜ï¼Œè€Œä¸æ˜¯é‡æ–°è®¡ç®—å®ƒä»¬ã€‚</li>
</ol>
<h3 id="optimizer-scheduler">Optimizer å’Œ Scheduler<a class="headerlink" href="#optimizer-scheduler" title="Permanent link">âš“ï¸</a></h3>
<p>åªè¦ä½ ä¸å¯ç”¨ <code>offload_optimizer</code>ï¼Œæ‚¨å¯ä»¥æ··åˆä½¿ç”¨DeepSpeedå’ŒHuggingFaceçš„è°ƒåº¦å™¨å’Œä¼˜åŒ–å™¨ï¼Œä½†æœ‰ä¸€ä¸ªä¾‹å¤–ï¼Œå³ä¸è¦ä½¿ç”¨HuggingFaceè°ƒåº¦å™¨å’ŒDeepSpeedä¼˜åŒ–å™¨çš„ç»„åˆï¼š</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Combos</th>
<th style="text-align: left;">HF Scheduler</th>
<th style="text-align: left;">DS Scheduler</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">HF Optimizer</td>
<td style="text-align: left;">Yes</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">DS Optimizer</td>
<td style="text-align: left;">No</td>
<td style="text-align: left;">Yes</td>
</tr>
</tbody>
</table>
<p>åœ¨å¯ç”¨ <code>offload_optimizer</code> çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿ç”¨éDeepSpeedä¼˜åŒ–å™¨ï¼Œåªè¦è¯¥ä¼˜åŒ–å™¨å…·æœ‰CPUå’ŒGPUçš„å®ç°ï¼ˆé™¤äº†LAMBï¼‰ã€‚</p>
<p><a id='deepspeed-optimizer'></a></p>
<h4 id="optimizer">Optimizer<a class="headerlink" href="#optimizer" title="Permanent link">âš“ï¸</a></h4>
<p>DeepSpeedçš„ä¸»è¦ä¼˜åŒ–å™¨åŒ…æ‹¬Adamã€AdamWã€OneBitAdamå’ŒLambã€‚è¿™äº›ä¼˜åŒ–å™¨å·²ç»ä¸ZeROè¿›è¡Œäº†å½»åº•çš„æµ‹è¯•ï¼Œå› æ­¤å»ºè®®ä½¿ç”¨å®ƒä»¬ã€‚ç„¶è€Œï¼Œä¹Ÿå¯ä»¥å¯¼å…¥<code>torch</code>ä¸­çš„å…¶ä»–ä¼˜åŒ–å™¨ã€‚å®Œæ•´çš„æ–‡æ¡£åœ¨<a href="https://www.deepspeed.ai/docs/config-json/#optimizer-parameters">è¿™é‡Œ</a>ã€‚</p>
<p>å¦‚æœåœ¨é…ç½®æ–‡ä»¶ä¸­ä¸é…ç½®<code>optimizer</code>æ¡ç›®ï¼Œ[<code>Trainer</code>] å°†è‡ªåŠ¨å°†å…¶è®¾ç½®ä¸º <code>AdamW</code>ï¼Œå¹¶ä½¿ç”¨æä¾›çš„å€¼æˆ–ä»¥ä¸‹å‘½ä»¤è¡Œå‚æ•°çš„é»˜è®¤å€¼ï¼š<code>--learning_rate</code>ã€<code>--adam_beta1</code>ã€<code>--adam_beta2</code>ã€<code>--adam_epsilon</code> å’Œ <code>--weight_decay</code>ã€‚</p>
<p>ä»¥ä¸‹æ˜¯<code>AdamW</code> çš„è‡ªåŠ¨é…ç½®ç¤ºä¾‹ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AdamW&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">         </span><span class="nt">&quot;lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">         </span><span class="nt">&quot;betas&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">         </span><span class="nt">&quot;eps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">         </span><span class="nt">&quot;weight_decay&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">       </span><span class="p">}</span>
<span class="w">   </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>è¯·æ³¨æ„ï¼Œå‘½ä»¤è¡Œå‚æ•°å°†è®¾ç½®é…ç½®æ–‡ä»¶ä¸­çš„å€¼ã€‚è¿™æ˜¯ä¸ºäº†æœ‰ä¸€ä¸ªæ˜ç¡®çš„å€¼æ¥æºï¼Œå¹¶é¿å…åœ¨ä¸åŒåœ°æ–¹è®¾ç½®å­¦ä¹ ç‡ç­‰å€¼æ—¶éš¾ä»¥æ‰¾åˆ°çš„é”™è¯¯ã€‚å‘½ä»¤è¡Œå‚æ•°é…ç½®é«˜äºå…¶ä»–ã€‚è¢«è¦†ç›–çš„å€¼åŒ…æ‹¬ï¼š</p>
<ul>
<li><code>lr</code> çš„å€¼ä¸º <code>--learning_rate</code></li>
<li><code>betas</code> çš„å€¼ä¸º <code>--adam_beta1 --adam_beta2</code></li>
<li><code>eps</code> çš„å€¼ä¸º <code>--adam_epsilon</code></li>
<li><code>weight_decay</code> çš„å€¼ä¸º <code>--weight_decay</code></li>
</ul>
<p>å› æ­¤ï¼Œè¯·è®°ä½åœ¨å‘½ä»¤è¡Œä¸Šè°ƒæ•´å…±äº«çš„è¶…å‚æ•°ã€‚</p>
<p>æ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼åœ°è®¾ç½®è¿™äº›å€¼ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">       </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;AdamW&quot;</span><span class="p">,</span>
<span class="w">       </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">         </span><span class="nt">&quot;lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.001</span><span class="p">,</span>
<span class="w">         </span><span class="nt">&quot;betas&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span><span class="w"> </span><span class="mf">0.999</span><span class="p">],</span>
<span class="w">         </span><span class="nt">&quot;eps&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e-8</span><span class="p">,</span>
<span class="w">         </span><span class="nt">&quot;weight_decay&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3e-7</span>
<span class="w">       </span><span class="p">}</span>
<span class="w">   </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>ä½†åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦è‡ªå·±åŒæ­¥[<code>Trainer</code>]å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚</p>
<p>å¦‚æœæ‚¨æƒ³ä½¿ç”¨ä¸Šé¢æœªåˆ—å‡ºçš„å…¶ä»–ä¼˜åŒ–å™¨ï¼Œæ‚¨å°†ä¸å¾—ä¸å°†å…¶æ·»åŠ åˆ°é¡¶å±‚é…ç½®ä¸­ã€‚</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;zero_allow_untested_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="p">}</span>
</code></pre></div>
<p>ç±»ä¼¼äº <code>AdamW</code>ï¼Œæ‚¨å¯ä»¥é…ç½®å…¶ä»–å®˜æ–¹æ”¯æŒçš„ä¼˜åŒ–å™¨ã€‚åªæ˜¯è®°ä½è¿™äº›å¯èƒ½æœ‰ä¸åŒçš„é…ç½®å€¼ã€‚ä¾‹å¦‚ï¼Œå¯¹äºAdamï¼Œæ‚¨å¯èƒ½éœ€è¦å°† <code>weight_decay</code> è®¾ç½®åœ¨ <code>0.01</code> å·¦å³ã€‚</p>
<p>æ­¤å¤–ï¼Œå½“ä¸DeepSpeedçš„CPU Adamä¼˜åŒ–å™¨ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œoffloadçš„æ•ˆæœæœ€å¥½ã€‚å¦‚æœæ‚¨æƒ³åœ¨offloadæ—¶ä½¿ç”¨ä¸åŒçš„ä¼˜åŒ–å™¨ï¼Œè‡ª <code>deepspeed==0.8.3</code> èµ·ï¼Œæ‚¨è¿˜éœ€è¦æ·»åŠ ï¼š</p>
<p><div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;zero_force_ds_cpu_optimizer&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="p">}</span>
</code></pre></div>
åˆ°é¡¶å±‚é…ç½®ä¸­ã€‚</p>
<p><a id='deepspeed-scheduler'></a></p>
<h4 id="scheduler">Scheduler<a class="headerlink" href="#scheduler" title="Permanent link">âš“ï¸</a></h4>
<p>DeepSpeedæ”¯æŒ<code>LRRangeTest</code>ã€<code>OneCycle</code>ã€<code>WarmupLR</code>å’Œ<code>WarmupDecayLR</code>å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚å®Œæ•´æ–‡æ¡£åœ¨<a href="https://www.deepspeed.ai/docs/config-json/#scheduler-parameters">è¿™é‡Œ</a>ã€‚</p>
<p>ä»¥ä¸‹æ˜¯ğŸ¤— Transformers å’Œ DeepSpeed ä¹‹é—´çš„è°ƒåº¦å™¨é‡å éƒ¨åˆ†ï¼š</p>
<ul>
<li>é€šè¿‡ <code>--lr_scheduler_type constant_with_warmup</code> å®ç° <code>WarmupLR</code></li>
<li>é€šè¿‡ <code>--lr_scheduler_type linear</code> å®ç° <code>WarmupDecayLR</code>ã€‚è¿™ä¹Ÿæ˜¯ <code>--lr_scheduler_type</code> çš„é»˜è®¤å€¼ï¼Œå› æ­¤ï¼Œå¦‚æœä¸é…ç½®è°ƒåº¦å™¨ï¼Œè¿™å°†æ˜¯é»˜è®¤é…ç½®çš„è°ƒåº¦å™¨ã€‚</li>
</ul>
<p>å¦‚æœåœ¨é…ç½®æ–‡ä»¶ä¸­ä¸é…ç½® <code>scheduler</code> æ¡ç›®ï¼Œ[<code>Trainer</code>] å°†ä½¿ç”¨ <code>--lr_scheduler_type</code>ã€<code>--learning_rate</code> å’Œ <code>--warmup_steps</code> æˆ– <code>--warmup_ratio</code> çš„å€¼æ¥é…ç½®å…¶ğŸ¤— Transformers ç‰ˆæœ¬ã€‚</p>
<p>ä»¥ä¸‹æ˜¯ <code>WarmupLR</code> çš„è‡ªåŠ¨é…ç½®ç¤ºä¾‹ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;scheduler&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">         </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;WarmupLR&quot;</span><span class="p">,</span>
<span class="w">         </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">             </span><span class="nt">&quot;warmup_min_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="nt">&quot;warmup_max_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="nt">&quot;warmup_num_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">         </span><span class="p">}</span>
<span class="w">     </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>ç”±äºä½¿ç”¨äº† <em>"auto"</em>ï¼Œ[<code>Trainer</code>] çš„å‚æ•°å°†åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„å€¼ã€‚è¿™æ˜¯ä¸ºäº†æœ‰ä¸€ä¸ªæ˜ç¡®çš„å€¼æ¥æºï¼Œå¹¶é¿å…åœ¨ä¸åŒåœ°æ–¹è®¾ç½®å­¦ä¹ ç‡ç­‰å€¼æ—¶éš¾ä»¥æ‰¾åˆ°çš„é”™è¯¯ã€‚å‘½ä»¤è¡Œé…ç½®é«˜äºå…¶ä»–ã€‚è¢«è®¾ç½®çš„å€¼åŒ…æ‹¬ï¼š</p>
<ul>
<li><code>warmup_min_lr</code> çš„å€¼ä¸º <code>0</code>ã€‚</li>
<li><code>warmup_max_lr</code> çš„å€¼ä¸º <code>--learning_rate</code>ã€‚</li>
<li><code>warmup_num_steps</code> çš„å€¼ä¸º <code>--warmup_steps</code>ï¼ˆå¦‚æœæä¾›ï¼‰ã€‚å¦åˆ™ï¼Œå°†ä½¿ç”¨ <code>--warmup_ratio</code> ä¹˜ä»¥è®­ç»ƒæ­¥éª¤çš„æ•°é‡ï¼Œå¹¶å››èˆäº”å…¥ã€‚</li>
<li><code>total_num_steps</code> çš„å€¼ä¸º <code>--max_steps</code> æˆ–è€…å¦‚æœæ²¡æœ‰æä¾›ï¼Œå°†åœ¨è¿è¡Œæ—¶æ ¹æ®ç¯å¢ƒã€æ•°æ®é›†çš„å¤§å°å’Œå…¶ä»–å‘½ä»¤è¡Œå‚æ•°ï¼ˆå¯¹äº <code>WarmupDecayLR</code> æ¥è¯´éœ€è¦ï¼‰è‡ªåŠ¨æ¨å¯¼ã€‚</li>
</ul>
<p>å½“ç„¶ï¼Œæ‚¨å¯ä»¥æ¥ç®¡ä»»ä½•æˆ–æ‰€æœ‰çš„é…ç½®å€¼ï¼Œå¹¶è‡ªè¡Œè®¾ç½®è¿™äº›å€¼ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;scheduler&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">         </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;WarmupLR&quot;</span><span class="p">,</span>
<span class="w">         </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">             </span><span class="nt">&quot;warmup_min_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">             </span><span class="nt">&quot;warmup_max_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.001</span><span class="p">,</span>
<span class="w">             </span><span class="nt">&quot;warmup_num_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span>
<span class="w">         </span><span class="p">}</span>
<span class="w">     </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>ä½†åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦è‡ªå·±åŒæ­¥[<code>Trainer</code>]å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚</p>
<p>ä¾‹å¦‚ï¼Œå¯¹äº <code>WarmupDecayLR</code>ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ¡ç›®ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;scheduler&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">         </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;WarmupDecayLR&quot;</span><span class="p">,</span>
<span class="w">         </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">             </span><span class="nt">&quot;last_batch_iteration&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">-1</span><span class="p">,</span>
<span class="w">             </span><span class="nt">&quot;total_num_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="nt">&quot;warmup_min_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="nt">&quot;warmup_max_lr&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">             </span><span class="nt">&quot;warmup_num_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">         </span><span class="p">}</span>
<span class="w">     </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>ç„¶åï¼Œ<code>total_num_steps</code>ã€<code>warmup_max_lr</code>ã€<code>warmup_num_steps</code> å’Œ <code>total_num_steps</code> å°†åœ¨åŠ è½½æ—¶è®¾ç½®ã€‚</p>
<p><a id='deepspeed-fp32'></a></p>
<h3 id="fp32">fp32ç²¾åº¦<a class="headerlink" href="#fp32" title="Permanent link">âš“ï¸</a></h3>
<p>DeepSpeedæ”¯æŒå®Œæ•´çš„fp32å’Œfp16æ··åˆç²¾åº¦ã€‚</p>
<p>ç”±äºfp16æ··åˆç²¾åº¦å…·æœ‰æ›´å°çš„å†…å­˜éœ€æ±‚å’Œæ›´å¿«çš„é€Ÿåº¦ï¼Œå”¯ä¸€ä¸ä½¿ç”¨å®ƒçš„æ—¶å€™æ˜¯å½“æ‚¨ä½¿ç”¨çš„æ¨¡å‹åœ¨è¿™ç§è®­ç»ƒæ¨¡å¼ä¸‹è¡¨ç°ä¸ä½³æ—¶ã€‚é€šå¸¸ï¼Œå½“æ¨¡å‹æ²¡æœ‰åœ¨fp16æ··åˆç²¾åº¦ä¸‹è¿›è¡Œé¢„è®­ç»ƒæ—¶ï¼ˆä¾‹å¦‚ï¼Œbf16é¢„è®­ç»ƒæ¨¡å‹ç»å¸¸å‡ºç°è¿™ç§æƒ…å†µï¼‰ï¼Œä¼šå‡ºç°è¿™ç§æƒ…å†µã€‚è¿™æ ·çš„æ¨¡å‹å¯èƒ½ä¼šå‘ç”Ÿæº¢å‡ºæˆ–ä¸‹æº¢ï¼Œå¯¼è‡´ <code>NaN</code> æŸå¤±ã€‚å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œé‚£ä¹ˆæ‚¨å°†å¸Œæœ›ä½¿ç”¨å®Œæ•´çš„fp32æ¨¡å¼ï¼Œé€šè¿‡æ˜¾å¼ç¦ç”¨é»˜è®¤å¯ç”¨çš„fp16æ··åˆç²¾åº¦æ¨¡å¼ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;fp16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>å¦‚æœæ‚¨ä½¿ç”¨åŸºäºAmpereæ¶æ„çš„GPUï¼ŒPyTorchç‰ˆæœ¬1.7åŠæ›´é«˜ç‰ˆæœ¬å°†è‡ªåŠ¨åˆ‡æ¢åˆ°ä½¿ç”¨æ›´é«˜æ•ˆçš„tf32æ ¼å¼è¿›è¡Œä¸€äº›æ“ä½œï¼Œä½†ç»“æœä»å°†ä»¥fp32æ ¼å¼å‘ˆç°ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯å’ŒåŸºå‡†æµ‹è¯•ï¼Œè¯·å‚è§<a href="https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices">TensorFloat-32(TF32) on Ampere devices</a>ã€‚å¦‚æœå‡ºäºæŸç§åŸå› æ‚¨ä¸å¸Œæœ›ä½¿ç”¨å®ƒï¼Œè¯¥æ–‡æ¡£åŒ…æ‹¬æœ‰å…³å¦‚ä½•ç¦ç”¨æ­¤è‡ªåŠ¨è½¬æ¢çš„è¯´æ˜ã€‚</p>
<p>åœ¨ğŸ¤— Trainerä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ <code>--tf32</code> æ¥å¯ç”¨å®ƒï¼Œæˆ–ä½¿ç”¨ <code>--tf32 0</code> æˆ– <code>--no_tf32</code> æ¥ç¦ç”¨å®ƒã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä½¿ç”¨PyTorchçš„é»˜è®¤è®¾ç½®ã€‚</p>
<p><a id='deepspeed-amp'></a></p>
<h3 id="_6">è‡ªåŠ¨æ··åˆç²¾åº¦<a class="headerlink" href="#_6" title="Permanent link">âš“ï¸</a></h3>
<p>æ‚¨å¯ä»¥ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨ç±»ä¼¼ PyTorch AMP çš„æ–¹å¼ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©ä½¿ç”¨ç±»ä¼¼ Apex çš„æ–¹å¼ï¼š</p>
<h3 id="fp16">fp16<a class="headerlink" href="#fp16" title="Permanent link">âš“ï¸</a></h3>
<p>è¦é…ç½®PyTorch AMP-like çš„ fp16ï¼ˆfloat16ï¼‰ æ¨¡å¼ï¼Œè¯·è®¾ç½®ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;fp16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale_window&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;initial_scale_power&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;hysteresis&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;min_loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>å¹¶ä¸”ï¼Œ[<code>Trainer</code>]å°†æ ¹æ®<code>args.fp16_backend</code>çš„å€¼è‡ªåŠ¨å¯ç”¨æˆ–ç¦ç”¨å®ƒã€‚å…¶ä½™çš„é…ç½®å€¼ç”±æ‚¨å†³å®šã€‚</p>
<p>å½“ä¼ é€’<code>--fp16 --fp16_backend amp</code>æˆ–<code>--fp16_full_eval</code>å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œæ­¤æ¨¡å¼å°†è¢«å¯ç”¨ã€‚</p>
<p>æ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼åœ°å¯ç”¨/ç¦ç”¨æ­¤æ¨¡å¼ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;fp16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale_window&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;initial_scale_power&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;hysteresis&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;min_loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>ä½†æ˜¯ä¹‹åæ‚¨éœ€è¦è‡ªå·±åŒæ­¥[<code>Trainer</code>]å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚</p>
<p>ä»¥ä¸‹æ˜¯<a href="https://www.deepspeed.ai/docs/config-json/#fp16-training-options">ç›¸å…³æ–‡æ¡£</a></p>
<h3 id="bf16">bf16<a class="headerlink" href="#bf16" title="Permanent link">âš“ï¸</a></h3>
<p>å¦‚æœéœ€è¦ä½¿ç”¨bfloat16è€Œä¸æ˜¯fp16ï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨ä»¥ä¸‹é…ç½®éƒ¨åˆ†ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;bf16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>bf16å…·æœ‰ä¸fp32ç›¸åŒçš„åŠ¨æ€èŒƒå›´ï¼Œå› æ­¤ä¸éœ€è¦æŸå¤±ç¼©æ”¾ã€‚</p>
<p>å½“ä¼ é€’<code>--bf16</code>æˆ–<code>--bf16_full_eval</code>å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œå¯ç”¨æ­¤æ¨¡å¼ã€‚</p>
<p>æ‚¨è¿˜å¯ä»¥æ˜¾å¼åœ°å¯ç”¨/ç¦ç”¨æ­¤æ¨¡å¼ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;bf16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p><Tip></p>
<p>åœ¨<code>deepspeed==0.6.0</code>ç‰ˆæœ¬ä¸­ï¼Œbf16æ”¯æŒæ˜¯æ–°çš„å®éªŒæ€§åŠŸèƒ½ã€‚</p>
<p>å¦‚æœæ‚¨å¯ç”¨äº†bf16æ¥è¿›è¡Œ<a href="#gradient-accumulation">æ¢¯åº¦ç´¯ç§¯</a>ï¼Œæ‚¨éœ€è¦æ„è¯†åˆ°å®ƒä¼šä»¥bf16ç´¯ç§¯æ¢¯åº¦ï¼Œè¿™å¯èƒ½ä¸æ˜¯æ‚¨æƒ³è¦çš„ï¼Œå› ä¸ºè¿™ç§æ ¼å¼çš„ä½ç²¾åº¦å¯èƒ½ä¼šå¯¼è‡´lossy accumulationã€‚</p>
<p>ä¿®å¤è¿™ä¸ªé—®é¢˜çš„å·¥ä½œæ­£åœ¨åŠªåŠ›è¿›è¡Œï¼ŒåŒæ—¶æä¾›äº†ä½¿ç”¨æ›´é«˜ç²¾åº¦çš„<code>dtype</code>ï¼ˆfp16æˆ–fp32ï¼‰çš„é€‰é¡¹ã€‚</p>
<p></Tip></p>
<h3 id="nccl">NCCLé›†åˆ<a class="headerlink" href="#nccl" title="Permanent link">âš“ï¸</a></h3>
<p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ‰ä¸¤ç§æ•°æ®ç±»å‹ï¼š<code>dtype</code>å’Œç”¨äºé€šä¿¡æ”¶é›†æ“ä½œçš„<code>dtype</code>ï¼Œå¦‚å„ç§å½’çº¦å’Œæ”¶é›†/åˆ†æ•£æ“ä½œã€‚</p>
<p>æ‰€æœ‰çš„gather/scatteræ“ä½œéƒ½æ˜¯åœ¨æ•°æ®ç›¸åŒçš„<code>dtype</code>ä¸­æ‰§è¡Œçš„ï¼Œæ‰€ä»¥å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨bf16çš„è®­ç»ƒæ¨¡å¼ï¼Œé‚£ä¹ˆå®ƒå°†åœ¨bf16ä¸­è¿›è¡Œgatheræ“ä½œ - gatheræ“ä½œæ˜¯éæŸå¤±æ€§çš„ã€‚</p>
<p>å„ç§reduceæ“ä½œå¯èƒ½ä¼šæ˜¯éå¸¸æŸå¤±æ€§çš„ï¼Œä¾‹å¦‚å½“æ¢¯åº¦åœ¨å¤šä¸ªgpuä¸Šå¹³å‡æ—¶ï¼Œå¦‚æœé€šä¿¡æ˜¯åœ¨fp16æˆ–bf16ä¸­è¿›è¡Œçš„ï¼Œé‚£ä¹ˆç»“æœå¯èƒ½æ˜¯æœ‰æŸå¤±æ€§çš„ - å› ä¸ºå½“åœ¨ä¸€ä¸ªä½ç²¾åº¦ä¸­æ·»åŠ å¤šä¸ªæ•°å­—æ—¶ï¼Œç»“æœå¯èƒ½ä¸æ˜¯ç²¾ç¡®çš„ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œbf16æ¯”fp16å…·æœ‰æ›´ä½çš„ç²¾åº¦ã€‚é€šå¸¸ï¼Œå½“å¹³å‡æ¢¯åº¦æ—¶ï¼ŒæŸå¤±æœ€å°ï¼Œè¿™äº›æ¢¯åº¦é€šå¸¸éå¸¸å°ã€‚å› æ­¤ï¼Œå¯¹äºåŠç²¾åº¦è®­ç»ƒï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œfp16è¢«ç”¨ä½œreductionæ“ä½œçš„é»˜è®¤å€¼ã€‚ä½†æ˜¯ï¼Œæ‚¨å¯ä»¥å®Œå…¨æ§åˆ¶è¿™ä¸ªåŠŸèƒ½ï¼Œå¦‚æœä½ é€‰æ‹©çš„è¯ï¼Œæ‚¨å¯ä»¥æ·»åŠ ä¸€ä¸ªå°çš„å¼€é”€ï¼Œå¹¶ç¡®ä¿reductionså°†ä½¿ç”¨fp32ä½œä¸ºç´¯ç§¯æ•°æ®ç±»å‹ï¼Œåªæœ‰å½“ç»“æœå‡†å¤‡å¥½æ—¶ï¼Œå®ƒæ‰ä¼šé™çº§åˆ°æ‚¨åœ¨è®­ç»ƒä¸­ä½¿ç”¨çš„åŠç²¾åº¦<code>dtype</code>ã€‚</p>
<p>è¦è¦†ç›–é»˜è®¤è®¾ç½®ï¼Œæ‚¨åªéœ€æ·»åŠ ä¸€ä¸ªæ–°çš„é…ç½®æ¡ç›®ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;communication_data_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;fp32&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>æ ¹æ®è¿™ä¸ªä¿¡æ¯ï¼Œæœ‰æ•ˆçš„å€¼åŒ…æ‹¬"fp16"ã€"bfp16"å’Œ"fp32"ã€‚</p>
<p>æ³¨æ„ï¼šåœ¨stage zero 3ä¸­ï¼Œbf16é€šä¿¡æ•°æ®ç±»å‹å­˜åœ¨ä¸€ä¸ªbugï¼Œè¯¥é—®é¢˜å·²åœ¨<code>deepspeed==0.8.1</code>ç‰ˆæœ¬ä¸­å¾—åˆ°ä¿®å¤ã€‚</p>
<h3 id="apex">apex<a class="headerlink" href="#apex" title="Permanent link">âš“ï¸</a></h3>
<p>é…ç½®apex AMP-likeæ¨¡å¼ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="nt">&quot;amp&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;opt_level&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>å¹¶ä¸”ï¼Œ[<code>Trainer</code>]å°†æ ¹æ®<code>args.fp16_backend</code>å’Œ<code>args.fp16_opt_level</code>çš„å€¼è‡ªåŠ¨é…ç½®å®ƒã€‚</p>
<p>å½“ä¼ é€’<code>--fp16 --fp16_backend apex --fp16_opt_level 01</code>å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œæ­¤æ¨¡å¼å°†è¢«å¯ç”¨ã€‚</p>
<p>æ‚¨è¿˜å¯ä»¥æ˜¾å¼é…ç½®æ­¤æ¨¡å¼ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;amp&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;opt_level&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;O1&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªå·±åŒæ­¥[<code>Trainer</code>]å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚</p>
<p>è¿™é‡Œæ˜¯<a href="https://www.deepspeed.ai/docs/config-json/#automatic-mixed-precision-amp-training-options">æ–‡æ¡£</a></p>
<p><a id='deepspeed-bs'></a></p>
<h3 id="batch-size">Batch Size<a class="headerlink" href="#batch-size" title="Permanent link">âš“ï¸</a></h3>
<p>é…ç½®batch sizeå¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‚æ•°:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;train_batch_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>å¹¶ä¸”ï¼Œ[<code>Trainer</code>]å°†è‡ªåŠ¨å°†<code>train_micro_batch_size_per_gpu</code>è®¾ç½®ä¸º<code>args.per_device_train_batch_size</code>çš„å€¼ï¼Œå¹¶å°†<code>train_batch_size</code>è®¾ç½®ä¸º<code>args.world_size * args.per_device_train_batch_size * args.gradient_accumulation_steps</code>ã€‚</p>
<p>æ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼è®¾ç½®è¿™äº›å€¼ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;train_batch_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">4</span>
<span class="p">}</span>
</code></pre></div>
<p>ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªå·±åŒæ­¥[<code>Trainer</code>]å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚</p>
<p><a id='deepspeed-grad-acc'></a></p>
<h3 id="gradient-accumulation">Gradient Accumulation<a class="headerlink" href="#gradient-accumulation" title="Permanent link">âš“ï¸</a></h3>
<p>é…ç½®gradient accumulationè®¾ç½®å¦‚ä¸‹:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>å¹¶ä¸”ï¼Œ[<code>Trainer</code>]å°†è‡ªåŠ¨å°†å…¶è®¾ç½®ä¸º<code>args.gradient_accumulation_steps</code>çš„å€¼ã€‚</p>
<p>æ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼è®¾ç½®è¿™ä¸ªå€¼ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span>
<span class="p">}</span>
</code></pre></div>
<p>ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªå·±åŒæ­¥[<code>Trainer</code>]å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚</p>
<p><a id='deepspeed-grad-clip'></a></p>
<h3 id="gradient-clipping">Gradient Clipping<a class="headerlink" href="#gradient-clipping" title="Permanent link">âš“ï¸</a></h3>
<p>é…ç½®gradient clippingå¦‚ä¸‹:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;gradient_clipping&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="p">}</span>
</code></pre></div>
<p>å¹¶ä¸”ï¼Œ[<code>Trainer</code>]å°†è‡ªåŠ¨å°†å…¶è®¾ç½®ä¸º<code>args.max_grad_norm</code>çš„å€¼ã€‚</p>
<p>æ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼è®¾ç½®è¿™ä¸ªå€¼ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;gradient_clipping&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1.0</span>
<span class="p">}</span>
</code></pre></div>
<p>ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªå·±åŒæ­¥[<code>Trainer</code>]å‘½ä»¤è¡Œå‚æ•°å’ŒDeepSpeedé…ç½®ã€‚</p>
<p><a id='deepspeed-weight-extraction'></a></p>
<h3 id="_7">è·å–æ¨¡å‹æƒé‡<a class="headerlink" href="#_7" title="Permanent link">âš“ï¸</a></h3>
<p>åªè¦æ‚¨ç»§ç»­ä½¿ç”¨DeepSpeedè¿›è¡Œè®­ç»ƒå’Œæ¢å¤ï¼Œæ‚¨å°±ä¸éœ€è¦æ‹…å¿ƒä»»ä½•äº‹æƒ…ã€‚DeepSpeedåœ¨å…¶è‡ªå®šä¹‰æ£€æŸ¥ç‚¹ä¼˜åŒ–å™¨æ–‡ä»¶ä¸­å­˜å‚¨fp32ä¸»æƒé‡ï¼Œè¿™äº›æ–‡ä»¶æ˜¯<code>global_step*/*optim_states.pt</code>ï¼ˆè¿™æ˜¯globæ¨¡å¼ï¼‰ï¼Œå¹¶ä¿å­˜åœ¨æ­£å¸¸çš„checkpointä¸‹ã€‚</p>
<p><strong>FP16æƒé‡ï¼š</strong></p>
<p>å½“æ¨¡å‹ä¿å­˜åœ¨ZeRO-2ä¸‹æ—¶ï¼Œæ‚¨æœ€ç»ˆä¼šå¾—åˆ°ä¸€ä¸ªåŒ…å«æ¨¡å‹æƒé‡çš„æ™®é€š<code>pytorch_model.bin</code>æ–‡ä»¶ï¼Œä½†å®ƒä»¬åªæ˜¯æƒé‡çš„fp16ç‰ˆæœ¬ã€‚</p>
<p>åœ¨ZeRO-3ä¸‹ï¼Œäº‹æƒ…è¦å¤æ‚å¾—å¤šï¼Œå› ä¸ºæ¨¡å‹æƒé‡åˆ†å¸ƒåœ¨å¤šä¸ªGPUä¸Šï¼Œå› æ­¤éœ€è¦<code>"stage3_gather_16bit_weights_on_model_save": true</code>æ‰èƒ½è®©<code>Trainer</code>ä¿å­˜fp16ç‰ˆæœ¬çš„æƒé‡ã€‚å¦‚æœè¿™ä¸ªè®¾ç½®æ˜¯<code>False</code>ï¼Œ<code>pytorch_model.bin</code>å°†ä¸ä¼šè¢«åˆ›å»ºã€‚è¿™æ˜¯å› ä¸ºé»˜è®¤æƒ…å†µä¸‹ï¼ŒDeepSpeedçš„<code>state_dict</code>åŒ…å«ä¸€ä¸ªå ä½ç¬¦è€Œä¸æ˜¯å®é™…çš„æƒé‡ã€‚å¦‚æœæˆ‘ä»¬ä¿å­˜è¿™ä¸ª<code>state_dict</code>ï¼Œå°±æ— æ³•å†åŠ è½½å®ƒäº†ã€‚</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;zero_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;stage3_gather_16bit_weights_on_model_save&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p><strong>FP32æƒé‡ï¼š</strong></p>
<p>è™½ç„¶fp16æƒé‡é€‚åˆæ¢å¤è®­ç»ƒï¼Œä½†å¦‚æœæ‚¨å®Œæˆäº†æ¨¡å‹çš„å¾®è°ƒå¹¶å¸Œæœ›å°†å…¶ä¸Šä¼ åˆ°<a href="https://huggingface.co/models">models hub</a>æˆ–ä¼ é€’ç»™å…¶ä»–äººï¼Œæ‚¨å¾ˆå¯èƒ½æƒ³è¦è·å–fp32æƒé‡ã€‚è¿™æœ€å¥½ä¸è¦åœ¨è®­ç»ƒæœŸé—´å®Œæˆï¼Œå› ä¸ºè¿™éœ€è¦å¤§é‡å†…å­˜ï¼Œå› æ­¤æœ€å¥½åœ¨è®­ç»ƒå®Œæˆåç¦»çº¿è¿›è¡Œã€‚ä½†æ˜¯ï¼Œå¦‚æœéœ€è¦å¹¶ä¸”æœ‰å……è¶³çš„ç©ºé—²CPUå†…å­˜ï¼Œå¯ä»¥åœ¨ç›¸åŒçš„è®­ç»ƒè„šæœ¬ä¸­å®Œæˆã€‚ä»¥ä¸‹éƒ¨åˆ†å°†è®¨è®ºè¿™ä¸¤ç§æ–¹æ³•ã€‚</p>
<p><strong>å®æ—¶FP32æƒé‡æ¢å¤ï¼š</strong></p>
<p>å¦‚æœæ‚¨çš„æ¨¡å‹å¾ˆå¤§ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒç»“æŸæ—¶å‡ ä¹æ²¡æœ‰å‰©ä½™çš„ç©ºé—²CPUå†…å­˜ï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¸èµ·ä½œç”¨ã€‚</p>
<p>å¦‚æœæ‚¨è‡³å°‘ä¿å­˜äº†ä¸€ä¸ªæ£€æŸ¥ç‚¹ï¼Œå¹¶ä¸”æƒ³è¦ä½¿ç”¨æœ€æ–°çš„ä¸€ä¸ªï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">transformers.trainer_utils</span> <span class="kn">import</span> <span class="n">get_last_checkpoint</span>
<span class="kn">from</span> <span class="nn">deepspeed.utils.zero_to_fp32</span> <span class="kn">import</span> <span class="n">load_state_dict_from_zero_checkpoint</span>

<span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">get_last_checkpoint</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">)</span>
<span class="n">fp32_model</span> <span class="o">=</span> <span class="n">load_state_dict_from_zero_checkpoint</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="p">)</span>
</code></pre></div>
<p>å¦‚æœæ‚¨åœ¨ä½¿ç”¨<code>--load_best_model_at_end</code>ç±»ï¼š<em>~transformers.TrainingArguments</em>å‚æ•°ï¼ˆç”¨äºè·Ÿè¸ªæœ€ä½³
æ£€æŸ¥ç‚¹ï¼‰ï¼Œé‚£ä¹ˆä½ å¯ä»¥é¦–å…ˆæ˜¾å¼åœ°ä¿å­˜æœ€ç»ˆæ¨¡å‹ï¼Œç„¶åå†æ‰§è¡Œç›¸åŒçš„æ“ä½œï¼š</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">deepspeed.utils.zero_to_fp32</span> <span class="kn">import</span> <span class="n">load_state_dict_from_zero_checkpoint</span>

<span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;checkpoint-final&quot;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">deepspeed</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>
<span class="n">fp32_model</span> <span class="o">=</span> <span class="n">load_state_dict_from_zero_checkpoint</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="p">)</span>
</code></pre></div>
<p><Tip></p>
<p>æ³¨æ„ï¼Œä¸€æ—¦è¿è¡Œäº†<code>load_state_dict_from_zero_checkpoint</code>ï¼Œè¯¥æ¨¡å‹å°†ä¸å†å¯ä»¥åœ¨ç›¸åŒçš„åº”ç”¨ç¨‹åºçš„DeepSpeedä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ‚¨éœ€è¦é‡æ–°åˆå§‹åŒ–deepspeedå¼•æ“ï¼Œå› ä¸º<code>model.load_state_dict(state_dict)</code>ä¼šä»å…¶ä¸­ç§»é™¤æ‰€æœ‰çš„DeepSpeedç›¸å…³ç‚¹ã€‚æ‰€ä»¥æ‚¨åªèƒ½è®­ç»ƒç»“æŸæ—¶è¿™æ ·åšã€‚</p>
<p></Tip></p>
<p>å½“ç„¶ï¼Œæ‚¨ä¸å¿…ä½¿ç”¨ç±»ï¼š<em>~transformers.Trainer</em>ï¼Œæ‚¨å¯ä»¥æ ¹æ®ä½ çš„éœ€æ±‚è°ƒæ•´ä¸Šé¢çš„ç¤ºä¾‹ã€‚</p>
<p>å¦‚æœæ‚¨å‡ºäºæŸç§åŸå› æƒ³è¦æ›´å¤šçš„ä¼˜åŒ–ï¼Œæ‚¨ä¹Ÿå¯ä»¥æå–æƒé‡çš„fp32 <code>state_dict</code>å¹¶æŒ‰ç…§ä»¥ä¸‹ç¤ºä¾‹è¿›è¡Œæ“ä½œï¼š</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">deepspeed.utils.zero_to_fp32</span> <span class="kn">import</span> <span class="n">get_fp32_state_dict_from_zero_checkpoint</span>

<span class="n">state_dict</span> <span class="o">=</span> <span class="n">get_fp32_state_dict_from_zero_checkpoint</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">)</span>  <span class="c1"># already on cpu</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
</code></pre></div>
<p><strong>ç¦»çº¿FP32æƒé‡æ¢å¤ï¼š</strong></p>
<p>DeepSpeedä¼šåˆ›å»ºä¸€ä¸ªç‰¹æ®Šçš„è½¬æ¢è„šæœ¬<code>zero_to_fp32.py</code>ï¼Œå¹¶å°†å…¶æ”¾ç½®åœ¨checkpointæ–‡ä»¶å¤¹çš„é¡¶å±‚ã€‚ä½¿ç”¨æ­¤è„šæœ¬ï¼Œæ‚¨å¯ä»¥åœ¨ä»»ä½•æ—¶å€™æå–æƒé‡ã€‚è¯¥è„šæœ¬æ˜¯ç‹¬ç«‹çš„ï¼Œæ‚¨ä¸å†éœ€è¦é…ç½®æ–‡ä»¶æˆ–<code>Trainer</code>æ¥æ‰§è¡Œæå–æ“ä½œã€‚</p>
<p>å‡è®¾æ‚¨çš„checkpointæ–‡ä»¶å¤¹å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<div class="highlight"><pre><span></span><code>$<span class="w"> </span>ls<span class="w"> </span>-l<span class="w"> </span>output_dir/checkpoint-1/
-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">1</span>.4K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>config.json
drwxrwxr-x<span class="w"> </span><span class="m">2</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">4</span>.0K<span class="w"> </span>Mar<span class="w"> </span><span class="m">25</span><span class="w"> </span><span class="m">19</span>:52<span class="w"> </span>global_step1/
-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w">   </span><span class="m">12</span><span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">13</span>:16<span class="w"> </span>latest
-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span>827K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>optimizer.pt
-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span>231M<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>pytorch_model.bin
-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w">  </span><span class="m">623</span><span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>scheduler.pt
-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">1</span>.8K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>special_tokens_map.json
-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span>774K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>spiece.model
-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">1</span>.9K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>tokenizer_config.json
-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w">  </span><span class="m">339</span><span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>trainer_state.json
-rw-rw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">2</span>.3K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">20</span>:42<span class="w"> </span>training_args.bin
-rwxrw-r--<span class="w"> </span><span class="m">1</span><span class="w"> </span>stas<span class="w"> </span>stas<span class="w"> </span><span class="m">5</span>.5K<span class="w"> </span>Mar<span class="w"> </span><span class="m">27</span><span class="w"> </span><span class="m">13</span>:16<span class="w"> </span>zero_to_fp32.py*
</code></pre></div>
<p>åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œåªæœ‰ä¸€ä¸ªDeepSpeedæ£€æŸ¥ç‚¹å­æ–‡ä»¶å¤¹<em>global_step1</em>ã€‚å› æ­¤ï¼Œè¦é‡æ„fp32æƒé‡ï¼Œåªéœ€è¿è¡Œï¼š</p>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>zero_to_fp32.py<span class="w"> </span>.<span class="w"> </span>pytorch_model.bin
</code></pre></div>
<p>è¿™å°±æ˜¯å®ƒã€‚<code>pytorch_model.bin</code>ç°åœ¨å°†åŒ…å«ä»å¤šä¸ªGPUsåˆå¹¶çš„å®Œæ•´çš„fp32æ¨¡å‹æƒé‡ã€‚</p>
<p>è¯¥è„šæœ¬å°†è‡ªåŠ¨èƒ½å¤Ÿå¤„ç†ZeRO-2æˆ–ZeRO-3 checkpointã€‚</p>
<p><code>python zero_to_fp32.py -h</code>å°†ä¸ºæ‚¨æä¾›ä½¿ç”¨ç»†èŠ‚ã€‚</p>
<p>è¯¥è„šæœ¬å°†é€šè¿‡æ–‡ä»¶<code>latest</code>çš„å†…å®¹è‡ªåŠ¨å‘ç°deepspeedå­æ–‡ä»¶å¤¹ï¼Œåœ¨å½“å‰ç¤ºä¾‹ä¸­ï¼Œå®ƒå°†åŒ…å«<code>global_step1</code>ã€‚</p>
<p>æ³¨æ„ï¼šç›®å‰è¯¥è„šæœ¬éœ€è¦2å€äºæœ€ç»ˆfp32æ¨¡å‹æƒé‡çš„é€šç”¨å†…å­˜ã€‚</p>
<h3 id="zero-3-infinity-nuances">ZeRO-3 å’Œ Infinity Nuances<a class="headerlink" href="#zero-3-infinity-nuances" title="Permanent link">âš“ï¸</a></h3>
<p>ZeRO-3ä¸ZeRO-2æœ‰å¾ˆå¤§çš„ä¸åŒï¼Œä¸»è¦æ˜¯å› ä¸ºå®ƒçš„å‚æ•°åˆ†ç‰‡åŠŸèƒ½ã€‚</p>
<p>ZeRO-Infinityè¿›ä¸€æ­¥æ‰©å±•äº†ZeRO-3ï¼Œä»¥æ”¯æŒNVMeå†…å­˜å’Œå…¶ä»–é€Ÿåº¦å’Œå¯æ‰©å±•æ€§æ”¹è¿›ã€‚</p>
<p>å°½ç®¡æ‰€æœ‰åŠªåŠ›éƒ½æ˜¯ä¸ºäº†åœ¨ä¸éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œä»»ä½•ç‰¹æ®Šæ›´æ”¹çš„æƒ…å†µä¸‹å°±èƒ½æ­£å¸¸è¿è¡Œï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½éœ€è¦ä»¥ä¸‹ä¿¡æ¯ã€‚</p>
<h4 id="_8">æ„å»ºå¤§æ¨¡å‹<a class="headerlink" href="#_8" title="Permanent link">âš“ï¸</a></h4>
<p>DeepSpeed/ZeRO-3å¯ä»¥å¤„ç†å‚æ•°é‡è¾¾åˆ°æ•°ä¸‡äº¿çš„æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å¯èƒ½æ— æ³•é€‚åº”ç°æœ‰çš„å†…å­˜ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœæ‚¨è¿˜æ˜¯å¸Œæœ›åˆå§‹åŒ–æ›´å¿«åœ°å‘ç”Ÿï¼Œå¯ä»¥ä½¿ç”¨<em>deepspeed.zero.Init()</em>ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆä¹Ÿæ˜¯ä¸€ä¸ªå‡½æ•°è£…é¥°å™¨ï¼‰æ¥åˆå§‹åŒ–æ¨¡å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">T5ForConditionalGeneration</span><span class="p">,</span> <span class="n">T5Config</span>
<span class="kn">import</span> <span class="nn">deepspeed</span>

<span class="k">with</span> <span class="n">deepspeed</span><span class="o">.</span><span class="n">zero</span><span class="o">.</span><span class="n">Init</span><span class="p">():</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">T5Config</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-small&quot;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">T5ForConditionalGeneration</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</code></pre></div>
<p>å¦‚æ‚¨æ‰€è§ï¼Œè¿™ä¼šä¸ºæ‚¨éšæœºåˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹ã€‚</p>
<p>å¦‚æœæ‚¨æƒ³ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œ<code>model_class.from_pretrained</code>å°†åœ¨<code>is_deepspeed_zero3_enabled()</code>è¿”å›<code>True</code>çš„æƒ…å†µä¸‹æ¿€æ´»æ­¤åŠŸèƒ½ï¼Œç›®å‰è¿™æ˜¯é€šè¿‡ä¼ é€’çš„DeepSpeedé…ç½®æ–‡ä»¶ä¸­çš„ZeRO-3é…ç½®éƒ¨åˆ†è®¾ç½®çš„ã€‚å› æ­¤ï¼Œåœ¨è°ƒç”¨<code>from_pretrained</code>ä¹‹å‰ï¼Œæ‚¨å¿…é¡»åˆ›å»º<strong>TrainingArguments</strong>å¯¹è±¡ã€‚ä»¥ä¸‹æ˜¯å¯èƒ½çš„é¡ºåºç¤ºä¾‹ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">deepspeed</span><span class="o">=</span><span class="n">ds_config</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-small&quot;</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</code></pre></div>
<p>å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯å®˜æ–¹ç¤ºä¾‹è„šæœ¬ï¼Œå¹¶ä¸”å‘½ä»¤è¡Œå‚æ•°ä¸­åŒ…å«<code>--deepspeed ds_config.json</code>ä¸”å¯ç”¨äº†ZeRO-3é…ç½®ï¼Œé‚£ä¹ˆä¸€åˆ‡éƒ½å·²ç»ä¸ºæ‚¨å‡†å¤‡å¥½äº†ï¼Œå› ä¸ºè¿™æ˜¯ç¤ºä¾‹è„šæœ¬çš„ç¼–å†™æ–¹å¼ã€‚</p>
<p>æ³¨æ„ï¼šå¦‚æœæ¨¡å‹çš„fp16æƒé‡æ— æ³•é€‚åº”å•ä¸ªGPUçš„å†…å­˜ï¼Œåˆ™å¿…é¡»ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚</p>
<p>æœ‰å…³æ­¤æ–¹æ³•å’Œå…¶ä»–ç›¸å…³åŠŸèƒ½çš„å®Œæ•´è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…<a href="https://deepspeed.readthedocs.io/en/latest/zero3.html#constructing-massive-models">æ„å»ºå¤§æ¨¡å‹</a>ã€‚</p>
<p>æ­¤å¤–ï¼Œåœ¨åŠ è½½fp16é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæ‚¨å¸Œæœ›<code>from_pretrained</code>ä½¿ç”¨<code>torch_dtype=torch.float16</code>ã€‚è¯¦æƒ…è¯·å‚è§<a href="#from_pretrained-torch-dtype">from_pretrained-torch-dtype</a>ã€‚</p>
<h4 id="_9">å‚æ•°æ”¶é›†<a class="headerlink" href="#_9" title="Permanent link">âš“ï¸</a></h4>
<p>åœ¨å¤šä¸ªGPUä¸Šä½¿ç”¨ZeRO-3æ—¶ï¼Œæ²¡æœ‰ä¸€ä¸ªGPUæ‹¥æœ‰æ‰€æœ‰å‚æ•°ï¼Œé™¤éå®ƒæ˜¯å½“å‰æ‰§è¡Œå±‚çš„å‚æ•°ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨éœ€è¦ä¸€æ¬¡è®¿é—®æ‰€æœ‰å±‚çš„æ‰€æœ‰å‚æ•°ï¼Œæœ‰ä¸€ä¸ªç‰¹å®šçš„æ–¹æ³•å¯ä»¥å®ç°ã€‚
æ‚¨å¯èƒ½ä¸éœ€è¦å®ƒï¼Œä½†å¦‚æœæ‚¨éœ€è¦ï¼Œè¯·å‚è€ƒ<a href="https://deepspeed.readthedocs.io/en/latest/zero3.html#manual-parameter-coordination">å‚æ•°æ”¶é›†</a>ã€‚</p>
<p>ç„¶è€Œï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªåœ°æ–¹ç¡®å®ä½¿ç”¨äº†å®ƒï¼Œå…¶ä¸­ä¸€ä¸ªä¾‹å­æ˜¯åœ¨<code>from_pretrained</code>ä¸­åŠ è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡ã€‚æˆ‘ä»¬ä¸€æ¬¡åŠ è½½ä¸€å±‚ï¼Œç„¶åç«‹å³å°†å…¶åˆ†åŒºåˆ°æ‰€æœ‰å‚ä¸çš„GPUä¸Šï¼Œå› ä¸ºå¯¹äºéå¸¸å¤§çš„æ¨¡å‹ï¼Œæ— æ³•åœ¨ä¸€ä¸ªGPUä¸Šä¸€æ¬¡æ€§åŠ è½½å¹¶å°†å…¶åˆ†å¸ƒåˆ°å¤šä¸ªGPUä¸Šï¼Œå› ä¸ºå†…å­˜é™åˆ¶ã€‚</p>
<p>æ­¤å¤–ï¼Œåœ¨ZeRO-3ä¸‹ï¼Œå¦‚æœæ‚¨ç¼–å†™è‡ªå·±çš„ä»£ç å¹¶é‡åˆ°çœ‹èµ·æ¥åƒè¿™æ ·çš„æ¨¡å‹å‚æ•°æƒé‡ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<p>å¼ºè°ƒ<code>tensor([1.])</code>ï¼Œæˆ–è€…å¦‚æœæ‚¨é‡åˆ°ä¸€ä¸ªé”™è¯¯ï¼Œå®ƒè¯´å‚æ•°çš„å¤§å°æ˜¯<code>1</code>ï¼Œè€Œä¸æ˜¯æŸä¸ªæ›´å¤§çš„å¤šç»´å½¢çŠ¶ï¼Œè¿™æ„å‘³ç€å‚æ•°è¢«åˆ’åˆ†äº†ï¼Œä½ çœ‹åˆ°çš„æ˜¯ä¸€ä¸ªZeRO-3å ä½ç¬¦ã€‚</p>
<p><a id='deepspeed-zero-inference'></a></p>
<h3 id="zero_1">ZeRO æ¨ç†<a class="headerlink" href="#zero_1" title="Permanent link">âš“ï¸</a></h3>
<p>"ZeRO æ¨æ–­" ä½¿ç”¨ä¸ "ZeRO-3 è®­ç»ƒ" ç›¸åŒçš„é…ç½®ã€‚æ‚¨åªéœ€è¦å»æ‰ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨éƒ¨åˆ†ã€‚å®é™…ä¸Šï¼Œå¦‚æœæ‚¨å¸Œæœ›ä¸è®­ç»ƒå…±äº«ç›¸åŒçš„é…ç½®æ–‡ä»¶ï¼Œæ‚¨å¯ä»¥å°†å®ƒä»¬ä¿ç•™åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼Œå®ƒä»¬åªä¼šè¢«å¿½ç•¥ã€‚</p>
<p>æ‚¨åªéœ€è¦ä¼ é€’é€šå¸¸çš„[<code>TrainingArguments</code>]å‚æ•°ã€‚ä¾‹å¦‚ï¼š</p>
<div class="highlight"><pre><span></span><code>deepspeed<span class="w"> </span>--num_gpus<span class="o">=</span><span class="m">2</span><span class="w"> </span>your_program.py<span class="w"> </span>&lt;normal<span class="w"> </span>cl<span class="w"> </span>args&gt;<span class="w"> </span>--do_eval<span class="w"> </span>--deepspeed<span class="w"> </span>ds_config.json
</code></pre></div>
<p>å”¯ä¸€çš„é‡è¦äº‹æƒ…æ˜¯æ‚¨éœ€è¦ä½¿ç”¨ZeRO-3é…ç½®ï¼Œå› ä¸ºZeRO-2å¯¹äºæ¨ç†æ²¡æœ‰ä»»ä½•ä¼˜åŠ¿ï¼Œå› ä¸ºåªæœ‰ZeRO-3æ‰å¯¹å‚æ•°è¿›è¡Œåˆ†ç‰‡ï¼Œè€ŒZeRO-1åˆ™å¯¹æ¢¯åº¦å’Œä¼˜åŒ–å™¨çŠ¶æ€è¿›è¡Œåˆ†ç‰‡ã€‚</p>
<p>ä»¥ä¸‹æ˜¯åœ¨DeepSpeedä¸‹è¿è¡Œ<code>run_translation.py</code>å¯ç”¨æ‰€æœ‰å¯ç”¨GPUçš„ç¤ºä¾‹ï¼š</p>
<div class="highlight"><pre><span></span><code>deepspeed<span class="w"> </span>examples/pytorch/translation/run_translation.py<span class="w"> </span><span class="se">\</span>
--deepspeed<span class="w"> </span>tests/deepspeed/ds_config_zero3.json<span class="w"> </span><span class="se">\</span>
--model_name_or_path<span class="w"> </span>t5-small<span class="w"> </span>--output_dir<span class="w"> </span>output_dir<span class="w"> </span><span class="se">\</span>
--do_eval<span class="w"> </span>--max_eval_samples<span class="w"> </span><span class="m">50</span><span class="w"> </span>--warmup_steps<span class="w"> </span><span class="m">50</span><span class="w">  </span><span class="se">\</span>
--max_source_length<span class="w"> </span><span class="m">128</span><span class="w"> </span>--val_max_target_length<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
--overwrite_output_dir<span class="w"> </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
--predict_with_generate<span class="w"> </span>--dataset_config<span class="w"> </span><span class="s2">&quot;ro-en&quot;</span><span class="w"> </span>--fp16<span class="w"> </span><span class="se">\</span>
--source_lang<span class="w"> </span>en<span class="w"> </span>--target_lang<span class="w"> </span>ro<span class="w"> </span>--dataset_name<span class="w"> </span>wmt16<span class="w"> </span><span class="se">\</span>
--source_prefix<span class="w"> </span><span class="s2">&quot;translate English to Romanian: &quot;</span>
</code></pre></div>
<p>ç”±äºåœ¨æ¨ç†é˜¶æ®µï¼Œä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦ä¸éœ€è¦é¢å¤–çš„å¤§é‡å†…å­˜ï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿå°†æ›´å¤§çš„æ‰¹æ¬¡å’Œ/æˆ–åºåˆ—é•¿åº¦æ”¾åˆ°ç›¸åŒçš„ç¡¬ä»¶ä¸Šã€‚</p>
<p>æ­¤å¤–ï¼ŒDeepSpeedç›®å‰æ­£åœ¨å¼€å‘ä¸€ä¸ªåä¸ºDeepspeed-Inferenceçš„ç›¸å…³äº§å“ï¼Œå®ƒä¸ZeROæŠ€æœ¯æ— å…³ï¼Œè€Œæ˜¯ä½¿ç”¨å¼ é‡å¹¶è¡Œæ¥æ‰©å±•æ— æ³•é€‚åº”å•ä¸ªGPUçš„æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªæ­£åœ¨è¿›è¡Œçš„å·¥ä½œï¼Œä¸€æ—¦è¯¥äº§å“å®Œæˆï¼Œæˆ‘ä»¬å°†æä¾›é›†æˆã€‚</p>
<h3 id="_10">å†…å­˜è¦æ±‚<a class="headerlink" href="#_10" title="Permanent link">âš“ï¸</a></h3>
<p>ç”±äº DeepSpeed ZeRO å¯ä»¥å°†å†…å­˜å¸è½½åˆ° CPUï¼ˆå’Œ NVMeï¼‰ï¼Œè¯¥æ¡†æ¶æä¾›äº†ä¸€äº›å·¥å…·ï¼Œå…è®¸æ ¹æ®ä½¿ç”¨çš„ GPU æ•°é‡å‘ŠçŸ¥å°†éœ€è¦å¤šå°‘ CPU å’Œ GPU å†…å­˜ã€‚</p>
<p>è®©æˆ‘ä»¬ä¼°è®¡åœ¨å•ä¸ªGPUä¸Šå¾®è°ƒ"bigscience/T0_3B"æ‰€éœ€çš„å†…å­˜ï¼š</p>
<div class="highlight"><pre><span></span><code>$<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;from transformers import AutoModel; \</span>
<span class="s1">from deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \</span>
<span class="s1">model = AutoModel.from_pretrained(&quot;bigscience/T0_3B&quot;); \</span>
<span class="s1">estimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=1, num_nodes=1)&#39;</span>
<span class="o">[</span>...<span class="o">]</span>
Estimated<span class="w"> </span>memory<span class="w"> </span>needed<span class="w"> </span><span class="k">for</span><span class="w"> </span>params,<span class="w"> </span>optim<span class="w"> </span>states<span class="w"> </span>and<span class="w"> </span>gradients<span class="w"> </span><span class="k">for</span><span class="w"> </span>a:
HW:<span class="w"> </span>Setup<span class="w"> </span>with<span class="w"> </span><span class="m">1</span><span class="w"> </span>node,<span class="w"> </span><span class="m">1</span><span class="w"> </span>GPU<span class="w"> </span>per<span class="w"> </span>node.
SW:<span class="w"> </span>Model<span class="w"> </span>with<span class="w"> </span>2783M<span class="w"> </span>total<span class="w"> </span>params,<span class="w"> </span>65M<span class="w"> </span>largest<span class="w"> </span>layer<span class="w"> </span>params.
<span class="w">  </span>per<span class="w"> </span>CPU<span class="w">  </span><span class="p">|</span><span class="w">  </span>per<span class="w"> </span>GPU<span class="w"> </span><span class="p">|</span><span class="w">   </span>Options
<span class="w">   </span><span class="m">70</span>.00GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">0</span>.25GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">1</span>
<span class="w">   </span><span class="m">70</span>.00GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">0</span>.25GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">0</span>
<span class="w">   </span><span class="m">62</span>.23GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">5</span>.43GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">1</span>
<span class="w">   </span><span class="m">62</span>.23GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">5</span>.43GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">0</span>
<span class="w">    </span><span class="m">0</span>.37GB<span class="w"> </span><span class="p">|</span><span class="w">  </span><span class="m">46</span>.91GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">1</span>
<span class="w">   </span><span class="m">15</span>.56GB<span class="w"> </span><span class="p">|</span><span class="w">  </span><span class="m">46</span>.91GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">0</span>
</code></pre></div>
<p>å› æ­¤ï¼Œæ‚¨å¯ä»¥å°†æ¨¡å‹æ‹Ÿåˆåœ¨å•ä¸ª80GBçš„GPUä¸Šï¼Œä¸è¿›è¡ŒCPU offloadï¼Œæˆ–è€…ä½¿ç”¨å¾®å°çš„8GB GPUï¼Œä½†éœ€è¦çº¦60GBçš„CPUå†…å­˜ã€‚ï¼ˆè¯·æ³¨æ„ï¼Œè¿™ä»…æ˜¯å‚æ•°ã€ä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦æ‰€éœ€çš„å†…å­˜ - æ‚¨è¿˜éœ€è¦ä¸ºCUDAå†…æ ¸ã€æ¿€æ´»å€¼å’Œä¸´æ—¶å˜é‡åˆ†é…æ›´å¤šçš„å†…å­˜ã€‚ï¼‰</p>
<p>ç„¶åï¼Œè¿™æ˜¯æˆæœ¬ä¸é€Ÿåº¦çš„æƒè¡¡ã€‚è´­ä¹°/ç§Ÿç”¨è¾ƒå°çš„ GPUï¼ˆæˆ–è¾ƒå°‘çš„ GPUï¼Œå› ä¸ºæ‚¨å¯ä»¥ä½¿ç”¨å¤šä¸ª GPU è¿›è¡Œ Deepspeed ZeROï¼‰ã€‚ä½†è¿™æ ·ä¼šæ›´æ…¢ï¼Œå› æ­¤å³ä½¿æ‚¨ä¸å…³å¿ƒå®ŒæˆæŸé¡¹ä»»åŠ¡çš„é€Ÿåº¦ï¼Œå‡é€Ÿä¹Ÿç›´æ¥å½±å“ GPU ä½¿ç”¨çš„æŒç»­æ—¶é—´ï¼Œä»è€Œå¯¼è‡´æ›´å¤§çš„æˆæœ¬ã€‚å› æ­¤ï¼Œè¯·è¿›è¡Œå®éªŒå¹¶æ¯”è¾ƒå“ªç§æ–¹æ³•æ•ˆæœæœ€å¥½ã€‚</p>
<p>å¦‚æœæ‚¨æœ‰è¶³å¤Ÿçš„GPUå†…å­˜ï¼Œè¯·ç¡®ä¿ç¦ç”¨CPU/NVMeå¸è½½ï¼Œå› ä¸ºè¿™ä¼šä½¿æ‰€æœ‰æ“ä½œæ›´å¿«ã€‚</p>
<p>ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬é‡å¤ç›¸åŒçš„æ“ä½œï¼Œä½¿ç”¨2ä¸ªGPUï¼š</p>
<div class="highlight"><pre><span></span><code>$<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;from transformers import AutoModel; \</span>
<span class="s1">from deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \</span>
<span class="s1">model = AutoModel.from_pretrained(&quot;bigscience/T0_3B&quot;); \</span>
<span class="s1">estimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=2, num_nodes=1)&#39;</span>
<span class="o">[</span>...<span class="o">]</span>
Estimated<span class="w"> </span>memory<span class="w"> </span>needed<span class="w"> </span><span class="k">for</span><span class="w"> </span>params,<span class="w"> </span>optim<span class="w"> </span>states<span class="w"> </span>and<span class="w"> </span>gradients<span class="w"> </span><span class="k">for</span><span class="w"> </span>a:
HW:<span class="w"> </span>Setup<span class="w"> </span>with<span class="w"> </span><span class="m">1</span><span class="w"> </span>node,<span class="w"> </span><span class="m">2</span><span class="w"> </span>GPUs<span class="w"> </span>per<span class="w"> </span>node.
SW:<span class="w"> </span>Model<span class="w"> </span>with<span class="w"> </span>2783M<span class="w"> </span>total<span class="w"> </span>params,<span class="w"> </span>65M<span class="w"> </span>largest<span class="w"> </span>layer<span class="w"> </span>params.
<span class="w">  </span>per<span class="w"> </span>CPU<span class="w">  </span><span class="p">|</span><span class="w">  </span>per<span class="w"> </span>GPU<span class="w"> </span><span class="p">|</span><span class="w">   </span>Options
<span class="w">   </span><span class="m">70</span>.00GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">0</span>.25GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">1</span>
<span class="w">   </span><span class="m">70</span>.00GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">0</span>.25GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">0</span>
<span class="w">   </span><span class="m">62</span>.23GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">2</span>.84GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">1</span>
<span class="w">   </span><span class="m">62</span>.23GB<span class="w"> </span><span class="p">|</span><span class="w">   </span><span class="m">2</span>.84GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>cpu<span class="w"> </span>,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">0</span>
<span class="w">    </span><span class="m">0</span>.74GB<span class="w"> </span><span class="p">|</span><span class="w">  </span><span class="m">23</span>.58GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">1</span>
<span class="w">   </span><span class="m">31</span>.11GB<span class="w"> </span><span class="p">|</span><span class="w">  </span><span class="m">23</span>.58GB<span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nv">offload_param</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">offload_optimizer</span><span class="o">=</span>none,<span class="w"> </span><span class="nv">zero_init</span><span class="o">=</span><span class="m">0</span>
</code></pre></div>
<p>æ‰€ä»¥ï¼Œæ‚¨éœ€è¦2ä¸ª32GBæˆ–æ›´é«˜çš„GPUï¼Œä¸”ä¸è¿›è¡ŒCPUå¸è½½ã€‚</p>
<p>å¦‚éœ€äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…<a href="https://deepspeed.readthedocs.io/en/latest/memory.html">å†…å­˜ä¼°ç®—å™¨</a>ã€‚</p>
<h3 id="issues">å½’æ¡£Issues<a class="headerlink" href="#issues" title="Permanent link">âš“ï¸</a></h3>
<p>è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æäº¤é—®é¢˜ï¼Œä»¥ä¾¿æˆ‘ä»¬èƒ½å¤Ÿè¿…é€Ÿæ‰¾åˆ°é—®é¢˜å¹¶å¸®åŠ©æ‚¨è§£é™¤å·¥ä½œé˜»å¡ã€‚</p>
<p>åœ¨æ‚¨çš„æŠ¥å‘Šä¸­ï¼Œè¯·å§‹ç»ˆåŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š</p>
<ol>
<li>å®Œæ•´çš„Deepspeedé…ç½®æ–‡ä»¶</li>
<li>å¦‚æœä½¿ç”¨äº†[<code>Trainer</code>]ï¼Œåˆ™åŒ…æ‹¬å‘½ä»¤è¡Œå‚æ•°ï¼›å¦‚æœè‡ªå·±ç¼–å†™äº†Trainerè®¾ç½®ï¼Œåˆ™åŒ…æ‹¬[<code>TrainingArguments</code>]å‚æ•°ã€‚è¯·ä¸è¦å¯¼å‡º[<code>TrainingArguments</code>]ï¼Œå› ä¸ºå®ƒæœ‰å‡ åä¸ªä¸é—®é¢˜æ— å…³çš„æ¡ç›®ã€‚</li>
<li>
<p>è¾“å‡ºï¼š</p>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import torch; print(f&quot;torch: {torch.__version__}&quot;)&#39;</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import transformers; print(f&quot;transformers: {transformers.__version__}&quot;)&#39;</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import deepspeed; print(f&quot;deepspeed: {deepspeed.__version__}&quot;)&#39;</span>
</code></pre></div>
</li>
<li>
<p>å¦‚æœå¯èƒ½ï¼Œè¯·åŒ…å«ä¸€ä¸ªGoogle Colab notebooké“¾æ¥ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒæ¥é‡ç°é—®é¢˜ã€‚æ‚¨å¯ä»¥ä½¿ç”¨è¿™ä¸ª<a href="https://github.com/stas00/porting/blob/master/transformers/deepspeed/DeepSpeed_on_colab_CLI.ipynb">notebook</a>ä½œä¸ºèµ·ç‚¹ã€‚</p>
</li>
<li>é™¤éä¸å¯èƒ½ï¼Œå¦åˆ™è¯·å§‹ç»ˆä½¿ç”¨æ ‡å‡†æ•°æ®é›†ï¼Œè€Œä¸æ˜¯è‡ªå®šä¹‰æ•°æ®é›†ã€‚</li>
<li>å¦‚æœå¯èƒ½ï¼Œå°è¯•ä½¿ç”¨ç°æœ‰<a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch">ç¤ºä¾‹</a>ä¹‹ä¸€æ¥é‡ç°é—®é¢˜ã€‚</li>
</ol>
<p>éœ€è¦è€ƒè™‘çš„å› ç´ ï¼š</p>
<ul>
<li>Deepspeedé€šå¸¸ä¸æ˜¯é—®é¢˜çš„åŸå› ã€‚</li>
</ul>
<p>ä¸€äº›å·²æäº¤çš„é—®é¢˜è¢«è¯æ˜ä¸Deepspeedæ— å…³ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€æ—¦å°†Deepspeedä»è®¾ç½®ä¸­ç§»é™¤ï¼Œé—®é¢˜ä»ç„¶å­˜åœ¨ã€‚</p>
<p>å› æ­¤ï¼Œå¦‚æœé—®é¢˜æ˜æ˜¾ä¸DeepSpeedç›¸å…³ï¼Œä¾‹å¦‚æ‚¨å¯ä»¥çœ‹åˆ°æœ‰ä¸€ä¸ªå¼‚å¸¸å¹¶ä¸”å¯ä»¥çœ‹åˆ°DeepSpeedæ¨¡å—æ¶‰åŠå…¶ä¸­ï¼Œè¯·å…ˆé‡æ–°æµ‹è¯•æ²¡æœ‰DeepSpeedçš„è®¾ç½®ã€‚åªæœ‰å½“é—®é¢˜ä»ç„¶å­˜åœ¨æ—¶ï¼Œæ‰å‘Deepspeedæä¾›æ‰€æœ‰å¿…éœ€çš„ç»†èŠ‚ã€‚</p>
<ul>
<li>å¦‚æœæ‚¨æ˜ç¡®é—®é¢˜æ˜¯åœ¨Deepspeedæ ¸å¿ƒä¸­è€Œä¸æ˜¯é›†æˆéƒ¨åˆ†ï¼Œè¯·ç›´æ¥å‘<a href="https://github.com/microsoft/DeepSpeed/">Deepspeed</a>æäº¤é—®é¢˜ã€‚å¦‚æœæ‚¨ä¸ç¡®å®šï¼Œè¯·ä¸è¦æ‹…å¿ƒï¼Œæ— è®ºä½¿ç”¨å“ªä¸ªissueè·Ÿè¸ªé—®é¢˜éƒ½å¯ä»¥ï¼Œä¸€æ—¦æ‚¨å‘å¸ƒé—®é¢˜ï¼Œæˆ‘ä»¬ä¼šå¼„æ¸…æ¥šå¹¶å°†å…¶é‡å®šå‘åˆ°å¦ä¸€ä¸ªissueè·Ÿè¸ªï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰ã€‚</li>
</ul>
<h3 id="troubleshooting">Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permanent link">âš“ï¸</a></h3>
<h4 id="deepspeed_2">å¯åŠ¨æ—¶<code>deepspeed</code>è¿›ç¨‹è¢«ç»ˆæ­¢ï¼Œæ²¡æœ‰å›æº¯<a class="headerlink" href="#deepspeed_2" title="Permanent link">âš“ï¸</a></h4>
<p>å¦‚æœå¯åŠ¨æ—¶<code>deepspeed</code>è¿›ç¨‹è¢«ç»ˆæ­¢ï¼Œæ²¡æœ‰å›æº¯ï¼Œè¿™é€šå¸¸æ„å‘³ç€ç¨‹åºå°è¯•åˆ†é…çš„CPUå†…å­˜è¶…è¿‡äº†ç³»ç»Ÿçš„é™åˆ¶æˆ–è¿›ç¨‹è¢«å…è®¸åˆ†é…çš„å†…å­˜ï¼Œæ“ä½œç³»ç»Ÿå†…æ ¸æ€æ­»äº†è¯¥è¿›ç¨‹ã€‚è¿™æ˜¯å› ä¸ºæ‚¨çš„é…ç½®æ–‡ä»¶å¾ˆå¯èƒ½å°†<code>offload_optimizer</code>æˆ–<code>offload_param</code>æˆ–ä¸¤è€…éƒ½é…ç½®ä¸ºå¸è½½åˆ°<code>cpu</code>ã€‚å¦‚æœæ‚¨æœ‰NVMeï¼Œå¯ä»¥å°è¯•åœ¨ZeRO-3ä¸‹å¸è½½åˆ°NVMeã€‚è¿™é‡Œæ˜¯å¦‚ä½•<a href="https://deepspeed.readthedocs.io/en/latest/memory.html">ä¼°è®¡ç‰¹å®šæ¨¡å‹æ‰€éœ€çš„å†…å­˜</a>ã€‚</p>
<h4 id="lossnan">è®­ç»ƒå’Œ/æˆ–è¯„ä¼°/é¢„æµ‹lossä¸º<code>NaN</code><a class="headerlink" href="#lossnan" title="Permanent link">âš“ï¸</a></h4>
<p>è¿™ç§æƒ…å†µé€šå¸¸å‘ç”Ÿåœ¨ä½¿ç”¨bf16æ··åˆç²¾åº¦æ¨¡å¼é¢„è®­ç»ƒçš„æ¨¡å‹è¯•å›¾åœ¨fp16ï¼ˆå¸¦æˆ–ä¸å¸¦æ··åˆç²¾åº¦ï¼‰ä¸‹ä½¿ç”¨æ—¶ã€‚å¤§å¤šæ•°åœ¨TPUä¸Šè®­ç»ƒçš„æ¨¡å‹ä»¥åŠç”±è°·æ­Œå‘å¸ƒçš„æ¨¡å‹éƒ½å±äºè¿™ä¸ªç±»åˆ«ï¼ˆä¾‹å¦‚ï¼Œå‡ ä¹æ‰€æœ‰åŸºäºt5çš„æ¨¡å‹ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè§£å†³æ–¹æ¡ˆæ˜¯è¦ä¹ˆä½¿ç”¨fp32ï¼Œè¦ä¹ˆåœ¨æ”¯æŒçš„æƒ…å†µä¸‹ä½¿ç”¨bf16ï¼ˆå¦‚TPUã€Ampere GPUæˆ–æ›´æ–°çš„ç‰ˆæœ¬ï¼‰ã€‚</p>
<p>å¦ä¸€ä¸ªé—®é¢˜å¯èƒ½ä¸ä½¿ç”¨fp16æœ‰å…³ã€‚å½“æ‚¨é…ç½®æ­¤éƒ¨åˆ†æ—¶ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;fp16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;loss_scale_window&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;initial_scale_power&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;hysteresis&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;min_loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>å¹¶ä¸”æ‚¨åœ¨æ—¥å¿—ä¸­çœ‹åˆ°DeepspeedæŠ¥å‘Š<code>OVERFLOW</code>å¦‚ä¸‹</p>
<div class="highlight"><pre><span></span><code>0%|                                                                                                                             | 0/189 [00:00&lt;?, ?it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 262144
  1%|â–Œ                                                                                                                    | 1/189 [00:00&lt;01:26,  2.17it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072.0
  1%|â–ˆâ–
 [...]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                   | 27/189 [00:14&lt;01:13,  2.21it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                  | 28/189 [00:14&lt;01:13,  2.18it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                  | 29/189 [00:15&lt;01:13,  2.18it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
[...]
</code></pre></div>
<p>è¿™æ„å‘³ç€DeepspeedæŸå¤±ç¼©æ”¾å™¨æ— æ³•æ‰¾åˆ°ä¸€ä¸ªå…‹æœæŸå¤±æº¢å‡ºçš„ç¼©æ”¾ç³»æ•°ã€‚</p>
<p>åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé€šå¸¸éœ€è¦æé«˜<code>initial_scale_power</code>çš„å€¼ã€‚å°†å…¶è®¾ç½®ä¸º<code>"initial_scale_power": 32</code>é€šå¸¸ä¼šè§£å†³é—®é¢˜ã€‚</p>
<h3 id="_11">æ³¨æ„äº‹é¡¹<a class="headerlink" href="#_11" title="Permanent link">âš“ï¸</a></h3>
<ul>
<li>DeepSpeed ä¸ PyTorch [<code>Trainer</code>] ä¸€èµ·å·¥ä½œï¼Œä½†ä¸ä¸ TF [<code>TFTrainer</code>] ä¸€èµ·å·¥ä½œã€‚</li>
<li>å°½ç®¡ DeepSpeed æœ‰ä¸€ä¸ªå¯å®‰è£…çš„ PyPI åŒ…ï¼Œä½†å¼ºçƒˆå»ºè®®ä»æºä»£ç å®‰è£…å®ƒï¼Œä»¥æœ€å¥½åœ°åŒ¹é…æ‚¨çš„ç¡¬ä»¶ï¼Œå¦‚æœæ‚¨éœ€è¦å¯ç”¨æŸäº›åŠŸèƒ½ï¼Œå¦‚ 1-bit Adamï¼Œè¿™äº›åŠŸèƒ½åœ¨ pypi å‘è¡Œç‰ˆä¸­ä¸å¯ç”¨ã€‚</li>
<li>æ‚¨ä¸å¿…ä½¿ç”¨ğŸ¤—  Transformersçš„ [<code>Trainer</code>] æ¥ä½¿ç”¨ DeepSpeed   - æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•æ¨¡å‹ä¸è‡ªå·±çš„è®­ç»ƒå™¨ï¼Œæ‚¨è¿˜éœ€è¦æ ¹æ® <a href="https://www.deepspeed.ai/getting-started/#writing-deepspeed-models">DeepSpeed é›†æˆè¯´æ˜</a> è°ƒæ•´åè€…ã€‚</li>
</ul>
<h2 id="non-trainer-deepspeed">Non-Trainer Deepspeedé›†æˆ<a class="headerlink" href="#non-trainer-deepspeed" title="Permanent link">âš“ï¸</a></h2>
<p>å½“<code>Trainer</code>æ²¡æœ‰è¢«ä½¿ç”¨æ—¶ï¼Œ<code>~integrations.HfDeepSpeedConfig</code>è¢«ç”¨æ¥å°†Deepspeedé›†æˆåˆ°huggingfaceçš„Transformersæ ¸å¿ƒåŠŸèƒ½ä¸­ã€‚å®ƒå”¯ä¸€åšçš„äº‹æƒ…å°±æ˜¯åœ¨<code>from_pretrained</code>è°ƒç”¨æœŸé—´å¤„ç†Deepspeed ZeRO-3å‚æ•°æ”¶é›†å’Œå°†æ¨¡å‹è‡ªåŠ¨åˆ†å‰²åˆ°å¤šä¸ªGPUä¸Šã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæ‚¨éœ€è¦è‡ªå·±å®Œæˆå…¶ä»–æ‰€æœ‰å·¥ä½œã€‚</p>
<p>å½“ä½¿ç”¨<code>Trainer</code>æ—¶ï¼Œæ‰€æœ‰äº‹æƒ…éƒ½è‡ªåŠ¨å¾—åˆ°äº†å¤„ç†ã€‚</p>
<p>å½“ä¸ä½¿ç”¨<code>Trainer</code>æ—¶ï¼Œä¸ºäº†é«˜æ•ˆåœ°éƒ¨ç½²Deepspeed ZeRO-3ï¼Œæ‚¨å¿…é¡»åœ¨å®ä¾‹åŒ–æ¨¡å‹ä¹‹å‰å®ä¾‹åŒ–<code>~integrations.HfDeepSpeedConfig</code>å¯¹è±¡å¹¶ä¿æŒè¯¥å¯¹è±¡æ´»è·ƒã€‚</p>
<p>å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨Deepspeed ZeRO-1æˆ–ZeRO-2ï¼Œæ‚¨æ ¹æœ¬ä¸éœ€è¦ä½¿ç”¨<code>HfDeepSpeedConfig</code>ã€‚</p>
<p>ä»¥é¢„è®­ç»ƒæ¨¡å‹ä¸ºä¾‹:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">transformers.integrations</span> <span class="kn">import</span> <span class="n">HfDeepSpeedConfig</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>
<span class="kn">import</span> <span class="nn">deepspeed</span>

<span class="n">ds_config</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>  <span class="c1"># deepspeed config object or path to the file</span>
<span class="c1"># must run before instantiating the model to detect zero 3</span>
<span class="n">dschf</span> <span class="o">=</span> <span class="n">HfDeepSpeedConfig</span><span class="p">(</span><span class="n">ds_config</span><span class="p">)</span>  <span class="c1"># keep this object alive</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">deepspeed</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">config_params</span><span class="o">=</span><span class="n">ds_config</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</code></pre></div>
<p>æˆ–è€…ä»¥éé¢„è®­ç»ƒæ¨¡å‹ä¸ºä¾‹ï¼š</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">transformers.integrations</span> <span class="kn">import</span> <span class="n">HfDeepSpeedConfig</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span><span class="p">,</span> <span class="n">AutoConfig</span>
<span class="kn">import</span> <span class="nn">deepspeed</span>

<span class="n">ds_config</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>  <span class="c1"># deepspeed config object or path to the file</span>
<span class="c1"># must run before instantiating the model to detect zero 3</span>
<span class="n">dschf</span> <span class="o">=</span> <span class="n">HfDeepSpeedConfig</span><span class="p">(</span><span class="n">ds_config</span><span class="p">)</span>  <span class="c1"># keep this object alive</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">deepspeed</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">config_params</span><span class="o">=</span><span class="n">ds_config</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</code></pre></div>
<p>è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨æ²¡æœ‰ä½¿ç”¨[<code>Trainer</code>]é›†æˆï¼Œæ‚¨å®Œå…¨éœ€è¦è‡ªå·±åŠ¨æ‰‹ã€‚åŸºæœ¬ä¸Šéµå¾ª<a href="https://www.deepspeed.ai/">Deepspeed</a>ç½‘ç«™ä¸Šçš„æ–‡æ¡£ã€‚åŒæ—¶ï¼Œæ‚¨å¿…é¡»æ˜¾å¼é…ç½®é…ç½®æ–‡ä»¶ - ä¸èƒ½ä½¿ç”¨<code>"auto"</code>å€¼ï¼Œè€Œå¿…é¡»æ”¾å…¥å®é™…å€¼ã€‚</p>
<h2 id="hfdeepspeedconfig">HfDeepSpeedConfig<a class="headerlink" href="#hfdeepspeedconfig" title="Permanent link">âš“ï¸</a></h2>
<p>[[autodoc]] integrations.HfDeepSpeedConfig
    - all</p>
<h3 id="deepspeed-zero">è‡ªå®šä¹‰DeepSpeed ZeROæ¨ç†<a class="headerlink" href="#deepspeed-zero" title="Permanent link">âš“ï¸</a></h3>
<p>ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œæ¼”ç¤ºäº†åœ¨æ— æ³•å°†æ¨¡å‹æ”¾å…¥å•ä¸ª GPU æ—¶å¦‚æœä¸ä½¿ç”¨[Trainer]è¿›è¡Œ DeepSpeed ZeRO æ¨ç† ã€‚è¯¥è§£å†³æ–¹æ¡ˆåŒ…æ‹¬ä½¿ç”¨é¢å¤–çš„ GPU æˆ–/å’Œå°† GPU å†…å­˜å¸è½½åˆ° CPU å†…å­˜ã€‚</p>
<p>è¿™é‡Œè¦ç†è§£çš„é‡è¦ç»†å¾®å·®åˆ«æ˜¯ï¼ŒZeROçš„è®¾è®¡æ–¹å¼å¯ä»¥è®©æ‚¨åœ¨ä¸åŒçš„GPUä¸Šå¹¶è¡Œå¤„ç†ä¸åŒçš„è¾“å…¥ã€‚</p>
<p>è¿™ä¸ªä¾‹å­æœ‰å¾ˆå¤šæ³¨é‡Šï¼Œå¹¶ä¸”æ˜¯è‡ªæ–‡æ¡£åŒ–çš„ã€‚</p>
<p>è¯·ç¡®ä¿ï¼š</p>
<ol>
<li>å¦‚æœæ‚¨æœ‰è¶³å¤Ÿçš„GPUå†…å­˜ï¼ˆå› ä¸ºè¿™ä¼šå‡æ…¢é€Ÿåº¦ï¼‰ï¼Œç¦ç”¨CPU offloadã€‚</li>
<li>å¦‚æœæ‚¨æ‹¥æœ‰Ampereæ¶æ„æˆ–æ›´æ–°çš„GPUï¼Œå¯ç”¨bf16ä»¥åŠ å¿«é€Ÿåº¦ã€‚å¦‚æœæ‚¨æ²¡æœ‰è¿™ç§ç¡¬ä»¶ï¼Œåªè¦ä¸ä½¿ç”¨ä»»ä½•åœ¨bf16æ··åˆç²¾åº¦ä¸‹é¢„è®­ç»ƒçš„æ¨¡å‹ï¼ˆå¦‚å¤§å¤šæ•°t5æ¨¡å‹ï¼‰ï¼Œå°±å¯ä»¥å¯ç”¨fp16ã€‚å¦åˆ™è¿™äº›æ¨¡å‹é€šå¸¸åœ¨fp16ä¸­æº¢å‡ºï¼Œæ‚¨ä¼šçœ‹åˆ°è¾“å‡ºæ— æ•ˆç»“æœã€‚</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="ch">#!/usr/bin/env python</span>

<span class="c1"># This script demonstrates how to use Deepspeed ZeRO in an inference mode when one can&#39;t fit a model</span>
<span class="c1"># into a single GPU</span>
<span class="c1">#</span>
<span class="c1"># 1. Use 1 GPU with CPU offload</span>
<span class="c1"># 2. Or use multiple GPUs instead</span>
<span class="c1">#</span>
<span class="c1"># First you need to install deepspeed: pip install deepspeed</span>
<span class="c1">#</span>
<span class="c1"># Here we use a 3B &quot;bigscience/T0_3B&quot; model which needs about 15GB GPU RAM - so 1 largish or 2</span>
<span class="c1"># small GPUs can handle it. or 1 small GPU and a lot of CPU memory.</span>
<span class="c1">#</span>
<span class="c1"># To use a larger model like &quot;bigscience/T0&quot; which needs about 50GB, unless you have an 80GB GPU -</span>
<span class="c1"># you will need 2-4 gpus. And then you can adapt the script to handle more gpus if you want to</span>
<span class="c1"># process multiple inputs at once.</span>
<span class="c1">#</span>
<span class="c1"># The provided deepspeed config also activates CPU memory offloading, so chances are that if you</span>
<span class="c1"># have a lot of available CPU memory and you don&#39;t mind a slowdown you should be able to load a</span>
<span class="c1"># model that doesn&#39;t normally fit into a single GPU. If you have enough GPU memory the program will</span>
<span class="c1"># run faster if you don&#39;t want offload to CPU - so disable that section then.</span>
<span class="c1">#</span>
<span class="c1"># To deploy on 1 gpu:</span>
<span class="c1">#</span>
<span class="c1"># deepspeed --num_gpus 1 t0.py</span>
<span class="c1"># or:</span>
<span class="c1"># python -m torch.distributed.run --nproc_per_node=1 t0.py</span>
<span class="c1">#</span>
<span class="c1"># To deploy on 2 gpus:</span>
<span class="c1">#</span>
<span class="c1"># deepspeed --num_gpus 2 t0.py</span>
<span class="c1"># or:</span>
<span class="c1"># python -m torch.distributed.run --nproc_per_node=2 t0.py</span>


<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoConfig</span><span class="p">,</span> <span class="n">AutoModelForSeq2SeqLM</span>
<span class="kn">from</span> <span class="nn">transformers.integrations</span> <span class="kn">import</span> <span class="n">HfDeepSpeedConfig</span>
<span class="kn">import</span> <span class="nn">deepspeed</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TOKENIZERS_PARALLELISM&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;false&quot;</span>  <span class="c1"># To avoid warnings about parallelism in tokenizers</span>

<span class="c1"># distributed setup</span>
<span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">))</span>
<span class="n">world_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">))</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">local_rank</span><span class="p">)</span>
<span class="n">deepspeed</span><span class="o">.</span><span class="n">init_distributed</span><span class="p">()</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;bigscience/T0_3B&quot;</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">model_hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">d_model</span>

<span class="c1"># batch size has to be divisible by world_size, but can be bigger than world_size</span>
<span class="n">train_batch_size</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">world_size</span>

<span class="c1"># ds_config notes</span>
<span class="c1">#</span>
<span class="c1"># - enable bf16 if you use Ampere or higher GPU - this will run in mixed precision and will be</span>
<span class="c1"># faster.</span>
<span class="c1">#</span>
<span class="c1"># - for older GPUs you can enable fp16, but it&#39;ll only work for non-bf16 pretrained models - e.g.</span>
<span class="c1"># all official t5 models are bf16-pretrained</span>
<span class="c1">#</span>
<span class="c1"># - set offload_param.device to &quot;none&quot; or completely remove the `offload_param` section if you don&#39;t</span>
<span class="c1"># - want CPU offload</span>
<span class="c1">#</span>
<span class="c1"># - if using `offload_param` you can manually finetune stage3_param_persistence_threshold to control</span>
<span class="c1"># - which params should remain on gpus - the larger the value the smaller the offload size</span>
<span class="c1">#</span>
<span class="c1"># For indepth info on Deepspeed config see</span>
<span class="c1"># https://huggingface.co/docs/transformers/main/main_classes/deepspeed</span>

<span class="c1"># keeping the same format as json for consistency, except it uses lower case for true/false</span>
<span class="c1"># fmt: off</span>
<span class="n">ds_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;fp16&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;enabled&quot;</span><span class="p">:</span> <span class="kc">False</span>
    <span class="p">},</span>
    <span class="s2">&quot;bf16&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;enabled&quot;</span><span class="p">:</span> <span class="kc">False</span>
    <span class="p">},</span>
    <span class="s2">&quot;zero_optimization&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;stage&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s2">&quot;offload_param&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">},</span>
        <span class="s2">&quot;overlap_comm&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;contiguous_gradients&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;reduce_bucket_size&quot;</span><span class="p">:</span> <span class="n">model_hidden_size</span> <span class="o">*</span> <span class="n">model_hidden_size</span><span class="p">,</span>
        <span class="s2">&quot;stage3_prefetch_bucket_size&quot;</span><span class="p">:</span> <span class="mf">0.9</span> <span class="o">*</span> <span class="n">model_hidden_size</span> <span class="o">*</span> <span class="n">model_hidden_size</span><span class="p">,</span>
        <span class="s2">&quot;stage3_param_persistence_threshold&quot;</span><span class="p">:</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">model_hidden_size</span>
    <span class="p">},</span>
    <span class="s2">&quot;steps_per_print&quot;</span><span class="p">:</span> <span class="mi">2000</span><span class="p">,</span>
    <span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="n">train_batch_size</span><span class="p">,</span>
    <span class="s2">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;wall_clock_breakdown&quot;</span><span class="p">:</span> <span class="kc">False</span>
<span class="p">}</span>
<span class="c1"># fmt: on</span>

<span class="c1"># next line instructs transformers to partition the model directly over multiple gpus using</span>
<span class="c1"># deepspeed.zero.Init when model&#39;s `from_pretrained` method is called.</span>
<span class="c1">#</span>
<span class="c1"># **it has to be run before loading the model AutoModelForSeq2SeqLM.from_pretrained(model_name)**</span>
<span class="c1">#</span>
<span class="c1"># otherwise the model will first be loaded normally and only partitioned at forward time which is</span>
<span class="c1"># less efficient and when there is little CPU RAM may fail</span>
<span class="n">dschf</span> <span class="o">=</span> <span class="n">HfDeepSpeedConfig</span><span class="p">(</span><span class="n">ds_config</span><span class="p">)</span>  <span class="c1"># keep this object alive</span>

<span class="c1"># now a model can be loaded.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="c1"># initialise Deepspeed ZeRO and store only the engine object</span>
<span class="n">ds_engine</span> <span class="o">=</span> <span class="n">deepspeed</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">config_params</span><span class="o">=</span><span class="n">ds_config</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ds_engine</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># inference</span>

<span class="c1"># Deepspeed ZeRO can process unrelated inputs on each GPU. So for 2 gpus you process 2 inputs at once.</span>
<span class="c1"># If you use more GPUs adjust for more.</span>
<span class="c1"># And of course if you have just one input to process you then need to pass the same string to both gpus</span>
<span class="c1"># If you use only one GPU, then you will have only rank 0.</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">text_in</span> <span class="o">=</span> <span class="s2">&quot;Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy&quot;</span>
<span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">text_in</span> <span class="o">=</span> <span class="s2">&quot;Is this review positive or negative? Review: this is the worst restaurant ever&quot;</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text_in</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">local_rank</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">ds_engine</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">synced_gpus</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">text_out</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;rank</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">   in=</span><span class="si">{</span><span class="n">text_in</span><span class="si">}</span><span class="se">\n</span><span class="s2">  out=</span><span class="si">{</span><span class="n">text_out</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<p>è®©æˆ‘ä»¬ä¿å­˜å®ƒä¸º <code>t0.py</code>å¹¶è¿è¡Œï¼š
<div class="highlight"><pre><span></span><code>$ deepspeed --num_gpus 2 t0.py
rank0:
   in=Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy
  out=Positive
rank1:
   in=Is this review positive or negative? Review: this is the worst restaurant ever
  out=negative
</code></pre></div></p>
<p>è¿™æ˜¯ä¸€ä¸ªéå¸¸åŸºæœ¬çš„ä¾‹å­ï¼Œæ‚¨éœ€è¦æ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œä¿®æ”¹ã€‚</p>
<h3 id="generate"><code>generate</code> çš„å·®å¼‚<a class="headerlink" href="#generate" title="Permanent link">âš“ï¸</a></h3>
<p>åœ¨ä½¿ç”¨ZeRO stage 3çš„å¤šGPUæ—¶ï¼Œéœ€è¦é€šè¿‡è°ƒç”¨<code>generate(..., synced_gpus=True)</code>æ¥åŒæ­¥GPUã€‚å¦‚æœä¸€ä¸ªGPUåœ¨å…¶å®ƒGPUä¹‹å‰å®Œæˆç”Ÿæˆï¼Œæ•´ä¸ªç³»ç»Ÿå°†æŒ‚èµ·ï¼Œå› ä¸ºå…¶ä»–GPUæ— æ³•ä»åœæ­¢ç”Ÿæˆçš„GPUæ¥æ”¶æƒé‡åˆ†ç‰‡ã€‚</p>
<p>ä»<code>transformers&gt;=4.28</code>å¼€å§‹ï¼Œå¦‚æœæ²¡æœ‰æ˜ç¡®æŒ‡å®š<code>synced_gpus</code>ï¼Œæ£€æµ‹åˆ°è¿™äº›æ¡ä»¶åå®ƒå°†è‡ªåŠ¨è®¾ç½®ä¸º<code>True</code>ã€‚ä½†å¦‚æœæ‚¨éœ€è¦è¦†ç›–<code>synced_gpus</code>çš„å€¼ï¼Œä»ç„¶å¯ä»¥è¿™æ ·åšã€‚</p>
<h2 id="deepspeed_3">æµ‹è¯• DeepSpeed é›†æˆ<a class="headerlink" href="#deepspeed_3" title="Permanent link">âš“ï¸</a></h2>
<p>å¦‚æœæ‚¨æäº¤äº†ä¸€ä¸ªæ¶‰åŠDeepSpeedé›†æˆçš„PRï¼Œè¯·æ³¨æ„æˆ‘ä»¬çš„CircleCI PR CIè®¾ç½®æ²¡æœ‰GPUï¼Œå› æ­¤æˆ‘ä»¬åªåœ¨å¦ä¸€ä¸ªCIå¤œé—´è¿è¡Œéœ€è¦GPUçš„æµ‹è¯•ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨åœ¨PRä¸­è·å¾—ç»¿è‰²çš„CIæŠ¥å‘Šï¼Œå¹¶ä¸æ„å‘³ç€DeepSpeedæµ‹è¯•é€šè¿‡ã€‚</p>
<p>è¦è¿è¡ŒDeepSpeedæµ‹è¯•ï¼Œè¯·è‡³å°‘è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š</p>
<div class="highlight"><pre><span></span><code>RUN_SLOW=1 pytest tests/deepspeed/test_deepspeed.py
</code></pre></div>
<p>å¦‚æœä½ æ›´æ”¹äº†ä»»ä½•æ¨¡å‹æˆ–PyTorchç¤ºä¾‹ä»£ç ï¼Œè¯·åŒæ—¶è¿è¡Œå¤šæ¨¡å‹æµ‹è¯•ã€‚ä»¥ä¸‹å°†è¿è¡Œæ‰€æœ‰DeepSpeedæµ‹è¯•ï¼š</p>
<div class="highlight"><pre><span></span><code>RUN_SLOW=1 pytest tests/deepspeed
</code></pre></div>
<h2 id="deepspeed_4">ä¸»è¦çš„DeepSpeedèµ„æº<a class="headerlink" href="#deepspeed_4" title="Permanent link">âš“ï¸</a></h2>
<ul>
<li><a href="https://github.com/microsoft/deepspeed">é¡¹ç›®GitHub</a></li>
<li><a href="https://www.deepspeed.ai/getting-started/">ä½¿ç”¨æ–‡æ¡£</a></li>
<li><a href="https://deepspeed.readthedocs.io/en/latest/index.html">APIæ–‡æ¡£</a></li>
<li><a href="https://www.microsoft.com/en-us/research/search/?q=deepspeed">åšå®¢æ–‡ç« </a></li>
</ul>
<p>è®ºæ–‡:</p>
<ul>
<li><a href="https://arxiv.org/abs/1910.02054">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></li>
<li><a href="https://arxiv.org/abs/2101.06840">ZeRO-Offload: Democratizing Billion-Scale Model Training</a></li>
<li><a href="https://arxiv.org/abs/2104.07857">ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a></li>
</ul>
<p>æœ€åï¼Œè¯·è®°ä½ï¼ŒHuggingFace [<code>Trainer</code>]ä»…é›†æˆäº†DeepSpeedï¼Œå› æ­¤å¦‚æœæ‚¨åœ¨ä½¿ç”¨DeepSpeedæ—¶é‡åˆ°ä»»ä½•é—®é¢˜æˆ–ç–‘é—®ï¼Œè¯·åœ¨<a href="https://github.com/microsoft/DeepSpeed/issues">DeepSpeed GitHub</a>ä¸Šæäº¤ä¸€ä¸ªissueã€‚</p>

  <hr>
<div class="md-source-file">
  <small>
    
      æœ€åæ›´æ–°:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        åˆ›å»ºæ—¥æœŸ:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  å›åˆ°é¡µé¢é¡¶éƒ¨
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="é¡µè„š" >
        
          
          <a href="../../4-%E6%A6%82%E5%BF%B5%E6%8C%87%E5%8D%97/task_summary/" class="md-footer__link md-footer__link--prev" aria-label="ä¸Šä¸€é¡µ: Task summary">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                ä¸Šä¸€é¡µ
              </span>
              <div class="md-ellipsis">
                Task summary
              </div>
            </div>
          </a>
        
        
          
          <a href="../model/" class="md-footer__link md-footer__link--next" aria-label="ä¸‹ä¸€é¡µ: Model">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                ä¸‹ä¸€é¡µ
              </span>
              <div class="md-ellipsis">
                Model
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="githubä¸»é¡µ" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="bç«™ä¸»é¡µ" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="ä¸ªäººä¸»é¡µ" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>